J/  PRODUCTION IN PROTON-PROTON COLLISIONS AT ALICE
J/ production in proton-proton
collisions at alice
Ravjeet Kour
Thesis submitted for the degree of
Doctor of Philosophy
Particle Physics Group,
School of Physics and Astronomy,
The University of Birmingham.
May, 2011.
University of Birmingham Research Archive 
e-theses repository 
This unpublished thesis/dissertation is copyright of the author and/or third 
parties. The intellectual property rights of the author or third parties in respect 
of this work are as defined by The Copyright Designs and Patents Act 1988 or 
as modified by any successor legislation.   
Any use made of information contained in this thesis/dissertation must be in 
accordance with that legislation and must be properly acknowledged.  Further 
distribution or reproduction in any format is prohibited without the permission 
of the copyright holder.  
Abstract
A Large Ion Collider Experiment (ALICE) studies the strong interaction part
(Quantum Chromo Dynamics) of the Standard Model at the CERN Large Hadron
Collider. ALICE has been designed as a general-purpose heavy-ion detector in order
to explore phenomena of strong interacting matter and the quark-gluon plasma
(QGP) at extreme values of energy density and temperature in nucleus-nucleus
collisions.
Results are presented here on the study of J/ production in pp collisions at
ALICE. In particular, a measurement of J/ cross-section at
s = 7 TeV energy has
been performed, together with a study of a possible algorithm to separate primary
J/ from those coming from decays of B hadrons. The validity of this algorithm in
ALICE has been demonstrated using Monte-Carlo samples. The J/ particles have
been searched exclusively in the decay channel J/  e+e. The study focused on
what would be achievable in a period of early running, with integrated luminosity
of L = 1.25 nb1, at a proton-proton centre of mass collision energy of
s = 7 TeV.
Authors contribution
All the work presented in this thesis, related to the analysis of J/ production
in pp collisions at
s = 7 TeV, performed on real and simulated data, is my own.
The software designed in order to carry out the study was written by myself; I have
developed the analysis and optimised the signal selection and background rejection;
and I have performed the cross section measurement and the study of the primary
versus secondary J/ separation.
However, the analysis makes use of the ALICE analysis software framework
(AliRoot), available to all within the collaboration. In addition, the majority of the
simulated data sample was produced centrally during the so-called Data Challenge
production 2010 ; and the real data were taken by the ALICE collaboration during
2010 and are distributed over the LHC computing grid.
Ravjeet Kour
Acknowledgements
I would like to take this opportunity to acknowledge all my friends, colleagues
and family who have supported and encouraged me during the time of my PhD. I
truly have been looking for this moment to come, so that I can give thanks to so
many people with whom I have been through all this time.
Birmingham ALICE group: My acknowledgement begins by giving a big
thanks to my supervisors Dr. Cristina Lazzeroni and Dr. Roman Lietava for all the
help and support they have given me throughout my PhD. I would not have been
at this point without them. Both of them were extremely benevolent with their
time throughout the course of my PhD. I would like to thank Cristina for always
giving me valuable advice be it in professional or personal matters. I think she has
the solution for every problem. I also would like to thank Roman from my heart
who has helped me many times to carry out the research and make this a complete
thesis.
I would like to thank the other people in the group in Birmingham: Dr. David
Evans, Dr Orlando Villalobos Baillie, Dr. Gron Jones, Dr. Peter Jones, Dr. Lee
Barnby, Dr. Pedja Jovanovic (hope he is enjoying his retirement life), Mr. Anton
Jusko, Dr. Marian Krivda, Prof. John Kinson, and Dr. Frank Votruba. Thanks
Lee for helping me on the Grid problems. I would like to thank all the present and
post ALICE students in particular J.D. Tapia Takaki, Sparsh Navin, Zoe Matthews,
Arvinder Palaha, Plamen Petrov and Patrick Scott.
Special thanks to Orlando and David for proof reading my thesis and making it
finish on time.
Birmingham Particle Physics group: I would like to pay my thanks to Prof.
Peter Watkins and Prof. Paul Newman for offering me a place in the Birmingham
group. Prof. Paul Newman helped me in applying for the scholarship, I think
without his advice it would have been difficult to receive the scholarship. A very
special thanks to Ms. Norma Simpson for being so kind and patient in dealing with
me in the admission process. Thanks for giving me the letters I needed for my visa
purposes. I really wish her good luck for her retirement life. I should not forget Dr.
Lawrie Lowe, for being so helpful in giving the computing support throughout my
PhD. Also last not but not least I should thank Prof. Raymund Jones who gave me
the teaching duties for the last three years. It was really helpful as my scholarship
was over by October 2010. Thanks for the teaching experience in this University.
I would like to thank the UK Overseas Research Student Award Scheme (OR-
SAS), the University of Birmingham who completely funded my PhD studies.
ALICE collaboration and colleagues: I feel good in myself that I have
worked for ALICE collaboration within the CERNs Large Hadron Collider project.
I would like to give a big thanks to Dr. Giuseppe Bruno who at first point, directed
me towards the analysis which I have presented in this thesis. Thanks Giussepe
for inviting me to Italy in his university to undertake my analysis. Also big thanks
for the lovely dinner which I had at your place. Special thanks to your wife who
prepared the delicious dinner. It was a great experience. Also thanks to Carmelo
Digiglio for discussing the J/ analysis. I would also like to thank Dr. Renu Bala for
helping me to understand some features of Alien. Thanks to Dr. Marek Bombara for
proof reading my mid-term report. Thanks for solving some of the software issues.
Also a person who truly deserves a very special thank giving is Prof. Anju
Bhasin. She inspired me to pursue my PhD after my Masters. She has always been
so kind for so many years. She is not just my teacher but also a good friend who
has always given me true advice in my personal and career front matters. She really
helped me during admission and scholarship application. Thanks to her for proof
reading my thesis.
People I cannot forget to thank: There are so many people I feel I have to
thank them for this journey. Coming from India and adjusting into this life in UK
was a tough thing, but with all my friends around this was a made easy.
I would like to thank Miss Vinothini Sangaralingam for being a very good friend
of mine all the time. Although I have not learnt south Indian food from her, but
have definitely enjoyed so many times the same. Thanks Vino for taking my teaching
in the need of emergency. Also thanks to Sathish for bringing the medicine so late
in the night when I had a fever. Thanks to Dr. Smriti Mahajan for being warm and
friendly and pouring good advice all the time.
I would like to thank my office mates: Sparsh Navin, Zoe Matthews, Arvinder
Palaha, Plamen Petrov and Patrick Scott. I wish I could have gone on LTA to spend
more time with you all. A big thanks to Arvinder and his parents for letting me
stay at their place. It really means a lot to me. Thanks Zoe for the sweet marriage
present. I should thank Angela Romano who substituted me a couple of times in
my teaching duties. Thanks for the lovely greeting that you gave to me.
I would like to thank my house mates: Dr. Yuvraj and Rashmi for the nice
company. Thanks Yuvraj for the nice cup of tea that you always make for us. I
cannot forget the shoe scandal for my entire life. Thanks Reshmi for good food that
I had so many times.
Thanks to all my colleagues from teaching with whom I have worked for the last
three years.
Thanks to all my friends in Bharat Parivaar, I throughly enjoyed all the events
I have participated in. It never gave me a feeling that I was out of India for such a
long time.
Special thanksgiving to the people that really matter in my life: On a
very personal basis, I would like to thank my family who have been a big support
during my PhD. A big thanks to my father who always had a big faith in me. Thanks
Dad. I cannot forget to give thanks to my eldest brother Mr. Manjeet Singh and
his wife Mrs. Kirndeep Kaur who have supported me in every aspect during my
stay in UK. Thanks to my other two brothers and their wives Mr. Bhopinder Singh,
Mr Loveleen Singh, Mrs Kamalpreet Kaur, Mrs Arminder Kaur for all the love
and moral support that they have provided me. Thanks to my younger sister Miss
Ravdeep for the moral support. I would like to thank my two sister-in-laws Dr.
Gurpreet Kaur and Dr. Amandeep Kaur and brother-in-law Dr. Surinderjeet Singh
for the moral support.
Special thanks to my husband Dr. Parminder Singh Sandhu for supporting and
encouraging me all the time. Thanks for proof reading although not being from a
physics background.
Last but not least, thanks to my parents Mr. Kirpal Singh, Mrs. Savtanter Kaur
and to my father-in-law Mr. Puran Singh Sandhu. This thesis is being dedicated to
you three.
Ravjeet Kour
Chapter 1
Introduction
It is believed that our universe originated in a Big Bang from a state of almost
infinite energy density and temperature. During the first few microseconds of its life
the energy density in our universe was so high that hadrons (colour singlet bound
states of quarks, antiquarks and gluons), such as the nucleons inside a nucleus, could
not form. Instead, quarks, antiquarks and gluons were deconfined and permeated
the entire universe in a thermalized state known as a Quark-Gluon Plasma (QGP).
Only when the energy density of the universe dropped below the critical value, about
1 GeV/fm3, equivalent to temperature 170 MeV, did the colour degree of freedom
become confined into colour singlet objects of approximately 1 fm diameter: the
first hadrons formed.
Understanding the properties of elementary particles at high temperature and
density is one of the major goals of particle physics. Through a study of the proper-
ties of elementary particles, formed from such extreme conditions, we hope to learn
about the equation of state that controlled the evolution of the early universe and
perhaps the structure of compact stars. The ALICE (A Large Ion Collider Exper-
iment) [1] experiment is devoted to the study of hot and dense matter created in
ultra relativistic heavy ion collisions.
1.1 Quantum Chromodynamics
1.1.1 Introduction
Quantum Chromodynamics [2] QCD is the theory of the strong force, one of the four
forces of nature. It describes the interactions of quarks, via their colour quantum
numbers. QCD calculations indicate that the potential between two heavy quarks
is of the form shown in equation 1.1 ( more details in chapter 2)
V (r) =
(r)
+ r. (1.1)
where r is the distance between the quarks,  is the coupling constant of coulomb
like term and  is the string constant.
For small r, the first term dominates and the system behaves similarly to the
electrodynamic case. At larger r, the potential energy of two quarks increases with
separation until enough energy is present to form a new quark-antiquark pair, which
occurs if the quarks are separated. As a result, quarks are never observed individ-
ually but always as part of a 3 quark state (baryon) or a quark-antiquark state
(meson). This property is known as confinement.
As r becomes small, however, this behaviour deviates from the simple models
for QED and QCD. In quantum field theory, an electron can emit a virtual photon
which can become a electron-positron pair. Therefore, an electron will spontaneously
become surrounded by a cloud of virtual e+e pairs. The charge on the original
electron will polarise this cloud, attracting the positrons. A probe far away will see
the actual charge, whereas a close probe sees a larger charge due to the effect of the
cloud. A similar, but opposite, effect occurs in the strong interaction. A probe close
to the colour charge will see a lower colour charge than a probe far away. In the
limit of zero separation, the charge appears to be zero. This is known as asymptotic
freedom.
1.1.2 Asymptotic freedom and confinement
The theory of asymptotic freedom states that the interaction between quarks reduces
as the distance between them reduces, and tends to zero as the distance between
them reduces to zero. Conversely, the interaction between them increases as they
are separated by larger distances.
Colour confinement is the physics phenomenon that colour charged particles
(such as quarks) cannot be isolated, and therefore cannot be directly observed.
Quarks, by default, clump together to form two types of hadrons ( the mesons and
the baryons, composed of quark and antiquark and three quarks respectively). The
constituent quarks in a group cannot be separated from their parent hadron, and
this is why quarks can never be studied or observed in any more direct way than at
a hadron level.
The reasons for quark confinement are somewhat complicated; there is no ana-
lytic proof that quantum chromodynamics should be confining, but intuitively con-
finement is due to the force-carrying gluons having colour charge. One can compare
the electromagnetic interaction with the strong interaction. As any two electrically-
charged particles separate, the electric fields between them diminish quickly, allowing
(for example) electrons to become unbound from nuclei. However, as two quarks
separate, the gluon fields form narrow tubes (or strings) of colour charge, which tend
to bring the quarks together as though they were some kind of rubber band. This is
quite different in behaviour from electrical charges. Because of this behaviour, the
colour force experienced by the quarks in the direction that holds them together,
remains constant, regardless of their distance from each other.
1.2 Heavy Ion collisions
If a nucleus is compressed enough, it would experience a change of state. The
standard combination of quarks inside particles would break down as a completely
different state and matter - a plasma of free quarks and gluons would be created,
which is known as a Quark Gluon Plasma.
1.2.1 Quark Gluon Plasma
Nuclear matter at normal energy densities is composed of protons and neutrons. If
the energy density is increased the protons, nucleons, and other particles overlap
and get squeezed so tightly that their constituents (quarks and gluons) are free to
roam the system without being confined inside hadrons. At this density, there is
deconfinement and the system becomes a quark-gluon plasma. Thus, relativistic
heavy ion collisions provide a possible way for creating QGP in the laboratory. The
QGP existed during the time of Big-Bang and is formed at energy densities of the
order 1 GeV/fm3. It has also been suggested that matter at such a density may
exist inside the cores of neutron stars [3].
1.2.2 Space Time Evolution in Relativistic Heavy Ion Col-
lisions
The space - time evolution of a head on Collision at high energy is shown in figure
1.1. In the first moments of a reaction, hard scattering processes on the parton level
may occur. These rates can be studied using structure functions and perturbative
QCD cross-sections.
After a short time, usually taken to be  1 fm/c, partons materialise out of
the highly excited QCD field. Thermal equilibrium may now be approached via
individual parton-parton or string-string interactions. A calculation of the mean
free path of quarks in QCD matter gives a value of  = 0.5 fm at an energy density
E = 2 GeV/fm3 [4], indicating that equilibrium may indeed be reached in collisions
of heavy nuclei where the transverse radii, and hence initial dimensions, are clearly
larger than .
As the system expands, mainly along the longitudinal direction as it is co-related
to the original ion motion, its energy density and temperature decreases until it
reaches a critical temperature Tc after 30 fm/c. Potentially, the matter now spends
a relative long time in the mixed phase. It has to rearrange the many degrees
of freedom (partons) of QGP into the smaller number available in the hadronic
phase, with a large associated release of latent heat. In the last and hadronic phase,
the interacting systems keep expanding. It may expand, until freeze out, when
interactions cease and the particles stream away to be detected by the experimental
apparatus.
(distance transverse
to the collision axis)
Transverse 
expansion at about 
half the light velocity
(distance along
the collision axis)
Pb Pb
Projectile and
Target Nuclei
Deconfined
Quark Gluon
Matter
Hot Hadron
Resonance
Free streaming
Hadrons
T ~ 110 MeV
 ~ 0.05 GeV/fm3
T ~ 175 MeV
 ~ 1 GeV/fm3
T ~ 230 MeV
 ~ 3 GeV/fm3
T = 0 MeV
 = 0.17 GeV/fm3
Chemical
Freeze-out
Thermal
Freeze-out
Figure 1.1: Space time evolution of a heavy-ion collision describing the chemical
freeze out (where the interactions changing particle species are stopped) and thermal
freeze out (where the mean free path is comparable to the size of the system).
1.3 Signals of Quark Gluon Plasma
In order to assess whether or not deconfined matter has been created, suitable sig-
natures are looked for. Some of the QGP signatures are strange particle production,
charmonium suppression, jet quenching, elliptic flow, electromagnetic signals like
direct photon and dilepton production [5].
Strangeness enhancement was one of the main pieces of evidence for CERNs
claim to have produced deconfined matter in 2000 [6] [7]. If a QGP phase was
formed in nucleus-nucleus collisions, the yield of strange particles produced, such as
those that contain one or more strange quarks or antiquarks, is expected to increase
compared to a non-QGP scenario. In other words, the density of strange quark pairs
is predicted to be unusually high compared to that for a hadron gas phase [8].
It was also predicted that the J/ meson should be suppressed if a QGP state
was formed at SPS energies [9] [10]. Because the mass of the charm quark is ten times
greater than that of the strange quark, at SPS energies, charm (and bottom) quarks
can be seen as particles exclusively produced during the early stages of the collision
through high energy hard interactions. The high abundances of quark-antiquark
pairs and gluons produced in the de-confined state would screen the heavy quarks
by surrounding qq pairs, which leads to the break up of J/ in quark medium. At
Large Hadron Collider energies, in particular in Pb-Pb collisions, cc and bb will be
produced abundantly. Quarkonia [5] will probe the medium created in a collision.
The production of quarkonia is described well by pQCD ( more details in next
chapter). Due to Debye screening the produced state is split up depending upon
the temperature of the surrounding medium. More details of why J/ is used as a
probe will be given in chapter 2.
The RHIC experiments [11] have confirmed that information about the QGP
can be revealed by studying the regime of high transverse momentum particles
[12, 13, 14, 15]. Jets of hadrons are formed from the initial hard scattered partons,
which are thought to be modified when they traverse the medium in the QGP phase
[16].
Another tool to study the QGP is to examine electromagnetically interacting
probes which have already decoupled from the hot coloured phase of the matter.
Direct photon and lepton pairs are such observables. They emerge as thermal radi-
ation from the heated matter without being altered by the final states so bringing
information about the temperature of the system.
Chapter 2
J/ measurement in heavy ion
collisions
2.1 Introduction
Strongly interacting matter, at sufficiently high density, is predicted to undergo
a transition to a state of deconfined quarks and gluons. In such a state colour
screening shields a given quark from the binding potential of any other quarks or
antiquarks. Bound states of very heavy quarks, such as J/ or , have radii which
are smaller than those of the usual mesons and nucleons : hence they can survive
in the deconfined medium until the temperature or density become so high that
screening dissolves their tighter binding (see figure 2.1) J/ suppression appears as
a signal for Quark Gluon Plasma formation.
The J/ system is a meson resonance which consists of a c and c quark. It has a
mass of about 3.097 GeV (in natural units with c=1). The PDG value corresponds
to 3096.9160.011 MeV [98]
This chapter is divided into two sections. The first half describes the mechanism
of J/ production and the effect of coloured medium on J/ production. Second
half gives the summary of results on J/ production from previous experiments.
2.1.1 Discovery of the J/
In November 1974 a narrow resonance at 3.1 GeV/c2 in the e+e invariant mass
spectrum was observed [17] at the Brookhaven alternating gradient synchrotron
(AGS) in collisions of 28 GeV/c protons on a Beryllium target and in electron-
positron collisions at Stanford Linear Accelerator Centre (SLAC), using the e+e
collider Standford Positron Electron Accelerating Ring (SPEAR) [18]. The particle
was named J/. At that time the known quarks were up, down and strange quarks.
In addition a fourth quark was predicted by the Glashow-Iliopoulos-Maiani (GIM)
[19] mechanism. Soon after the discovery it was evident that the newly discovered
particle consisted of the predicted quark species, the charm quark. Thus this dis-
covery added a new particle to the fundamental building blocks of nature. Another
sharp resonance peak in the dimuon1 spectrum was later discovered in 400 GeV
proton-nucleus collisions in 1977 at Fermilab. [20], the . The  is the bound state
of bb quarks. The heaviest of all the quarks, the top quark, was discovered in 1995
1The dimuon spectrum denotes the invariant mass spectrum of muon anti-muon pairs. In
general a combination of two leptons is called dilepton.
[21]. This discovery formed the quark family. Up(u), down(d) and strange(s) quarks
are called the light quarks, while the charm(c), bottom(b) and top(t) are referred to
as heavy quarks. Bound states of these heavy quarks with their corresponding anti-
particles are called quarkonia. The top quark cannot form a bound state because of
its short lifetime of less than 1024s.
Given the mass of the charm quark of 1.3 GeV/c2 and the QCD coupling constant
QCD = 0.3, the system can be studied in a non-relativistic approach starting from
the Schrodinger equation for the charm anti-charm system
(2mc 
2 +V (r))i(r) =Mii(r) (2.1)
where i and Mi is the system wave-function and mass respectively with a binding
potential
V (r) = r 
(2.2)
where mc is the charm mass, r is the distance between the quarks,  is the coupling
constant of coulomb like term /r,   QCD and  is the string constant estimated
as 0.16 GeV2.
This so-called Cornell potential was proposed in papers [22][23]. It consists of
a linear term accounting for the specific feature of QCD that the potential energy
increases with increasing distance. The charmonium spectrum is well described by
the Schrodinger equation (2.1). One can use the uncertainty principle that the
product of uncertainity in the position and moomentum is approximately equal to
1 i.e. r.p  1 to estimate the energy of the bound state :
E(r)  2mc +
+ r 
(2.3)
Minimising E(r) with respect to r gives the radius of the ground state :
dE(r0)
= 0 = 
+  +
(2.4)
With QCD (coupling constant of coulomb like term) = 0.3 and  (string constant)
= 0.16 GeV2 and the charm mass mc = 1.3 GeV/c
2, one can obtain the radius of the
ground state r0 = 0.36 fm. With this radius the mass of the ground state is calculated
as M0 = E(r0) = 2.95 GeV/c
2, close to the measured mass of 3.096 GeV/c2. Table
2.1 shows the radius, mass, binding energy (E = 2mc - M0) and difference in
the theoretical and the measured mass (M) for the J/. The theoretical values
are obtained by solving the exact Schrodinger equation (2.1) [4] though having a
agreement with the uncertanity principle.
Table 2.1: Radius, mass, binding energy and M of J/ [4].
state J/
mass [GeV/c2] 3.10
E[GeV ] 0.64
radius [fm] 0.25
M [GeV/c2] 0.02
2.1.2 Why charmonium as a probe
There have been significant developments in the study of quarkonium production,
both in theory and experiment, and these developments have important implications
for the use of charmonium as a probe in heavy ion collisions. The charmonium states
are produced in abundance in heavy-ion collisions. The heavy nature of charmonium
(cc) allows one to apply potential models in non-relativistic quantum mechanics to
calculate the meson binding radius. It was predicted that the modification of the
heavy quark pair potential in the hot dense matter created in heavy ion collisions
would cause the pair to become uncorrelated due to colour charge screening. This
modification of the pair potential via Debye screening leads to charmonium suppres-
sion [24] when compared to a binary collision. 2
Due to the different binding energies for the different charmonium states, as
seen in figure 2.1, it is possible to gain access to the temperature of the medium.
Charmonium suppression in hot and dense matter has been considered to be a
signature for the production of the quark gluon plasma (QGP).
Figure 2.1: Different charmonium states corresponding to different temperature.
Some of the non-QGP factors leading to the suppression include shadowing of
the partons in a nuclear environment, breakup of a correlated c-c as it traverses
the nuclear fragment, suppression of feed-down from higher mass state as well as
2A binary collision is a collision between two nucleons. The nucleons in a heavy ion collision can
(and often do) collide more than once during the course of the nucleus-nucleus collision, hence for a
given process typical collision numbers are higher than the corresponding numbers of participating
nucleons
other initial state interactions. In order to disentangle these effects it is important
to measure the charmonium production rates in both proton+proton and proton
nucleus collisions. The p-p collisions serve as a baseline for searching for suppres-
sion compared to the binary scaling predictions, predicts the amount of feed-down
from higher states and serve as a tool to distinguish between different theoretical
calculations for charmonium production mechanisms. In order to quantify nuclear
effects it is also necessary to study charmonium production in prpton-nucleus col-
lisions where the temperature and density of the system are low compared to the
heavy ion collision.
2.1.3 J/ production
The charmonium production in proton-proton can be divided into two parts :
 Production of a heavy quark pair in hard collisions
 Formation of quarkonia out of the two heavy quarks
Due to the high mass of the heavy quarks (mcharm  1.3 GeV/c2, mbottom  4.7
GeV/c2) the first process can happen only during the first phase of a collision. Only
at that time can the elementary collisions with sufficiently high momentum transfers
to create such high masses take place. For this reason the heavy quark production
is called a hard process that can be treated perturbatively. In next-to-leading order
(NLO) calculations the available experimental data at different energies and collision
systems [25][26] are used to obtain parameters to predict the total cross-section in
proton-proton collisions at the LHC energies. The charm production cross- section
is predicted to be 6.3 mb and that of bottom is 0.19 mb [27].
The second part, namely the formation of quarkonia out of the quark-antiquark
pair, a priori cannot be treated perturbatively. Due to the high quark masses and
small relative velocities in the quarkonia system, the formation can be described
using non-relativistic QCD (NRQCD). This allows the factorisation into a pertur-
bative small range, high momentum part and a long range, low momentum part.
In the past, three models were developed, namely the Colour Singlet Model (CSM)
[28][29], the colour Octet Model (COM) [30][31][32] and the Colour Evaporation
Model (CEM) [33][34][35].
A quarkonium state has to be formed from two quarks that are colour neutral
but, in principle, the two heavy quarks are not necessarily carriers of one colour
and the corresponding anti-colour, so the combination might be coloured. The
colour singlet model rejects all colour octet states; in the NRQCD factorisation the
produced quarkonium state has the same quantum numbers as the quark-antiquark
pair. Predictions by the CSM for the production of the quarkonia at the Tevatron
underestimated the data by an order of magnitude. Thus it was clear that the colour
octet state cannot be neglected. Figure 2.2 shows J/ production mechanism as
described in the colour singlet model [36].
Figure 2.3 shows the cross-section for production of prompt charmonium in pp
collisions. Prompt means that the charmonium is produced by the QCD interaction
rather than by weak decays of hadrons containing bottom quarks. The cross-section
for prompt  production at the Tevatron has been measured by the CDF collabora-
Figure 2.2: J/ production as predicted by the colour singlet model in pp.
tion for the transverse momenta in range 5 < pT < 20 GeV/c [37]. The background
from decays of bottom hadrons and radiative decays were subtracted. In figure 2.3,
the dashed curve shows the leading-order predictions of the colour singlet model,
and the dotted line the predictions from fragmentation in the colour singlet model.
The measured cross-section was found to be about a factor of 30 larger than pre-
dicted by the colour-singlet model and hence there is the need to take into account
the colour octet model.
The colour octet model considers the octet state as well and within the model
quarkonia is produced in an octet 3 and thus coloured state. The pre-resonant
coloured state neutralises its colour by the emission of soft gluons [36] as seen in
figure 2.4. Though the colour octet model was able to reproduce the production
cross-section, it failed to describe the large transverse J/ polarisation [38] at inter-
mediate to large pT [39].
3The symmetry group of QCD is SU(3). In this group there are three colour triplet R, G, and
B and their corresponding descriptors R, G and B. Out of these one can form 3  3 = 8  1
combinations, which contain both the octet and the singlet state
Figure 2.3: CDF data on differential cross-section for prompt . The dashed curve
shows the leading-order predictions of the colour singlet model, and the dotted line
the predictions from fragmentation in the colour singlet model, while the solid line
is the prediction of the colour-octet mechanism, with the normalisation adjusted to
fit the data [37].
Figure 2.4: J/ production as predicted by the colour octet model in pp.
Due to the limitation of the COM, another model, the Color Evaporation Model
was developed. It included the evaporation of surplus colour via different processes
not by the the emission of a soft gluon. The large number of processes results in a
relatively large number of parameters, that have to be determined by comparison
to existing data. This large number of the parameters limits the predictive power
of the CEM. Nevertheless it is the best available approach to describe the available
measurements and it is used to predict the cross-section at the LHC energies.
In this approach the parameter sets matching the CDF data are taken to ex-
trapolate the cross-sections to a LHC energy of 14 TeV (pp) and 5.5 TeV/A (pp).
The resulting cross-sections are given in Table 2.2. The production cross-sections
include two effects:
 The expected feed down. Feed-down denotes the effect that the observed cross-
section of J/ is the composite of directly produced J/ and J/ originating
from the decay of heavier particles.
 Branching ratio into dielectrons.
Table 2.2: Prediction for J/ cross-sections at the LHC by the CEM. The cross-
section includes the branching ratio into electrons as well as feed down from higher
states. All the numbers are given in b [40].
system
s (TeV)  (J/) b
proton-proton 14 TeV 3.18
proton-proton 5.5 TeV 1.83
2.1.4 Behaviour of J/ in the hot matter
T. Matsui and H. Satz were the first to suggest that heavy quarkonia could be used
as a probe for the matter created in a heavy ion collision [9]. There are different
scenarios for the matter created. The first scenario revolves around the assumption
that the energy density is not sufficient to dissolve the hadrons contained in the
colliding nuclei. This is what is known as a hadron gas. The second scenario is that
of Quark-Gluon-Plasma, where the energy density is large enough for the hadrons
to be melted and results in a state of free quarks and gluons. The basic aim is to
find a probe which is sensitive to the surrounding material. Quarkonium production
measurement is one of the ideal probes for the following reasons :
 Due to the high masses heavy quarks are produced in the first stages of the col-
lision, such that the initial production is not affected by the produced medium.
 Due to the high decay probability into leptons, which have the property of
not interacting with the medium, they remain unchanged by the medium they
traverse
 Also they are highly sensitive on whether the surrounding medium consists of
deconfined matter or not, which is described below.
Since a hadron gas consists of hadrons and is thus colour neutral one would ex-
pect quarkonia to be produced in a comparable way as observed in proton-proton
or proton-nucleus collisions. The dominant interaction between produced quarkonia
and the medium would be scattering off nucleons and pions. These scattering pro-
cesses can lead to the dissociation of the quarkonium state. Since the cross-sections
of these processes are hardly known and also the theoretical predictions range from
0.1 to 8 mb, the effect of these processes has to be evaluated by comparison with col-
lisions of smaller systems and extrapolated to heavy-ion collisions. All these effects
are usually called Cold Nuclear Matter effects.
By taking into account, where the Quark-Gluon-Plasma is formed, that the
hadron melts and that a state of free quarks and gluons is formed, these particles
can move freely within a volume of few fm3. As this medium is not colour neutral, it
behaves as a colour conductor. Analogously to the screening of Coulomb potential
where the effect is called Debye screening (screening of the charges), the Cornell
potential (eq. 2.2) is modified to
V (r) = D(1 e
D )
D (2.5)
where D is the Debye screening radius and it depends upon the temperature of
the produced medium.
2.2 Results from Previous Experiments
The expected yields per central collision 4 of cc and bb at SPS, RHIC and LHC
are given in table 2.3. This yields are proportional to the amount of produced
quarkonia. The aim is to measure a suppression that can be interpreted as a result
of quarkonium dissociation in the deconfined medium. Most of the measurements
4The distance between the centres of the nuclei in the impact parameter plane (the more central
the smaller the impact parameter.
relate the quarkonium production to either the number of participants Npart or with
a parameter L, representing the length traversed from the parton collision point
through the nuclear matter. Both quantities can be determined via Glauber model
calculations [41] and reflect the volume of medium achieved in the collision. To
observe a deviation, a reference process defining the normal or expected behaviour
has to be chosen. Basically there are two different approaches for this reference
process:
 The first approach relates the observed quarkonia production to a differ-
ent process measured simultaneously. An example is the Drell-Yan process
(qq  l+l) as it is used as a reference at the SPS experiments. The Drell-Yan
process is a hard process, meaning that it includes large momentum transfers
of more than 1 GeV/c. The necessary momentum transfers takes place during
the first phases of the collision, thus the cross-section of the Drell-Yan process
is expected to scale with the number of initial binary collisions. Since the
Drell-Yan process is, in addition, expected not to be affected by a deconfined
medium, the ratio between the two processes will be constant if the charmo-
nium production is not affected by the medium. If charmonium production is
affected, the ratio is expected to decrease with increasing centrality.
 The second approach, followed at RHIC, reflects the general question as to
how the observations change when comparing binary proton-proton collisions
to the collision of two nuclei. A basic model would predict that the cross-
sections for hard processes of two colliding nuclei A and B can be described
as proton-proton cross-section. Models include the geometry of the colliding
nuclei and use the number of collisions as a scaling variable. For charmonium
production the nuclear modification factor is defined in equation(2.6)
RAA(c) =
Ninel
NAAJ/(c)
Nbinary(c)
(2.6)
where 
Ninel and 
are the total inelastic cross-section and the cross-section
for J/ production in pp collisions, respectively. NAAJ/(c) is the measured number
of J/ per A-A collisions at centrality c, and Nbinary(c) is the number of binary
collisions for the same centrality. By definition, if no nuclear modification, meaning
no medium effect, is present, one expects RAA = 1. Any deviation from one can
then be attributed to the produced medium.
The existing experimental status of J/ production is described in the following
sections. The measurements performed by the three fixed target experiments NA38
[42], NA50 [43] and NA60 [44] and the measurements of the collider experiment
PHENIX [45] are described along with the most prominent theoretical models and
their possible implications for the LHC.
Table 2.3: Number of heavy quark-anti-quark pairs per central collision (small im-
pact parameter) for SPS, RHIC and LHC energies
s=17 AGeV RHIC
s=200 AGeV LHC
s=5500 AGeV
Ncc 0.2 10 120
Nbb - 0.05 5
2.3 Results from the CERN SPS
2.3.1 Results from NA38
There has been a series of experiments at the SPS, starting with NA38 continuing
with NA50 and then NA60 over a fairly long period from 1986 until now.
The NA38 experiment consisted mainly of a muon spectrometer [46] : tracks
were deflected by a toroidal magnet, and reconstructed using two sets of four Multi
Wire Proportional Chambers(MWPCs). Muon pairs were detected in the pseudo
rapidity interval 2.8 <  < 4.0.
The first signal of the J/ suppression was observed in 1989 by the NA38 ex-
periment [42]. They examined oxygen-uranium collisions with an incident oxygen
beam energy of 200 GeV per nucleon, resulting in a collision energy of
s = 20
GeV per nucleon. Figure 2.5 shows the measured J/ yield normalised to number
of dimuons pairs in the mass region 2.7-3.5 Gev/c2 as a function of the measured
transverse energy as a measure of centrality. A similar pattern was observed later
in sulphur-uranium collisions [42]. With increasing centrality, the nuclear matter is
more compressed, and at some point a volume of deconfined matter forms, contain-
ing free colour charges. Due to these charges the charmonium binding potential is
screened, the bound state is dissolved and the measured J/ production decreases
with respect to the reference process.
Figure 2.5: The evolution of the ratio of produced J/ over produced Drell-Yan
dimuons pairs as a function of the transverse energy along with systematic , as
measured by NA38 [46]. Systematic error is included in error bars.
2.3.2 Results from NA50
NA50 was a high luminosity fixed target experiment, essentially dedicated to the
study of dimuon production in Pb-Pb collisions at 158 GeV per nucleon. The
NA50 apparatus was also used for the study of the p-A system. NA50 was the
upgraded version of the NA38 experiment for the study of Pb-Pb interactions at
158 GeV/nucleon. The main change was the introduction of a new target system
under vacuum [47], which allowed a better rejection of out-of-target interactions
and, in particular, of Pb-air interactions. Furthermore, in order to identify almost
simultaneous multiple interactions, a new method was developed based on the shape
analysis of the signal in the Electromagnetic Calorimeter. The setup is described in
detail in Ref. [43].
Figure 2.6 shows the comparison of the Pb-Pb results with lighter collision sys-
tems. The ratio of produced dimuons from J/ to dimuons from the Drell-Yan
process is shown as a function of the length L of traversed nuclear matter together
with the results obtained in S-U (NA38) and p-A (NA50) interactions. L is obtained
from Glauber model calculations [41] and is directly related to the centrality of the
collision. The model estimates the mean length L traversed by the J/ by assuming
that the J/ can be created anywhere along the length of the interaction volume
(assumed to be the intersection of two hard spheres). The solid line represents
the suppression obtained from proton-proton and proton-nucleus collisions. Thus
the line shows the amount of suppression due to nuclear absorption, that cannot
be related to dissociation due to deconfinement. A deviation is observed for L >
7.5 fm [48]. At this centrality the energy density is sufficiently high to create de-
confined matter, leading to dissociation of charmonium beyond the dissociation by
Figure 2.6: The J/ suppression pattern as measured by the NA50 experiment.The
solid line indicates the normal nuclear absorption as expected from comparison to
proton nucleus data. L is the length of traversed nuclear matter. Anomalous sup-
pression is observed for L >7.5 fm [48]. The measured data have been rescaled to
158 GeV/nucleon.
nucleon scattering. However an alternative description to this suppression can also
be made in terms of co-movers (hadrons move along the J/ with small relative
velocity, excite the nuclear medium and thus disrupt J/ )[49] that does not require
deconfinement.
2.3.3 Results from NA60
NA60 has been the last heavy ion experiment running at the SPS and performed a
measurement of dimuon production in p-A and In-In collisions. NA60 had a silicon
pixel detector to get a precise measurement of the interaction vertex. In addition a
vacuum target cell was added to suppress the beam gas interactions which could be
mistaken as peripheral collisions.
The suppression of charmonium states in nuclear collisions is considered as one of
the most powerful signatures of the production of a deconfined state [9]. However,
cold nuclear effects, and in particular the interaction of the projectile and target
nucleons with cc pair, sizeably contribute to the observed suppression [50]. Such
effects are usually studied in p-A collisions, then extrapolated to A-A collisions and
compared with the observed yield in nuclear collisions, as a function of centrality.
Figure 2.7 shows the results of nuclear effects on J/ production in p-A collisions
at 158 GeV and 400 GeV. In order to provide reference p-A data collected at the same
energy and kinematic domain. NA60 also studied J/ production in p-A collision
at 158 GeV. The incident beam, with an intensity of 5*108 protons/s, was incident
on various sub targets, with the mass ranging from 9 (Be) to 238 (U). The analysis
of the J/ production data at 158 GeV was performed in the rapidity domain
0.28 < ycm < 0.78, covered with reasonable acceptance by all the sub-targets, and
for rapidity range 0.17 < ycm < 0.33 for 400 GeV.
In Figure 2.7 [51] the y axis represents the cross-section ratios 
pA /
pBe for the
7 nuclear targets (Be, Al, Cu, In, W, Pb and U) with mass number A with respect to
lightest one (Be). This was done so that beam luminosity factors cancel out, apart
from a small beam attenuation factor. Along the x axis is L, the mean thickness of
the nuclear matter crossed by the cc pair in its way through the nucleus. The same
figure, shows the results of the same analysis, carried out on a data sample at 400
GeV. These results refer to the rapidity range -0.17 < ycm < 0.33, corresponding to
the same rapidity in the lab as 158 GeV. Performing a Glauber fit to the data, the
cross-section obtained for the NA60 p-A data is : 7.6  0.7 (stat.)  0.6 (syst.) mb
at 158 GeV and 4.3 0.8 (stat.) 0.6 (syst.) mb at 400 GeV. The J/ absorbtion
cross-section result at 400 GeV is smaller with respect to the one extracted from
the 158 GeV, pointing to an energy dependence of this quantity. The lower slope
corresponding to 158 GeV indicates that the nuclear effects are more important
when moving towards lower energy. Systematic errors include uncertainties on the
target thickness on the y distribution used in the acceptance calculation and on the
reconstruction efficeiency.
L (fm)
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
 / i)
Statistical errors
Systematic errors
400 GeV
158 GeV
Figure 2.7: J/ absorbtion cross-section as a function of L, the mean thickness of
nuclear matter crossed by the cc pair in its way through the nucleus [51]. On the
y-axis the index i refers to 7 nuclear targets. The nuclear effects in lower energy
range change the slope as seen in the figure. Systematic errors include uncertainities
on the target thickness, on the y distribution used in the acceptance calculation and
on the reconstruction efficiency.
2.4 Results from RHIC
The J/ production mechanism is expected to depend on rapidity at RHIC energies
centre-of-mass energy of 200 GeV. In the mid rapidity region, it is expected to be
dominated by gluon fusion but can also come from gluon or quark fragmentation
or from feed down from heavier mesons. In the forward rapidity, it is hypothesised
that the dominant production comes from intrinsic heavy flavour components in the
proton wave function [52].
The PHENIX collaboration compared J/ data in A-A collisions to pp ones.
Such a comparison was carried out using the RAA ratio, which can be written as in
equation(2.6).
Number of participants
0 50 100 150 200 250 300 350 400
12%=
Au+Au : |y|<0.35 sys
20%=commonCu+Cu : |y|<0.35 sys
Au+Au : 1.2<|y|<2.2 sys
16%=
Cu+Cu : 1.2<|y|<2.2 sys
Au+Au PHENIX Final
Cu+Cu PHENIX Preliminary
Number of participants
0 50 100 150 200 250 300 350 400
 14% = 
global
Figure 2.8: The nuclear suppression factor for Au-Au (circle) and Cu-Cu (square)
collisions at mid-rapidity (closed symbols) and at forward-rapidity (open-symbols)
s = 200 GeV, as a function of centrality [53]. The J/ production is suppressed
for large number of participants. Right: Ratio of RAA at forward-rapidity to that
at mid-rapidity in Au-Au collisions
Figure 2.8 (left) shows the suppression factor observed by the PHENIX collab-
oration at RHIC [45] in Cu-Cu and Au-Au at
s = 200 GeV, as a function of
centrality. The J/ production is suppressed for large numbers of participants.
RAA is similar between mid-rapidity and forward-rapidity up to Npart  100 and
stronger suppression is observed at forward rapidity for Npart > 100. Figure 2.8
(right) shows the ratio RAA at forward-rapidity to that at mid-rapidity, which goes
down to  0.6 for Npart > 100. Figure 2.9 shows a comparison of the PHENIX and
STAR [3] results for nuclear modification in Cu-Cu at
s = 200 Gev. Suppression
is observed in PHENIX data. The RAA vs Npart was obtained using minimum bias
Cu-Cu collision only.
Figure 2.9: The nuclear suppression factor of J/ as a function of centrality (repre-
sented by the number of participants). Suppression is more clear in PHENIX data
[3]. STAR data points have statistical (bars) and systematic (caps) uncertainties.
The solid line and band show the average and uncertainty of the two 0-20% data
points. RAA equal to 1 means no suppression.
2.5 Theoretical interpretation
The models can be divided into two classes: pure dissociation models and mod-
els including recombination. The pure dissociation models [54] of quarkonium are
computed using lattice QCD calculations. This leads to a charmonium dissocia-
tion temperature close to the proposed critical temperature of 170 MeV [54] [55]
[56] [57] [58]. Higher charmonium states dissociate sooner due to their size. Since
a large fraction of the measured J/ originate from decay of the higher excited
charmonium states, the total yield of J/ will decrease as well. This effect, called
sequential dissociation [59] is used to explain the suppression pattern observed at
the SPS.
Number of Participants
0 50 100 150 200 250 300 350 400
Au+Au : |y|<0.35
Au+Au : 1.2<|y|<2.2
 = 0mb : y=0
Comover : 
 = 0mb : y=2
Comover : 
Number of Participants
0 50 100 150 200 250 300 350 400
1.2 Au+Au : |y|<0.35
Dissociation (Rapp et al) y=0
Dissociation (Xu et al) y=0
Number of Participants
0 50 100 150 200 250 300 350 400
1.2 Au+Au : |y|<0.35
R.Rapp : y=0
Thews : y=0
Nu Xu : y=0
Bratkovskaya : y=0
Andronic : y=0
Figure 2.10: Left: Comparison of RAA to the models with dissociation by comovers
[54]. Middle: Comparison of RAA to the models with dissociation by thermal gluons
[60]. Right: Comparison of RAA to the models with dissociation and recombination
of J/ [61, 64].
According to this model one would expect that at RHIC, due to the higher energy
density, the ground state melts and charmonia are almost completely suppressed.
Figure 2.10 (left and middle) shows a comparison of RAA in Au-Au collisions to
the models involving only the dissociation of J/ by comoving partons and hadrons
and by thermal gluons, respectively [60]. These models [60] over-predict the sup-
pression. Even before the suppression was measured, different authors argued that
the relatively large number of charm quarks produced at RHIC (10) would lead to
charmonium production at the hadronization stage. These models became known
as recombination models. Several models include the charm hadronization in their
calculations. A comparison of these recombination models [60] [61] [62] [63] [64]
is shown in the figure 2.10. The details of these models are not described in this
thesis. The recombination models include the assumption that the charmonium is
dissolved in the deconfined medium and they do not contradict the original idea of
charmonium suppression.
However at the LHC about 100 cc -pairs per central collision will be produced and
about 1 J/. At the LHC a higher energy density is expected compared to RHIC.
Thus all initially produced J/ are expected to be suppressed. But due to the large
number of charm quarks produced within the hadronization phase it is expected to
produce an even higher J/ yield compared to production from initial collisions [65].
The J/ should be strongly enhanced, as predicted by the recombination models.
In the next chapter I will concentrate on J/ in p-p collisions mainly for two
reasons. Firstly the J/ cross-section comparision with the QCD prediction and
secondly to provide a benchmark to compare p-p collision with heavy ions.
Chapter 3
The ALICE experiment at the
3.1 LHC
The Large Hadron Collider [66] is an accelerator complex at the CERN laboratory
in Switzerland, which accelerate protons and/or nuclei to unprecedented energies,
allowing access to the highest energy densities and temperatures ever created in
man-made experiments. The LHC ring sits in the tunnels of its predecessor, the
LEP (Large Electron and Positron) collider, crossing the French-Swiss border with
a circumference of 27 km. It has 4 intersection points between the two conversely
circulating beams where collisions occur, marking the sites of the four detector
experiments: ALICE [1], ATLAS [68], CMS [69] and LHCb [70], as in Figure 3.1.
Figure 3.1: Schematic layout of the LHC [66]
The protons fed into the LHC are first created by stripping hydrogen atoms
from their electrons. These protons are then injected from the LINAC2 (linear
accelerator) into the Proton Synchrotron Booster which accelerates the protons to
an energy of 1.4 GeV before injecting them into the Proton Synchrotron. The PS
ring accelerates protons up to 25 GeV, at which point they are fed into the SPS,
which accelerates protons to 450 GeV. Then they can be fed in either direction into
the LHC, where they achieve a maximum energy of 7 TeV. Figure 3.2 shows the
layout of the injection complex.
Figure 3.2: The various stages of acceleration of both protons and ions on their way
to injection into the LHC [71].
3.2 The ALICE detector
The ALICE (A Large Ion Collider Experiment) [1] experiment is a general-purpose
heavy ion detector. It has been designed to detect, measure and identify mid-rapidity
hadrons, leptons and photons produced in heavy ion interactions. In addition it will
study collisions of protons (both pp and pA) which primarily provide reference data
for nucleus-nucleus collisions. ALICE is required to track and identify particles,
from very low (  100MeV/c) to fairly high (  100 GeV/c) transverse momen-
tum pt, to reconstruct short-lived particles such as hyperons and do this in a high
multiplicity environment. The detectors are designed to cope with charged parti-
cle densities dNch/dy of up to 8000. Theoretical predictions for the multiplicity
in central Pb-Pb collisions at the LHC currently range from 2000 to 6000 charged
particles per unit rapidity giving a comfortable safety margin. The key design fea-
tures of the main ALICE sub-detectors are described in this chapter. A cutaway
drawing of the ALICE experiment is shown in figure 3.3. It consists of a central
detector system, covering mid-rapidity ||  0.9 1 over the full azimuth, and several
forward systems. The central system is installed inside a large solenoidal magnet
which generates a magnetic field of up to 0.5 T. The main factor in choosing this
value of the magnetic field is to optimize the range over which accurate tracking
can be done. This means that the radius of curvature should lead to sagittas over
the typical allowed length of track that are well measurable by the detector. Too
1Pseudorapidity,  , is a commonly used variable describing the angle of a particle relative to
the beam axis. Mathematically it can be represented as
 =  ln
strong a field leads to very curved tracks which are difficult to reconstruct. Too
weak a field leads to straight tracks which give poor momentum resolution. The
central barrel system includes, from the interaction vertex to the outside, six layers
of high-resolution silicon detectors (Inner Tracking System-ITS), the main tracking
system of the experiment (Time-Projection Chamber - TPC), a Transition Radia-
tion Detector for electron identification (TRD), and a particle detector which can
discriminate between lighter and heavier particle of the same momentum using their
time of flight ( Time-Of-Flight - TOF). The central system is complemented by two
small-area detectors: an array of ring-imaging Cherenkov detectors for the identifica-
tion of high-momentum particles (High-Momentum Particle Identification Detector-
HMPID), and two electromagnetic calorimeters consisting of array of high-density
crystals (Photon Spectrometer - PHOS and EMCal).
The forward muon arm consists of a complex arrangement of absorbers, a large
dipole magnet, and fourteen planes of tracking and triggering chambers [67]. An ab-
sorber positioned very close to the vertex shields the muon spectrometer. A system
of scintillators and quartz counters (VO) and (TO) provide fast trigger signals, and
two sets of hadron calorimeters, located about 115 m away on either side of the in-
teraction vertex, measure the centrality (Zero-Degree Calorimeter - ZDC). Another
forward detector in ALICE is the Photon Multiplicity Detector (PMD), which mea-
sures the multiplicity and spatial distribution of photons produced in the collisions.
An array of scintillators (ACORDE) on the top of the L3 magnet is used to trigger
on cosmic rays.
Figure 3.3: The ALICE detector schematic layout.
3.2.1 Inner Tracking System (ITS)
The main purpose of the ITS is the detection of secondary vertices (hyperons and
charm particles) and the stand-alone track finding of low-pt charged particles, down
to a pt of 20 MeV/c for electrons. Also it has a number of additional roles: improve-
ment of the momentum resolution at large momenta, momentum reconstruction of
low energy particles, and their identification. The ITS recognises particles contain-
ing heavy quarks by identifying the point at which they decay.
The ITS is made up of six layers of silicon detectors, shown in figure 3.4. It is
required to localise the primary vertex to better than 100 m, and give excellent
spatial resolution so that an impact parameter of better than 60 m can be achieved
for low momentum particle, as well as coping with a high track density. The Silicon
Pixel Detector(SPD) makes up the inner two layers, with a spatial resolution of 12
m which optimises impact parameter resolution, followed by SDD (Silicon Drift
Detector) layers. These two detectors handle the high particle density of heavy ion
collisions. The SSD (Silicon Strip Detector) layers are placed in the region where
the particle density reduces to below 1 per cm 2.
Silicon Pixel Detector (SPD)
The two innermost layers of the ITS as shown in figure 3.3 are fundamental in
determining the vertexing quality of ALICE (determination of the position of the
primary vertex and measurement of the impact parameter of secondary tracks from
the weak decays of strange, charm and beauty particles). They operate in a region
Figure 3.4: ITS showing six layers of silicon detector.
where the track density can exceed 50 tracks/cm2. Thus it is a detector of high pre-
cision and granularity and also operates in a relatively high-radiation environment.
The SPD is based on hybrid silicon pixels, consisting of a two dimensional matrix
of reverse biased silicon detector diodes bump bonded to readout chips. Each diode
is connected through a conductive solder bump to a contact on the readout chip
corresponding to the input of an electronics readout cell. The readout is binary: in
each cell, a threshold is applied to the pre-amplified shaped signal and the digital
output level changes when the signal is above a set threshold. The basic building
block of the ALICE SPD is the ladder, consisting of a pixel detector matrix bonded
to 5 front-end chips. The detector matrix consists of 256  160 cells, each mea-
suring 50m in the r direction by 425m in the z direction. Each detector ladder
measures 12.8 mm (r) 70.7 mm(z). Each front-end chip contains the electronics
for the readout of a sub matrix of 256 (r)  32 (z) detector cells. The detector is
200 m thick and the electronics chip is 150 m thick.
Silicon Drift Detector (SDD)
SDDs have been selected to equip the two intermediate layers of the ITS as shown
in figure 3.3, since they couple a very good multi-track capability with dE/dx infor-
mation. The SDDs, with 7.25  7.53 cm2 active area each, are mounted on linear
structures called ladders, each holding six detectors for layer 3, and eight detectors
for layer 4. The layers are located at average radii of 14.9 and 23.8 cm respectively
and are composed of 14 and 22 ladders respectively.
SDDs, like gaseous drift detectors, exploit the measurement of the transport time
of the charge deposited by a traversing particle to localise the impact point in one of
the dimensions, thus enhancing resolution and multi-track capability at the expense
of speed. They are therefore well suited to applications in which very high particle
multiplicities are coupled with relatively low event rates.
A linear SDD has a series of parallel, implanted p+ field strips, connected to
a voltage divider on both surfaces of the high-resistivity n-type silicon wafer. The
voltage divider is integrated on the detector substrate itself. The field strips provide
the bias voltage to fully deplete the volume of the detector and they generate an
electrostatic field parallel to the wafer surface, thus creating a drift region.
Electron-hole pairs are created by the charged particles crossing the detector.
The holes are collected by the nearest p+ electrode, while the electrons are focused
into the middle plane of the detector and driven by the drift field towards the edge
of the detector where they are collected by an array of anodes composed of n+ pads.
The small size of the anodes, and hence their small capacitance ( 50fF), imply low
noise and good energy resolution. The readout is at the end of the SDD cell and
measures the charge deposited in time slices. The amount of collected charge is
measure of particle energy loss dE/dx. With a bias voltage of about 1.65 kV the
charge drifts at 5.6 microns/ns (which can be checked by calibration triggers to get
accurate local triggers) and is read out using the PASCAL chip, which samples the
charge arriving at the anode at 40.08 MHz (LHC clock rate) and digitizes.
Owing to diffusion and mutual repulsion during the drift, the electrons reach
the anode region with a Gaussian distribution. The coordinate perpendicular to the
drift direction is given by the centroid of the collected charge. The coordinate along
the drift direction is measured by the centroid of the signal in the time domain,
taking into account the amplifier response. The SDDs are positioned so that the
electrons drift orthogonal to the beam axis and therefore to the ALICE magnetic
field. The low magnetic field would cause a marginal effect on the electron cloud
formation and essentially none on the charge transport, since the Lorentz force is
compensated by the confining electric field. The average resolution is 35 microns in
r direction and 25 microns in z direction.
Silicon Strip Detector (SSD)
The two outer layers of the ITS as shown in figure 3.3 are crucial for the connection
of tracks from the ITS to the TPC (Time Projection Chamber). They provide dE/dx
information to assist particle identification for low-momentum particles. Both outer
layers of the ITS consist of double-sided SSDs with a 35 mrad stereo angle. Each
detector has an active area of 73 mm by 40 mm. The active area is surrounded
by bias and guard rings which occupy 1 mm along each side of the detector. The
implanted strips are inclined with a 17.5 mrad angle with respect to the 40 mm side
of the detector. Therefore the patterns are identical on the p and the n-sides of
the detector. The stereo angle is small in order to minimise of ambiguities for the
high particle densities expected. The detectors are mounted with the strips (nearly)
parallel to the magnetic field, so that the best position resolution is obtained in the
bending direction.
3.2.2 Time Projection Chamber (TPC)
The Time Projection Chamber (TPC) is the main tracking detector in the central
barrel of the ALICE experiment as shown in figure 3.3. With its large acceptance,
it enables us to analyse individual events and perform charged particle exclusive
analysis in a wide range of pseudo-rapidity ||  0.9. Its function is to provide
track finding, charged particle momentum measurement, particle identification, and
two-track separation in the region pt  10 GeV/c and pseudo-rapidity ||  0.9.
Particles can be identified within the TPC by their specific loss of energy due to in-
teractions with the TPC gas. TPC is the main detector for the hadronic observables
in both heavy-ion and proton-proton collisions.
TPC Layout
The TPC is cylindrical in shape with an active gas volume that ranges from about
85 cm to 250 cm, in the radial direction, and has a length of 500 cm along the beam
direction resulting in an active volume of 95m3, the largest TPC ever built. The
detector is made of a large cylindrical field cage, filled with Ne/CO2/N2 (90:10:5)
which is needed to transport the primary electrons over a distance of up to 2.5 m
on either side of the central electrode to the end-plates. N2 is also used as it is more
adequate quencher for neon.
The advantage of this gas mixture is that it shows almost no ageing effects in
contrast to other mixtures like CF4. Further advantages are a short drift time, small
diffusion and a low radiation length. These nice features have to be paid for with
a strong dependence of the drift velocity on the temperature. For this reason the
temperature has to be kept constant within an interval of 0.1 K. To prevent heat
conduction from the outer detectors a thermal shield is added between the TPC and
the TRD (Transition Radiation Detector).
The central electrode operates at a voltage of 100 kV, giving a field gradient of
400 V/cm and a maximum drift time of 106 s. The signals are read out at the
two end caps by 72 multi-wire proportional chambers. Each of these chambers has
three layers of wires. To prevent space charge effects within the detector volume,
the outermost wire layer of the read-out chambers is used as a gating grid such that
electrons are only collected in the chambers if a Level-One trigger was sent. The
TPC detector is shown in the figure 3.5
ALICE is the only experiment at the LHC using a large TPC as the central
tracking detector. This can be understood when looking at the desired physics
observables. The ALICE TPC is divided in two drift regions by the central electrode
located at its axial centre. A field cage creates a uniform electric field along each half
88 s
Figure 3.5: The Time Projection Chamber (TPC) layout.
of the chamber. Charged particles traversing the TPC volume ionise the gas along
their path, liberating electrons that drift towards the end plates of the chamber is
shown in figure 3.6. The necessary signal amplification is provided through avalanche
effect in the vicinity of the anode wires. Moving from the anode wire towards the
surrounding electrodes, the positive ions created in the avalanche induce a positive
current signal on the pad plane. This current signal, which is characterised by a
fast rise time (less than 1 ns) and a long tail with a rather complex shape, carries a
charge of 4.8fC, for a minimum ionising particle.
3.2.3 Transition-Radiation Detector (TRD)
Transition radiation is produced by the passage of highly relativistic charged parti-
cles through layers of material with different indices of refraction. Transition radi-
ation detectors are unique tools for separating high energy electrons and positrons
Figure 3.6: The Time Projection Chamber ionisation cage.
from charged pions. Unlike pions, electron and positrons are not subject to the
strong force. This makes them ideal probes to study the hottest and densest phase
of such collisions. In ALICE the Transition Radiation detector (TRD) will be used
to study the production of J/ and  -particles both in Pb-Pb and pp collisions
where its principal use is the identification of electrons among the charged tracks. It
has two main purposes: the identification of electrons over a large momentum range
via their emission of transition radiation, and to serve as a trigger device for events
containing high pT > 3 GeV/c electrons. In addition, since it provides additional
points to charged particle tracks, it increases the tracking resolution.
The detector is shown in figure 3.7. It consists of 540 read-out chambers arranged
in 18 super modules covering the same angle as a corresponding TPC sector. Each
of these super modules consists of 30 chambers arranged in 6 radial layers and 5
stacks in the z-direction. The total active volume is about 27 m3, filled with a
mixture of Xenon (85%) and CO2 (15%). Since Xenon is a very rare noble gas
(0.08 ml Xenon in 1m3 air), the amount of Xenon used in the TRD represents
roughly one years worth of production worldwide. This puts strong requirements in
terms of gas tightness on the detector. The total sensitive area of the detector is
roughly 750m2 divided into 1.16 million read-out pads. Each channel is individually
readout; 18 read-out channels are bundled and connected to a highly integrated
multi chip module (MCM). The MCM contains two main parts: the pre-amplifier
and shaper chip ( PASA ) and the Tracklet processor (TRAP) [72] containing a 10
bit analog to digital converter with a sampling rate of 10MHz, configurable digital
filters providing further shaping, pedestal subtraction, tail cancellation and zero
suppression. In addition short tracks within one chamber, called tracklets, are used
for the trigger on high pt particles.
Figure 3.7: Schematic drawing of (one half) of the ALICE TRD. The complete
detector consists of 540 read-out chambers (green, red and yellow) arranged in 18
super modules covering the full azimuth. Each of these super modules consists of 6
radial layers and 5 stacks of chambers in the z-direction. The total sensitive area of
the detector is 750m2 divided into 1.16 million read-out channels.
Electron Identification
The principle the TRD is used to discriminate between electrons and heavier par-
ticles in the emission of transition radiation. Transition radiation was predicted in
1945 [73] and first observed in 1959 [74]. It denotes the effect that a charged particle,
moving with a certain velocity, undergoing transitions between materials of different
dielectrical properties emits electromagnetic radiation. Since the electrical field sur-
rounding every charged particle depends not only on the charge but also on the speed
of the particle and on the dielectric properties of the surrounding medium, changing
one of these parameters leads to a change in the field. For example changing the
velocity of a charged particle leads to the emission of Bremsstrahlung. Changing the
medium surrounding the particle also leads to a changing field and thus to the emis-
sion of transition radiation. A detailed theoretical treatment can be found in [75]
[76]. Important for the design of a transition radiation detector are the probability
to produce a transition radiation photon and its energy.
The probability to produce a photon during one transition of a charged particle
depends on the relativistic -factor, which is directly related to the mass of a par-
ticle. This enables, just by the observation of transition radiation, the distinction
between different particles without the need of a precise momentum measurement
like is needed for particle identification via the specific energy loss of particles in the
medium.
Table 3.1 shows values for  for different particles with different momenta. The
threshold transition radiation emission depends on the thickness and on the plasma
frequency difference of the radiator materials. For polypropylene/air radiators parti-
cles with a  exceeding 1000 produce transition radiation [77]. Over a large momen-
tum range (1-100 GeV/c) only electrons are expected to emit transition radiation.
Thus transition radiation detectors are very well suited to separate especially elec-
trons from heavier particles. The probability to emit a transition radiation photon
during one transition is of order of em = 1/137. For this reason transition radiation
detectors are designed such that the particles undergo not one but many transitions.
Table 3.1: The relativistic  factor for different particles with various momenta.
Only particles with  > 1000 produce significant transition radiation for a typical
detector with polypropylene/air interfaces.
Particle e   K p
Mass(MeV/c2) 0.511 105.658 139.57 493.677 938.272
p (GeV/c)     
0.1 195. 1.4 1.2 1.0 1.0
1. 1956. 9.5 7.2 2.26 1.5
10. 19569. 94.5 71.2 20.3 10.7
100. 195000. 946. 716.5 202.6 106.6
1000. 2106000 9500. 7200 2000. 1065.
3.2.4 Forward detectors and Trigger system
The forward detectors were designed for different functions. They are used to extend
the measurement of the charged particles and photons at large values of rapidity,
and to characterise the event in terms of the collision centrality. Centrality is a
bit difficult to quantify, but is usually measured using some measure of the energy,
or number of particles, produced at rapidities close to that of the centre of mass.
The name probably comes from the distance between the centres of the nuclei in
the impact parameter plane (the more central the smaller the impact parameter).
Since we cannot measure the impact parameter (a few fm) directly, instead we use
correlated quantities, such as the transverse energy or the multiplicity. In ALICE
we use the multiplicity.
Two detectors are especially designed to deliver fast trigger information of gen-
eral interest namely the detector V0 triggering on centrality, and the detector T0
delivering fast information on multiplicity. The pulse height in each slab in V0 is
proportional to the number of tracks going through it, so by converting and sum-
ming we can estimate the multiplicity from the pulse height information. We use the
V0, which are not at mid-rapidity but slightly forward, because that way we do the
main physics measurements based on different tracks, and avoid auto-correlations,
which could be a problem in the case of (e.g.) jet production, where large numbers
of particles are produced.
In addition more specialised detector systems can cause triggers on their specific
process of interest: like the EMCAL, that will trigger on jets; PHOS on high pt pho-
tons; the muon spectrometer triggers on muons; and the TRD offers the possibility
to trigger on electrons. The trigger system is staged into three levels. The lowest
level trigger L0 is delivered within 1.2 s of an interaction and registers if there was
a collision and evaluates simple information like multiplicity, centrality or if there
was a signal in one of the especially dedicated detectors as previously mentioned.
The next higher trigger level L1 gives an accept or reject within 6.5 s. It allows
time to do more complex analysis like electron identification with the TRD, coarse
momentum determination (low/high PT ) or topological cuts. The third trigger level
L2 prevents recording events with pile-up. As the interaction rate is predicted to
be 8 kHz in Lead-Lead collisions there is a non-negligible probability that within
the drift time of the TPC of 92 s a second collision might be recorded that would
spoil the previous event. To ensure that only pure events are recorded the L2 rejects
events where a subsequent collision caused signals in the detector within the drift
time interval. The past future protection which counts the number of interactions
in a given time interval is used for this purpose
T0 Detector
T0 detector consist of two arrays of Cherenkov counter as shown in figure 3.3 with
time resolution of 50 ps. It is the fast timing and trigger detector for the ALICE
experiment at CERN. It gives a the trigger and timing signals, measures on-line
vertex position and give rough centrality. Data from T0 are crucial not only for
extraction of the precise interaction time but also for normalisation between proton-
proton and heavy ion runs. Its aims include the supply of several signals to the
ALICE trigger, to deliver an early ( prior to L0 trigger) wake-up to TRD, and also
to give a precise start for the time-of-flight (TOF) particle identification.
The trigger functions requested from T0 are to measure the approximate vertex
position, to give a rough estimate of event multiplicity and to also inform that at
least one of the arms of the T0 detector has registered a valid pulse.
Given its location, the pseudo-rapidity range covered is 2.9 <  < 3.3 and
5 <  < 4.5 . The measured multiplicity is analysed against 2 pre-set values
to generate one of the three possible trigger signals: T0(minimum bias), T0(semi-
central), or T0(central) corresponding to low, intermediate, and high multiplicities.
There are only two threshold values because the minimum bias signal is identical
with T0-vertex. T0 vertex is a proposed trigger signal ( not yet implemented) which
notes the relative timing between the hits in the two T0s (one on either side of
the vertex point) and does not allow the difference to be too big. This amounts to
demanding that the vertex must be inside a certain range in z, and so constrains
the z co-ordinate for accepted vertices.
V0 Detector
The V0 detector is a small angle detector consisting of two arrays of scintillator
counters, called V0A and V0C, which are installed on either side of the ALICE
interaction point as shown in figure 3.3. The V0C counter is located right upstream
of the dimuon arm absorber and cover the spectrometer acceptance while the V0A
counter is located at around 3.5 m away from the collision vertex, on the other
side. The counters cover the pseudo-rapidity ranges of 2.8 <  < 5.1 (V0A) and
3.7 <  < 1.7 (V0C).
It is designed to provide the minimum bias trigger and triggers on centrality 2
in Pb-Pb mode, multiplicity information and luminosity control. It also provides
beam gas interaction identification. A beam gas interaction is one where one
of the beams interacts with the residual gas in the beam pipe. They can occur
2The distance between the centres of the nuclei in the impact parameter plane (the more central
the smaller the impact parameter.
anywhere, but are more likely to do so outside the zone between the two V0s than
the one between them (more space). Let us imagine tracks coming from an upstream
interaction outside the V0 area. The normal timing of the V0s is based on an
interaction between them, and then a short flight for particles from the interaction
point to each of the V0s. In the beam gas case, particles hit the nearer V0 BEFORE
the expected time of the interaction (which is a known time based on the timing
of the LHC bunches). The timing in the further V0 will look fairly similar to that
from an ordinary interaction. It is these early hits in V0 which signal a beam gas
interaction.
Central Trigger Processor
The ALICE trigger system is situated in the experimental cavern and has a cen-
tralised layout: the Central Trigger Processor (CTP), the detector interface or Local
Trigger Unit (LTU), and the Trigger Timing and Control partitions are all installed
in adjacent racks. The CTP generates three levels of hierarchical hardware triggers
: L0, L1 and L2. At any time, up to 24 detectors from the ALICE experiment
can be dynamically partitioned into up to 6 independent clusters (group of read out
detectotrs). The level of event pile up is controlled by the past-future Protection
logic 3. The LTU serves as a uniform interface between the CTP and the detector
readout electronics. In the standalone mode of operation, the LTU fully emulates
the CTP protocol.
3A procedure that selects events with a programmable time interval before and after the colli-
sion, during which there can be a number of pile-up interactions tolerated up to a programmable
limit.
The Central Trigger Processor [80] is designed to combine and synchronise in-
formation from all triggering detectors and to send the correct sequences of the
trigger signals to all the detectors, in order to make them read out correctly. It also
co-ordinates calibration requests from the detectors and generates data summaris-
ing why a particular trigger has been taken. It is designed to operate in several
modes with significantly different characteristics: in Pb-Pb mode, the interaction
rate is 8 kHz, but, due to the high multiplicity, the event size is very large (up to 86
MB); while in the proton-proton mode, the event size is smaller (2.5 MB), but the
interaction rate goes up to 200 kHz.
Trigger logic
In all, there are 60 trigger inputs: 24 for those inputs with a latency of less than 800
ns (L0); 24 for those with a latency of up to 6.1 s (L1); 12 for those with a latency
of up to about 96 s (L2). These can be used to activate up to 6 different detector
groupings, called clusters, which can be made up from any arbitrary combination
of detectors. The same detector can be included in more than one cluster. While
taking data it is possible for the CTP to generate internal signals which are treated
in the same way as detector inputs by the CTP logic. These are: two random inputs
(RND1 and RND2) with a programmable mean rate, and two regular inputs (BC1
and BC2) with a programmable rate determined from the LHC clock by downscaling.
Up to 50 different trigger definitions, called classes, can be run simultaneously. The
parameters required to make up a trigger selection together define a trigger class.
To specify a trigger class it is necassary to define the trigger logic condition at
each trigger level, to associate the trigger cluster with the trigger class, and the
downscaling factors to be applied.
The data used for the analysis contains a sample of p-p collisions at a beam
momentum of 3.5 TeV corresponding to LHC10b and LHC10c periods for a series
of run from 114778 to 116572 and 118507 to 120069 respectively. The data was
recorded in April 2010. In the LHC four proton bunches per beam were circulated,
with two pairs of bunches crossing at the ALICE interaction region. The detector
readout was triggered with signals from the two upstream beam pick-up counters
and a minimum-bias interaction trigger requiring a signal in at least one of the SPD
pixels or one of the VZERO counters [97]. These counters are placed around the
beam pipe on either side of the interaction region and are known as VZERO-A and
VZERO-C. A total of 78 million events are studied in this thesis. The integrated
luminosity corresponding to the data set analyzed in this thesis is (1.25  0.09)
nb1, the details of which are found in chapter 5.
Chapter 4
Reconstruction and selection of
J/ at ALICE
4.1 Introduction
One of the aims of the ALICE experiment is to measure the yield of J/. To achieve
this, it is necessary to reconstruct its decay products and to obtain a pure sample.
In order to remove the background, a set of selection criteria is imposed, known as
track quality cuts and selection cuts. These will be described and justified in this
chapter.
4.2 ALICE Software Framework
Since the ALICE experiment is expected to take data for at least the next ten years,
the accumulated raw data for a particular run have to be completely reconstructed
before the next run in order not to generate a backlog of unprocessed raw data.
The analysis framework includes generation and reconstruction. The software used
for the ALICE offline is called ALIROOT and is based on the ROOT analysis
framework.
ROOT [81] is an object oriented framework written in the C++ language. It
consists of 650 classes, taken from C++ base classes. This structure is suited to
manage the enormous amount of data from a high energy experiment as it provides
the packages for event generation, detector simulation, data reconstruction and data
analysis. As an extension to ROOT, ALIROOT [82] was developed to include and
simulate the geometry of the ALICE detectors, and their response to the passage
of particles. The scheme of ALIROOT is shown in figure 4.1. The module STEER
provides the interface to detector specific code, to event generators, to Monte-Carlo
simulators and to steering class for reconstruction. There are several event genera-
tors (like PYTHIA) and detector generators (like GEANT3) which will be described
later in this chapter.
For proton-proton data the first reconstruction can be run on-line in parallel with
the data taking. For lead-lead raw data, this is not possible due to the ten times
higher data volume. For this reason the Grid computing concept has been adopted.
The Grid is hierarchically subdivided into 3 levels of so-called Tier centres. A Tier
level is defined by the type of the stored data. There are four different types of data:
Figure 4.1: Schematic view of the ALIROOT framework.
 Raw Data: As recorded by the data acquisition.
 ESD (Event Summary Data): Reconstructed data; minimal cuts.
 AOD (Analysis Oriented Data): Extracted from the ESDs, only data relevant
for a specific type of analysis are stored.
 TAG - Event tags for event selection
Grid computing is designed to handle the huge amounts of data as well as to give
physicists access to it for further analysis. The raw data are kept in the Tier 0
centre, namely at CERN, where also parts or even all of it will be reconstructed
for the first time. Parallel to this the raw data are distributed among the Tier 1
centres, usually one large computer centre per country. In the Tier 1 centres the
raw data are reconstructed for at least a second time with improved calibrations.
Due to the huge costs in terms of CPU power to reconstruct the raw data, this task
is done centrally, and since it consumes the available computing resources during
one ALICE running period, more iterations on the reconstruction is careful planned
and are not repeated arbitrarily often on the full data set. In addition the Tier 0
centre is not foreseen to contribute significantly to the data analysis. The Tier 1
centres, apart from parts of the raw data, keep a subset of all ESDs; however via the
Grid all ESDs are available for analysis. The Tier 2 centres do not contribute to the
reconstruction of the raw data at all, and for this reason do not store the raw data.
Instead the Tier 2 centres perform the necessary Monte-Carlo production needed
for the data analysis. Each centre keeps a subset of all ESDs and AODs for data
analysis. The next Tier levels are the Tier 3 and 4. Tier 3 centres are planned as
medium sized clusters at laboratories or universities keeping only a small subset of
the total amount of the data as a copy. Finally the desktop machine of a physicist
doing analysis is regarded as Tier 4.
The AODs represent a more specific version of the ESDs. During the production
of the ESDs any cuts or irreversible changes are avoided. The AODs are produced
with respect to the requirements of a specific analysis and might for this reason, as
an example, already include cuts on the quality of ESD tracks as well as particle
identification. In addition, results of very CPU intensive algorithms like secondary
vertex finding might be performed during the production of the AODs; in this way
such expensive operations need to be performed only once. The analysis of data
is performed within the framework of an AliAnalysisTask. The concept of an
analysis task is that, since a lot of time is spent on reading the data from disks or
tape, one should perform not only one specific analysis task within one analysis run,
but many tasks, to make maximal use of the event currently stored in the memory.
To perform an analysis on the complete data set one has to first develop a task
derived from a prototype class. Different tasks, which may even depend on each
other, can then be organised in an analysis train. The input and output of this
train is managed by the analysis manager. Each task residing in this train is then
subsequently executed as soon as the data are available. This system ensures that
a lot of tasks can run on the full data set, without too many files being queried at
the same time.
For the studies presented on J/ production, an analysis train has been devel-
oped by the author. The train has been run on data sets of real data at
s = 7
TeV (as described in later sections) and on three MC samples (as mentioned later)
to evaluate the effect of the applied cuts with respect to signal as well as to possible
background contributions. This analysis train was used on AliEn [83]. AliEn is a
Grid framework built around existing Open Source components using a combination
of Web Service and distributed agent models. It is being developed by the ALICE
collaboration as a production environment for the simulation, reconstruction and
analysis of physics data.
4.3 Event Generators
Multi particle production is an important feature of high-energy physics. It is here
that the so-called event generators come into play. In an event generator, the aim
is to use computers to generate events as detailed as those observed by a perfect
detector. The output of the event generator is a set of events, with almost the same
behaviour as real data. In generators, Monte-Carlo techniques are used to get all the
desired probability distributions, thus ensuring randomness in final events. Event
generators are used for the following purposes:
 To get an idea of the kind of events one may expect or hope, and also at what
rates.
 In the planning of a new detector, so that detector performance is optimised.
 To plan the analysis strategies that should be used on the real data, so that
signal to background conditions are optimised
 To calculate the detector acceptance corrections that needs to be applied to
raw data so that physics signals can be extracted. The detector simulation is
tuned to reproduce the real data. The MC sample is used to perform correction
to reproduce real data. For MC data to agree with the real data certain control
regions are defined. Comparison is done within these controlled regions. If a
agreement is reached, then MC can be used to correct the data.
The event generators are grouped in a module called EVGEN. This module
includes a variety of generators which were developed outside the ALICE collabo-
ration. As some of these were written in the FORTRAN language, they are linked
to ALIROOT through wrapping classes. The main generators used for the hadron-
hadron collisions are PYTHIA [84] and PHOJET [85].The generators for heavy-ion
collisions are HIJING [86], DPMJET (Dual Parton Model Jet [87]) and SFM (String
Fusion Model Jet [88]). The generator used in the work presented here is PYTHIA
for the p-p collisions, while HIJING is in generally used for Pb-Pb interactions. The
PYTHIA program is a tool for the generation of high-energy collisions as accurately
as possible, comprising a set of physics models for the evolution from a few-body
hard process to a complex multi-hadronic final state.
4.4 Detector Simulations
The behaviour of the detector after particles are produced by the event generator,
how they traverse the detector, spiral in magnetic fields, shower in calorimeters, or
escape through cracks is simulated in programs such as GEANT3 [89] and FLUKA
[90], written in FORTRAN. GEANT4 [91] is the evolution of GEANT3 towards
C++ language. So far, GEANT3 has been used and FLUKA is thought to be what
ALICE will use in the near future. These transport packages also include models
describing all the possible interactions occurring between radiation and matter. The
various sub-detectors provide independent modules with specific code for simulation
and local reconstruction. The information that one gets from these local recon-
structions are grouped into the global event reconstruction, which gives the track
reconstruction, primary and secondary vertices and particle identification. The out-
put of this simulation has exactly the same format as the real data recorded by the
detector, and thus can be put through the same event reconstruction and physics
analysis chain.
Event simulation and reconstruction
Figure 4.2 shows a chain of event simulation and reconstruction. The left part is
the simulation down to raw data, while the right part is the procedure which is used
for the real data. The various steps corresponding to simulation and reconstruction
are as following.
Simulation: In the collisions, the particles produced are generated with a generator
code. The simulation packages help in transporting the final state particles through
the detector, while taking into account all the processes occurring via the interac-
Figure 4.2: Data processing framework. [92]
tion of particles with detector materials. In these processes the energy deposited
in the detector is calculated and is called hits. Hits represent the ideal response
of the detector to the passage of particles. The next step is the transformation of
hits into digits, which represents the real detector response and takes into account
instrumental effects such as the physical noise due to the front end electronics which
adds to the physical signal. After the transformation of hits into digits, the digits
are transformed into the raw data format, which is identical to that coming from
the data acquisition system during data taking.
Reconstruction: The reconstruction starts after the raw data have been created.
A single signal is formed from the digits which are extracted from the raw signal
and convoluted with physical and electronic contributions. The clusterisation pro-
cess takes place, in which several digits are grouped together in order to find a
cluster which represents the realistic signal given by a particle in the detector. The
reconstructed point (called rec point) is found by calculating the centre of gravity of
the cluster. This rec point is a realistic estimate of the position where the particle
crossed the sensitive area of the detector. The reconstruction points are then asso-
ciated to tracks, which not only contain information on the kinematic variables but
also the identity and the energy loss of the particles. In the ALICE experiment the
reconstruction of tracks is based on the Kalman filter algorithm[93] which is widely
used in high-energy physics experiments. In the Kalman filter procedure, a track
is identified by a state vector of five parameters which define the track, and by its
covariance matrix. Tracking starts from the track-seed performed considering all the
pairs of points in the TPC outer-most pad row. A second seed finding is performed
using another couple of pad rows. Then it proceeds with the Kalman filter through
the whole TPC. If the procedure reaches the inner wall of the TPC it tries to find
matching clusters within the ITS. Especially in a high multiplicity environment this
may result in a large tree of possibilities which have to be analysed with respect to
the highest probability. During this extrapolation, multiple scattering (by adding
the corresponding matrix to the track covariance matrix [94]) and energy loss (by
means of the Bethe-Bloch formula) are taken into account. Thus for all the clusters
whose coordinates are inside suitable windows, a 2  increment is calculated.
The windows are estimated taking into account the cluster position precision and
the uncertainty of the track position extracted from covariance matrix associated to
the track state vector. The cluster with the minimum 2 is assigned to the track
and state vector and its covariance matrix are updated according to the standard
filtering procedure. Clusters with large 2 [95] are removed from the track. From
the outer wall of the TPC the track is then propagated into the TRD and from
there to TOF, HMPID, PHOS and EMCAL. At the last reconstruction step, the
information relevant for particle identification is assigned to the track and the track
is refitted towards the centre of the detector.
Thus the tracking procedure takes place in three steps [96]:
 the seeding of tracks,
 the reconstruction of tracks,
 a best fit of the track parameters.
The track reconstruction process allows one to determine the momentum of par-
ticles and their charge in space. Also, it is capable of precisely extrapolating the
tracks to the detectors that provide the particle identification information such TOF,
HMPID and PHOS. These are situated far away from the main interaction point.
4.5 Monte-Carlo Samples:
Primary, Secondary and Minimum Bias Samples
Samples of 2 106 primary J/ , 106 secondary J/ and about 106 Minimum Bias
proton-proton events were produced with PYTHIA 6.214 and analysed using AliEn.
The analysis was performed using the MC data provided by the ALICE Particle
Data Challenge production during 2010 for primary J/, secondary and Minimum
Bias data samples. Both primary and secondary J/ samples are not minimum bias
i.e. there is
1 B  J/ +X (4.1)
1 J/  e+e (4.2)
per event. In the primary J/ MC sample of 2  106 events, the signal is thus
enhanced by:
1/(0.059 0.14 103) = 1.21 105 (4.3)
where 0.059 corresponds to the branching ratio of J/  e+e and 0.14  103 is
the number of J/ per collision. This is equivalent to
(1.21 105) 2 106 = 2.42 1011 (4.4)
minimum bias events. In case of the secondary sample, the enhancement is
1/(0.01 0.059 0.0072) = 2.35 105 (4.5)
where 0.01 corresponds to the branching ratio of B  J/ X, and 0.0072 cor-
responds to the number of bb pairs per minimum bias collision. This means the
secondary sample of 106 is equivalent to
(2.35 105) 106 = 2.35 1011 (4.6)
minimum bias events.
4.6 Data Sample
The data used for the analysis contains a sample of p-p collisions at a beam momen-
tum of 3.5 TeV corresponding to LHC10b and LHC10c periods for a series of run
from 114778 to 116572 and 118507 to 120069 respectively. The data was recorded
in April 2010. In the LHC four proton bunches per beam were circulated, with
two pairs of bunches crossing at the ALICE interaction region. The detector read-
out was triggered with signals from the two upstream beam pick-up counters and
a minimum-bias interaction trigger requiring a signal in at least one of the SPD
pixels or one of the VZERO counters [97]. These counters are placed around the
beam pipe on either side of the interaction region and are known as VZERO-A and
VZERO-C. The time resolution of this detector is better than 1 ns. Its response is
recorded in a time window of 25 ns around the nominal beam crossing time. A
total of 78 million events are studied in this thesis.
4.7 Cuts
The basic idea of the analysis is that for each event all electron and positron tracks
are combined with each other and the invariant mass is calculated. This is done by
running the AnalysisTask on two AODs simultaneously. One is known as general
AOD, which contains information about the tracks; the other is called friend AOD,
which contains information about the candidates. In order to obtain an estimate
of the uncorrelated background one uses mass sideband fitting and mixing of like
sign pairs. The major background contributions are expected from semi-leptonic
decays of charm and beauty-mesons and from misidentified pions and protons. There
are various possible cuts that can be applied to increase the performance of the
measurement and hence increase the signal over background ratio. The following
cuts will be discussed in detail:
 cuts on track quality
 selection cuts one can apply to improve the signal to background ratio
4.7.1 Track quality cuts
The standard track quality cuts for 2010 are used while forming AODs from the
ESDs:
Number of TPC Clusters(Ncls): A cluster denotes a combination of TPC
channels used for a given track reconstruction. For the presented studies, in the
case of TPC we demand Ncls > 70 to ensure good quality tracks while rejecting
background. Figure 4.3 shows the distribution of the number of TPC clusters for
the MC primary and secondary J/, MC minimum bias and real data respectively.
Real data is data sample mentioned in section 4.6.
2/Ncls: In order to measure the quality of the fit to the track, the 
2 [95] of
each fit is stored. For a good fit the quantity 2/Ncls should be close to 1. A cut of
2/Ncls < 3.5 is used for this analysis.
Entries  7441222
Mean    135.4
RMS     20.81
No. of Clusters
0 50 100 150 200 250 300
Entries  7441222
Mean    135.4
RMS     20.81
Entries  7652134
Mean    133.4
RMS     19.96
No. of Clusters
50 100 150 200 250 300
Entries  7652134
Mean    133.4
RMS     19.96
Entries  448750
Mean    127.7
RMS     18.63
No. of Clusters
0 50 100 150 200 250 300
10000
15000
20000
25000
30000
35000
40000
Entries  448750
Mean    127.7
RMS     18.63
Entries    1.420433e+07
Mean    114.1
RMS     21.44
No. of Clusters
0 50 100 150 200 250 300
Entries    1.420433e+07
Mean    114.1
RMS     21.44
Figure 4.3: Top left: Distribution of Number of TPC Clusters in case of Primary
MC J/, Top right: Secondary MC J/, Bottom left: Minimum Bias MC Sample,
Bottom right: real data.
TPC and the ITS Refit: For every track a status word is stored. This consists
of 32 bits, each bit indicating whether a certain criterion is fulfilled for this track
or not. It is stored whether a certain track is successfully propagated to inner TPC
wall (TPCin), then passed over to ITS (ITSin), fitted back out (ITSout, TPCout),
propagated and tracked through the TRD (TRDout) and finally if the refit through
all detectors is successful (TRDrefit, TPCrefit, ITSrefit). Only tracks which pass
TPC and ITS refit are selected.
KinkDaughters: Apart from the parameters discussed above, originating from
the basic reconstruction, another parameter which is of great importance is used:
the kink index. The algorithm to find kinks was introduced to detect Kaon decays
such as K+  +, where only the muon is measured, but since the neutrino carries
momentum and is not measured, the whole process appears as a positively charged
track with a kink at the point of the Kaon decay. Although this algorithm was
designed for these Kaon decays it also finds a lot of kinks for other tracks, which
basically leads to a duplication of the corresponding track. Whether a track was
reconstructed as a mother (decaying particle) or daughter (produced particle) is
indicated via the kink index. Since double counting of tracks should be avoided, all
kink daughter particles are excluded from further analysis. Another kinks are the
particles such as pions produced or scattered during the interaction in the detector.
MaxCovDiagonalElements:
This represents the maximum value of the covariance matrix diagonal elements.
The 2 constraints correspond to the error limits on track values that the tracking
detector can measure, namely the x and y coordinates of the cluster hits on the
readout pads of the TPC, the azimuthal and polar angle of the track, and P1t .
The diagonal elements are 2x, 
y , 
sin, 
sin, 
, where Pt is the track transverse
momentum. The 2x and 
y are the mean square deviation of the scattered track inci-
dence points about the unscattered one. The values corresponding to these diagonal
elements are 2x < 2 cm
2, 2y < 2 cm
2, 2sin < 0.5, 
sin < 0.5, 
< 2 (GeV/c)2
respectively and are related to track momentum errors. The track cuts select good
quality tracks suppressing the background from inefficient reconstruction.
4.7.2 Kinematic cuts
The cuts in the previous section are made at track level and they select only tracks
with reasonable quality. The remaining cuts, since they reflect more on the kine-
matics of the J/ and its decay products, are called kinematic cuts, and will be
discussed giving the distribution in each of the three MC samples and data sample.
The various parameters studied are:
 Distance of Closest Approach (DCA) of J/ candidate tracks
 Cos angle between negative track and J/ flight line in j/ rest frame
 Pt transverse momentum of positive or negative track
In the first subsection, a comparison of the distributions of above mentioned pa-
rameters for candidates in primary, secondary, minimum bias and real data samples
are shown. To observe the effect of these cuts on the signal, a study on Monte-
Carlo distributions with ideal particle identification using monte-carlo information
is carried out and discussed in the next subsection.
Distance of Closest Approach The distance of closest approach (DCA) de-
notes the closest distance between the two tracks of the electron pair. The distri-
bution for DCA for all the electrons coming from primary J/ and also for electron
positron pairs originating from the decay of the secondary J/ sample, is shown in
figure 4.4 (top left and right respectively ). The distributions for electron positron
pairs from a minimum bias Monte-Carlo sample and real data are shown in figure
4.4 (bottom left and right respectively).
Cos:  is defined as the angle between negative track momentum and J/
flight line in the J/ rest frame. The distributions for the primary and secondary J/
sample are shown in figures 4.5(top left and right respectively). The distributions
in the case of a minimum bias Monte-Carlo sample and from real data are given in
figure 4.5 (bottom left and right respectively). The cos  of the background is more
populated at values 1. As there is no significant difference between the minimum
bias MC sample and real data as seen in figure 4.5, cos  is not applied in the final
cuts.
Transverse Momentum Pt: Another cut used in reducing the amount of back-
ground is the Pt of the two tracks. We denote the value of this cut as PCUTt. The
range of PCUTt from 1 GeV/c to 5 GeV/c is investigated. The implications of this
cut are shown later in this chapter. The Pt distributions of positive tracks in case of
the primary and secondary J/ samples are shown in figure 4.6 (top left and right
respectively). For the minimum bias MC sample and real data they are shown in
Entries  3720611
Mean    1.277
RMS      1.02
dca [mm]
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
10000
20000
30000
40000
50000
60000
70000
80000
90000
Entries  3720611
Mean    1.277
RMS      1.02
Entries  3826067
Mean    1.442
RMS     1.142
dca [mm]
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
10000
20000
30000
40000
50000
60000
70000
80000 Entries  3826067
Mean    1.442
RMS     1.142
Entries  429549
Mean    1.312
RMS      1.05
 dca [mm]
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
10000 Entries  429549
Mean    1.312
RMS      1.05
Entries  623893
Mean    1.403
RMS     1.106
 dca [mm]
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
10000
12000
14000
Entries  623893
Mean    1.403
RMS     1.106
Figure 4.4: DCA distribution of the two decay tracks in case of Top left: Primary,
Top right: Secondary J/ MC Sample, Bottom left: Minimum Bias MC sample and
Bottom right: real data sample. These distributions includes all type of particles.
Entries  3720611
Mean   0.001053
RMS    0.6185
-1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1
Entries  3720611
Mean   0.001053
RMS    0.6185
Entries  3826067
Mean   0.002465
RMS    0.6407
-1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1
310 Entries  3826067
Mean   0.002465
RMS    0.6407
Entries  429549
Mean   -6.302e-05
RMS    0.5766
* Cos
-1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1
Entries  429549
Mean   -6.302e-05
RMS    0.5766
Entries  623893
Mean   -0.003777
RMS    0.5625
* Cos
-1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1
Entries  623893
Mean   -0.003777
RMS    0.5625
Figure 4.5: cos  distribution in case of Top left: Primary J/ MC Sample, Top
right: Secondary J/ MC Sample, Bottom left: Minimum Bias MC and Bottom
right: data sample. These distributions includes all type of particles.
figure 4.6 (bottom left and right respectively). The Pt distributions in the case of
negative tracks are compatible with those for the positive tracks.
4.7.3 True PID distributions and Summary of the cuts
The effect of cuts on the J/ signal can be studied using so-called true PID dis-
tributions. In the MC sample a flag is available for each track, to indicate its true
identity. Therefore in order to select only those tracks which belong to generated
J/ we can use the true electron PID available in MC. Then the tuning of all
the above mentioned cuts is done using the true PID. Figures 4.7 and 4.8 show
the distribution of DCA, cos , Pt for the cases of primary and secondary J/ MC
sample with true electron identification. The lines show the position of the cuts.
Thus the cuts applied on the data are summarised below:
1. Ncls > 70 ensures good quality tracks while rejecting the background.
2. ITS and TPC refit improving the quality of tracks.
3. Rejecting Kink daughters to avoid duplication of tracks.
4. 2/Ncls < 3.5 to measure the quality of the fit to the tracks.
5. DCA of J/ candidate pair < 0.5 cm. This have been studied.
6. The positive and negative tracks transverse momenta Pt > 1.3 GeV/c (PCUTt =
1.3 GeV/c). This have been studied.
Entries  3720611
Mean    1.622
RMS     1.149
 (GeV/c)tP
0 1 2 3 4 5 6 7 8 9 10
Entries  3720611
Mean    1.622
RMS     1.149
Entries  3826067
Mean    1.763
RMS     1.388
 (GeV/c)tP
0 1 2 3 4 5 6 7 8 9 10
Entries  3826067
Mean    1.763
RMS     1.388
Entries  224375
Mean    1.519
RMS    0.9907
 (GeV/c)tP
0 1 2 3 4 5 6 7 8 9 10
10000
12000
14000 Entries  224375
Mean    1.519
RMS    0.9907
Entries  7102166
Mean    1.725
RMS     1.015
 (GeV/c)tP
0 1 2 3 4 5 6 7 8 9 10
Entries  7102166
Mean    1.725
RMS     1.015
Figure 4.6: Top left and right is the Transverse Momentum of positive tracks distri-
bution in case of Primary and Secondary J/ MC Sample. Bottom left and right is
the Transverse Momentum of positive tracks distribution in case of Minimum Bias
MC and data sample. These distributions includes all type of particles.
Entries  223586
Mean    1.017
RMS    0.8419
dca [mm]
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
Entries  223586
Mean    1.017
RMS    0.8419
Entries  223586
Mean   -0.001642
RMS    0.5821
-1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1
Entries  223586
Mean   -0.001642
RMS    0.5821
Entries  223586
Mean    2.113
RMS     1.287
 (GeV/c)tP
0 1 2 3 4 5 6 7 8 9 10
10000 Entries  223586
Mean    2.113
RMS     1.287
Entries  223586
Mean    2.105
RMS     1.277
 (GeV/c)tP
0 1 2 3 4 5 6 7 8 9 10
10000 Entries  223586
Mean    2.105
RMS     1.277
Figure 4.7: All the plots are with true electron identification in case of primary
J/ MC sample. Top left and right is the DCA and cos  distribution respectively.
Bottom left and right are the Pt distributions for positive and negative tracks re-
spectively. The red line represents where a cut has been made.
Entries  189156
Mean   0.9903
RMS    0.8371
dca [mm]
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
Entries  189156
Mean   0.9903
RMS    0.8371
Entries  189156
Mean   -0.0008722
RMS    0.5901
-1 -0.8 -0.6 -0.4 -0.2 0 0.2 0.4 0.6 0.8 1
Entries  189156
Mean   -0.0008722
RMS    0.5901
Entries  189156
Mean    2.359
RMS     1.596
 (GeV/c)tP
0 1 2 3 4 5 6 7 8 9 10
Entries  189156
Mean    2.359
RMS     1.596
Entries  189156
Mean    2.353
RMS     1.595
 (GeV/c)tP
0 1 2 3 4 5 6 7 8 9 10
Entries  189156
Mean    2.353
RMS     1.595
Figure 4.8: All the plots are with true electron identification in case of secondary
J/ MC sample. Top left and right is the DCA and cos  distribution respec-
tively. Bottom left and right is the Pt distributions for positive and negative tracks
respectively. The red line represents where a cut has been made.
7. A hit in at least one of the two innermost layers of the ITS to reduce the
contribution of electrons from  conversions
8. M = |MmeasuredMPDG| < 1.2 GeV/c2 whereMmeasured is the measured J/
mass value and MPDG is the value from the Particle Data Group(PDG) [98].
The interval has been chosen to include the J/ peak and enough background
to be able to perform a fit to the side-bands.
4.8 Particle identification using TPC dE/dx
Since true particle identification cannot be used and also since the combined PID
technique has not yet been tuned for the real data and the TRD was not complete
at that point, particle identification is done using uniquely dE/dx values from the
TPC detector. The efficiency of the cut on energy loss dE/dx is estimated from
data.
Charged particles, while traversing the TPC gas volume, interact with the gas
atoms and lose energy by ionising electrons out of the gas atoms. This ionising
energy loss per unit length, called the dE/dx, is a function of the magnitude of the
particle velocity. This property is used for particle identification. The dependence
of the specific energy loss on the particle momentum is shown in figure 4.9 and
is almost constant in the momentum range 1-6 GeV/c. The energy loss of the
charged particles is described by the Bethe-Bloch [99] formula, where low velocity
particles lose a large amount of energy. With increasing momentum the energy
loss approaches a minimum, e.g. for pions at around 0.6 GeV/c. For electrons
due to their small mass the minimum is outside the momentum range of the TPC
and their dE/dx is constant for momenta larger than 200 MeV/c. However kaons
with momenta around 600 MeV/c and protons with momenta around 1 GeV/c lose
the same amount of energy in TPC as electrons. Applying a cut on the different
particle bands on the TPC signal > 65 (arb. units see in figure (4.9)) can help in
removing the background. Thus a cut on TPC dE/dx is used to improve the signal
to background ratio. While a clear band for electrons is present in the primary and
secondary J/ MC sample, a much less pronounced contribution is visible in the
MC minimum bias. This is because electron fraction in J/psi samples is enhanced
(see discussion in section 4.5) and so background pion tracks are dominant in MB
sample. It is evident from figure 4.9 that the TPC dE/dx distributions in data and
in Monte Carlo minimum bias are different because the Monte-Carlo code for PID
has not been yet been tuned fully for real data. For this reason the efficiency of TPC
dE/dx cut is estimated using only real data. For the explanation of the different
bands, see figure 4.9 top left. In figure 4.9 bottom right, a band due to deuteron is
also visible.
The Bethe-Bloch formula [100] predicts the energy loss of charged particles in
a material. At low momentum, ionisation energy loss is approximately inversely
proportional to the square of the particle velocity. From the measured energy loss
and particle momentum, the particle type can be determined by comparing the mea-
surement against the Bethe-Bloch expectations. Figure 4.10 (left) and 4.11 (left)
show the distribution of energy loss (dE/dx) as a function of particle momentum
p in the case of real data and Monte-Carlo primary J/ samples. Different bands
correspond to different particles. These particles are separated at low p as seen in
figure 4.11 (left). As one proceeds towards higher p, they all converge together.
Momentum
0 1 2 3 4 5 6 7 8 9 10
140 Entries  7050200
Mean x   1.801
Mean y   66.43
RMS x   1.262
RMS y   16.02
Entries  7050200
Mean x   1.801
Mean y   66.43
RMS x   1.262
RMS y   16.02
Protons
Kaons
Electrons
PIONS
Momentum
0 1 2 3 4 5 6 7 8 9 10
140 Entries  7332618Mean x   1.948
Mean y   61.24
RMS x   1.503
RMS y   14.78
Entries  7332618
Mean x   1.948
Mean y   61.24
RMS x   1.503
RMS y   14.78
Momentum
0 1 2 3 4 5 6 7 8 9 10
140 Entries  453932
Mean x   2.141
Mean y   52.44
RMS x   1.395
RMS y   15.24
Entries  453932
Mean x   2.141
Mean y   52.44
RMS x   1.395
RMS y   15.24
Momentum
0 1 2 3 4 5 6 7 8 9 10
Entries     1.36527e+07
Mean x   2.054
Mean y    53.5
RMS x   1.195
RMS y   6.276
Entries     1.36527e+07
Mean x   2.054
Mean y    53.5
RMS x   1.195
RMS y   6.276
Figure 4.9: Top left and right is the TPC dE/ dx (arb. units) distribution in case of
Primary and Secondary J/ MC Sample. Bottom left and right is the TPC dE/dx
(arb. units) distribution in case of Minimum Bias MC and data Sample. In all the
plots momentum is measured in GeV/c. Deuteron band is visible in data sample.
Particles can be distinguished by a fitting procedure which allows us to disentangle
the overlapped distributions into several components. This technique was also used
by the STAR [3] experiment. Since, for a fixed particle type, the dE/dx distribution
is not a Gaussian [101], a new variable called z is used, whose distribution in mo-
mentum bins is close to a Gaussian as seen in previous experiment [3]. The variable
z is defined as:
zi = ln(
dE/dx
(dE/dx)BBi
) (4.7)
where (dE/dx) is the measured energy loss, (dE/dx)BBi is the Bethe-Bloch value of
dE/dx for a given particle type i, and i for the present case is the electron. For this
study (dE/dx)BBi is defined as
(dE/dx)BBi = Ai(1 +
) (4.8)
where mi is the particle rest mass and p is the particle momentum magnitude.
Ai is a normalisation constant determined from the data. A is chosen in such a way
that the average expected value of z for electrons is 0. Figures (4.10 (right) and 4.11
(right) show the distribution of z versus momentum for real data and primary MC
J/ sample respectively.
The electron energy loss, see figure 4.11 (left), does not depend on momentum
in the range 0.2 < p < 6 GeV/c; therefore in this range the electron PID efficiency
can be estimated as one number independent of momentum. As the J/ signal
selection uses a cut on transverse momentum of the J/ PT > 1 GeV/c or higher,
we apply the same cut on PID spectra as plotted in figures 4.12 (left) and 4.13
(left) for Monte-Carlo and data samples. A simultaneous Gaussian fit to electron
and hadron signals is used to estimate the composition of the sample and therefore
electron PID efficiency. The method is tested first on the Monte-Carlo sample and
then applied to data.
The distributions of electron and hadron signals for p > 1 GeV/c for the MC
primary sample are shown in figure 4.12 (right). In this case hadrons and electrons
are well separated. The curve is well described using one Gaussian for all hadrons
and another for electrons. The fit results are shown in figure 4.12 (right). The
fraction of electrons above the zcut is estimated as
Gausselectron(z) dz. (4.9)
where Gausselectron is the Gaussian probability density function fitted to electron
curve.
A check of the Gaussian fit can be done by retrieving results using true electron
identification, i.e. PDG identification available in Monte-Carlo. For this purpose,
a Monte-Carlo sample of 62198 primary J/ was studied. Firstly, for zcut = 0.2
and the formula (4.9), f = 0.342  0.007 is derived. Counting the number of true
electrons in MC gives
f = 1 3240/4940 = 0.344 0.011 (4.10)
which is in agreement with the fitting procedure.
A TPC dE/dx cut above 65 is equivalent to zcut = log(65/70) = 0.074, where
Momentum
0 1 2 3 4 5 6 7 8 9 10
Momentum
0 1 2 3 4 5 6 7 8 9 10
Figure 4.10: Left: Ionisation loss (dE/dx) of various particles as a function of mo-
mentum measured in GeV/c in MC Primary J/ sample; Right: z variable for
electron in MC Primary J/ sample as a function of momentum measured in GeV/c.
Momentum
0 1 2 3 4 5 6 7 8 9 10
Momentum
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5 5
Figure 4.11: Left: Ionisation loss (dE/dx) of various particles as a function of mo-
mentum measured in GeV/c in data taken with 7 TeV pp collisions; Right: z variable
for electron in data taken with 7 TeV pp collisions as a function of momentum mea-
sured in GeV/c. In both the figures red corresponds to pions, green corresponds to
kaons, blue corresponds to protons and pink to electrons.
Momentum
0 1 2 3 4 5 6 7 8 9 10
Entries  1149621
Mean x   2.034
Mean y  -0.04348
RMS x  0.9833
RMS y  0.2192
Entries  1149621
Mean x   2.034
Mean y  -0.04348
RMS x  0.9833
RMS y  0.2192
pT>0.025000 
Entries  9357
Mean   -0.01776
RMS    0.2198
 / ndf 2  92.99 / 46
Prob   5.067e-05
p0        7.5   401 
p1        0.001 -0.237 
p2        0.00099 0.08683 
p3        12.5 681.1 
p4        0.0008 0.1766 
p5        0.00068 0.05741 
Z Values
-2 -1.5 -1 -0.5 0 0.5 1 1.5 2
pT>0.025000 
Entries  9357
Mean   -0.01776
RMS    0.2198
 / ndf 2  92.99 / 46
Prob   5.067e-05
p0        7.5   401 
p1        0.001 -0.237 
p2        0.00099 0.08683 
p3        12.5 681.1 
p4        0.0008 0.1766 
p5        0.00068 0.05741 
Figure 4.12: Monte-Carlo Primary J/ sample: Left: z variable for electrons with
p > 1 GeV/c ; Right: fitted z variable with two Gaussians. The peak at z > 0
corresponds to electrons which are offset as normalisation is tuned to real data. The
peak at z < 0 corresponds to superposition of pi ,K, and p signals.
Momentum
0 1 2 3 4 5 6 7 8 9 10
Entries  1171601
Mean x   1.972
Mean y  -0.2538
RMS x  0.8487
RMS y  0.07161
Entries  1171601
Mean x   1.972
Mean y  -0.2538
RMS x  0.8487
RMS y  0.07161
p>1.325000 
Entries  106889
Mean   -0.2961
RMS    0.08521
 / ndf 2   36.1 / 38
Prob   0.5575
p0        754.5  9006 
p1        0.0040 -0.2719 
p2        0.00168 0.06626 
p3        657.0  3182 
p4        0.014 -0.371 
p5        0.00339 0.07314 
p6        103.7 220.2 
p7        0.0334 -0.1792 
p8        0.1   0.1 
p9        9.39 28.95 
p10       0.01094 0.02075 
p11       0.00889 0.03683 
Z Values
-2 -1.5 -1 -0.5 0 0.5 1 1.5 2
p>1.325000 
Entries  106889
Mean   -0.2961
RMS    0.08521
 / ndf 2   36.1 / 38
Prob   0.5575
p0        754.5  9006 
p1        0.0040 -0.2719 
p2        0.00168 0.06626 
p3        657.0  3182 
p4        0.014 -0.371 
p5        0.00339 0.07314 
p6        103.7 220.2 
p7        0.0334 -0.1792 
p8        0.1   0.1 
p9        9.39 28.95 
p10       0.01094 0.02075 
p11       0.00889 0.03683 
Figure 4.13: Data sample: Left: z variable for electrons with p > 1 GeV/c; Right:
fitted z variable with four Gaussians at p > 1 GeV/c. The black curve correspond
to the sum of four Gaussians and blue corresponds to the electron signal. Deutron
band is visible in left plot.
p>1.425000 
Entries  91385
Mean   -0.2945
RMS    0.08411
 / ndf 2  38.47 / 35
Prob   0.3151
p0        432.4  5483 
p1        0.0016 -0.2579 
p2        0.00113 0.06087 
p3        344.2  4730 
p4        0.0056 -0.3305 
p5        0.00140 0.08159 
p6        32.04 82.59 
p7        0.0349 -0.1446 
p8        0.00724 0.09927 
p9        6.88 31.98 
p10       0.00820 0.01245 
p11       0.00676 0.03744 
Z Values
-2 -1.5 -1 -0.5 0 0.5 1 1.5 2
p>1.425000 
Entries  91385
Mean   -0.2945
RMS    0.08411
 / ndf 2  38.47 / 35
Prob   0.3151
p0        432.4  5483 
p1        0.0016 -0.2579 
p2        0.00113 0.06087 
p3        344.2  4730 
p4        0.0056 -0.3305 
p5        0.00140 0.08159 
p6        32.04 82.59 
p7        0.0349 -0.1446 
p8        0.00724 0.09927 
p9        6.88 31.98 
p10       0.00820 0.01245 
p11       0.00676 0.03744 
p>1.525000 
Entries  81212
Mean   -0.293
RMS    0.08407
 / ndf 2     37 / 32
Prob   0.249
p0        329.0  3781 
p1        0.0015 -0.2537 
p2        0.00207 0.05709 
p3        284.1  5043 
p4        0.0036 -0.3145 
p5        0.00076 0.08517 
p6        6.350e+02 1.417e-07 
p7        0.1  -0.3 
p8        0.07626 0.09863 
p9        4.59 48.32 
p10       0.009065 -0.002246 
p11       0.00562 0.04869 
Z Values
-2 -1.5 -1 -0.5 0 0.5 1 1.5 2
p>1.525000 
Entries  81212
Mean   -0.293
RMS    0.08407
 / ndf 2     37 / 32
Prob   0.249
p0        329.0  3781 
p1        0.0015 -0.2537 
p2        0.00207 0.05709 
p3        284.1  5043 
p4        0.0036 -0.3145 
p5        0.00076 0.08517 
p6        6.350e+02 1.417e-07 
p7        0.1  -0.3 
p8        0.07626 0.09863 
p9        4.59 48.32 
p10       0.009065 -0.002246 
p11       0.00562 0.04869 
Figure 4.14: Data sample: Left: fitted z variable with four Gaussian at p > 1.425
GeV/c; Right: fitted z variable with four Gaussian at p > 1.525 GeV/c. The black
curve correspond to the sum of four Gaussians and blue corresponds to electron
signal.
p>1.075000 
Entries  119347
Mean   -0.2963
RMS    0.08845
 / ndf 2  40.82 / 41
Prob   0.4787
p0        52 1.101e+04 
p1        0.0006 -0.2818 
p2        0.00057 0.07155 
p3        82.3  2194 
p4        0.1  -0.4 
p5        0.00068 0.06736 
p6        26.2 195.6 
p7        0.00450 -0.09847 
p8        0.00578 0.02504 
p9        12.5 190.5 
p10       0.01 -0.05 
p11       0.00188 0.05981 
Z Values
-2 -1.5 -1 -0.5 0 0.5 1 1.5 2
p>1.075000 
Entries  119347
Mean   -0.2963
RMS    0.08845
 / ndf 2  40.82 / 41
Prob   0.4787
p0        52 1.101e+04 
p1        0.0006 -0.2818 
p2        0.00057 0.07155 
p3        82.3  2194 
p4        0.1  -0.4 
p5        0.00068 0.06736 
p6        26.2 195.6 
p7        0.00450 -0.09847 
p8        0.00578 0.02504 
p9        12.5 190.5 
p10       0.01 -0.05 
p11       0.00188 0.05981 
Z Values
-2 -1.5 -1 -0.5 0 0.5 1 1.5 2
Figure 4.15: Data sample: Left: Fitted z variable with four Gaussian at p > 1.075
GeV/c. The black curve correspond to the sum of four Gaussians and blue cor-
responds to electron signal; Right: Superposition of two momentum slices: Red
corresponds to 1.075 < p < 1.075 + 0.05 GeV/c, blue to 1.375 < p < 1.375 + 0.05
GeV/c. In the red curve a proton contamination is visible at zero and disappears
in the blue curve.
70 is the normalisation constant from the data, and the momentum dependence of z
in formula (4.7) is neglected due to the small electron mass. Using this z-cut and the
Gaussian curve from figure 4.12 (right), the estimated PID efficiency for electrons
is f = 1 0.02. Information from the true electrons gives a second estimate for the
efficiency. For electrons with pT > 1 GeV/c:
f = 1 2/4940 = 0.9996 0.0003 (4.11)
where 2 is the number of electrons that are lost and 4940 is the number of entries
in the same plot when considering only true electrons.
The distribution for electron and hadron signals for the data sample is shown in
figure 4.13. In this case the particles are not well separated due to the incomplete
TPC Calibration. Four Gaussians, one each for pions, kaons, protons and electrons,
are used in the fit.
Figure 4.13 and 4.15 demonstrates the dependence of proton contamination of
electron signal on the lepton momentum. The superposition of fitted curves to
different p are shown on the figure 4.15 (right) . The red Gaussian corresponds to
1.075 < p < 1.075 + 0.05 GeV/c, the blue one corresponds to 1.375 < p < 1.375
+ 0.05 GeV/c. As observed, there is a small proton peak around 0 in case of 1.075
< p < 1.075 + 0.05 GeV/c and this peak disappears for the higher p values.
To estimate the systematic uncertainty the electron PID efficiency is calculated
in 3 momentum regions: p > 1.325 GeV/c, p > 1.425 GeV/c, p > 1.525 GeV/c. The
fitted parameters are as shown in figures 4.13 (right), 4.14 (left), 4.14 (right). The
fraction of electrons above the zcut = log(65/70) = 0.074 is estimated following
(4.9). The three momentum ranges correspond to efficiencies as listed in table 4.1.
All the values are consistent.
Table 4.1: Values of efficiencies for different momentum ranges
Pt(GeV/c) Efficiencies
1.325 0.95  0.05
1.425 0.99  0.05
1.525 0.93  0.05
The final efficiency is thus taken as the value closest to Pt > 1.325 GeV/c and
the spread in three different momentum ranges gives the estimate of the system-
atic error. The statistical error on efficiency is calculated by propagating the fit
parameter errors  the Gaussian mean and width, using the numerical derivation
of equation (4.9)  and is estimated to be 5%. This is only partial investigation of
systematics. For example the contribution from PID calibration and the shape of
various PID curves has not been investigated here. The ALICE paper [105] follows a
more sophisticated method of PID which leads to a stronger background reduction.
However this also leads to systematics of 10%, being a dominant one.
The resulting efficiency is:
f = 0.95 0.05(stat) 0.03(sys)
4.9 Signal extraction
The J/ candidate pair distributions passing the cuts described in section 4.7 (i.e.
no pid cut) step by step is shown in figures 4.16, 4.17, 4.18 for the cases of the
primary, secondary and minimum bias J/ MC sample respectively. The pid cut is
studied in section 4.8 would be applied only to data itself. Apart from the minimum
bias sample which is purely background a peak is found at a mass of 3.1 GeV/c2,
which corresponds to the J/ mass. The mass distributions for the primary and
secondary J/ MC sample in the case of true electrons are shown in figure 4.16 and
4.17 (bottom right) respectively. The Crystal-Ball function parameters obtained
from fit to Monte-Carlo sample (see figure 4.16) are tabulated in table 4.2. The
parameters are fixed to values obtained from fit performed to data. These values
are the starting point for the fit performed to data. The fit converge to values close
to the starting point. An estimate of the signal to background ratio in each of
these cases is tabulated in tables 4.3 and 4.4 and is discussed later in this chapter.
Since signal to background is very sensitive to the Pt cut as it suppresses proton
contamination, several Pt cuts on the real data are examined later in the chapter.
4.10 Fitting the mass plot
To fit invariant mass distribution of J/ candidates, a Crystal Ball function GCBM
is used while for the background polynomial function P (Mee) is used. In the case of
the Monte-Carlo samples the background is fitted using a second order polynomial
while in the case of real data higher orders are used. The total probability density
function is:
F (Mee) = fsigGCBM(Mee) + (1 fsig)P (Mee) (4.12)
Fraction of signal fsig is defined as
fsig = nsig/Ntot
where Ntot is the total number of events in fitted sample and nsig is fit parameter.
Fraction of background events in sample nbkg is estimated as nbkg = Ntot(1  fsig
The Crystal Ball function can be defined as
GCBM(x) =
||x)n
for x < ||
)2 for x > ||
(4.13)
The Crystal Ball line-shape distribution [102] is a Gaussian with a tail on the
lower side that is used to describe the effect of radiative energy loss in an invariant
mass distribution. It uses the five parameters x, mean m, sigma , cut  , power
n. The parameter n is not necessarily an integer, and is usually held fixed in a fit:
lower values generate a longer tail. The parameter  determines the crossover point
from the Gaussian distribution to the power law tail distribution, in units of the
peak width . Typical values for || are 0.6-1.1. With  > 0 the tail is below the
peak, and with a negative value the tail is above the peak.
A maximum likelihood method (see appendix A) is used for fitting the real
data. For Pt < 1.1 GeV/c due to the strong proton contamination, a fourth order
polynomial is used while a second order polynomial is used for Pt > 1.1 GeV/c.
The mass distributions in case of real data for DCA < 0.5 cm, TPC dE/dx > 65
(arb. units) and with different Pt, are shown in figure 4.19. The results of the fit
are summarised in the tables 4.5, 4.6, 4.7, 4.8, 4.9, 4.10.
The parameters nsig (number of signal events) and nbkg (number of back-
Table 4.2: Table of Crystal-Ball function parameters from the fit to Monte-Carlo
primary J/ sample from figure 4.12.
Name Value Error
mean 3.0981 0.0006
sigma  0.0206 0.0004
alpha  0.553 0.021
n 1.485 0.037
ground events) are computed in the mass range is from 2.1 < M < 4.2 GeV/c2
(where M is the invariant mass). The probability for the non-existence of a peak
in the invariant mass distributions in figure 4.19 is respectively, from top left to
bottom right: 99%, 0.12%, 22%, 8%, 3%, and 75% (see Appendix-A for details of
the calculation).
The results of the fit are cross-checked with the subtraction method in which
like sign pairs are subtracted from unlike sign electron pairs. The distributions for
different Pt, having DCA < 0.5 cm and TPC dE/dx > 65 (arb. units), are shown
in figure 4.20. The results of the fit are shown in table 4.11. The two methods
are compatible within uncertainties and the fractional error are the same. But
the subtraction method may suffer due to the presence of correlated background
(mostly from semileptonic charm decays) in the opposite sign distribution, but also
influenced by misidentified electrons. In the ALICE publication [105] the same sign
background was multiplied with 1.25. However in this thesis no factor is applied
because the subtracted spectrum is consistant with 0 within the uncertainity. Beside
the background in the two cases is different because of the different PID procedure
applied. In rest of the thesis the average of fitting and subtraction methods will be
used as the signal; the difference relative to the mean is taken as the estimate of
the systematic error of the signal extraction. Despite of low statistics there is some
evidence that a residual background is still present and this is compatible with the
number of events in the subtraction method to be higher than as quoted in table
Tables 4.3 and 4.4 shows the signal to background ratio for the primary and
secondary J/ MC samples. These ratios were not used in thecalculations of the
cross-section for J/ but in principle shows the effectiveness of the various cuts
applied.
Table 4.3: Signal-to-Background ratio in case of Primary J/ MC sample.
Various steps S/B ratio
Without the cuts 0.31
With all the cuts mentioned in (4.7.3) 0.49
With all the cuts mentioned in (4.7.3) plus TPC dE/dx 3.39
Table 4.4: Signal-to-Background ratio in case for the Secondary J/ MC sample.
Various steps S/B ratio
Without the cuts 0.30
With all the cuts mentioned in (4.7.3) 0.41
With all the cuts mentioned in (4.7.3) plus TPC dE/dx 5.24
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
15000
20000
25000
 0.0058a0 = -0.41821 
 0.0034a1 =  0.0338 
 0.012alpha =  0.978 
 0.00013mean =  3.09596 
 0.030n =  0.619 
 2491nbkg =  516829 
 2423nsig =  181358 
 0.00014sigma =  0.02302 
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
15000
20000
25000
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
12000
 0.0089a0 = -0.47013 
 0.0052a1 =  0.0474 
 0.0075alpha =  0.9511 
 0.00016mean =  3.09532 
 0.028n =  0.681 
 1414nbkg =  177076 
 1385nsig =  92722 
 0.00017sigma =  0.02277 
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
12000
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
15000
20000
25000
 0.030a0 = -0.3862 
 0.018a1 =  0.010 
 0.0094alpha =  0.6672 
 0.00012mean =  3.09803 
 0.046n =  1.258 
 740nbkg =  31532 
 789nsig =  106889 
 0.00012sigma =  0.02035 
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
15000
20000
25000
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
9000  0.021alpha =  0.553 
 0.00058mean =  3.09812 
 0.037n =  1.485 
 11nbkg =  49 
 119nsig =  13983 
 0.00040sigma =  0.02061 
Figure 4.16: Invariant Mass (measured in GeV with natural units c=1) distributions
for primary J/ MC sample. Top left is the invariant mass plot without any cuts,
top right is with DCA < 0.5 cm, Pt > 1 GeV/c for both the positive and negative
track. Bottom left is the invariant mass distribution with the above cuts including
TPC dE/dx > 65 (arb. units). Bottom right is the invariant mass plot of the J/
with true particle identification of electrons.
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
20000
30000
40000
50000  0.0069a0 = -0.31947 
 0.0031a1 =  0.0290 
 0.00041alpha =  1.00000 
 0.00014mean =  3.09362 
 0.024n =  0.437 
 3223nbkg =  584217 
 3159nsig =  175213 
 0.00017sigma =  0.02738 
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
20000
30000
40000
50000
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
15000
20000
25000
 0.0092a0 = -0.24317 
 0.0052a1 =  0.0026 
 0.013alpha =  0.650 
 0.00017mean =  3.09809 
 0.079n =  1.176 
 1520nbkg =  225323 
 1475nsig =  91698 
 0.00020sigma =  0.02108 
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
15000
20000
25000
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
12000
14000
16000
18000
20000  0.042a0 = -0.4882 
 0.025a1 =  0.062 
 0.010alpha =  0.637 
 0.00014mean =  3.09783 
 0.060n =  1.420 
 595nbkg =  16448 
 651nsig =  86194 
 0.00013sigma =  0.02127 
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
10000
12000
14000
16000
18000
20000
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
 0.039alpha =  0.587 
 0.0011mean =  3.0962 
 0.071n =  1.513 
 8.4nbkg =  23.9 
 68nsig =  4584 
 0.00084sigma =  0.02394 
Figure 4.17: Invariant Mass (measured in GeV with natural units c=1) distributions
for secondary J/ MC sample. Top left is the invariant mass plot without any cuts,
top right is with DCA< 5 cm, Pt > 1 GeV/c for both the positive and negative
track. Bottom left is the invariant mass distribution with the above cuts including
TPC dE/dx > 65 (arb. units). Bottom right is the invariant mass plot of the J/
with true particle identification of electrons.
Entries  200974
Mean    2.976
RMS    0.3805
Invariant mass [GeV]
2.6 2.8 3 3.2 3.4 3.6 3.8 4
Entries  200974
Mean    2.976
RMS    0.3805
Entries  41316
Mean    3.011
RMS    0.3908
Invariant mass [GeV]
2.6 2.8 3 3.2 3.4 3.6 3.8 4
1200 Entries  41316
Mean    3.011
RMS    0.3908
Entries  4938
Mean    3.047
RMS    0.3635
Invariant mass [GeV]
2.6 2.8 3 3.2 3.4 3.6 3.8 4
250 Entries  4938
Mean    3.047
RMS    0.3635
Figure 4.18: Invariant Mass (measured in GeV with natural units c=1) distributions
for Minimum Bias MC sample. Top left is the invariant mass plot without any cuts,
top right is with DCA< 0.5 cm, Pt > 1 GeV/c for both the positive and negative
track. Bottom left in the invariant mass distribution with the above cuts including
TPC dE/dx > 65 (arb. units). Applying true particle identification all the events
are removed.
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
Figure 4.19: Invariant Mass distributions in case of real data sample measured in
GeV with natural units c=1. Top left is the invariant mass plot with Pt > 1 GeV/c,
right is with Pt > 1.1 GeV/c. In the middle row, left is with Pt > 1.2 GeV/c while
right is with Pt > 1.3 GeV/c. At bottom, left is with Pt > 1.4 GeV/c and right with
Pt > 1.5 GeV/c. The bin size is randomly chosen bylikelihood fit. The probabilities
for non-existence of the peak in the various cases is specified in the main text.
Table 4.5: Table of parameters from the likelihood fit with PCUTt = 1.0 GeV/c
Numbers Name Value Error Step-size
1 a0 -1.16 0.02 4.9e-05
2 a1 0.59 0.02 4.0e-05
3 a2 -0.26 0.02 3.5e-05
4 a3 0.08 0.02 3.3e-04
5 nbkg 6735.4 87.1 1.8e-04
6 nsig 74.4 31.6 6.0e-04
Table 4.6: Table of parameters from the likelihood fit with PCUTt = 1.1 GeV/c
Numbers Name Value Error Step-size
1 a0 -0.64 0.04 5.7e-05
2 a1 -1.9e-03 0.04 5.2e-05
3 a2 0.13 0.03 4.7e-05
4 a3 -0.12 0.03 9.4e-05
6 nbkg 2609.7 55.3 2.2e-05
7 nsig 76.2 22.9 5.8e-05
Table 4.7: Table of parameters from the likelihood fit with PCUTt = 1.2 GeV/c
Numbers Name Value Error Step-size
1 a0 -0.27 0.05 5.8e-04
2 a1 -0.12 0.05 3.8e-05
3 nbkg 1277.9 39.1 2.1e-04
4 nsig 62.8 17.8 8.5e-04
Table 4.8: Table of parameters from the likelihood fit with PCUTt = 1.3 GeV/c
Numbers Name Value Error Step-size
1 a0 -0.06 0.06 5.6e-04
2 a1 -0.12 0.06 3.7e-05
3 nbkg 849.2 31.9 5.6e-05
4 nsig 56.8 15.1 1.18e-04
Table 4.9: Table of parameters from the likelihood fit with PCUTt = 1.4 GeV/c
Numbers Name Value Error Step-size
1 a0 0.04 0.07 5.4e-04
2 a1 -0.12 0.07 1.8e-04
3 nbkg 630.3 27.4 4.7e-05
4 nsig 41.7 12.9 9.9e-05
Table 4.10: Table of parameters from the likelihood fit with PCUTt = 1.5 GeV/c
Numbers Name Value Error Step-size
1 a0 7.7e-03 0.08 5.3e-04
2 a1 -0.04 0.08 3.4e-05
3 nbkg 474.2 23.9 4.0e-05
4 nsig 34.0 11.5 8.2e-05
)2Invariant Mass (GeV/c
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
)2Invariant Mass (GeV/c
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
)2Invariant Mass (GeV/c
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
)2Invariant Mass (GeV/c
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
)2Invariant Mass (GeV/c
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
)2Invariant Mass (GeV/c
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
Figure 4.20: Invariant mass distributions in case of real data sample when like signs
are subtracted from unlike signs. Top left is the invariant mass plot with Pt > 1
GeV/c, right is with Pt > 1.1 GeV/c. In the middle, left is the invariant mass
distribution with Pt > 1.2 while right is with Pt > 1.3 GeV/c. At bottom left, is
with Pt > 1.4 GeV/c and right with Pt > 1.5 GeV/c. Outside the signal region, the
subtracted spectrum is consistant with 0 within the uncertaninty.
Table 4.11: Table of comparison of nsig with the errors for different Pt using the
subtraction method and fitting method. nsig is the number of signal events that are
computed in the mass range from 2.1 < M < 4.2 GeV/c2 (where M is the invariant
mass). The yields in the 2nd and 3rd coulomn are relative to same data sample.
The fractional errors of the two yields are similar. Therefore the uncertainties on
the average yield is taken as the fractional error of the yield in the 2nd column, in
order to take into account the correlation.
PCUTt [GeV/c] nsig (subtraction method) nsig (fitting method) average
1.0 76  45 74  32 75  39
1.1 81  35 76  23 79  30
1.2 73  26 63  18 68  22
1.3 77  21 57  15 67  18
1.4 80  18 42  13 61  16
1.5 53  15 34  12 44  14
4.11 Conclusions
Thus all the cuts mentioned above help in improving the signal(S)-to-background(B)
ratio. From the fitted values, S and B are extracted. In the case of the Primary J/
MC sample (figure(4.16)), the ratios of signal to background before and after the cuts
are 0.31 and 3.9 respectively, while for the secondary J/ MC sample (figure(4.17)),
the ratios are 0.30 and 5.24 respectively. In the case of real data the likelihood fit
is performed on different Pt ranges to see the variation of S/B ratio. The difference
between the signal from fitting and subtraction method (see table 4.11) is taken as
estimate of systematic error. The choice of Pt is explained in the next chapter. The
corrected yield will be discussed and calculated in the next chapter.
Chapter 5
Production of J/  e+e in the
ALICE Experiment
5.1 Introduction to the Correction Framework
In ALICE a framework has been developed to assist users in deriving the corrections
for their respective analysis. The main utilities provided by this Correction Frame-
work (CORRFW)[103] are the possibilities to store, while performing analysis, both
real and simulated data over binned N-dimensional grids. It then derives the effi-
ciency correction maps and corrects the observed data (all stored in the so-called
Container Class). Also general selections which may be common to several analy-
sis, at different stages of the selection process (for example, generator, acceptance,
reconstruction, user-specific analysis selection), are done within this framework and
the selection variables are all stored in the so-called Selection Class . The user can
then calculate efficiencies in terms of the steps one chooses: for example, the ratio
between reconstructed and generated levels.
Figure 5.1 shows the general scheme for the CF Container Classes, indicating
the main functionalities of each class and the relationships between them. For the
Correction Framework in ALICE the two main classes can be categorized into:
 Container Class
 Selection Class
This framework was first used forD0  K. Taking that as the base, it was modified
by the author for the analysis of J/  e+e.
Figure 5.1: General scheme of the CF Container Classes, indicating the main func-
tionalities of each class and relationships between them.
5.2 Steps in the Correction Framework
5.2.1 Steps at the Generated Level and Reconstructed level
The various selection steps involved at the generation and reconstruction level are:
 particle generation cuts performed on non-kinematic variables of generated
particles (PDG value, production vertex, charge etc);
 kinematic cuts, applied both to the generated and reconstructed tracks for a
given range in momentum and pseudo-rapidity;
 track quality cuts;
 selection cuts for J/ analysis.
For the efficiency calculations inside the correction framework, a container is
defined with a 5-dimensional grid. 5 analysis steps are selected, 2 steps at the
generated Monte-Carlo level and 3 at reconstructed level. For each of the 5 steps,
five physical variables are considered: invariant mass M , transverse momentum PT
and rapidity y of J/, transverse momentum of electron (or positron) PT and cos 
of the electron. The transverse momentum PT and cos 
 of the positron is the same
as that of electron.
The two steps at the generated level select the Monte-Carlo J/ decaying into
dielectrons inside the fiducial volume which satisfies the condition PGENT > PCUTt
GeV/c and GENt < 0.9 for each lepton track.
The steps at the reconstructed level start by looking at reconstructed e+e pairs.
The second step at reconstructed level looks for the (e+e) candidates which pass
the condition PRECT > PCUTt GeV/c and 
t < 0.9 (known as the acceptance
step), along with ITS Cluster  5 (known as ITSCls cut) and TPC Cluster > 70 to
improve track quality. The third and final reconstructed step includes J/ selection
cuts. For the present studies, the selection cuts include the list of cuts studied
in chapter 4 except TPC dE/dx, which was considered in the previous chapter 4,
section 4.8.
The AnalysisTask was run on the two AODs simultaneously. For each J/ can-
didate, either simulated or reconstructed, the five physical variables were calculated
and the corresponding grid filled. Figures 5.2 - 5.6 shows the distributions of all 5
variables passing through the different analysis steps for a sample of primary J/
sample containing 106 events. In the tables 5.2 and 5.3:
 Step1 refers to Monte-Carlo generated J/.
 Step2 refers to MC generated J/ passing acceptance cuts.
 Step3 is the reconstructed J/ candidates.
 Step4 includes step3 with acceptance, ITS and TPC Clusters cuts to improve
track quality.
 Step5 includes step4 with selection cuts for J/ analysis.
From the various steps one can define the acceptance and efficiencies as:
 The geometrical acceptance: acc = step2/step1.
 The reconstruction efficiency: eff
reco = step3/step2
 Track Cluster Cut efficiency: eff
cluster = step4/step3.
 Analysis efficiency: eff
=step5/step4.
 The weight: 1/w = acc eff
reco  eff cluster  eff anal =step5/step1.
To maximise the number of J/ candidates the selection cutsare left as open as
possible leading to almost 100% analysis efficency.
5.2.2 Calculation of J/ yield
Assuming that the Particle Identification (PID) procedure has 100% efficiency, and
the Monte-Carlo sample was generated with the correct pT and y distributions for
the J/, the observed yield Y is:
Y = Nsignal  w (5.1)
where Nsignal is taken from the fit to the invariant mass spectrum for data, (figure
5.9) and the weight is w = N
signal
, where NGen is the number of generated J/ at
step1 and NGensignal is the number of reconstructed J/ in step5.
If instead the PID procedure is not fully efficient, the corrected number of J/
is given by
NPIDJ/ =
Nsignal
(5.2)
where f is the efficiency of electron identification (detailed discussion in section 4.8).
The residual contamination from hadrons is assumed to be removed by using either
a fit to the signal and background or by like-sign pair background subtraction (see
section 4.10). The validity of this assumption is demonstrated in table 5.1 where a
MC sample of primary J/ is used to compare the fit results and like-sign subtracted
Nsignal with respect to known number of J/ .
Table 5.1: Evaluation of signal extraction by fitting compared to like-sign pair sub-
traction. The cuts are those described in section 4.7.3. PID selection is done by MC
TPC energy loss dE/dx.
No. of events Fitting method Like-sign subtraction
True 10000 1006 1006
Cuts without PID 10000 1186  204 1029  64
Cuts with PID 10000 1183  79 1033  41
Therefore the corrected number of J/ is instead :
Y = NPIDJ/  w. (5.3)
The geometrical acceptance acc, reconstruction efficiency eff
reco, track cluster
cut efficiency eff
cluster, analysis efficiency eff anal and weight w for primary and
secondary MC J/ samples for transverse momenta of J/ decay products PT <
1 GeV/c (i.e. PCUTT = 1) are given in table 5.2. The average acceptance for the
secondary J/ is higher than for primary J/ due to the difference in the kinematic
distributions. On the contrary, reconstruction efficiency is higher for the primary
J/ sample due to the selection of primary tracks. As a result, the final weights for
primary and secondary J/ are comparable. The J/ selection cuts do not bias the
data sample with respect to the origin of the J/ (primary and secondary). In tables
5.3 and 5.4, the acc, eff , and the w are given for different PCUTT in case of primary
and secondary J/ MC sample. The acceptances decrease with the increase of PT
while the efficiencies remains the same. This is due to the fact that the distribution
of lepton momenta has a maximum around 1 GeV/c. So, bigger PCUTT means
that we are losing more J/. The final weights for primary and secondary J/ are
comparable.
Table 5.2: Table of acceptance and efficiency for Primary and Secondary J/ MC
sample for PTCUTT = 1 GeV/c.
Steps Primary MC J/ sample Secondary MC J/ sample
acc =step2/step1 0.325  0.002 0.378  0.003
effreco = step3/step2 0.808  0.001 0.650  0.001
effcluster =step4/step3 0.658  0.001 0.658  0.001
effanal =step5/step4 0.999  0.0002 0.999  0.002
1/w =step5/step1 0.173  0.001 0.162  0.001
The fraction of secondary J/ at the LHC energy of 7 TeV is estimated to be
about 20% [104] with large uncertainty. To estimate the uncertainty due to the
differences in correction factors for primary and secondary J/ (see table 5.2), the
final weight is taken as the average ( assuming equal proportions) of the weights of
primary and secondary J/ for PCUTt = 1.3 GeV/c:
1/w = 0.1025 0.0028 (5.4)
Table 5.3: Table of acceptance and efficiency for Primary J/ MC sample with
different PCUTT cuts.
PCUTt[GeV/c] acc =step2/step1 eff = step5/step2 1/w = step5/step1
1.1 0.266  0.001 0.533  0.001 0.142  0.001
1.2 0.235  0.001 0.523  0.001 0.123  0.007
1.3 0.201  0.001 0.511  0.001 0.103  0.004
1.4 0.167  0.001 0.507  0.001 0.085  0.004
1.5 0.135  0.001 0.506  0.001 0.068  0.004
Table 5.4: Table of acceptance and efficiency for Secondary J/ MC sample with
different PT cuts.
PCUTt[GeV/c] acc =step2/step1 eff = step5/step2 1/w = step5/step1
1.1 0.352  0.001 0.392 0.001 0.137  0.001
1.2 0.317  0.001 0.365  0.001 0.116  0.007
1.3 0.282  0.001 0.362  0.001 0.102  0.004
1.4 0.247  0.001 0.358  0.001 0.088  0.004
1.5 0.215  0.001 0.352  0.001 0.076  0.004
and the difference between the two estimates is within statistical error. Recent mea-
surement from other LHC experiment indicate a substantial component of secondary
J/. The exact ratio between primary and secondary J/ has small impact on the
weight because the acceptance are very similar.
The next source of systematic error to be considered is the dependence of the
weight on the J/ momentum distribution. A simple Monte-Carlo is used to es-
timate this effect. The Monte-Carlo takes into account the kinematics of the J/
decay and the acceptance of the ALICE TPC detector. In accordance with the
PYTHIA generator, J/ particles with a flat rapidity distribution and exponen-
tial transverse momentum distribution dN/dPT  P 1.5T exp(PT ), with  = 0.95
GeV 1 are generated. The calculated acceptance for  = 0.95 GeV 1 is equivalent
to the acceptance as defined in table 5.3; and gives the value of 0.201 indeed. To
study the influence of the momentum distribution on acceptance, the transverse
momentum distribution is modified by changing the slope  by 10%, and the flat
rapidity distribution is modified to a Gaussian with  = 6 as estimated from AL-
ICE dimuon data [105]. The results are in table 5.5. A systematic error of 13% is
calculated, as maximum difference between the reference value and the values from
modified distribution acceptances.
The other source of systematic error is the unknown J/ polarization. The
angular distribution of leptons from J/ decay, integrated over the azimuthal angle,
is given by [106]
d cos 
= A(1 +  cos2 ) (5.5)
where A is a normalization constant and  is the angle between the momentum
vector of electron (positron) and the direction of J/ momentum in the J/ rest
frame. The polarization parameter   [1, 1] is related to the dynamics of the J/
production. The systematic uncertainty due to the polarization is estimated as the
variation of J/ acceptance between  = 1 and  = 1 in two different J/ centre
of mass frames (for details see appendix B). The results are in table 5.6. The errors
are quoted as a percentage.
Table 5.5: Variation of J/ acceptance with momentum distribution for different 
values.
Rapidity Distribution Slope  = 0.95  = 1.045  = 0.855
Flat 0.201 0.193 0.214
Gauss 0.208 0.199 0.220
Table 5.6: Variation of J/ acceptance with polarization both for Helicity (HE) and
Collins-Soper (CS) frames. For example the percentage error for = -1 represents
the difference between the acceptance for  = -1 with respect to  = 0.
 = 0  = 1  = 1
acc. (HE) 0.201 0.248 0.179
Error (HE) 0 +18.9% -12.3%
acc. (CS) 0.201 0.260 0.173
Error (CS) 0 +22.7% -16.2%
5.3 Checking of correction procedure using Monte-
Carlo Samples
For real data, the J/ yield is calculated by multiplying the raw number of J/
obtained from the reconstructed distribution by the correction factor, i.e the weight
w. To check the procedure, an exercise was performed using a fraction of Monte-
Carlo data in the role of real data, using the correction framework (CORRFW).
The MC sample of primary J/ containing about 2 million events was divided into
two halves (sample 1 and sample 2). Sample 1 was considered to be real data (964200
events) while the sample 2 (933336 events) was used to retrieve the correction factor.
The invariant mass distributions for each of the correction framework steps for the
first half are shown in figure 5.7; the fitted mass plots after step5 are shown in figure
5.8 for both samples. Figure 5.8 (left) refers to the first half and 5.8 (right) refers
to the second half.
The correction factor w obtained from the sample 2 is defined as the ratio of the
number of J/ in step 1 to the Nsignal from the step 5 when fitted with Crystal-Ball
function. Thus according to relation (5.1):
N(J/) = w Nsignal (5.6)
where Nsignal is the number of J/ when fitted with Crystal-Ball in step 5 from
sample 1 and N(J/) is the corrected Number of J/ in step 1 from sample 2.
Substituting the values in equation (5.6) gives:
NJ/ =
944200
17569
 17293 = 929367. (5.7)
The error of the result is the sum of fractional errors on the weight w and Nsignal,
giving:
NJ/ = 930, 000 10, 000 (5.8)
This result is to be compared with the total number of J/ generated for the
sample 2 which is 933336. Therefore the result is less than 1 standard deviation
from the corrected value.
5.4 Measurement of the inclusive production J/
cross-section (J/)
The J/ cross-section (sum of primary and secondary production) J/ is defined
J/ =
(5.9)
where L is the integrated luminosity for the analyzed data sample and it is calcu-
lated as in equation 5.10. The integrated luminosity corresponding to the data set
analyzed in this thesis is (1.25 0.09) nb1:
= (1.25 0.09) nb1 (5.10)
where MB = 62.3  0.4 (stat)  4.3 (syst) mb is the cross-section of minimum
bias events measured in a Van Der Meer scan [108] and NMB = 78 million is the
number of recorded minimum bias events..
The corresponding invariant mass plot of J/ with the selection cuts described
in section (5.2.1) is shown in figure 5.9 and for an independent analysis done by
ALICE [105] is shown in figure 5.10 respectively. In table 4.11 the results of the
average between maximum likelihood fit and subtraction method gives for J/ decat
product transverse momenta PT > 1.3 Gev/c (i.e. PTCUTT = 1.3 GeV/c):
NJ/ = 67 18 (5.11)
The dependence of NJ/ on the PT range was studied. The maximum likelihood
fit was performed in six different PT bins starting from 1.0 GeV/c to 1.5 GeV/c.
For the calculation of the J/ cross-section, PTCUTT > 1.3 GeV/c is chosen as the
pion contamination is least with this cut.
The PID efficiency for electrons as calculated in section (4.8) is
f = 0.95 0.05
The total correction factor for PTCUTT > 1.3 GeV/c is w = 9.76  0.04. So the
corrected yield is
NPIDJ/
0.952
 9.76 (5.12)
Y = 725 195 (5.13)
The yields resulting from table 4.11, corresponding to different cuts PT (PTCUTT )
are given in table 5.7.
Table 5.7: Comparison of yields for different PTCUTT resulting from fitting proce-
PTCUTT (GeV/c) Yield from fitting
1.0 480  250
1.1 616  242
1.2 612  204
1.3 725  195
1.4 795  209
1.5 717  228
Therefore the cross-section for J/  e+e is
(J/  e+e) =
(5.14)
(J/  e+e) = [580 156(stat.)] nb (5.15)
Given that the branching ratio of J/  e+e:
J/  e+e = (5.94 0.06)% (5.16)
Therefore the cross-section is:
(J/) =
(J/  e+e)
0.0594
(5.17)
Thus the final cross-section of the J/ for |y| < 0.9, Pt > 0 is:
(J/) = [9.8 2.6(stat.) 1.8(sys.)1.5+2.0(syst.pol.)] b (5.18)
(J/), (|y| < 0.9, Pt > 0) (5.19)
Table (5.8) contains a summary of the systematic errors. The first column de-
scribes the source of systematic error, the second column is the estimated magnitude
of the uncertainty. The third column refers to where the procedure of error estima-
tion is described.
5.5 Comparison with other experiments
The J/ production in p+ p collisions at
s = 200 GeV has been measured by the
PHENIX experiment at the BNL Relativistic Heavy Ion Collider (RHIC) [109], by
Table 5.8: Table of Systematic Errors
Sources of systematic errors Percentage (%) Reference
Signal Extraction 15 Section 4.10
PID cuts 4 Section 4.8
Primary/Secondary J/ < 3 Section 5.2.2
PT and y distribution 13.0 Section 5.2.2
Total systematic error 20
Polarization  = 1  = +1 Section 5.2.2
CS +22.7 -16.2
HE +18.9 -12.3
CDF [110] in pp collisions at
s = 1960 GeV and by the ATLAS [111], CMS [104]
and ALICE [105] and LHCb [112] experiments at 7 TeV at LHC.
The PHENIX experiment measures the J/ production for transverse momen-
tum PT > 0 GeV/c in two rapidity windows: |y| < 0.35 for dielectrons and
|y|  [1.2, 2.2] for dimuons. The total cross-section times the branching ratio
pp = 178  3(stat.)  53(stat.)  18(norm) nb is obtained from a fit to the
measured J/ rapidity distribution using a double Gaussian. The cross-section at
central rapidity used for comparison in this section is read from figure 4 of paper
[109] as BR(J/  e+e) d/dy(y = 0) = 43.0 2.5(stat) 5.0(sys) nb.
The CDF experiment measures the J/ production for transverse momentum
PT > 0 GeV/c in rapidity window |y| < 0.6 in the dimuon channel. The J/ cross-
section of 4.08  0.02(stat)+0.360.33 (syst) b is measured in this window. The value at
central rapidity is obtained dividing by 1.2 ( the width of the rapidity window).
The CMS experiment measures the J/ production for transverse momentum
PT > 6.5 GeV/c and in a rapidity window |y| < 2.4, in the dimuon channel. The
J/ cross-section times the dimuon decay branching fraction is 70.9  2.1(stat.) 
3.0(sys)  7.8(luminosity) nb for the prompt J/ meson, and 26.0  1.4(stat.) 
1.6(syst.) 2.9(luminosity) nb for the J/ mesons from b-hadron decays.
The ATLAS experiment measures the J/ production for transverse momentum
PT > 7 GeV/c and in a rapidity window |y| < 2.4, in the dimuon channel. The J/
cross-section times the dimuon decay branching fraction is 591(stat.)8.0(sys)
2(luminosity) nb for the prompt J/ meson, and 23.0  0.6(stat.)  2.8(syst.) 
0.8(luminosity) nb for the J/ mesons from b-hadron decays.
The LHCb experiment measures the J/ production for transverse momentum
PT  [0, 14] GeV/c and in a rapidity window |y|  [2.0; 4.5] in the dimuon channel.
The measured J/ cross-sections are 10.50.04(stat.)1.40(sys) nb for the prompt
J/ meson, and 1.140.01(stat.)0.16(syst.) b for the J/ mesons from b-hadron
decays.
The cross-sections at y = 0 for PHENIX , CDF, and ALICE experiments as a
function of centre of mass energies of colliding beams are shown in figure 5.11. The
ATLAS, CMS and LHCb points cannot be added due to the transverse momentum
cut (ATLAS, CMS) and rapidity (LHCb) cuts. For the ALICE experiment two
points are presented. The red one corresponds to results published in [105] (10.7
1.2(stat.) 1.7(syst.)+1.62.3) b and was produced by an analysis of full ALICE data
set done independently from that presented in this thesis. The blue one is the result
of analysis presented in this thesis.
Entries  1897536
Mean    3.092
RMS    4.215e-008
M_JPSI (GeV/c
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
Entries  1897536
Mean    3.092
RMS    4.215e-008
Entries  277915
Mean    3.092
RMS    4.215e-008
) 2M_JPSI (GeV/c
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
Entries  277915
Mean    3.092
RMS    4.215e-008
Entries  224639
Mean    3.024
RMS    0.1072
) 2M_JPSI (GeV/c
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
Entries  224639
Mean    3.024
RMS    0.1072
Entries  147864
Mean    3.029
RMS     0.103
) 2M_JPSI (GeV/c
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
Entries  147864
Mean    3.029
RMS     0.103
Entries  147841
Mean    3.029
RMS     0.103
) 2M_JPSI (GeV/c
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
Entries  147841
Mean    3.029
RMS     0.103
Figure 5.2: Top left: Invariant mass of primary J/ at the generated level; Top
right: Invariant mass of J/ at the generated level including the acceptance cuts;
Middle left: Invariant mass of J/ at reconstructed level including the vertex and
refit cuts; Middle right: Invariant mass of J/ including above cuts, acceptance and
ITSCluster cuts; Bottom left: Invariant mass of J/ including all above selection
criteria and selection cuts mentioned in chapter 4. Mass is measured in GeV (natural
units for c=1)
Entries  1897536
Mean    2.174
RMS     0.981
pT_JPSI (GeV/c)
0.5 1 1.5 2 2.5 3 3.5 4 4.5
Entries  1897536
Mean    2.174
RMS     0.981
Entries  277915
Mean    2.123
RMS     1.047
pT_JPSI (GeV/c)
0.5 1 1.5 2 2.5 3 3.5 4 4.5
10000
20000
30000
40000
50000
60000
70000
Entries  277915
Mean    2.123
RMS     1.047
Entries  224639
Mean    2.169
RMS    0.9919
pT_JPSI (GeV/c)
0.5 1 1.5 2 2.5 3 3.5 4 4.5
10000
20000
30000
40000
50000
60000
Entries  224639
Mean    2.169
RMS    0.9919
Entries  147864
Mean    2.097
RMS     1.042
pT_JPSI (GeV/c)
0.5 1 1.5 2 2.5 3 3.5 4 4.5
10000
15000
20000
25000
30000
35000
Entries  147864
Mean    2.097
RMS     1.042
Entries  147841
Mean    2.097
RMS     1.042
pT_JPSI (GeV/c)
0.5 1 1.5 2 2.5 3 3.5 4 4.5
10000
15000
20000
25000
30000
35000
Entries  147841
Mean    2.097
RMS     1.042
Figure 5.3: Top left: PT of J/ at the generated level, Top right: PT of J/
at the generated level including the acceptance cuts, Middle left: PT of J/ at
reconstructed level including the vertex and refit cuts, Middle right: PT of J/
including above cuts, acceptance and ITSCluster cuts, Bottom left: PT of J/
including above and selection cuts.
Entries  1897536
Mean   -4.943e-005
RMS    0.5769
cosThetaStar
-1 -0.5 0 0.5 1
Entries  1897536
Mean   -4.943e-005
RMS    0.5769
Entries  277915
Mean   -0.0002264
RMS      0.45
cosThetaStar
-1 -0.5 0 0.5 1
Entries  277915
Mean   -0.0002264
RMS      0.45
Entries  224639
Mean   -0.001669
RMS    0.5828
cosThetaStar
-1 -0.5 0 0.5 1
Entries  224639
Mean   -0.001669
RMS    0.5828
Entries  147864
Mean   -0.0004044
RMS    0.4345
cosThetaStar
-1 -0.5 0 0.5 1
Entries  147864
Mean   -0.0004044
RMS    0.4345
Entries  147841
Mean   -0.000404
RMS    0.4343
cosThetaStar
-1 -0.5 0 0.5 1
Entries  147841
Mean   -0.000404
RMS    0.4343
Figure 5.4: Top left: Rapidity of J/ at the generated level, Top right: Rapidity of
J/ at the generated level including the acceptance cuts, Middle left: Rapidity of
J/ at reconstructed level including the vertex and refit cuts, Middle right: Rapidity
of J/ including above cuts, acceptance and ITSCluster cuts, Bottom left: Rapidity
of J/ including above and selection cuts.
Entries  1897536
Mean    1.825
RMS     1.131
pT_Ele (GeV/c)
0 1 2 3 4 5 6 7 8 9 10
Entries  1897536
Mean    1.825
RMS     1.131
Entries  277915
Mean    2.117
RMS    0.9671
pT_Ele (GeV/c)
0 1 2 3 4 5 6 7 8 9 10
Entries  277915
Mean    2.117
RMS    0.9671
Entries  224639
Mean    1.974
RMS     1.106
pT_Ele (GeV/c)
0 1 2 3 4 5 6 7 8 9 10
Entries  224639
Mean    1.974
RMS     1.106
Entries  147864
Mean    2.056
RMS    0.9386
pT_Ele (GeV/c)
0 1 2 3 4 5 6 7 8 9 10
Entries  147864
Mean    2.056
RMS    0.9386
Entries  147841
Mean    2.056
RMS    0.9386
pT_Ele (GeV/c)
0 1 2 3 4 5 6 7 8 9 10
Entries  147841
Mean    2.056
RMS    0.9386
Figure 5.5: Top left: PT of electrons at the generated level, Top right: PT of electrons
at the generated level including the acceptance cuts, Middle left: PT of electrons at
reconstructed level including the vertex and refit cuts, Middle right: PT of electrons
including above cuts, acceptance and ITSCluster cuts, Bottom left: PT of electron
or positrons including above and selection cuts.
Entries  1897536
Mean   -4.943e-05
RMS    0.5769
cosThetaStar
-1 -0.5 0 0.5 1
Entries  1897536
Mean   -4.943e-05
RMS    0.5769
Entries  277915
Mean   -0.0002264
RMS      0.45
cosThetaStar
-1 -0.5 0 0.5 1
Entries  277915
Mean   -0.0002264
RMS      0.45
Entries  224639
Mean   -0.001669
RMS    0.5828
cosThetaStar
-1 -0.5 0 0.5 1
Entries  224639
Mean   -0.001669
RMS    0.5828
Entries  147864
Mean   -0.0004044
RMS    0.4345
cosThetaStar
-1 -0.5 0 0.5 1
Entries  147864
Mean   -0.0004044
RMS    0.4345
Entries  147841
Mean   -0.000404
RMS    0.4343
cosThetaStar
-1 -0.5 0 0.5 1
Entries  147841
Mean   -0.000404
RMS    0.4343
Figure 5.6: Top left: cos  distribution at the generated level, Top right: cos 
distribution at the generated level including the acceptance cuts, Middle left: cos 
distribution at reconstructed level including the vertex and refit cuts, Middle right:
cos  distribution including above cuts, acceptance and ITSCluster cuts, Bottom
left: cos  distribution including above and selection cuts.
Entries  964200
Mean    3.092
RMS    4.107e-08
Mass_JPSI (GeV)
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
10 Entries  964200Mean    3.092
RMS    4.107e-08
Entries  196444
Mean    3.092
RMS    4.16e-08
Mass_JPSI (GeV)
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
10 Entries  196444Mean    3.092
RMS    4.16e-08
Entries  57171
Mean    3.025
RMS    0.1074
Mass_JPSI (GeV)
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
Entries  57171
Mean    3.025
RMS    0.1074
Entries  51866
Mean    3.025
RMS    0.1076
Mass_JPSI (GeV)
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
Entries  51866
Mean    3.025
RMS    0.1076
Entries  22086
Mean    3.028
RMS    0.1036
Mass_JPSI (GeV)
2.7 2.8 2.9 3 3.1 3.2 3.3 3.4 3.5
10 Entries  22086Mean    3.028
RMS    0.1036
Figure 5.7: Top left: Invariant mass of primary J/ at the generated level; Top
right: Invariant mass of J/ at the generated level including the acceptance cuts;
Middle left: Invariant mass of J/ at reconstructed level including the vertex and
refit cuts; Middle right: Invariant mass of J/ including above cuts, acceptance and
ITSCluster cuts; Bottom left: Invariant mass of J/ including above and selection
Cuts. Mass is measured in GeV (natural units for c=1)
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
 0.022a0 = -1.3624 
 0.025a1 =  0.377 
 0.021alpha =  0.605 
 0.00035mean =  3.09915 
 0.11n =  1.51 
 174nbkg =  1023 
 216nsig =  17569 
 0.00028sigma =  0.02087 
Invariant Mass [GeV]
2.8 2.9 3 3.1 3.2 3.3 3.4
 0.046a0 = -1.3092 
 0.077a1 =  0.286 
 0.021alpha =  0.604 
 0.00034mean =  3.09934 
 0.12n =  1.50 
 186nbkg =  866 
 226nsig =  17293 
 0.00027sigma =  0.02066 
Figure 5.8: Left: Invariant mass distribution of primary J/ after step 5 when
fitted with Crystal-Ball function for sample 1; Right: Invariant mass distribution
of primary J/ after step 5 when fitted with Crystal-Ball for sample 2. Mass is
measured in GeV (natural units for c=1). The bin size has been automatically
chosen by root.
Invariant Mass (GeV)
2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4 4.2
Figure 5.9: J/ invariant mass distribution for real data, for 78 million events
passing all the selection cuts mentioned in section (5.2.1), when fitted with Crystal-
Ball function.
1.5 2 2.5 3 3.5 4 4.5 5
LS*1.25
=7 TeVsALICE  pp   
)2 (GeV/ceem
1.5 2 2.5 3 3.5 4 4.5 5
OS-1.25*LS
/dof=1.1)2MC (
Figure 5.10: J/ invariant mass distribution for real data as cited in [105]. Top:
invariant mass distribution for like-sign (LS) and opposite-sign (OS) electron pairs.
Bottom: the difference of the two distributions with the fit to the Monte-Carlo (MC)
signal superimposed. The luminosity used for this analysis is L = 3.9 nb1 . In the
bottom plot a correction factor for like sign 1.25 has been applied to correct for
residual background with the opposite sign sample in the side bands.
 (TeV)s
0 1 2 3 4 5 6 7 8
PHENIX
ALICE
Figure 5.11: J/ production cross-section as a function of collision energy for various
experiments. ALICE points show only the statistical error. The red one corresponds
to results published in [105]. The blue one is the result of analysis presented in this
thesis given by formula 5.18. The systematic error corresponding to these two points
is 1.7 and 1.8 respectively.
Chapter 6
Determination of the fraction of
J/ from B hadron decays
Bmesons decay into J/ mesons with a branching ratio of about 1%. Since B mesons
are produced by a factor of 5 [79] more abundantly than the direct J/ mesons, and
since direct J/ production in ion-ion collisions might be further suppressed by QGP
effects, secondary J/ mesons contribute to a large fraction of the observable J/
signal. The fraction of J/ originating from B rises from about 10% at Tevatron
[110] to about 35% at LHC 7 TeV energy [104].
The interest for developing a procedure to measure the production of secondary
J/ is two-fold. Firstly they provide a sensitive measurement of the B meson produc-
tion cross-section. Secondly, the identification and reconstruction of the secondary
J/ meson is essential to investigate medium effects on primary charmonia. The pt
distribution of the J/ is particularly interesting since J/ from B meson decays
exhibit a much harder transverse momentum spectrum than the primary ones and
at large transverse momentum the ratio of the secondary to primary J/ may grow
as large as 1:1.
The lifetime for the B meson is about 1.530  1012 seconds [113]. The J/
lifetime is very small ( 7.2  1021 seconds), so when a J/ comes from a B decay
its vertex is likely to be displaced with respect to the primary vertex. The distance
L the J/ meson appears to travel in the detector is:
 (6.1)
where p is the magnitude of the B meson momentum. MB and  are the mass
and mean lifetime of B meson respectively. The length L can be measured as the
distance between the primary event vertex and the secondary vertex corresponding
to the J/ decay. The vertex resolution in the direction parallel to the beam (axis z
in ALICE coordinate system) is of the order of millimetres and so any information
about the z component of the distance L is smeared out. In order to separate J/
originating from B hadrons from those directly produced, it is useful to introduce
the component of L perpendicular to the beam. The variable Lxy is defined as the
projection of the J/ flight distance on its transverse momentum:
Lxy =
p t(J/)
|p t(J/)|
(6.2)
as is shown in figure 6.1. p t(J/) is the J/ transverse momentum vector and
L is the vector from the primary vertex where B hadrons are produced to the J/
decay vertex.
This method works well for a J/ with high pt where the flight direction is
aligned with that of the B-hadrons, while for low pt, the contribution of a J/ with
a large opening angle between its flight direction and that of the B-hadron will affect
the separation ability.
The quantity Lxy depends on the B meson momentum. In order to reduce this
dependence the so called proper decay length variable is defined as:
x = Lxy.
|p t(J/)|
(6.3)
where the MJ/ is the mass of the J/ candidate. This works best if the J/ takes
most of the momentum of the decaying B meson. In order to calculate the percentage
of J/ that comes from the B hadrons, a method based on a simultaneous fit of the
invariant mass and proper decay length distributions has been developed, using a
maximum likelihood fitting technique. Our method is a modification of the method
used by the CDF [110], CMS [104] and ATLAS [111] collaborations. A simultaneous
invariant mass and proper length fit is performed using a log-likelihood function L
given by equation:
lnL =
lnF (x,Me+e) (6.4)
where N is the total number of events and F is the probability density function.
The invariant mass and proper decay length distribution is given by the equation:
F (x,Me+e) = fSig  FSig(x,Mee) + (1 fSig) FBkg(x,Mee) (6.5)
Figure 6.1: Definition of the vector L from the primary vertex where B hadrons are
produced to the J/ decay vertex.
where fSig is the fraction of signal J/ events (primary and secondary), FSig(x,Mee)
and FBkg(x,Mee) are two dimensional functions describing simultaneously proper-
decay length and invariant mass distributions of the signal and background events
respectively. The signal function convolutes physics distributions of primary and
secondary J/ with detector responses using MC simulation. The background func-
tion is extracted from like-sign pairs including the detector response. Despite the
short coming of like-sign events described in the previous chapter, it is suitable to
use like-sign for this purpose.
6.1 Signal and Background Functions
The function for the J/ proper decay length and invariant mass signal distributions
consist of two terms, prompt J/ decay and the B  J/ + X decay functions
labelled FP (x,Mee) and FB(x,Mee) respectively:
FSig(x,Mee) = fP  FP (x,Mee) + (1 fP ) FB(x,Mee) (6.6)
iwhere fP is the fraction of J/ mesons originating from prompt J/ decays. Sub-
stituting the value of FSig(x,Mee) in equation (6.5) we get:
F (x,Me+e) = fSig  fP  FP (x,Mee) + fSig  (1 fP ) FB(x,Mee) +
(1 fSig) FBkg(x,Mee) (6.7)
The projections of the 2-dimensional invariant mass and proper length distribu-
tions for the primary (prompt) J/ sample is shown in figure 6.2. For the prompt
J/ the true proper decay length x is zero and the distribution seen in figure 6.2
reflects the resolution of the ALICE detector. The green curve represents the proba-
bility density function FP (x,Mee) obtained from 2 dimensional histogram by a linear
interpolation leading to piece-wise linear function.
The projections of the 2-dimensional invariant mass and proper length distri-
butions for the secondary J/ (B  J/X) sample are shown in figure 6.3. The
expected exponential decay of B hadrons in the proper decay length region x > 0
is evident. The red curve represents the probability density function FB(x,Mee)
obtained from a 2 dimensional histogram by a linear interpolation.
The projections of 2-dimensional invariant mass and proper decay length distri-
butions for real data like-sign candidates ( same cuts as opposite sign candidates)
is shown in figure 6.4. There is no mass peak observed as expected.
Invariant Mass [GeV]
2.4 2.5 2.6 2.7 2.8 2.9 3 3.1 3.2 3.3 3.4
10000
Invariant Mass [GeV]
2.4 2.5 2.6 2.7 2.8 2.9 3 3.1 3.2 3.3 3.4
10000
proper decay length (mm)
-2 -1 0 1 2 3 4
proper decay length (mm)
-2 -1 0 1 2 3 4
Figure 6.2: Primary J/ Monte-Carlo sample: Left side: The invariant mass Mee
distribution ( measured in GeV in natural units with c=1); Right side: proper decay
length x distribution. The curves correspond to linear interpolation and give the
function FP .
Invariant Mass [GeV]
2.4 2.5 2.6 2.7 2.8 2.9 3 3.1 3.2 3.3 3.4
Invariant Mass [GeV]
2.4 2.5 2.6 2.7 2.8 2.9 3 3.1 3.2 3.3 3.4
proper decay length (mm)
-2 -1 0 1 2 3 4
proper decay length (mm)
-2 -1 0 1 2 3 4
Figure 6.3: Secondary J/ Monte-Carlo sample: Left side: The invariant mass Mee
distribution ( measured in GeV in natural units with c=1); Right side: proper decay
length x distribution. The curves correspond to linear interpolation and give the
function FB.
The black curve represents the probability density function FBkg(x,Mee) ob-
tained from 2 dimensional histogram by linear interpolation. These parameterisa-
tions already take into account the physical distributions and detector resolutions.
6.2 Implementation and validation
The procedure as described in the previous section is implemented using the fitting
package in the ROOT framework known as RooFit [114]. The Monte-Carlo sam-
ples of primary and secondary J/s described in chapter 4 are used to obtain a
parametrisation of primary and secondary probability density functions, while for
background it is taken from real data like-sign (see figures 6.4, 6.2 and 6.3).
In order to validate the procedure a mixture of primary, secondary and back-
ground samples is created with fTRUEP = 0.70 and f
sig = 0.50 and fractions fsig
and fP are extracted. In this section the mixtures are called fake data. The results
are shown in table 6.1. The different lines in the table correspond to different PDFs
used in the fit. The results in the first line are obtained using PDFs identical to
fake data histogram (i.e. piecewise constant histogram). The results are indeed
exactly equal to the fractions chosen as input in fake data. There are no errors
because of 100% correlation as the data samples are the same. This control calcu-
lation excludes trivial errors in the procedure. The results in the second line are
obtained using PDFs extracted from the fake data histogram by linear interpola-
tion (i.e. piecewise linear function). In this case the fractions differ by 7 - 8% from
the input values. The samples are again 100% correlated and the deviation can be
Invariant Mass [GeV]
2.42.52.62.72.82.9 3 3.13.23.33.4
proper decay length (mm)
-2 -1 0 1 2 3 4
Figure 6.4: Data like-sign: Left side: The invariant massMee distribution (measured
in GeV in natural units with c=1); Right side: proper decay length x distribution.
The curves correspond to linear interpolation and gives the function FBkg.
taken as an estimate of the systematic uncertainty of the method due to the finite
bin size and the limited statistics used for the PDFs extraction. The results in the
last line are obtained using the PDFs extracted from a Monte-Carlo sample which
is independent of the fake data sample and as such is the closest to the situation
we encounter with real data. The projections of invariant mass and proper length
together with fitted functions for this case are shown in figure 6.5.
Table 6.1: Validation of fitting procedure
Samples PDFs Primary fraction fP Signal fraction fsig
Identical 0 0.70 0.50
Identical 1 0.82 0.57
Independent 1 0.811  0.005 0.571  0.004
6.3 Comparison with data and summary
An attempt has been made to use the method with the real data sample. The projec-
tion of invariant mass and proper decay length for data sample with PTCUTT>1.3
GeV/c are shown in figure 6.6. The estimated fraction of inclusive J/ in sample is
0.15  0.07. The fraction of primary J/ with respect to inclusive is 0.6  0.3. The
result is limited by the statistics availale and the sensitivity of the method requires
further investigation.
In future, with the implementation of the electron TRD trigger [1], the sample
size will increase and this method is then expected to work better than in the present
scenario. An ALICE measurement of the fractions if primary and secondary J/ in
Invariant Mass [GeV]
2.42.52.62.72.82.9 3 3.13.23.33.4
10000
12000
14000
16000
18000
proper decay length (mm)
-2 -1 0 1 2 3 4
Figure 6.5: The Invariant mass (measured in GeV in natural units c=1); and proper
decay length distributions from a fake data mixture (data points). The green, red,
black curves correspond to primary, secondary and background samples. The fit
values for fP and fsig correspond to the last line in the table 6.1
Invariant Mass [GeV]
2.42.52.62.72.82.9 3 3.13.23.33.4
proper decay lenght (mm)
-0.4 -0.2 0 0.2 0.4 0.6 0.8 1
Figure 6.6: The Invariant mass (measured in GeV in natural units c=1) and proper
decay length distributions for real data (dots with error bars). The green, red, black
curves correspond to primary, secondary and background samples.
the dimuon channel is in preparation.
With the increased statistics it will be possible to perform the differential analysis
in terms of Pt bins as done previously by CDF [110]. In addition a complete study
of the lepton pair like-sign distribution both in MC and data would be possible.
This will imply that a better understanding of the background would be necessary,
similar to what has been done by CDF [110], CMS [104] and ATLAS [111].
Chapter 7
Summary and outlook
The ALICE experiment at CERN has been designed to study QCD processes with
heavy-ion collisions. However it allows studies of proton-proton physics to be per-
formed as well, and the majority of data accumulated so far has been recorded with
pp collisions.
This thesis presents the study of J/ production in pp collisions at ALICE. In
particular, a measurement of J/ cross-section at
s = 7 TeV energy has been
performed, together with a study of a possible algorithm to separate primary J/
from those coming from decays of B hadrons. The J/ particles have been searched
exclusively in the decay channel J/  e+e without the TRD trigger, which is
designed especially for the identification of the electrons but was not available at the
time. The study focused on what would be achievable in a period of early running,
with integrated luminosity of L = 1.25 nb1, at a proton-proton centre of mass
collision energy of
s = 7 TeV.
First, a number of physics and quality cuts have been optimised to improve the
signal to background ratio, using Monte-Carlo samples and real data taken during
early 2010. The result highlights that the most efficient criterion to reject the
background and select a sufficiently pure sample of electrons is a selection on the
ITS clusters and TPC energy deposit. Still, the TPC detector was not used at its
full capacity during the 2010 runs; therefore the cut studied were optimised with
respect to the detector capabilities available at that time.
Second, acceptances and efficiencies have been calculated using an adaptation
of the ALICE correction framework for various Pt of the electrons. Performing a
fit to the J/ mass distribution as a function of electron transverse momentum,
gives the value Pt > 1.3 GeV/c, as the cut giving the most favourable signal-to-
background ratio. In addition, a dedicated procedure has been implemented to
evaluate efficiency and correction due to the electron identification algorithm, based
on the TPC detector response.
Third, the J/ cross-section has been calculated, taking into account acceptances
and efficiencies, and systematic uncertainties have been evaluated. The measure-
ment is dominated by statistical uncertainty. The biggest systematic uncertainty
comes from signal extraction. The result presented in this thesis is consistent with
the value recently published by the ALICE collaboration. The cross-section pre-
sented here is intended as measurement on an early sample of data, with an al-
ternative method which proves to be comparably good with respect to the ALICE
published paper [105]. The statistics used here has not been increased due to time
constraints and to the fact that including later periods of data would involve study-
ing different cuts and applying different corrections.
Finally, in a similar manner to that adopted by the CDF and CMS collaborations,
to calculate the fractions of primary and secondary J/ (i.e. those coming from B
hadrons) an algorithm has been developed. The validity of this algorithm in ALICE
has been demonstrated using Monte-Carlo samples. However, due to low statistics,
at the moment such a method is not applicable to real data. In future, with the use
of the TRD detector and implementation of a special TRD trigger with increased
statistics, this algorithm is foreseen to work for real data and will allow the extraction
of primary J/ and the J/ from B directly from data as well.
Appendix A
Maximum Likelihood method
A common problem in particle physics is to estimate parameters from data. In this
appendix the common methods of Least Squares and Maximum Likelihood
are described.
The method of least squares looks for parameters, in such a manner that 2 is
minimum. The 2 can be written as:
) (A.1)
where each bin have vi events with a total number of n events in the sample and r
is the total number of bins. pi is the probability that the individual event falls into
the i-th bin being a function of s parameters, j , whose value we want to estimate.
The values of j for which the 
2 is minimum are the best estimators of the true j
values.
The 2 method works in case of binned data and also it requires a sufficient
sample size in order for the 2 method to be valid.
On the other hand maximum likelihood method is used when the density of
events over the physical region is low and when there would not be sufficient events
per bin to make alternative methods usable. In this thesis maximum likelihood
method is used to determine the values of the parameters from the data.
the vector of the measured variable and 1, 2...s are s parameters.
L = f(x1)f(x2)...f(xn) (A.2)
is the density function for obtaining a set of events if  is fixed. L is called the
likelihood of the experimental results.
The maximum likelihood method consist in finding an estimate of the parameter
 , which maximises L. As the maximum of L is also the maximum of log L, we
tend to use the latter function. The log L carries more directly the information of
the uncertainty for the estimated parameters ~. Thus the set of likelihood equations
w = log L =
log f(xi ;1, 2, ..., s) (A.3)
f(xi )
f(x i)
= 0 (A.4)
To demonstrate how this method works, a simple example of lifetime measure-
ment is presented below. The probability density function is
f(t; ) =
 (A.5)
where t is the measured lifetime in a given event and  is the mean life time, i.e.
the parameter to be estimated. The Likelihood function is:
L = f(t1; )f(t2; )...f(tn; ) (A.6)
and substituting equation (A.5) for f gives:
L = n ln  
ti (A.7)
The estimate of the mean lifetime  which maximises the likelihood function L is,
in this case, the arithmetic average on measured lifetimes ti:
(A.8)
The ratio of log L functions gives an estimate of how two different models com-
pare with each other. For example, a fit with full parameters can be compared with
a fit with a reduced number of parameters. For a sufficiently large enough number of
events, the ratio is distributed as 2 with degrees of freedom equal to the number of
fixed parameters. From the 2 distribution and the value of the ratio, a confidence
level can be established [115].
Appendix B
J/ polarisation frame
The angular distribution of J/ decay leptons carries information about the J/
polarisation. The angular distribution integrated over the azimuthal angle is given
by [106]:
d cos 
= A(1 +  cos2 ) (B.1)
where A is a normalisation factor,  is the angle between the momentum vector
of one lepton in the polarisation quarkonia rest frame and the longitudinal direction
(z) of a selected polarisation vector (frame). The polarisation parameter  is related
to the magnitude of the polarisation, where  = 0 means no polarisation,  = 1
means maximum tranverse polarisation and  = 1 means maximum longitudinal
polarisation.
Different definitions of the polarisation axis are used to define the average spin
alignment of quarkonia, depending on the particular choice of reference frame:
The Helicity frame: The frame in which z is the direction of quarkonium
momentum in the J/ rest frame. Our lab frame is defined so that z axis is in the
same direction. The transformation from lab frame to helicity frame corresponds to
the Lorentz boost along the momentum of J/.
The Collins-Soper frame : The frame which defines z as the bisector between
the directions of the first colliding proton p1 and of the opposite of the second
colliding proton p2 in the dilepton rest frame. The vectors
p1 , p2 , p J/ lie in the
same plane.
All the frames differ only by a rotation around the axis perpendicular to the
reaction plane, giving different numerical values for the parameters of the decay
leptons full angular distribution. The figure B.1 shows the charmonium polarisation
axis defined both in the helicity and Collins-Soper frame, in case when the J/ is
relativistic. In chapter 5 both of above frames are used to calculate the systematic
uncertainity from the J/ polarisation.
Figure B.1: The charmonium polarisation axes defining both the helicity and Collins-
Soper frame.
Bibliography
[1] The ALICE experiment at the CERN LHC J. Instr. 3 (2008) S08002
http://dx.doi.org/10.1088/1748-0221/3/08/S08002.
[2] QCD and Collider Physics by R. Keith Ellis, W. James Stirling and Bryan R.
Webber, Cambridge University Press (2003).
[3] B. I. Abelev et al. [STAR Collaboration], [arXiv:0907.4458v2] J/ production
in Au+Au and Cu+Cu collisions at sqrt(sNN) = 200 GeV at STAR.
[4] H. Satz,Quarkonium binding and dissociation : The spectral analysis of the
QGP, Nucl. Phys. A 783, 249 (2007) [arXiv : hep-ph/0609197].
[5] ALICE: Physics Performance Report, Volume I, ALICE Collaboration et al
2004 J. Phys. G: Nucl. Part. Phys. 30 1517.
[6] S. Margetis et al., Ann. Rev. Nucl. Part. Sci 50, 299-342 (2000).
[7] J. Rafelski and B. Muller, Phys. Rev. Lett. 48, 1066 (1982).
[8] J. Rafelski and J. Letessier, J. Phys. Conf. Ser. 50, 176-191 (2006).
[9] T. Matsui and H. Satz, J/psi Suppression by Quark-Gluon Plasma Formation,
Phys. Lett. B 178 (1986) 416.
[10] R. Vogt, Phys. Rept. 310, 197-260 (1999).
[11] http://www.bnl.gov/rhic/.
[12] C. Adler et al., Phys. Rev. Lett. 89, 202301 (2002).
[13] S. S Adler et al., Phys. Rev. C69, 034910 (2004).
[14] B. B. Back et al., Phys. Rev. B578, 297-303 (2004).
[15] I. Arsene et al., Phys. Rev. Lett. 91, 072305 (2003).
[16] D. A. Appel, Phys. Rev. D33, 717 (1986).
[17] J. J. Aubert et al. [E598 Collaboration], Experimental Observation Of A Heavy
Particle, Phys.Rev.Lett.33 (1974) 1406.
[18] J. E. Augustin et al. [SLAC-SP-017 Collaboration], Discovery Of A Narrow
Resonance In e+e Annihilation, Phys. Rev. Lett. 33 (1974) 1406.
[19] S. L. Glashow, J. Iliopoulos and L. Maiani, Weak Interactions with Lepton-
Hadron Symmetry, Phys. Rev. D 2 (1970) 1285.
[20] S. W. Herb et al., Observation of a dimuon resonance at 9.5 GeV in 400 GeV
proton-nucleus collisions, Phys. Rev. Lett. 39, 252 (1977).
[21] F.Abe et al. [CDF Collaboration], Identification of top quarks at CDF using
kinematic variables, Phys. Rev. D 52, 2605 (1995).
[22] E. Eichten, K. Gottfried, T. Kinoshita, K. D. Lane and T. M.
Yan,Charmonium: The Model, Phys. Rev. D 17, 3090 (1978) [Erratum-ibid.
D 21, 313 (1980)].
[23] E. Eichten, Recent Theoretical Developments For Heavy Quark - Anti-Quark
Systems. (Talk), Harvard Univ. Cambridge - HUTP-80-A084 (80,REC.JUN.
81) 14p.
[24] B. Gong, X. Q. Li, J.-X. Wang, QCD corrections to J/ production via color
octet states at Tevatron and LHCarXiv:0805.4751
[25] J. Baines et al., Heavy quarks(Working Group-3): Summary report,
arXiv : hep-ph/0601164.
[26] R. Vogt, Open and hidden charm production at RHIC and LHC, J. Phys. G
31 (2005) S773 [arXiv : hep-ph/0412303].
[27] R. Vogt [Hard Probe Collaboration], The A dependence of open charm
and bottom production, Int. J. Mod. Phys. E 12 (2003) 211 [arXiv : hep-
ph/0111271].
[28] L. Berger and D. L. Jones, Inelastic Photoproduction Of J/ And Upsilon By
Gluons,Phys. Rev. D23 (1981) 1521.
[29] M. Cacciari and M. Kramer, Color-Octet Contributions to J/ Photoproduc-
tion, Phys. Rev. Lett. 76 (1996) 4128 [arXiv : hep-ph/9601276].
[30] E. Braaten and S. Fleming, Color octet fragmentation and the psi-prime
surplus at the Tevatron, Phys. Rev. Lett. 74 (1995) 3327 [arXiv : hep-
ph/9411365].
[31] P. L. Cho and A. K. Leibovich, Color octet quarkonia production, Phys. Rev.
D 53 (1996) 150 [arXiv : hep-ph/9505329].
[32] P. L. Cho and A. K. Leibovich, Color-octet quarkonia production II, Phys.
Rev. D 53 (1996) 6203 [arXiv : hep-ph/9511315].
[33] H. Fritzsch,Producing Heavy Quark Flavors In Hadronic Collisions: A Test
Of Quantum Chromodynamics,Phys. Lett. B 67 (1977) 217.
[34] J. F. Amundson, O. J. P. Eboli, E. M. Gregores and F. Halzen,Colorless States
in Perturbative QCD: Charmonium and Rapidity Gaps, Phys. Lett. B 372
(1996) 127 [arXiv : hep-ph/9512248].
[35] J. F. Amundson, O. J. P. Eboli, E. M. Gregores and F. Halzen, Quantitative
tests of color evaporation: Charmonium production, Phys. Lett. B 390 (1997)
323 [arXiv : hep-ph/9605295].
[36] Heavy Quarkonia Production in p+p Collision from the PHENIX Experiment,
Abigail Bickley, University of Colorando, November 18, 2006.
[37] A. Sansoni et al. (CDF Collaboration), FERMILAB-CONF-95/263-E, to ap-
pear in the Proceedings of the sixth International Symposium on Heavy
Flavour Physics.
[38] A. A. Affolder et al. [CDF Collaboration], Measurement of J/ and (2S)
polarisation in pp collisions at
s = 1.8 TeV, Phys. Rev.Lett. 85 (2000) 2886
[arXiv:hep-ex/0004027].
[39] B. Gong, X. Q. Li, J.-X. Wang, QCD correction of J production via color
octet states at Tevatron and LHCarXiv:0805.4751.
[40] B. Alessandro et al. [ALICE Collaboration], ALICE: Physics performance re-
port, volume II, J. Phys. G 32 (2006) 1295.
[41] D. Kharzeev, C. Lourenco, M. Nardi and H. Satz, A quantitative analysis
of charmonium suppression in nuclear collisions, Z. Phys. C 74 (1997) 307
[arXiv:hep-ph/9612217].
[42] C. Baglin et al. [NA38 Collaboration], The production of J/ in 200
GeV/NUCLEON Oxygen, Uranium Interactions. Phys. lett. B 220 (1989) 471.
[43] M.C. Abreu et al. (NA50 Collaboration), Phys. Lett. B 410 (1997) 327.
[44] A. Baldit et al., Study of prompt dimuon and charm production with proton
and heavy ion beams at the CERN SPS, CERN-SPSC-P-316.
[45] A. Adare, et al., J/ production vs centrality, tranverse momentum, and
rapidity in Au+Au collision at
sNN=200 GeV, Phys. Rev. Lett. 98 (2007)
232301.
[46] Anderson L.et al., Nucl. Inst. Meth. 223 (1984) 26.
[47] C. Castanier, Ph.D Thesis, Universite Blaise Pascal, Aubiere, France, 2003.
[48] A new measurement of J/ suppression in Pb-Pb collisions at 158 GeV per
nucleon. arXiv:hep-ex/0412036v1.
[49] J/ and  suppression by comovers in Pb+Pb collisions. arXiv:nucl-
th/9609064v1.
[50] C. Gerschel and J. Huefner, Phys. Lett. B207 (1988) 194.
[51] Nuclear Physics A 830 (2009) 239c-242c J/ production in p-A collisions at
158 and 400 GeV: recent results from the NA60 experiment.
[52] S. J. Brodsky, A.S. Goldhaber, B. Z. Kopeliovich, and I. Schmidt., Nuclear
Physics B 807 (2009) 334.
[53] T . Gunji [PHENIX Collaboration], J. Phys, G 34 (2007) S749 [arXiv:nucl-
ex/0703004v1]. Centrality Dependence of J/ Production in Au+Au and
Cu+Cu Collisions by the PHENIX Experiment at RHIC.
[54] L. Susskind, Lattice Models Of Quark Confinement At High Temperature,
Phys. Rev. D 20 (1979) 2610.
[55] J. Kuti, J. Polonyi and K. Szlachanyi, Monte Carlo Study Of SU(2) Gauge
Theory At Finite Temperature, Phys. Lett. B 98 (1981) 199.
[56] J. Engels, F. Karsch, H. Satz and I. Montvay, High Temperature SU(2) Gluon
Matter On The Lattice, Phys. Lett. B 101 (1981) 89.
[57] F. R. Brown et al., On the existence of a phase transition for QCD with three
light quarks, Phys. Rev. Lett. 65 (1990) 2491.
[58] F. Karsch, The Phase transition to the quark gluon plasma: Recent re-
sults from lattice calculations, Nucl. Phys. A 590 (1995) 367C [arXiv:hep-
lat/9503010].
[59] F. Karsch, D. Kharzeev and H. Satz, Sequential charmonium dissociation,
Phys. Lett. B 637 (2006) 75 [arXiv:hep-ph/0512239].
[60] R. Rapp, Quark coalescence and charm(onium) in QGP, Eur. Phys. J. C 43
(2005) 91 [arXiv:hep-ph/0502208].
[61] L. Yan, P. Zhuang and N. Xu, Competition between J suppression and regen-
eration in quark-gluon plasma, Phys. Rev. Lett. 97 (2006) 232301 [arXiv:nucl-
th/0608010].
[62] R. L. Thews and M. L. Mangano, Momentum spectra of charmonium pro-
duced in a quark-gluon plasma, Phys. Rev. C 73 (2006) 014904 [arXiv:nucl-
th/0505055].
[63] A. Andronic, P. Braun-Munzinger, K. Redlich and J. Stachel, Statistical
hadronization of heavy quarks in ultra-relativistic nucleus nucleus collisions,
Nucl. Phys. A 789 (2007) 334 [arXiv:nucl-th/0611023].
[64] W. Cassing, E. L. Bratkovskaya and S. Juchem, Excitation functions of
hadronic observables from SIS to RHIC energies, Nucl. Phys. A 674 (2000)
249 [arXiv:nucl-th/0001024].
[65] A. Andronic, P. Braun-Munzinger, K. Redlich and J. Stachel, Statistical
hadronization of charm in heavy-ion collisions at SPS, RHIC and LHC, Phys.
Lett. B 571 (2003) 36 [arXiv:nucl-th/0303036].
[66] L. Evans, P. Bryant, LHC Machine, (2008). JINST 3 S08001
[67] ALICE Collaboration, ALICE Physics Performance Report, Volume 1. J.
Phys. G: Nucel. Part. Phys. 30 (2004) 1517-1763.
[68] ATLAS Collaboration, The ATLAS Experiment at the CERN LHC, (2008).
JINST 3 S08003.
[69] CMS Collaboration, The CMS Experiment at the CERN LHC, (2008). JINST
3 S08004.
[70] LHCb Collaboration, The LHCb Detector at the LHC, (2008). Jinst 3 S08005.
[71] S. Karlheinz, Project to prepare the PS Complex to be a Pre-injector for
the LHC, (1998). Available: http://ps-div.web.cern.ch/ps-div/LHC-PS/LHC-
PS.html.
[72] V. Angelov [ALICE TRD Collaboration], Design and performance of the AL-
ICE TRD front-end electronics, Nucl. Instrum. Meth. A 563 (2006) 317.
[73] V. Ginzburg, I. Frank, Radiation of a uniformly moving electron due to
its transition from one medium into another, Journ. Phys. USSR, v.9, 353,
(1945).
[74] P. Goldsmith, J. V. Jelley, Phil. Mag. 4, 836, 1959.
[75] V. L. Ginzburg and V. N. Tsytovich, On The Derivation Of The Transition
Radiation Intensity, Phys. Lett. A 79 (1980) 16.
[76] V. L. Ginzburg and V. N. Tsytovich, Several Problems Of The Theory Of
Transition Radiation And Transition Scattering, Phys. Rept. 49 (1979) 1.
[77] B. Dolgoshein, Transition radiation detectors, Nucl. Instrum. Meth. A 326
(1993) 434.
[78] ALICE collaboration, ALICE transition-radiation detector: Technical Design
Report, CERN-LHCC-2000-012, http://cdsweb.cern.ch/record/430132; AL-
ICE Time-of Flight system (TOF): addendum to the technical design report,
CERN-LHCC-2002-016, http://cdsweb.cern.ch/records/545834.
[79] B. Alessandro et al., ALICE: physics performance report, volume II, J. Phys.
G 32 (2006) 1295.
[80] ALICE CTP website: http://www.ep.ph.bham.ac.uk/user/pedja/alice/.
[81] http://root.cern.ch/drupal.
[82] http://aliceinfo.cern.ch/Offline/AliRoot/Manual.html.
[83] S Bagnasco et al 2008 J. Phys.: Conf. Ser. 119 062012.
[84] http://www.thep.lu.se/torbjorn/Pythia.html.
[85] A. Capella, A. Kaidalov, and J. Tran Thanh Van, Heavy Ion Phys. 9 (1999)
[86] M. Gyulassy and X. N. Wang, Comput. Phys. Commum. 83 (1994) 307
[arXiv:nucl-th/9502021].
[87] A. Capella, U. Sukhatme, C-I Tan and J. Tran Thanh Van: Dual Parton
Model. Phys. Rept. 236 (1994) 225.
[88] H. J. Mohring, J. Ranfit, Phys. Rev. D 47, 41424145 (1993) String fusion in the
dual parton model and the production of antihyperons in heavy-ion collisions.
[89] R. Brun et al., GEANT 3, CERN report DD/EE/84-1 (1989); Geant4 Collab-
oration, S. Agostinelli et al., NIM A506 (2003) 25.
[90] A. Ferrari, P. R. Sala, A. Fasso and J. Ranft, FLUKA: A multi-particle trans-
port code (Program version 2005).
[91] S. Agostinelli et al. [GEANT4 Collaboration], GEANT4: A simulation toolkit,
Nucl. Instrum. Meth. A 506 (2003) 250.
[92] http://www.physi.uni-heidelberg.de/ minjung/alicegirl/alice.../primer.pdf.
[93] ALICE Collaboration, ALICE technical design report of the computing,
CERN-LHCC-2005-018 http://aliceinfo.cern.ch/Collaboration/Documents/
TDR/Computing.html.
[94] http://arxiv.org/abs/0810.2241.
[95] W. R. Leo, Techniques for Nuclear and Particle Physics Experiments,
Springer-Verlag, 1994.
[96] ALICE Collaboration, Physics Performance Report Vol. 2, 2006.
[97] ALICE collaboration, ALICE forward detectors: FMD, T0
and V0: Technical Design Report, CERN-LHCC-2004-025,
http://cdsweb.cern.ch/record/781854.
[98] http://pdg.lbl.gov/.
[99] H. Bichsel, Nucl. Instrum. Math. A562, 154 (2006).
[100] J. D. Jackson, Classical Electrodynamics, John Wiley Sons, Inc., 1999.
[101] M. Aguilar-Benitez et al., Z. Phys. C 50, 405 (1991).
[102] T. Skwarnicki, A Study of the Radiative Cascade Transition Between the
Upsilon-Prime and Upsilon Resonance, DESY F31-86-02 (1986).
[103] http://aliceinfor.cern.ch/static/aliroot-new/html/roothtml/ClassIndex.html.
[104] The CMS collaboration: CERN-PH-EP/2010-046, submitted to the EPJC.
[105] ALICE collaboration, http://arxiv.org/abs/1105.0380v1 [hep-ex] 2 May 2011.
Rapidity and transverse momentum dependence of inclusive J/ production
in pp collisions at
s = 7 TeV.
[106] PHENIX collaboration, Phys. Rev. D 82, 012001 (2010) Transverse momentum
dependence of J/ polarisation in p + p collisions at
s = 200 GeV.
[107] K. Oyama et al. (ALICE Collaboration), proc. of the Workshop LHC Lumi
Days, to be published.
[108] S. van der Meer, ISR-PO/68-31, KEK 68-64.
[109] PHENIX collaboration, J/ production versus Transverse Momentum and
Rapidity in p-p collisions at
s=200 GeV, Phys. Rev. Letter 98, 232002
(2007).
[110] CDF collaboration, arXiv:hep-ex/0412071v1 27 Dec 2004. Measurement of
the J/ Meson and b-Hadron Production Cross Sections in pp Collisions at
s = 1960 GeV .
[111] ATLAS collaboration, arXiv:1104.3038v1 14th April 2011. Measurement of
the differential cross-sections of inclusive, prompt and non-prompt J/ pro-
duction in proton-proton collisions at
s = 7 TeV
[112] Measurement of J/ production in pp collisions at sqrt(s)=7 TeV. By
LHCb Collaboration (R. Aaij et al.). CERN-PH-EP-2011-018, Mar 2011.
24pp. Temporary entry Published in Eur.Phys.J.C71:1645,2011. e-Print:
arXiv:1103.0423 [hep-ex]
[113] http://pdg.lbl.gov/
[114] http://root.cern.ch/drupal/content/roofit.
[115] Statistical methods in Experimetal physics, W.T.Eadie, D.Drijard, F.E.
James, M.Roos, B,Sadoulet, North-Hollonad Publishing Company (1998)
