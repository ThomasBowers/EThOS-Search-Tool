This electronic thesis or dissertation has been
downloaded from Explore Bristol Research,
http://research-information.bristol.ac.uk
Author:
Harewood-Gill, Douglas A E
Title:
Q-Routing for enhanced performance within a SDN controlled network
General rights
Access to the thesis is subject to the Creative Commons Attribution - NonCommercial-No Derivatives 4.0 International Public License.   A
copy of this may be found at https://creativecommons.org/licenses/by-nc-nd/4.0/legalcode  This license sets out your rights and the
restrictions that apply to your access to the thesis so it is important you read this before proceeding.
Take down policy
Some pages of this thesis may have been removed for copyright restrictions prior to having it been deposited in Explore Bristol Research.
However, if you have discovered material within the thesis that you consider to be unlawful e.g. breaches of copyright (either yours or that of
a third party) or any other law, including but not limited to those relating to patent, trademark, confidentiality, data protection, obscenity,
defamation, libel, then please contact collections-metadata@bristol.ac.uk and include the following information in your message:
	Your contact details
	Bibliographic details for the item, including a URL
	An outline nature of the complaint
Your claim will be investigated and, where appropriate, the item in question will be removed from public view as soon as possible.
Q-Routing for Enhanced Performance within 
a SDN Controlled Network 
DOUGLAS HAREWOOD-GILL 
Department of Electrical and Electronic Engineering 
UNIVERSITY OF BRISTOL 
A dissertation submitted to the University of Bristol in 
accordance with the requirements of the degree of DOCTOR OF 
PHILOSOPHY in the Faculty of Engineering. 
SEPTEMBER 2021 
Word count: 69,248 
Abstract 
Since its commercialisation in 1995, the Internet has grown exponentially. Cisco estimates that the 
number of Internet users will increase to 5.3 billion in 2023 from 3.9 billion as of 2018. To confront 
the issue of increased Internet usage, new, smarter, and more versatile networking solutions are 
required.  
Software Defined Networking (SDN) is a relatively new paradigm that introduces a centralised 
approach where the intelligence of each network device is stored in a central SDN controller. SDN 
offers several advantages over distributed networking including, faster adaptation to network 
topology changes, easier integration of network applications, simultaneous control of many network 
devices, etc. However, despite these advantages, SDN traditionally uses heuristic algorithms such as 
single metric shortest path which may not be suitable for Quality of Service (QoS) based routing. 
The aim of the research was to create, implement and test a routing algorithm as an alternative to 
existing heuristic algorithms. Q-Routing was selected as the basis of a new routing algorithm as 
literature shows that Q-Learning holds several advantages over other reinforcement learning 
algorithms while being faster at pathfinding than shortest path in distributed networks. The Q-Routing 
based algorithm had to meet several criteria: i) Use the advantages presented by SDN. ii) Employ 
multiple network metrics for QoS based routing. iii) Perform as well as K-Shortest Path. iv) Find paths 
faster than K-Shortest Path. v) Adapt to dynamic network environments. vi) Work efficiently in 
network topologies of different sizes and densities.  
Research was split into three phases, initially looking at SDN based single metric Q-Routing leading to 
the final algorithm, Dual Metric, Multi-Estimate, Pareto, Q-Routing which successfully met all stated 
goals. Emulated results show that the algorithm in terms of the percentage of flows blocked 
performed as well as K-Shortest Path while being faster at pathfinding in both static and dynamic 
network environments. 
Dedication and Acknowledgements   
During the course of this PhD, I have been supported by many people who without their support, this 
research would not have been possible. In that vein, I would first like to thank my academic 
supervisors, Professor Trevor Martin and Professor Reza Nejabati for their guidance, knowledge and 
feedback throughout the PhD. 
Next, I would like to thank my colleagues and the academic staff within the Centre for Doctoral 
Training (CDT) for Communications, High Performance Networking (HPN) and the University of Bristol 
in general for their continuous support and advice with specific thanks going to Anderson Bravalheri 
from HPN, visiting Associate Professor Magnos Martinello from the Universidade Federal do Esprito 
Santo and Professor Celio Trois from the Universidade Federal de Santa Maria. 
Special thanks go to Suzanne Binding, CDT Manager and the administrative staff of the School of 
Computer Science, Electrical and Electronic Engineering and Engineering Maths, and Barb Lowden, 
HPN Administrator for fielding endless questions during the course of my research. 
I would also like to thank CDT program, the University of Bristol, and the Gilchrist Educational Trust 
for their financial support during the course of the PhD and my industrial supervisors from Roke Manor 
for their valued feedback.  
Finally, I want to give special thanks to my late friend and colleague, Giovanni Ciurleo who offered 
unflinching support after the passing of my father and to my late father, who gave me the courage to 
embark on this journey.   
Authors Declaration  
I declare that the work in this dissertation was carried out in accordance with the requirements of the 
University's Regulations and Code of Practice for Research Degree Programmes and that it has not 
been submitted for any other academic award. Except where indicated by specific reference in the 
text, the work is the candidate's own work. Work done in collaboration with, or with the assistance 
of, others, is indicated as such. Any views expressed in the dissertation are those of the author. 
SIGNED:    ,   DATE: 
Contents 
Chapter 4:- The Implementation and Improvement of Q-Learning for Optimal Pathfinding in an SDN 
4.3.7) Adaptive Q-Routing for Path Calculation using Bandwidth within the SDN Controller:- . 103 
4.5.1) Discussion of Q-Learning and Q-Routing Algorithms regarding the Percentage of Flows 
4.5.2) Discussion of K-Shortest Path Performance Tests (Path Calculation Time and Percentage 
4.5.3) Discussion of Adaptive Q-Routing (Pathfinding Time and Percentage of Paths Blocked):-
5.5.1) Discussion of the Multi-Metric Q-Routing Algorithms regarding the Percentage of Flows 
5.5.2) Discussion of Multi-Metric K-Shortest Path Performance Tests (Path Calculation Time and 
6.3.4) Comparison of the time complexity between Dual-Metric, Multi-Estimate, Pareto Q-
6.5.2) Dual-Metric, K-Shortest Path Performance Tests (Path Calculation Time and Percentage of 
6.5.3) Adaptive, Dual-Metric, Multi-Estimate, Pareto, Q-Routing (Path Calculation Time and 
Appendix C) Q-Routing Algorithm Pseudo Code and Additional Implementation Details (where 
C.6) Section 5.3.2, Q-Routing using Latency, Total Link Bandwidth & Free Link Bandwidth Pseudo 
List of Tables 
Table 3:- Showing the topologies of different sizes and Average No of Connections per Node used in 
Table 4:- Showing a comparison between the time complexities for each single metric routing 
Table 5:- Showing each K-Shortest Path algorithm and the equivalent Q-Learning / Q-Routing 
Table 6:- Showing the average blocking % results for K-Shortest Path vs Q-Learning using Latency.110 
Table 7:- Showing the average blocking % results for K-Shortest Path vs Q-Routing using Latency. 112 
Table 8:- Showing the average blocking % results for K-Shortest Path vs Q-Routing using Bandwidth.
Table 9:- Showing a comparison of the average times required to calculate a path for each of the K-
Table 10:- Showing a comparison of the percentages of flows blocked by each K-Shortest Path 
Table 11:- Showing the average path calculation times and percentage of flows accepted and 
Table 12:- Showing the points awarded for the Latency and Bandwidth values for each neighbouring 
Table 13:- Showing a comparison between the time complexities for multi-metric routing algorithm.
Table 14:- Showing each K-Shortest Path algorithm and the equivalent Multi-Metric Q-Routing 
Table 15:- Showing the average blocking % results for K-Shortest Path vs Q-Routing using Latency & 
Table 16:- Showing the average blocking % results for K-Shortest Path vs Amalgamation Q-Routing 
Table 17:- Showing the average blocking % results for K-Shortest Path vs Total Score Q-Routing using 
Table 18:- Showing a comparison of the average times required to calculate a path for each of the 
Table 19:- Showing a comparison of the percentages of flows blocked by each Multi-Metric K-
Table 20:- Showing how multiple estimates are stored in a Q-Table for SD for the Dual Metric, Multi-
Estimate, Pareto Q-Routing algorithm (Right-hand Side) in comparison to traditional Q-routing (Left-
Table 21:- Showing a comparison between the time complexities for each dual-metric routing 
Table 22:- Showing the average results for the percentage of flows blocked for Dual Metric K-
Table 23:- Showing a comparison between Dual-Metric K-Shortest Path and Q-Routing between the 
Table 24:- Showing a comparison between Dual-Metric K-Shortest Path and Q-Routing between of 
Table 25:- Showing the percentage of flows blocked and the path calculation times for both 
List of Figures 
Figure 8:- The irregular 6 x 6 grid network topology used for testing different Q-Routing algorithm 
Figure 21:- A custom topology to test Q-Routing's ability to adapt to changes in a dynamic network.
Figure 22:- Showing a Box & Whisker Plot for the Blocking Results for Q-Learning vs K-Shortest Path 
Figure 23:- Showing a Box & Whisker Plot for the Blocking Results for Q-Learning vs K-Shortest Path 
Figure 24:- Showing a Box & Whisker Plot for the Blocking Results for Q-Learning vs K-Shortest Path 
Figure 25:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in 
Figure 26:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in 
Figure 27:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in 
Figure 28:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in 
Figure 29:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in 
Figure 30:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in 
Figure 32:- Showing the relationship between the K-Value and the percentage of flows blocked by K-
Figure 34:- Showing the Average Path Calculation Time against the Average Percentage of Flows 
Figure 35:- Implementation of the K Shortest Path Algorithm using Latency, TLB & FLB for Path 
Figure 36:- Implementation of the Q-Routing Algorithm using Latency & TLB & FLB for Path Finding.
Figure 37:- Implementation of the K-Shortest Path Algorithm using Latency & Bandwidth for Path 
Figure 38:- Implementation of the Amalgamation Q-Routing Algorithm using Latency & Bandwidth 
Figure 40:- Implementation of the Total Scoring Q-Routing Algorithm using Latency & Bandwidth 
Figure 41:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in 
Figure 42:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in 
Figure 43:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in 
Figure 44:- Showing a Box & Whisker Plot for the Blocking Results for Amalgamation Q-Routing vs K-
Figure 45:- Showing a Box & Whisker Plot for the Blocking Results for Amalgamation Q-Routing vs K-
Figure 46:- Showing a Box & Whisker Plot for the Blocking Results for Amalgamation Q-Routing vs K-
Figure 47:- Showing a Box & Whisker Plot for the Blocking Results for Total Score Q-Routing vs K-
Figure 48:- Showing a Box & Whisker Plot for the Blocking Results for Total Score Q-Routing vs K-
Figure 49:- :- Showing a Box & Whisker Plot for the Blocking Results for Total Score Q-Routing vs K-
Figure 50:- Showing the relationship between the Multi-Metric K-Value algorithms and the time to 
Figure 51:- Showing the relationship between the K-Value and the percentage of flows blocked by 
the Multi-Metric K-Shortest Path algorithms compared to the equivalent Q-Routing algorithms. .. 153 
Figure 52:- Showing how multiple estimates are created for the Q-Table of a Destination node. ... 164 
Figure 54:- Showing how the current and new tuple estimates for the Current Node are combined.
Figure 55:- Implementation of the Pathfinding phase of Dual Metric, Multi-Estimate, Pareto Q-
Figure 56:- A custom topology to allow the testing of Q-Routing's ability to adapt to link changes in a 
Figure 57:- Showing the Box & Whisker Plot results for the percentage of flows blocked for the Dual-
Figure 58:- Showing the Box & Whisker Plot results for the percentage of flows blocked for the Dual-
Figure 59:- Showing the Box & Whisker Plot results for the percentage of flows blocked for the Dual-
Figure 60:- Showing the relationship between the K-Value and the time to calculate a path for both 
Figure 61:- Showing the relationship between the K-Value and the percentage of flows blocked by 
Figure 62:- Showing the time to find a path against the percentage of flows blocked for Dual Metric 
Figure 63:- Showing the number of flows required for Adaptive, Dual-Metric Q-Routing to adapt to 
Figure 64:- Showing the Path Calculation Time against the Percentage of Flows Blocked for each 
Acronyms 
4G  = Fourth Generation 
5G  = Fifth Generation 
AI  = Artificial Intelligence 
AQRERM  = Adaptive Q-routing with Random Echo and Route Memory 
AMC  = Average Mesh Connectivity 
Aps  = Access Points 
API  = Application Program Interface 
ARPNET  = Advanced Research Project Agency Network 
CAN  = Campus Area Network 
CEL  = Complete Estimate List 
CLI  = Command Line Interface 
COADM  = Configurable Optical Add-Drop Multiplexer 
DDQN   = Deep Double Q-network 
DDPG   = Deep Deterministic Policy Gradient 
DDoS   = Distributed Denial of Service 
DNN  = Deep Neural Network 
DQN   = Deep Q-Learning Neural Network 
DQR   = Deep Q-Routing 
DRL   = Deep Reinforcement Agent 
DRP  = Dynamic Routing Protocols (DRP) 
DRQ-Routing  = Dual Reinforcement Q-Routing 
DV  = Distance Vector 
DVR  = Distance Vector Routing 
EDP  = Edge Disjoint Paths 
ERB  = Experience Reply Buffer 
ECMP   = Equal-Cost Multi-Path 
FEL  = Filtered Estimate List 
FLB  = Free Link Bandwidth 
GUI  = Graphical User Interface 
HARMLESS  = Hybrid ARchitecture for Migrating Legacy Ethernet Switches to SDN 
HetNet   = Heterogeneous Network 
IP  = Internet Protocol 
IS-IS  = Intermediate System to Intermediate System 
LAN  = Local Area Network 
LiFi  = Light Fidelity 
LS  = Link State 
LSR  = Link State Routing 
LTE   = Long-Term Evolution 
MCS  = Modulation Coding Scheme 
MAN  = Metropolitan Area Network 
ML  = Machine Learning 
MSA   = Multi-Source Agreement 
MOO  = Multi-Objective Optimisation 
MORL  = Multi-Objective Reinforcement Learning 
NDP  = Node Disjoint Paths 
NETCONF  = Network Configuration Protocol 
NFV   = Network Functions Virtualization 
NN  = Neural Networks 
NOS  = Network Operating System 
NREN   = Africas National Research and Education Network 
PER  = Prioritised Experience Replay 
PLR  = Packet Loss Rate 
POC  = Proof of Concept 
OaaS   = Optimization as a Service 
QAR  = QoS-aware Adaptive Routing 
ODL  = OpenDayLight 
OECD  = The Organisation for Economic Co-operation and Development 
Ofcom  = Office of Communications 
QoS   = Quality of Service 
OSPF  = Open Shortest Path First 
RL  = Reinforcement Learning 
RL-QAQ  = Reinforcement Learning empowered QoS-aware Adaptive Q-routing 
ROADM  = Reconfigurable Optical Add-Drop Multiplexer 
SAHQ   = Simulated Annealing based Hierarchical Q-Routing 
SAN  = Storage Area Network 
SARSA  = State-Action-Reward-State-Action 
SDN  = Software Defined Network 
SDON  = Software Defined Optical Networking 
SDWN    = Software Defined Wireless Networking 
SL  = Supervised Learning 
TDM  = Time Division Multiplexing 
TE  = Traffic Engineering 
TLB   = Total Link Bandwidth 
UAV  = Unmanned Autonomous Vehicle 
UDP   = User Datagram Protocol 
UL  = Unsupervised Learning 
WAN  = Wide Area Network 
WHO   = World Health Organization 
WiFi  = Wireless Fidelity 
YANG  = Yet Another New Generation  
Chapter 1:- Introduction 
1.1) Short-Term & Long-Term Global Internet Usage:- 
The Internet, first introduced commercially in 1995 [1], is the product of decades of research and 
development and has revolutionised the way that modern communications devices interconnect. The 
Internet is capable of providing almost instantaneous communication for an array of digital platforms 
across a diverse set of different mediums on a global scale. Usage of the modern-day Internet is vast 
and varied with applications including e-mail, audio and video streaming, file sharing, social medial, 
gaming, e-commerce, retail, etc (Figure 1). Given this, the internet can arguably be called one of the 
greatest achievements in the last 100 years. 
Figure 1:- Activities performed online by individuals in Great Britain in 2020 [2]. 
However, since the commercialisation of the Internet and because of the Internets utility and 
flexibility, the popularity of the Internet has increased exponentially. Ciscos annual Internet report 
[3] has stated that by 2023, the predicted total number of Internet users will increase to 5.3 billion 
worldwide. A 1.4 billion user increase from the 3.9 billion in 2018. The number of devices connected 
to IP networks worldwide is also expected to increase from the 18.4 billion estimated in 2018 to a 
predicated 29.3 billion in 2023, a 33% increase. While this predicted, growth is substantial, it should 
be noted that Ciscos annual report was released in March of 2020 and did not factor in the 
consequences of the Covid-19 pandemic. 
On the 11th of March in 2020 (two days after Ciscos released their annual Internet report), the World 
Health Organizations (WHO) Director General, Tedros Adhanom gave a speech declaring a global 
pandemic [4]. As a result, countries around the world scrambled to develop strategies to fight the 
spread of Covid-19. One of the most common solutions proposed and adopted by countries worldwide 
was a lockdown strategy. In the United Kingdom (UK), Prime Minister Boris Johnson on the 23rd of 
March 2020 gave a speech announcing the instigation of a lockdown with immediate effect. A similar 
lockdown policy was implemented in the USA with the state of California instigating a lock down on 
the 19th of March 2020 with the remaining US states following suit over a three week period [5]. In 
those countries that did impose a lockdown strategy, most businesses and institutions were required 
to close their doors unless they were detrimental to the running of the country. In the UK, all citizens 
were asked to stay at home. Only those workers that were deemed as essential, such as NHS staff, 
supermarket employees, transport personal, etc, were allowed to travel to and from their places of 
employment. Family members and friends who loved in different households were also not allowed 
to meet. 
To counter this situation, individuals, businesses and institutions looked to Internet based 
technological solutions. Businesses and institutions such as Universities and Schools turned to 
software packages such as Microsoft Teams that allowed video communication and project 
collaboration between employees and students and teachers. This enabled many people to work from 
home and for children and students to carry on learning remotely, with online lectures and by 
accessing digital resources. Individuals turned to programs like Zoom and Skype to keep in contact 
with their friends and family. According to a study undertaken by Ofcom [6], streaming services such 
as Netflix, Amazon Prime, Disney Plus and others saw increased subscriptions within the UK with an 
additional twelve million customers subscribing to these streaming services. The Ofcom report also 
noted that in May 2020, total viewing figures for streaming services in the UK had increased by 71% 
compared to May 2019. The result was a substantial increase in Internet usage worldwide. According 
to an article by the BBC [7], overall Internet usage in the UK had doubled by December 2020 when 
compared December 2019. The same article also reported that Openreach customers consumed 
50,000 petabytes of data in 2020 when compared to 22,000 petabytes consumed in 2019. In a report 
[8] covering the period between September 2019 and March 2020, the Organisation for Economic Co-
operation and Development (OECD) published and citied statistics showing an increase in Internet 
usage attributed to Covid-19 which included:- 
 An increase of core network traffic in the USA of 23%, reported by AT%T. 
 An increase of data usage by 30  40% in Japan, reported by NTT Communications. 
 An increase of bandwidth usage by nearly 40% as reported by Telefnica in Spain. 
However, the rapid increase in Internet usage within such a small-time frame resulted in a number of 
technical issues. A paper published in December 2020 [9] that looked at the impact of the Lockdowns 
in different European countries showed that in Italy, path delay increased on average by 3  4 times 
compared to pre-lockdown figures as alternate paths for Internet traffic were selected to avoid 
congestion. Packet loss also increased by 2  3 times compared to pre-lockdown figures. Other 
European countries (Spain, France, Germany, Sweden) had similar outcomes. This was of course not 
limited to Europe. Countries across the world also experienced similar Quality of Service (QoS) issues, 
the severity varying depending on location and the infrastructure in place. QoS was not the only issue. 
According to IT Brief [10], a study released by ThousandEyes  (a network intelligence company owned 
by Cisco) reported that global Internet outages had increased by 63% in March 2020 and by 44% in 
June 2020 when compared to January of the same year. Most of these outages were attributed to 
increased Internet usage. It should be noted that despite an increase in network disruptions and 
outages, the Internet and the network infrastructure that supported it was able, for the most part, to 
cope with the increased demands of Internet users though at a cost of slower download speeds as 
noted in a report by Fastly [11] and in many cases, reduced QoS for Internet users. 
Overall, the challenges presented by the short- and long-term increase in Internet usage cannot be 
taken lightly as the possible repercussions could be detrimental. Solutions are required that will allow 
the QoS of Internet service and applications to be maintained as Internet usage continues to increase. 
Either due to the addition of new Internet users or unforeseen events such as the Covid-19 outbreak. 
1.2) Solutions to a Growing Challenge:- 
One of the outcomes to emerge from the Covid-19 pandemic was that it allowed countries who 
initiated lockdowns as well as businesses and other institutions to examine the successes and failures 
of the strategies employed. More importantly, it allowed for a number of recommendations to be 
made to deal with the increase of both short and long-term Internet usage. Some of the suggested 
solutions and recommendations were as follows:-  
Temporary and Short-Term Solutions:-  
To reduce the scale of the problems caused by increased Internet usage during the Covid-19 outbreak, 
several suggestions were offered from a number of different sources:- 
1. The European Commissioner, Thierry Breton of the EU called on streaming companies such as 
Netflix, Amazon Prime and YouTube to reduce the default video resolution of videos streams 
into the EU to help prevent congestion and gridlock [12][13].  
2. The CEO of Telstra, an Australian Internet provider, urged its users to download films during 
off-peak times and to spread Internet usage throughout the day [13] [14]. 
3. The OECD [8] suggested for mobile networks, releasing unused spectrum on a temporary basis 
to increase bandwidth capacity over the air to reduce the possibility of mobile Internet 
congestion. 
4. The OECD [8] also suggested that engineers working for network operators who are 
responsible for connecting/disconnecting private broadband to homes should be granted the 
mobility required to maintain functionality of both the core and access networks to expedite 
repairs of Internet infrastructure when faults occur.  
Long-Term Solutions:-  
For solutions pertaining to the future of the Internet and growing usage, the following 
recommendations were made, again from various different sources:- 
1. Both the OECD [8] and the ITIF [13] made recommendations about Internet infrastructure 
though focusing on different aspects. The ITIF looked more upgrading rural infrastructure to 
increase broadband speeds, while the OECD discussed upgrading overall infrastructure in 
general by phasing out older, DSL technologies and replacing them with optical fibre.  
2. The OECD [8] suggested that network operators should attempt to anticipate increases in 
Internet usage to avoid congestion by co-operating and upgrading their interconnection 
capacity with other network operators and providers.  
3. The OECD [8] also suggested that network operators should have access to the equipment 
supply chain and maintain controlled and prioritised access to datacentre facilities. 
The short- and long-term solutions and recommendations are a sample of some of the solutions 
available, primarily concentrating on physical infrastructure, service provider and network operator 
policy, and human resources. In addition to these areas, while not covered strongly in the solutions 
presented above, there is also the control and software aspects of the Internet. 
Traditional networking from Local Area Networks (LANS) to Wide Area Networks (WANS) were 
originally designed using a distributed structure where each forwarding node, typically a router or a 
switch would undertake a discovery process to find all the nodes that it was connected to. Each 
forwarding node would build a table and from this table, the node would know which of the 
neighbouring nodes would be the best option when it was required to forward a packet to a 
destination host. This was important as some of the neighbouring nodes might lead to routes more 
suitable than others depending on the metrics and routing algorithms used. However, traditional 
distributed networking does have several disadvantages (see section 2.2). For example, in a 
distributed network topology, if a forwarding node was to fail, the nodes that neighbour the failed 
node will not learn about the nodes failure straightaway and will continue to forward packets to that 
node. This could result in an increased packet loss rate, increased end-to-end delay and possibly 
congestion which in turn could be detrimental to the overall QoS of the application and its 
performance. This especially true when considered in terms of the Internet networks experiencing 
increased traffic due to Covid-19. 
To counter this issue and several others that affect distributed networking, a software and control 
solution known as Software Defined Networking (SDN) [15] was introduced. SDN (see section 2.2) 
offers many advantages over traditional, distributed networking methods. SDN uses a centralised 
control approach that separates the Control and Forwarding planes within a network device. Instead 
of each forwarding node making independent forwarding decisions, a central controller makes 
forwarding decisions and because the SDN controller is connected to each forwarding node, the SDN 
controller can build a complete topology of the overall network is controls. This in turn allows for 
smarter forwarding decisions and allows the controller to react to problems such as congestion and 
node failure a lot quicker than a distributed network can. However, while SDN offers many advantages 
over distributed networking, it also has some disadvantages (see section 2.2.4). 
SDN by default uses traditional heuristic routing algorithms. One of the most used is known as Shortest 
Path which as the name suggests, is designed to find the shortest path between two points based on 
some metric. For example, in Link State Routing (LSR), Dijkstras [16] Shortest Path algorithm is used 
in routing protocols such as Intermediate System to Intermediate System (IS-IS) and Open Shortest 
Path First (OSPF) using latency to find the shortest path based on end-to-end delay. In Distance Vector 
Routing (DVR), Bellman-Ford [17] [18] is used in routing protocols such as Routing Information 
Protocol (RIP) where the number of hops between source and destination nodes are used as the basis 
to find the Shortest Path. Shortest Path can also be used in tandem with Equal-Cost Multi-Path (ECMP) 
[19] routing, a load-balancing method that allows for traffic to be split equally between multiple paths 
to help ease congestion. Overall, shortest path is a flexible and popular algorithm. 
Unfortunately, Shortest Path has two key issues that should be noted. The first is that traditionally, 
Shortest Path uses a single metric, normally latency. This means that for network applications that 
require a path to meet multiple QoS requirements, Shortest Path is not suitable. It should be noted 
that it is possible to modify the Shortest Path protocol to use multiple network metrics, especially 
within SDN. This however leads to the second issue, the time required to find a path between two 
nodes. The more metrics that introduced into the pathfinding process, the longer Shortest Path takes 
to return a path between two nodes. This is especially true when considering K-Shortest Path [20]. 
Instead of returning the best path between two nodes, K-Shortest Path returns all the paths between 
two nodes up the value of K. This makes K-Shortest Path very useful in network environments with 
mesh topologies because if one path is not suitable due to congestion or the path not meeting QoS 
criteria, another path can be found that is. Unfortunately, using multiple metrics in conjunction with 
multiple paths results in delay as the algorithm requires longer to find a path between two nodes.  
Given this, one possible solution would be to replace the Shortest Path routing algorithm within SDN 
with an algorithm capable of using multiple metrics to meet the QoS requirements of an application. 
In theory, replacing the algorithm, combined with the advantages of a centralised SDN approach over 
distributed networking would present an overall solution that would allow for faster routing decisions 
to be made while reacting very quickly to changing network conditions. When this is considered in 
terms of increased Internet usage, such an approach would allow for faster QoS based routing, 
reduced congestion and an overall more dynamic and a quicker response to changing network 
environments.  
1.3) The Focus, Novelty and Hypothesis of the Research:- 
Of all the potential solutions mentioned in section 1.2, the research presented in this Thesis 
concentrated on the proposed control and software solution discussed previously, where the primary 
objective was to design and implement a multi-metric-based routing algorithm within a centralised 
SDN controller network topology. The specific requirements for the routing algorithm were as 
follows:- 
 SDN controller: Given the advantages that a centralised SDN approach offers in contrast to 
distributed networking methods (see section 2.2), any routing algorithm employed would aim 
to utilise these advantages to increase overall efficiency.  
 Multi-Metric Routing: As discussed in section 1.2, routing algorithms such as Shortest Path 
use only one metric (normally latency) for pathfinding. To meet the QoS demands of more 
specific network applications, a routing algorithm using more than one network metric for 
pathfinding was required. 
 Routing Efficiency: Any routing algorithm employed was required to be able to find a path 
between nodes faster than the equivalent algorithm. In this instance, an equivalent K-Shortest 
Path algorithm. 
 Scaling: Related to the previous point, as network topologies grow in size and connectivity, 
the performance of a routing algorithm can suffer in terms of the time required to find a path 
as the number of available paths between source and destination nodes increase. The 
implemented routing algorithm would need to be able to scale to maintain performance in 
larger and denser networks topologies. 
 Adaptive: Any routing algorithm would be required to adapt to a dynamic network 
environment (node failure, link failure, congestion, etc), thus reflecting the true nature of real-
life network topologies.  
To implement the requirements as listed above, the Q-Learning [21] based algorithm, Q-Routing [22] 
was selected as the template for the routing algorithm designed to meet these requirements. This was 
because firstly, literature shows that Q-Routing is faster at pathfinding in general than K-Shortest Path 
[23]. Secondly, Q-Learning holds several advantages compared to other Reinforcement Learning (RL) 
techniques (see section 2.3.1). Finally, Q-Learning is relatively easy to implement in its original form. 
However, despite the general popularity of Q-Routing, there are few examples in literature (see 
section 2.4.3) of Q-Learning or Q-Routing being utilised within SDN. Moreover, of those examples, 
many of the advantages of SDN are not utilised or at the very least, not mentioned in the literature.  
This allowed for several novel ideas to be incorporated into the creation of a multi-metric, Q-Routing 
based, SDN hosted pathfinding algorithm:- 
 Topology Map: Because the centralised approach of SDN allows the controller to build a 
topology map, this information (link/edge latency and bandwidth values, number of hosts and 
forwarding nodes, all node IDs, port numbers, etc) could be passed to the centralised located 
Q-Routing algorithm. This allowed for faster convergence compared to Q-Routing in a 
distributed network as the centralised Q-Routing algorithm could start training with accurate 
information instead of having to accumulate it slowly overtime. There was no need for 
forwarding node to request estimates to the destination from the nodes that neighboured it. 
 Training and Pathfinding: The access to the topology map and the data it provided allowed 
Q-Routing an option that was not available in distributed networking, the separation of the 
training and pathfinding phases. In a distributed network topology, each time a forwarding 
node received a packet to forward, and after receiving estimate information from each node 
neighbouring it, the current forwarding node would do two things. First, use the information 
to train its own Q-Table. Second, use the freshly updated Q-Table to decide which 
neighbouring node would be the best choice for where to forward the packet to. Essentially, 
distributed Q-Routing implemented the training and pathfinding phases concurrently. SDN 
could separate these phases. All of the Q-Table estimate training for each destination node 
could be completed as soon as the SDN controller was initiated using the data provided by the 
topology map. This meant that the routing in the pathfinding phase had access to completely 
trained and accurate Q-Table estimates as soon as the network was active. For a dynamic 
network environment, a hybrid approach was used where additional, single re-training cycles 
were employed in addition to the pre-trained Q-Tables to allow the Q-Routing algorithm to 
adapt to possible network topology changes. 
 Scalability: One of the challenges for routing networking is scalability. Distributed Q-Routing 
in not immune to this as it stores the Q-Tables in each forwarding node. As the number of 
forwarding nodes in a network increase, the size of the Q-Table also increases. As each 
forwarding node only has so much available memory, if the Q-Table becomes too large, the 
available memory might not be sufficient to support the growing Q-Table. As a result, 
forwarding decisions would be based on out-of-date estimates and incomplete node 
information leading to either inefficient routing or failed delivery of packets. Another issue is 
that as the Q-Tables increase in size, the time required to make a forwarding decision also 
increases. As the microprocessors within a forwarding node has more information to process, 
the time required to make a forwarding decision increase. This in turn can result in sluggish 
routing, compromising overall network performance. However, with a centralised SDN 
approach, the Q-Tables, could be moved to a computer/server that not only had a lot more 
memory available, but also was equipped with a faster processor, allowing for much larger Q-
Tables to be stored and for faster forwarding decisions to be made. 
 Faster Exploration and Reduced Overhead: In order to reduce the time required to reach 
convergence, and to prevent loops, some variants of distributed Q-Routing keep track of the 
nodes already visited within the training and pathfinding phases. To do, the current node 
passes on a list of the nodes already visited to the next node in the path. However, just as 
forwarding nodes sharing estimates with each other generates overhead, so does the sharing 
of the list of nodes already visited. However, this list of nodes visited can be created, updated 
and stored with the centrally located Q-Routing algorithm. Not only could this remove the 
overhead required for this operation, but also speed up for convergence as the list of nodes 
visited is instantly available to the centralised Q-Routing algorithm. 
In addition to the points above, there were several concepts introduced that made this research 
unique:- 
 Multiple Network Metrics: While the idea multiple metrics for QoS based routing is not new, 
there are few examples of it within Q-Routing literature as Q-Routing was originally designed 
to use one metric, latency. Of those examples, either one metric is prioritised over the other 
or all metrics are combined in one formula (see section 2.7). The final algorithm presented in 
this research used two metrics (latency and bandwidth) to meet the QoS requirements of an 
application. Both metrics were given the same level importance in both the training and 
pathfinding phases so any path found would meet both the QoS requirements for latency and 
bandwidth. 
 Q-Routing using Bandwidth: As previously stated, Q-Routing was originally designed to create 
Q-Table estimates based on latency. However, in order to create a multi-metric, Q-Routing 
based algorithm, a version of Q-Routing than utilised bandwidth instead of latency was 
created. At the time of writing, no examples of Q-Routing using only bandwidth had been 
discovered in literature for either centralised or distributed networking. 
 Separate Formulas and Q-Tables: For multi-metric Q-Routing, the preference shown by 
current literature is to combine multiple metrics using one reward formula (as previously 
discussed). The resulting Q-Table estimate entry on how to reach the destination node from 
the current node is a hybrid value that does not represent any one single metric fully and as 
such, cannot be used reliably to find a path to meet the multiple QoS requirements. In this 
research, the idea of using separate reward formulas to train separate Q-Tables for each 
different network metric was introduced. 
 Multiple, Tuple Estimates: When using multiple metrics as separate values (e.g, latency and 
bandwidth), the possibility of path conflict in both the training and pathfinding phases is likely 
to arise. This happens when latency trained Q-Table suggests one node as the next best option 
based on existing latency estimates while the bandwidth trained Q-Table suggests another. 
Even if both agree on the next node, this conflict is almost certain to appear again further 
down the path towards the destination node. To avoid this challenge, the use of multiple 
estimates comprised of tuple pairs (Latency, Bandwidth) was introduced. These tuple pair 
estimates for both metric propagate backwards together during training from the destination 
node to each forwarding node in the topology. As a result, each tuple pair estimate when 
training is complete, accurately represents a specific path to the destination node, thus 
avoiding any potential conflict. By storing multiple tuple estimates, the paths that support all 
QoS requirements can be utilised while those that do not can be ignored. 
The novel research is designed to target a small, yet important area (control and software) to help 
alleviate both the short- and long-term increased in Internet usage. Specifically, the research 
presented introduces a multi-metric, Machine Learning (ML) based, centralised routing algorithm 
designed to meet multiple QoS requirements, giving equal measure to each metric while being able 
to find paths faster than an equivalent, heuristic, routing algorithm (K-Shortest Path). Overall, the 
research in this Thesis set out to investigate a way to improve routing based on the points listed above 
to prove the following hypothesis:- 
Q-Learning can be used for multi-metric, centralised routing in a scalable and adaptive fashion. 
1.4) Research Methodology:- 
The research presented was completed in three separate phases. The first phase (Chapter 4) was 
designed to investigate and implement the use of single metric Q-Learning and Q-Routing within an 
SDN network. In this case of Q-Routing, separate versions included Q-Routing using latency and Q-
Routing using bandwidth. Both static and dynamic (adaptive) versions of these algorithms were 
created and tested. 
The second phase, (Chapter 5) looked at three different ways to implement multi metric Q-Routing. 
The first implementation (Q-Routing using latency, total link bandwidth and free link bandwidth) was 
based on existing research while the other two implementations (Amalgamation Q-Routing using 
latency and bandwidth, Total Score Q-Routing using latency and bandwidth) were new initiatives. 
The third and final phase (Chapter 6) focused on the final, working algorithm known as Dual Metric, 
Multi-Estimate, Pareto, Q-Routing. The research performed in this chapter built on the concepts and 
ideas from the previous two chapters (Chapter 4, Chapter 5), using the initiatives that worked along 
with new ideas to make both a static and dynamic (adaptive) version of the Dual Metric, Multi-
Estimate, Pareto, Q-Routing algorithm. 
Testing for each algorithm created throughout the research was undertaken through emulation using 
a real SDN controller connected to an emulated network topology which created random network 
traffic. The tests were designed to evaluate the performance of each Q-Routing algorithm in terms of 
relative routing performance compared to equivalent K-Shortest Path algorithms and in terms of 
efficiency (average time required to find a path for each algorithm). For the adaptive versions of the 
Q-Routing algorithms (Chapter 4, Chapter 6), additional tests were undertaken to assess their 
performance, again in comparison to K-Shortest Path.   
1.5) Research Publications:- 
During the course of the research presented in this Thesis, a number of papers were published based 
on the research outcomes:- 
 The first paper, The Performance of Q-Learning within SDN Controlled Static and Dynamic 
Mesh Networks[24] was based on the research presented in Chapter 4 and some of the 
research in Chapter 5. The focus of the paper was on the use of single metric Q-Routing using 
latency and Q-Routing using bandwidth within SDN. This paper also introduced the idea of 
multi-metric Q-Routing. This paper presented at the IEEE Conference on Network 
Softwarization (NetSoft) in June 2020 was published by the IEEE in August 2020. 
 The second paper, Q-Routing Using Multiple QoS Metrics in SDN [25] was based on the 
research presented in Chapter 6. This paper looked at the implementation of a Q-Routing 
algorithm that used two network metrics for routing. This paper was presented in September 
2021 at the UKCI Workshop on Computational Intelligence conference and was published by 
Springer in Advances in Intelligent Systems and Computing. 
 The third paper, Q-Routing with Multiple Soft Requirements [26] was also based on the 
research in Chapter 6. The work presented built upon the research in the second paper and 
introduced an idea of using fuzzy logic to decide if a path found by the dual metric Q-Routing 
algorithm met the QoS requirements of an application. Instead of hard limits, fuzzy logic would 
find an acceptable range of values that met or nearly met the QoS requirements. This paper 
was presented in September 2021 at the UKCI Workshop on Computational Intelligence 
conference and was published by Springer in Advances in Intelligent Systems and 
Computing. 
1.6) Structure of the Thesis:- 
The overall structure of the Thesis is split into seven different chapters (including the current chapter, 
Introduction) followed by a Bibliography and appendices. 
Chapter 2 is a detailed literature review designed to examine both SDN and Q-Learning. SDN is 
reviewed first detailing the structure and rationale for SDN, the abstraction used by SDN, the 
disadvantages of SDN and possible solutions to these disadvantages, and an overall conclusion about 
SDN. This is followed by a review of Q-Learning which examines what Q-Learning is and how it works, 
the advantages and disadvantages of Q-Learning, the state of art for Q-Learning which examines Q-
Routing and variants of the Q-Routing algorithm from current literature including multi-metric Q-
Routing and Q-Routing used within SDN. This is followed by an overall conclusion on Q-Learning. Next, 
the literature review discusses testing methodology for different algorithms, the controllers available 
for SDN, and the simulators and emulators available for network development. Finally, the literature 
ends with an overall conclusion regarding to the reviewed literature and makes suggestions about 
novel approaches to utilising Q-Routing within SDN to support the Thesis objectives or creating a 
multi-metric, routing algorithm. 
Chapter 3 covers the creation of the SDN testbed used to host and test the performance of the 
different variants of routing algorithms (Q-Learning, Q-Routing and K-Shortest Path) created during 
the research. The requirements for the SDN controller, the topologies used for experimentation and 
the traffic generation are also discussed. Following this, the details of how the SDN testbed was 
implemented are covered including the use of emulation tools, the SDN controller, the QoS 
requirement used for testing, how network metrics were collected, followed by a discussion on the 
elements that make up the network emulator used in testing. Finally, the methods used to test the 
SDN testbed are discussed. 
Chapter 4 looks at the implementation of the first group of routing algorithms within the SDN testbed, 
and the results that they produce. Five, single metric RL algorithms were employed, Q-Learning using 
latency, Q-Routing using latency, Q-Routing using bandwidth, adaptive Q-Routing using latency and 
adaptive Q-Routing using bandwidth with each of these having a K-Shortest Path equivalent algorithm 
acting as a basis for comparison. Chapter 4 start by looking at the objectives for the chapter. This is 
followed by a discussion on the theory and the implementation of the algorithms described above. 
Next, the chapter focuses on the design, settings and results of the three different experiments 
performed for each of the routing algorithms (were relevant). Finally, the chapter discusses the results 
for each of the experiments, gives a discussion summary which is the followed by a conclusion for 
Chapter 4. 
Chapter 5 looks at the implementation of the second group of routing algorithms within the SDN 
testbed, and the results that they produce. Three, multi-metric routing algorithms were utilised, Q-
Routing using latency, total link bandwidth and free link bandwidth, Amalgamation Q-Routing using 
latency and bandwidth and Total Score Q-Routing using latency and bandwidth. Each of these 
algorithms had a K-Shortest Path equivalent algorithm acting as a basis for comparison. The layout 
and presentation of Chapter 5 was identical to that of Chapter 4 with one difference, only the first 
two experiments in Chapter 4 were carried out in Chapter 5. 
Chapter 6 looks at the implementation of the third group of routing algorithms within the SDN 
testbed, and the results that they produce. Two, dual-metric routing algorithms were employed, Dual 
Metric, Multi-Estimate, Pareto Q-Routing and adaptive Dual Metric, Multi-Estimate, Pareto Q-Routing. 
Both of these algorithms had a corresponding K-Shortest Path equivalent acting as a basis for 
comparison. The layout and presentation of Chapter 6 was identical to that of Chapter 4. 
Chapter 7 is the final chapter that gives an overall conclusion for the research carried out in the thesis 
from each of the main research chapters (Chapter 4, Chapter 5, Chapter 6) highting the key points. 
This is the followed by a discussion on possible ideas for further research based on the work and 
outcomes presented in this Thesis.  
Chapter 2:- Literature Review 
2.1) Introduction:- 
One possible solution for keeping pace with the increasing amount of internet traffic and the 
increasing number of users is to examine some of the existing networking methods and tools to see if 
these can be improved or replaced. Routing for example is vital as it is the mechanism that finds the 
path between two points in a network, be it a small LAN or a WAN such as the Internet. Without it, 
computer networks on any scale simply could not function. 
Looking briefly at the two classes of distributed Dynamic Routing Protocols (DRP) [27] primarily used 
for networking, Link State (LS) and Distance Vector (DV), there are several differences. In LS, each 
forwarding node shares the knowledge of its neighbour with every other forwarding node in the 
network, so each node has a complete picture of the network topology. LS uses Dijkstras [16] shortest 
path algorithm to calculate cost-based paths using the metrics of the Link State including latency, 
bandwidth, jitter, etc. Each forwarding node using DV by contrast only shares forwarding information 
with the connecting neighbouring nodes and uses a distance-based metric such as the number of 
hops to find a path using the Bellman-Ford [17] [18] shortest path algorithm. While employing 
different approaches, both DRPs are established classes of routing used the world over. The important 
difference between LS and DV is their application. For traffic that has specific QoS requirements, LS 
would seem to be the better choice. If QoS was not a factor, then DV could be better suited. Both 
protocols, of course have their weaknesses. DV is not as fast to converge and has known issues such 
as looping and the well-known count to infinity problem. LS tends to flood the network with packets 
as each node attempts to learn about the topology and pass on that knowledge. Issues such as these 
can affect the overall network performance. However, both of these DRPs are old by technological 
standards with LS being created for the Advanced Research Project Agency Network (ARPNET) around 
1978 [28] and DV in the early 1980s with RIP-1 [29]. Moreover, both of these DRPs were designed for 
distributed networks using a variant of the shortest path algorithm to find a path based on the least 
cost or minimal number of hops.  
With this in mind, this literature review examines the two key components utilised for the research in 
this Thesis: SDN, a centralised network method designed to address the innate problems of distributed 
networking, and Q-Learning for pathfinding (Q-Routing), an ML algorithm created as an alternative to 
the shortest path algorithm. SDN is reviewed first with a detailed overview of what SDN is and how it 
works, the abstraction models it utilises, the competing approaches to SDN, the possible challenges 
to SDN and a conclusion. Following this is a similar overview of Q-Learning which describes the core 
principles of Q-Learning, the advantages and disadvantages of this approach, how Q-Learning for 
routing (Q-Routing) is employed, a review of the different variants of the Q-Routing algorithm in 
current literature, a review of the research that combines Q-Routing with SDN utilising multiple 
network metrics followed by a conclusion on Q-Learning and Q-Routing. Finally, this review looks at 
different methods of testing routing algorithms, an overview of the most common SDN controllers 
and network emulators/simulators ending with a conclusion regarding the weak areas in the available 
literature as well as suggestions on how to address these areas.  
2.2) An Overview of Software Defined Networking (SDN):- 
First conceived of in the mid-1990s [30], SDN is a relatively new networking approach for packet-
switched networks such as ethernet which has evolved overtime as an alternative to legacy, 
distributed networking techniques and to address some of the problems inherent with traditional 
networking methodologies such as to node failure, link failure, congestion, to name but a few. The 
aim of SDN is to allow a greater degree of control over all the network elements and to improve 
network performance. 
Because of the importance of SDN in the research presented in this Thesis and the core part that SDN 
plays, it was essential to have a good understanding on the core precepts that makeup SDN. As such, 
this section looks at the rationale behind SDN, the basic structure and architecture of SDN, the 
abstraction model used by SDN and the advantages and disadvantages of SDN. 
2.2.1) The Rationale Behind SDN:- 
As previously mentioned, SDN was designed to address some of the issues that exist in traditional 
decentralised legacy networks [15].  
Firstly, despite the protocols popularity and worldwide adoption, the use of the Internet Protocol (IP) 
in existing networks is both complex and hard to control as each network operator has to configure 
each network device separately to reflect the network policies that they wish to employ. This is further 
complicated by the fact that they often have to do this using low-level and often vendor-specific 
commands native to the network device which may require additional expertise or training and can 
also differ from one device to the next. This can be both time consuming and costly.  
Secondly, there is little in the way of automatic network reconfiguration and response mechanisms. 
This means that a network cannot adapt easily to networks faults such as a failed node or an 
unexpected increase in network traffic which can compromise overall network performance. As a 
result, specific network policy becomes impractical to enforce.  
Finally, current networks traditionally use forwarding devices/network nodes that are designed to 
work and make forwarding decisions independently to all other network nodes. These devices are 
vertically integrated housing both the intelligence that decides how to process and forward network 
traffic that the node receives and the forwarding aspect that forwards the traffic as indicated by the 
nodes intelligence. While this approach is used successfully all over the world, the overall lack of 
flexibility can hinder the network operators and, as a result, the performance of the entire network. 
2.2.2) An Overview of SDN:- 
To tackle some of the existing challenges that are inherent in a traditional network, SDN introduces 
four core principles that allow a greater level of control and smarter decision making [31]. These 
principles are as follows:- 
1. The network Control Plane and Forwarding or Data Planes are decoupled and become 
separate entities. 
2. Forwarding decisions are made by the Control Plane are flow-based as opposed to 
destination-based. 
3. The network forwarding logic is abstracted from hardware to a programmable software 
layer. 
4. An element called a Controller is introduced to co-ordinate network-wide forwarding 
decisions.  
Figure 2:- Overview of SDN architecture [15]. 
Figure 2 shows an example of a typical SDN architecture that illustrates how these four principles are 
applied to create a networking approach that differs from the standard used in everyday networking:-  
1. At the top of the diagram in green is the Management Plane. It is from this level in the SDN 
architecture that all Network Applications such as Load Balancing, Routing Protocols, etc 
reside and where decisions regarding network behaviour are made. The Management Plane 
is also the location where new protocols are implemented using high-level programming 
languages (C++, Python, Java). From here, all commands are passed on in the form of a 
common language that an SDN Controller in the Control Plane can interpret.  
2. In an SDN architecture, the Control Plane does not reside in the network device with the 
Forwarding or Data Plane. The middle part of the architecture, pink in the diagram is the 
Control Plane where the SDN Controller or Network Operating System (NOS) is located. This 
plane acts as a conduit between the Management Plane and the Data Plane. From the 
Management Plane, the Control Plane will receive instructions (such as a path between source 
and destination nodes) from applications which the Control Plane will convert into commands 
that the Data Plane can understand and react to. The Control Plane is also used to interpret 
and transport data from the Data Plane up to the Management Plane. 
3. Located at the bottom of the SDN architecture, illustrated in blue in the diagram is the Data 
or Forwarding Plane. It is here that the physical or virtual network devices (forwarding nodes 
such as switches or routers) are located. Flows are forwarded based on forwarding 
instructions received from the Control Plane. 
As previously mentioned, the Control Plane and the Forwarding or Data plane are separated from each 
other. In traditional networks, both the control and forwarding functionality would exist in the same 
network device (router, switch, node, etc). However, in the case of SDN, all forwarding instructions 
are passed down from the NOS or SDN Controller in the Control Plane to the forwarding nodes in the 
Data Plane. This is done via the Open Southbound API with the Network Hypervisor (part of the Control 
Plane) creating an abstraction that decouples the Control and Data Planes. This separation of the Data 
and Control Planes offers several advantages. The first is a single SDN Controller in the Control Plane. 
It can be used to program the forwarding instructions for multiple network nodes in the Data Plane. 
Having a centralised approach allows faster adaptation to changing network circumstances such as 
congestion, node failure, QoS demands, etc. Second, this also allows the NOS or SDN Controller to be 
located on a more powerful device such as a computer or server which would normally have more 
processing power, memory and buffer space than a typical router allowing for larger amounts of 
routing information to be stored and quicker decision making than a typical network node. 
In the Control Plane, below the NOS or SDN Controller is the Hypervisor, an abstraction of the 
underlying network and its topology. The abstraction created here by the SDN-controlled network 
allows for Network Applications in the Management Plane which may wish to send data across the 
network or perform other network-related tasks such as the collection of network statistics to use a 
simplified model of the network topology without knowing any of the underlying complexities such as 
the make and model of network devices. Instead, each application can use the simplified, general 
abstraction model provided by the Hypervisor to request information or send instructions to the 
relevant network devices via the SDN Controller (Figure 3). 
Figure 3:- Network Applications with an SDN architecture [15]. 
A Network Application located in the Management Plane when needing to send forwarding 
instructions, for example to the network devices in the Data Plane, will first send this information to 
the SDN Controller in the Control Plane via the Northbound Interface. 
The SDN Controller will then decide on a course of action and forward these commands issued by the 
SDN Controller to the Hypervisor which will convert these general commands into specific actions and 
pass these actions onto the specific network devices in the Data Plane via the Southbound Interface. 
This means that a Network Application can make a request of the SDN Controller and let the SDN 
Controller, working with the Hypervisor, fulfil this request.  
There are several advantages to this approach. Firstly, programming Network Applications becomes 
easier since the network abstraction (Hypervisor) in the Control Plane means that a uniform network 
programming language can be implemented in the Management Plane without needing to use 
languages that are specific to each network node. Secondly, because all Network Applications can 
utilise the same network information that the SDN controller provides through the Network 
Abstraction, there is the potential for more consistent policy decisions between network devices 
which, in turn, leads to improved network performance overall. Thirdly, Network Applications can 
utilise and reconfigure network devices from any part of the network. This means that network device 
placement is not as critical as it is in current network topologies. Finally, the integration of different 
Network Applications becomes easier. For example, if there are two Network Applications, (load 
balancing and routing), one or more Network Applications can be combined and priority for each 
Network Application can be decided sequentially or based on some other criteria. 
2.2.3) SDN Abstraction:- 
Part of the SDN approach is the idea of abstraction which is a key part of the underlying SDN process. 
Abstraction, according to the Collins English Dictionary, is defined as "the process of formulating 
generalized ideas or concepts by extracting common qualities from specific examples" [32]. This is 
evident in the SDN approach where generally the abstraction layer shields the complexities of the 
actual network, translates this information into a more general form or "common qualities" and allows 
network applications to work with this information using it to decide network policy and forwarding 
decisions. 
However, because the overall format of network abstraction can vary depending on who created it, 
there will always be differences from one form of abstraction to another. The first and most common 
model for SDN and abstraction is called OpenFlow [33]. OpenFlow, a communications protocol, was 
derived from a networking project called Ethane in 2006 by a PhD student at Stanford University. 
OpenFlow was designed as a way for academic institutions to test new networking protocols without 
having access to the manufactures underlying software in the network device. Instead, OpenFlow was 
installed in many makes of network devices (HP, Belkin, Netgear, Cisco) and ran side by side with the 
native software of these devices. This allowed OpenFlow to be activated for experimentation as 
required without affecting or replacing the native network device software. The main concept that 
makes OpenFlow so popular and most commonly used with SDN is that OpenFlow allows for the 
decoupling of the Control Plane and the Data Plane. Figure 4 shows the basic SDN approach as applied 
to OpenFlow abstraction.  
Figure 4:- Representation of OpenFlow abstraction in SDN [15]. 
When used in combination with SDN, OpenFlow splits the abstraction into three separate parts:- 
Forwarding Abstraction:- 
The first is the Forwarding Abstraction which enables all forwarding activity in the Data / Forwarding 
Plane to take place as defined by the Network Applications in the Management Plane. This abstraction 
also isolates the underlying hardware in the Data Plane from that of the Control and Management 
Planes. This approach is like that of a device driver that an operating system would use with a piece 
of hardware.  
Distribution Abstraction:- 
The next is the Distribution Abstraction which is designed to change the distributed control format 
that exists in most standard network devices and nodes to a centralised control format where an SDN 
Controller or NOS is responsible for all decisions regarding the networks operation. All independent 
control aspects that each network device or node have are effectively negated. To do this, the 
Distribution Abstraction also works in a similar way to that of the Forwarding Abstraction as it shields 
Network Applications within the SDN network from the networks actual distribution. In order to 
implement this abstraction, a common distribution layer is required so the Distribution Abstraction is 
aware of the individual distribution of all Network Devices within the network. Normally in OpenFlow, 
this layer resides within the NOS or SDN Controller. 
The distribution layer also contributes two additional properties to the overall SDN system: First, it is 
responsible for implementing control commands made in the Management Plane via the SDN 
Controller or NOS into the individual network devices or nodes in the Data Plane; Second, it collects 
information about the status of the network from the Data Plane and passes this information via the 
SDN Controller or NOS in the Control Plane to Network Applications in the Management Plane so these 
applications can assess the state of the network.  
Specification Abstraction:- 
The last abstraction used commonly in OpenFlow is the Specification Abstraction. A Network 
Application can state how it wishes the overall network or even part of it to behave to achieve a 
desired outcome. For example, rerouting network traffic to combat congestion. To perform this 
action, the Network Application in the Management Plane (Figure 2) makes the request of the NOS in 
the Control Plane which will perform the "specific" actions that make the Network Applications 
request a reality. These actions, which can be carried out by programming commands in the 
Management Plane are converted via the Language-Based Virtualisation into a format that the SDN 
Controller or NOS in the Control Plane can understand and implement.     
Overall, these three abstractions when used together give one general abstraction which allows 
applications to use the network without requiring an intimate or in-depth knowledge of its layout. This 
abstraction effectively allows a Network Application to see the physical state of the network in a 
simplified way and use it completely or in part as required. 
However, while OpenFlow is the most commonly used protocol with SDN, there are a number of 
alternatives. Table 1 shows some of the possible protocol options available for use with SDN and 
compares some of the key points such as the control and abstraction mechanisms. It should be noted 
however that while Table 1 lists a number of alternatives to OpenFlow, Table 1 is not exhaustive as 
there are many networking companies working on alternative protocols to OpenFlow [34].  
Name of 
Protocol 
Supporting 
Companies 
Standards 
Control 
Mechanism 
Decoupled 
Control & 
Data Planes? 
Network 
Abstraction 
Legacy 
Support 
OpenFlow 
ADI, Ciena, 
Juniper, 
Belkin, 
Netgear, 
Cisco, 
Brocade, 
BigSwitch, 
IBM, HP, 
NEC, Arista, 
Pica8 [36] 
Networking 
Foundation 
(ONF) 
Centralised 
Intelligent 
Controller 
Yes Forwarding, 
Distribution 
Specification 
Abstraction 
No Native 
Support for 
OpenFlow 
Network 
Devices [37] 
Cisco 
OpFlex 
Cisco, IBM, 
Canonical, 
RedHat, 
Embrane and 
Internet 
Engineering 
Task Force 
(IETF) 
(Pending) 
Central 
Policy Maker 
Distributed 
Intelligent 
Controllers 
Yes Policy Model 
& Concrete 
Model 
No Legacy 
Support for 
Non-Cisco 
devices 
VMware 
NSX [39] 
Big Switch 
Networks 
Inc, Cisco, 
Checkpoint, 
Arista 
Standards 
Support 
Virtual 
Overlay of 
Existing 
Networks  
Virtual 
Decoupling 
Uses Existing 
Hypervisors / 
Abstractions 
in Network 
Yes via 
Virtualisation 
NETCONF  
[40] [41] 
Cisco, Oracle, 
Intel, 
Juniper, 
Ericsson [42] 
Internet 
Engineering 
Task Force 
(IETF) 
Used in 
Conjunction 
with Existing 
Network 
Depends on 
Architecture 
of Existing 
Network 
Uses Existing 
Hypervisors / 
Abstractions 
in Network 
Juniper 
Contrail 
XMPP [43] 
Juniper, 
Arista, 
Mirantis 
Internet 
Engineering 
Task Force 
(IETF)  
Controller is 
Logically 
Centralised 
& Physically 
Distributed 
Yes High Level 
Abstraction 
using Red 
Hats KVM & 
Citrix 
Systems Xen 
Hypervisors 
Yes via 
Virtualisation 
NETCONF/
YANG [45] 
Cisco, 
Juniper, 
Ericsson 
Internet 
Engineering 
Task Force 
(IETF) 
Used in 
Conjunction 
with Existing 
Network 
Depends on 
Architecture 
of Existing 
Network 
Uses Existing 
Hypervisors / 
Abstractions 
in Network 
NETCONF 
Yes, for 
YANG, No 
Table 1:- Comparison between some of the available protocols utilised in SDN. 
From Table 1, it is clear that OpenFlow faces some stiff competition against protocols that clearly work 
in different ways in regard to SDN. For example, Cisco's OpFlex [38] depends on a distributed SDN 
architecture while other protocols, such as VMware's NSX [39], use a virtual overlay designed to be 
implemented on legacy network equipment. Both approaches differ from that of OpenFlow. Despite 
the different and varied approaches, OpenFlow in its various versions and formats is still the most 
popular protocol choice to bridge the divide between the Control and Data Planes. 
2.2.4) The Challenges and Solutions of SDN:- 
SDN in general can be seen to hold several advantages over legacy networking with the main 
advantages having been discussed previously (decoupled Control and Forwarding Planes, forwarding 
logic abstraction, etc). However, SDN is not perfect and does have a few possible disadvantages. This 
section looks at some of the issues with SDN along with possible solutions from current literature.  
2.2.4.1) SDN Controller Failure, Centralised and Distributed:- 
If a forwarding node such as a switch or a router in a traditional distributed network breaks down, 
other nodes over time can become aware of this problem and learn to reroute network traffic until 
the node that has failed is repaired or replaced. This is because forwarding nodes in legacy networks 
contain both the control and forwarding aspects giving each node the intelligence to make routing 
decisions. Obviously, if multiple nodes failed then the network could be slowed to the point that it 
was no longer functional, but the chances of multiple node failure are slim.  
The standard approach to SDN is a centralised NOX or controller co-ordinating all forwarding decisions 
based on information from the Management Plane. Failure of such a controller would completely 
cripple the network it controls. One paper [47] on enhanced controller placement strategy introduces 
a model called "Survivor" specifically designed for SDN controller survivability by introducing path 
diversity to the SDN controller and enhanced capacity-awareness so the SDN controller is not 
overloaded, either from a surge in network flows or due to node failure. However, a Distributed Denial 
of Service (DDoS) attack on a controller could also bring about SDN controller failure [48] which 
Survivor could not remedy. The obvious solution would be to have a replacement controller that 
automatically takes over when the primary controller is no longer operational, but this controller can 
also be subject to a DDoS attack even if it is not at risk of failure.  
The next possible option is a distributed SDN architecture which, while costly and potentially difficult 
to implement, could compensate for a single SDN controller failure. Unfortunately, one paper [49] on 
cascade SDN controller failure states that simply using multiple controllers cannot protect an SDN 
network from a single point of failure. Depending on the load of the network, if one SDN controller 
was to fail and the network load capacity was near 100%, the remaining controllers would not be able 
to cope with the additional load placed upon them from the failed controller. The result would be a 
cascade failure. While this paper presents a model utilising load balancing to reduce the probability of 
cascade failure, it does not eliminate the risk completely. Another approach presented [50] uses load 
balancing in tandem with feedback control showing positive result but again it does not combat the 
underlying issue completely. 
While the chances of an SDN controller being a target for a DDoS attack and general node failure are 
small, these issues cannot be ignored, especially when using SDN controllers in prominent network 
control positions. It is possible that a distributed architecture might present a better option than a 
single centralised SDN controller but there are plainly risks in both approaches.  
2.2.4.2) Latency of SDN Controller Placement:- 
One of the major challenges intrinsically related to SDN controller problems is the actual placement 
of the SDN controller. In theory, an SDN controller can issue commands to every forwarding node in 
the network, regardless of the controllers actual location.  However, due to issues such as latency 
affecting delay and the response times between controllers and nodes, SDN controller placement 
needs to be considered carefully to deal with these issues and to prevent load imbalance. It is very 
similar to the Shared Tree or Source-Based problem found in multicasting and the placement of the 
multicast node.  
One solution proposed [51] is the use of multiple SDN controllers in different network domains. A 
dynamic optimisation model is used where, depending on the traffic load, idle SDN controllers are 
temporarily shut down with the forwarding nodes assigned to those idle controllers being reassigned 
to active controllers. This approach essentially uses the SDN controllers optimally placed to control 
forwarding devices to balance the traffic load at that moment with different SDN controllers becoming 
idle and others taking up the burden depending on the state of each network domain at the time. The 
outcome, according to the paper, indicates that reducing the number of active SDN controllers results 
in the maximisation of the control resource utilisation and improved load balancing.   
Another idea proposed setting a baseline SDN controller called a Candidate [52]. Depending on the 
size and the density of the network, many Candidates can be employed. To find which forwarding 
node to physically connect the candidate to for optimal controller placement, the nodes in the 
network topology are examined and need to meet set criteria. First, the node must be able to process 
data at a set rate or faster. Second, the maximum propagation delay of each potential node is 
measured. Finally, the maximum load of the controller is considered. All these factors are combined 
into a framework designed to ensure that the placement of the controller or controllers are located 
where the load on the network is not able to exceed the capacity of any of the SDN controllers utilised.  
An older solution, yet possibly the most resilient out of those presented proposes using an approach 
called K-Critical [53] to find the optimal placement of the SDN controller or controllers (depending on 
the size of the network and number of nodes). The aim, to create a robust control topology to deal 
with controller failure and to keep the load balanced between all controllers in the network. The 
authors claim that this approach is more effective than other solutions as most controller placement 
proposals do not deal with scalability and assume that commercial controllers are scalable in terms of 
capacity and quantity of flows processed per second. 
In all three papers the proposed solutions had been tested on simulated or emulated environments 
with encouraging results where each proposal did provide a solution that allowed for effective SDN 
controller placement resulting in more balanced loads being placed on the SDN controllers. However, 
it should be noted that in all these cases, the tests were carried out in emulated or simulated 
environments. Experiments performed on real-life testbeds would reveal how accurate these results 
were.  
2.2.4.3) Scalability of SDN Networks:- 
An obvious point of concern for any network infrastructure is the ability of the network to cope and 
perform efficiently as the size of the network increases. This could be due to new links and new 
network nodes being added. Scalability is an important characteristic in traditional network 
architectures. This is also true of SDN networks. As networks grow over time, the amount of traffic 
that passes through a network will, obviously increase and thus, this traffic growth needs to be 
sustainable. Given the level of importance of this issue, there is fortunately a lot of research into this 
subject. 
There are two avenues of research into SDN scalability, direct and indirect. Indirect research normally 
focuses on a different SDN problem but considers scalability. For example, the previously mentioned 
paper on the K-Critical model [53] discussing SDN controller placement also referred to the lack of 
scalability in other solutions and how their proposal could help to address the problem of scalability. 
Regarding direct scalability, one paper [54] builds on an idea called "Elephant Flow Detection" by 
introducing a two-stage adaptive technique to identify Elephant Flows with low-overhead in the 
controller and, to dynamically configure the decision threshold for those flows and treating them 
differently, as required at the time. According to the paper, this has been tested and shows benefits 
over "other methods", unfortunately, the information on other methods, techniques and 
performance are a little vague. A more recent paper [55] in a similar approach, as discussed previously 
[51], creates a system that uses self-balancing binary search trees as a means to optimise SDN control 
plane scalability and the SDN controllers load balancing rate through efficient switch to controller 
migration. A dynamic approach where the switches or forwarding devices, in general, are controlled 
by different SDN controllers depending on the state of the network. 
Overall, scalability in SDN is a growing field of research with many institutions investigating methods 
on reliable scalability. The papers discussed represent a sample of some of the available research 
published. From this research, it is clear that there is no universal solution. However, there are many 
different approaches that could be combined to tackle the issue of scalability on different fronts. 
Moreover, given the interest in this topic, a solution to allow scalability within SDN could be available 
in the near future. 
2.2.4.4) Lack of legacy support in SDN:- 
While not considered a key issue, the lack of SDN and OpenFlow support in legacy nodes and 
traditional networks is a very practical concern worth mentioning. Most of the network hardware 
vendors as seen in Table 1 have some level of support for SDN using OpenFlow within their network 
hardware. The means that the Centralised SDN architecture separating the Control and Forwarding 
planes can be implemented in SDN networks. However, for legacy networks using older forwarding 
nodes or nodes from vendors who have no mechanism for OpenFlow and SDN, this can be a problem. 
The obvious solution is to upgrade the firmware of the non-conforming nodes to support SDN with 
OpenFlow assuming such an upgrade exists. If not, then the next option would be to replace the 
incompatible nodes with nodes that support OpenFlow. This, however, could be a very expensive 
undertaking depending on the size and type of the network. It would also be a waste of forwarding 
nodes that are still fully operational and modern, but simply do not support SDN. 
One proposed solution discussed previously, was the implementation of virtualisation as evidenced 
by VMware's NSX [39] and Juniper Contrail XMPP [43] shown in Table 1. A virtual overlay is used which 
effectively operates on top of the existing software within the network node allowing OpenFlow type 
operations to be implemented. Unfortunately, virtualisation does have some limitations. SDN using 
OpenFlow or similar protocols in SDN compliant nodes directly updates the forwarding tables of those 
nodes depending on instructions from the Management Plane via the Control Plane. Virtualisation 
cannot replicate this process. There is also the issue of the additional overhead that virtualisation 
places on the network as the virtual overlay requires additional network resources to function 
correctly. This might not be an issue on networks with little traffic but on heavily loaded networks, 
this could be a serious problem. This additional use of network resources is also an important factor 
when considering SDN controller redundancy, SDN controller placement and scalability in SDN 
networks. As previously discussed, each of these points can be seriously influenced by available 
network resources or the lack thereof. 
An approach combining virtualisation and emulation was proposed called Hybrid ARchitecture for 
Migrating Legacy Ethernet Switches to SDN or HARMLESS [56]. HARMLESS works by building on SDN 
by adding an extra layer of abstraction between the Control and Data Planes. The result is the 
decoupling of the forwarding hardware from the operating system in the legacy switch or network 
node. To control the forwarding behaviour of the legacy device using an SDN controller, a software 
switch designed to emulate OpenFlow is implemented. This approach combines the advantages of 
software and hardware switching where, the hardware component delivers the high port density, 
and raw packet processing functionality and the softswitch adds programmability, adaptability and 
standards-compliance. According to the authors of HARMLESS, this approach does not cause any 
significant impact in terms of raw packet processing performance, latency or data plane transparency 
when compared to standard OpenFlow switches of forwarding devices. 
Assuming SDN and OpenFlow continue to be embraced, then, given time, the majority of legacy 
network devices will be replaced with OpenFlow compatible network devices reducing the need for 
virtualisation and other techniques. However, given the long life of modern-day electronic devices and 
taking into account the cost of commercial network routers and switches, the search for methods to 
incorporate legacy network nodes will continue for the foreseeable future.   
2.2.4.5) WiFi & Optical Compatibility in SDN / Open Flow:-  
As mentioned previously, OpenFlow and SDN were initially designed for a packet-switched network 
where the initial concepts of SDN were instigated before the creation of WiFi and before optical 
networking started to become more common-place. However, with various heterogeneous wireless 
methods (3g, 4G, 5G, LTE, 802.11, Bluetooth, etc) now popular and widely used in conventional 
networking in tandem with optical fibre lines connecting networks across the world, SDN must be able 
to work with networks comprised of all these technologies if SDN is to remain useful and ultimately, 
maintain an advantage over legacy networking methods. Combining different networking 
technologies can be a challenge. If for example wireless technology is considered. Each different 
wireless technology works at different distances, use different Modulation Coding Schemes (MCS's), 
operates on diverse frequencies and so on. There are also key differences between wired and wireless 
technologies, such as full-duplex and half-duplex respectively. Standard ethernet networking is also 
very different from optical networking. Optical uses pulses of light to send data instead of electrical 
pulses as used in ethernet. Optical fibre also has a much larger throughput being able to transmit vast 
amounts of information that ethernet simply cannot match, as an optical fibre can support a much 
broader range of frequencies than the copper in a standard ethernet cable. There are, of course many 
other differences between each of these networking technologies. However, despite the key 
differences in each of these networking technologies, there is plenty of research looking to apply SDN 
to optical and wireless networks and, using SDN to control networks made up of all these technologies. 
Looking first at wireless technology, one of the main solutions for wireless integration came in the 
form of Software-Defined Wireless Networking (SDWN) [57]. SDWN is an approach similar to that of 
SDN in that both separate the Control Plane from the Forwarding Plane. However, wireless forwarding 
devices are connected to the SDN controller via Access Points (APs) instead of a physical connection, 
such as ethernet in a packet-switched SDN network. The Wireless OpenFlow protocol used to transmit 
forwarding data to the wireless network devices and to send network metric data to the SDWN 
controller is again similar to the standard OpenFlow protocol used by SDN but again is modified. The 
Wireless OpenFlow protocol operates for each AP and attempts to take into account specific 
characteristics and problems that are unique to wireless channels such as channel selection, 
connections from multiple wireless devices, interference mitigation, traffic control, collision 
avoidance, etc. This is an important factor because whereas the network nodes in an SDN network are 
connected to the controller, this is not the case in SDWN where the AP connects to the SDWN 
controller. It is possible that many wireless devices can be connected to a single AP with more than 
one APs connected to the SDWN controller. It is also possible for each AP to connect to a different 
type of wireless technology.  
A recent paper on wireless SDN heterogeneity [58] introduced an idea called Heterogeneous Network 
(HetNet) to bring a diverse range of wireless networking technologies into one network domain. 
HetNet experimented with the idea of using SDN to control several different wireless technologies 
including Wireless Fidelity (WiFi), Fifth Generation (5G), Long-Term Evolution (LTE) and a light-based 
wireless technology Light Fidelity (LiFi). Each AP had the OpenFlow protocol tailored to a specific 
wireless technology and where each AP could issue forwarding instructions to the wireless devices 
connected to that specific AP. The Control Plane in this instance was responsible for maintaining the 
state of the network and managing network resources by allocating them depending on how the 
network state changed. According to the paper, with constantly changing network states and wireless 
resources, the SDN applications cannot provide reliable or guaranteed services to wireless network 
devices.  The solution in this case was to employ a Traffic Engineering (TE) scheme designed to support 
dynamic agnostic downlink flows routing to APs in combination with differentiated granular services. 
This was employed in tandem with a developed network and user-centric policies to make network 
applications aware of the available network resources via the Northbound and Southbound interfaces 
of the SDN Controller. According to the paper, the performed experiments indicate that the employed 
TE scheme used by HetNet guarantees QoS in the form of minimal delay and throughput for each 
service class while improving the overall throughput for HetNet. 
Next, looking at optical networking, as optical cables are used to transport vast quantities of data 
globally, being able to integrate optical networking technology into SDN would be a great asset and 
like that of SDN and SDWN, research into Software Defined Optical Networking (SDON) [59] has also 
been taking place for a number of years. SDON, like that of SDWN, is based on the SDN approach with 
similar abstractions and a layer-based format where the SDN controller is connected to each optical 
device through an OpenFlow protocol designed to work with compatible, OpenFlow friendly optical 
networking devices. Such devices include a Reconfigurable Optical Add-Drop Multiplexer (ROADM) 
switches or Configurable Optical Add-Drop Multiplexer (COADM) switches.  
There is a lot of ongoing work that either is designed to make efficient use of SDON or to improve how 
Optical SDN works in terms of QoS and smarter path selection. For example, in regards to improving 
on optical SDN, one paper [60] looked at the achievements of an approach called INSPIRING-SNI 
(INvestigating SDN Programmability ImpRovING optical South- and North- Bound Interfaces). The aim 
was to enhance the level of programmability in optical SDN using two different methods. The first 
looked at the Southbound Interface and how INSPIRING-SNI controls, manages and operates optical 
networks using initiatives such as OpenROADM [61]. In this context, the OpenROAD Multi-Source 
Agreement (MSA) [62] is used to define the interoperability specifications for Reconfigurable ROADMs 
as agreed by many networking and telecommunications companies including AT&T, Ciena, Fujitsu, 
Orange S.A, Cisco, Saudi Telecom Company, Telecom Italia, Juniper Networks, Deutsche Telekom AG 
and many others. This agreement is also used to specify and agree upon Yet Another New Generation 
(YANG) [63] data models. YANG is a data modelling language used to model configuration and state 
data which is then used by the Network Configuration Protocol (NETCONF) to program and pass on 
instructions to the underlying optical network devices. In this instance, YANG in conjunction with 
NETCONF is used instead of OpenFlow.  
The second approach looked at the Northbound Interface and the development and the 
implementation of Optimisation-as-a-Service (OaaS), a framework for dynamic optimisation, 
specifically for multilayer backbone/metro networks (where IP over optical is employed) used in 
conjunction with metro/access segments. The OaaS framework would be based on an open-source 
networking planning, a Java-based tool called Net2Plan [64] designed for protocol development, 
network optimisation, planning and evaluation. At the time of writing, the research being carried out 
on this INSPIRING-SNI initiative was still in progress. 
The last paper reviewed in the section [65] again took a heterogeneous approach except, in this 
instance, combined both optical and wireless network elements controlled by an SDN controller. The 
paper aimed to create a methodology for the efficient allocation of both optical and wireless resources 
using both SDN in tandem with Network Functions Virtualization (NFV). NFV, like that of SDN, uses 
network abstractions. However, SDN and NFV differ in their approach to separating functions and 
abstracting resources. While SDN abstracts physical networking resources such as the network 
forwarding devices and deciding forwarding decisions, NFV aims to virtualise all physical resources 
beneath the network hypervisor. This allows the network to grow without the addition of more 
network devices as it allows the introduction of network slicing. Network slicing is a specific form of 
virtualisation that allows multiple virtual networks to run on top of an existing physical network 
structure. The key benefit of network slicing is that it provides a virtual end-to-end network that not 
only takes into account the networking but the computing and storage functions too making it very 
flexible. This paper proposed using SDN and NFV together where a set number of networking slices 
was created to form logically isolated networks. Each of these different networks was dedicated to a 
different type of service where each service had different requirements. The papers objective was 
how to define the network slices so that the specific delay and bandwidth requirements for multiple 
services could be met while taking into consideration both the optical and wireless network resources. 
To address this, the SDN controller was used to define the network slices and the channels per network 
slice dynamically in real time by creating slices depending on the resources that were currently 
available. The paper suggests that by monitoring the bandwidth, it could be seen that resources were 
allocated more efficiently and dynamically. The result was a balanced and granular response.  
2.2.5) Conclusions on SDN:- 
It is clear from the literature available on SDN, OpenFlow and its variants that SDN is an immensely 
popular field of interest, both for academic and commercial organisations, and from this literature a 
number of conclusions can be drawn:- 
1. While originally designed with packet-switched networks in mind, the research undertaken 
into SDN shows that the application of SDN using OpenFlow or alternative Southbound 
Interface protocols for optical and wireless networks is no longer an obstacle. There are 
numerous research examples showing the use of SDN with optical and wireless networks and 
SDN using heterogeneous networking technologies. However, while OpenFlow seems to be 
the most popular protocol for SDN and packet-switched networks, this is not the case for 
optical and wireless networking where the Southbound Interface protocols are more varied. 
Moreover, while individual Southbound Interface protocols maybe standardised such as 
YANG/NETCONG, there is no standardised approach to a combined heterogeneous SDN 
system. This could be due to the fact that optical and wireless technology is more varied than 
packet-switched networks, requiring different approaches depending on the type of optical 
or wireless device. SDN for packet-switched networking has been a topic of research longer 
than that of SDN for optical and wireless, so a standard approach for the later could happen 
given time. 
2. SDN allows network users a great deal of flexibility. A high-level programming language such 
as Python or C++ can be used to program the control functionality of the SDN controller and 
applications in the Management Plane without needing to access the network nodes in the 
Data Plane. This means that network management becomes easier in several ways thanks to 
SDNs centralised approach. It also means that network engineers looking to experiment with 
new ideas such as routing protocols can do so with relative ease.  
3. SDN is an extremely popular area of research in networking. This is good for two reasons. 
Firstly, for those looking to leverage SDN, it means that there is a great deal of support 
material to draw upon when embarking upon a new SDN based project. Secondly, this means 
that it is likely that more solutions will be presented to deal with the highlighted disadvantages 
such as the lack of legacy support and scalability. 
4. The research, development and usage of SDN by leading networking and telecommunications 
companies (Cisco, VMware, Juniper, Versa Networks, etc [66]) indicates that SDN is not a 
passing trend and likely to be heavily utilised across the world as existing network infra and 
infer structures are upgraded or replaced. 
SDN, despite having some issues, has great potential with the level of interest in SDN, both in industry 
and academia, being extremally high. Combined with SDNs inbuilt flexibility and the innate 
advantages, SDN will come to play a key part in the feature of local and global networks. Until that 
time, SDN itself can be used to help further research into other networking fields such as algorithm 
development, load balancing, QoS, etc while the research into SDN itself continues.  
2.3) An Overview of Machine Learning & Q-Learning:- 
This section gives a summary on the three main categories of ML techniques, looks briefly looks briefly 
at the origins of Q-Learning, the theory behind Q-Learning and the advantages and disadvantages that 
Q-Learning presents. 
2.3.1) A Summary of Machine Learning:- 
When it comes to ML techniques, there are many different types that can be approximately defined 
into three main categories, Supervised Learning (SL), Unsupervised Learning (UL) and RL [67]. 
Additional categories tend to focus on hybrid ML techniques comprised of methods from the three 
main categories. 
Supervised Learning: SL [68] is a ML technique primarily used for tasks including classification, 
regression and forecasting in both offline and online environments. SL works by example, where the 
algorithm is provided with a known dataset that includes the desired inputs and outputs. The 
algorithm uses this information to find a method that determines how the inputs can be used to meet 
the outputs. To do this, SL looks for patterns in the dataset provided, learns from observations and 
then makes predictions which are corrected by a supervisor until the until the algorithm achieves a 
high level of accuracy. Well known SL algorithm include Nave Bayes Classifier, Neural Networks (can 
be both supervised and unsupervised depending on the application), Support Vector Machine, 
Nearest Neighbour, Decision Trees and Linear Regression. 
The advantage of this approach is that the supervisor can determine the number of classes to be used 
and the specificity of the classes allowing for detailed decision boundaries. However, the accuracy of 
the outcome of SL can vary depending on several factors. If, for instance SL is used for classification 
and there are no examples or few examples of training data for a specific class, it is possible miss-
classification to occur. The efficiency of SL can also be affected if the quality of the samples with poor- 
or low-quality examples leading to less efficient results. For example, when using Neural Networks 
(NN) for image recognition, it is possible for NN to incorrectly classify example images that makeup 
part of the dataset. A paper on this phenomenon (Explaining and Harnessing Adversarial Examples) 
[69] gave an example where a picture of a Panda was more likely to be identified as a Gibbon. In 
another example involving a self-driving car, a Deep Neural Network (DNN) processed a Stop sign as 
a Speed Limit 45 sign.  
SL also has a few potential disadvantages which need to be considered. Depending on the size of the 
training data and the specifications of the SL algorithm, pre-processing of the training data can be a 
time-consuming affair. Time can also be a factor when it comes to training, again, dependant on the 
size of the training data where, for example, an SL algorithm such as DNN can be extremely resource 
intensive. Because SL employs classifications set by the user, it cannot give you unknown training data 
in the same was UL can. Finally, if the dataset is large or contains dynamic elements, it can be difficult 
to set the labels to predefine the rules. 
Unsupervised Learning: UL [68], primarily used for tasks such as clustering and association is similar 
to that of SL. The key difference is that UL does not require the dataset to be predefined using labels 
and as such, does not require a supervisor to help teach the algorithm what is correct and what isnt 
and as such, this allows an UL algorithm to run in real-time. Examples of UL based algorithms include 
K-Means Clustering, Neural Networks and Deep Learning, Hierarchical Clustering, Singular Value 
Decomposition, etc. 
Apart from being unsupervised and not requiring input labels for the dataset, UL also presents several 
additional advantages. For example, UL algorithms classify the data they process which means official 
labels can be added, saving time in comparison to SL algorithms and because of the lack of pre-
labelling, the overall complexity of UL is reduced. Finally, because there are no official input labels, UL 
algorithms can find interesting facets in the raw data which do not fall easily into any one classification 
or pre-defined label as with SL.  
However, UL is not without its faults. Interpreting the results can be a challenge and there is no 
guarantee that the results obtained by UL will be useful as there is no label or output measure, 
requiring human intervention on some occasions. It is also possible that the accuracy of results may 
suffer depending on the quality and quantity of the raw data provided as the UL algorithm is learning 
from that data without any user defined labels or pre-training. Finally, with UL, it is hard to know if 
the answer presented is the correct one in many cases as there is no prior knowledge as with SL. 
Reinforcement Learning: RL is a ML approach that unlike SL and UL, does not require a data set to 
learn from. Instead, RL learns by using an agent that interacts with its environment where the desired 
outcome is to find a suitable action model to maximise the total cumulative reward. More specifically, 
the agent learns from the consequences of its actions on a trial-and-error basis using past choices and 
new choices to learn the best action to take depending on the current state. Reinforcement in this 
case is provided in the form of a numerical reward or penalty received by the agent to indicate success 
or failure respectively. The outcome is stored in association with the action taken to achieve that 
outcome. The goal for the agent is to find the correct actions to maximise the accumulated reward 
over time. 
 This makes RL best suited to tasks that deal with exploration and exploitation problems where pre-
existing data sets are not available, following a Markov Decision Process to find a policy that will result 
in optimal behaviour. Because of this, RL is used for a variety of applications including improving the 
learning speed for autonomous vehicles [70], reducing failure rates in drug discovery and 
development [71], traffic signal control for isolated junctions [72], digital image dehazing [73], 
interference avoidance for communication stations [74], etc.  
Examples of RL include Q-Learning, Deep Q-Learning Neural Network (DQN), Deep Deterministic Policy 
Gradient (DDPG) and State-Action-Reward-State-Action (SARSA).  
RL has several advantages in contrast to Supervised and UL. i) RL does not require supervision while it 
is learning. ii) RL does not require a predefined dataset to start learning [75], instead learning directly 
from the environment by interacting. iii) RL is bias resistant [76]. For example, if the method used to 
label the data in SL is in anyway biased, it is possible for the algorithm to pickup on that bias and 
incorporate it. As RL does not use datasets to learn, no bias can be introduced in a similar manner to 
that of SL. iv) RL operates in real-time. v) RL is adaptive [76], allowing the algorithm to adapt to 
dynamic situations. vi) RL in general can correct errors [77] that might have occurred during the 
training process or phase. Once corrected, the chances of the same error occurring again are vastly 
reduced. vii) RL can be used to solve complex problems that cannot be solved using conventional 
approaches [78].  
It should be noted that there are several disadvantages to the RL approach. i) Depending on the 
algorithm type and the application, RL in general can require a lot of data and computational power. 
This makes RL unsuitable for simple problem solving [78]. ii) RL uses a Markovian approach [79] which 
does not accurately reflect real-world behaviour. For example, the Markovian model describes a series 
of possible events where the probability of the current action is dependent only on the state attained 
by the previous action. iii) Exploration vs exploitation [79] is a common issue in RL where a solution 
may be presented, but it is hard to know if it is the best solution. Additional exploration might find an 
alternative, superior solution but it is also possible the solution presented cannot be improved upon 
and as such, additional exploration would not be fruitful, and exploitation of the current solution 
would be the best approach. iv) The Curse of Dimensionality [79] is a challenge in RL that arises 
when trying to apply appropriate states and actions to real-word problems. If too many states are 
used to represent the environment with a wide variety of actions, it can be come challenging to 
adequately explore all possible actions from all possible states. v) A noted issue with RL is a challenge 
referred to as the Temporal Credit Assignment Problem [79]. Time is required for updated estimates 
for each state propagate backwards. This means that for applications that require instant rewards or 
feedback, RL might not be suitable.  
It should be noted that while each ML approach has its own set of advantages, the application is one 
of the key points in deciding which of these approaches to use. When considering the focus of the 
research presented in this Thesis, e.g., routing, RL seemed to be the logical choice as it is designed for 
exploration, exploitation, policy learning, value learning, etc. The advantages that RL also offers are 
beneficial to routing. For example, RL is adaptive so an algorithm based on RL for routing could adapt 
to a changing networking topology in real-time. RL learns directly from the environment which in the 
case of routing and networking, would mean that RL was learning directly from the network topology 
which it could also do unsupervised. Given these factors and considering the general advantages that 
RL hold over both Unsupervised and SL, a RL based approach was selected as the basis for the 
proposed multi-metric routing algorithm. Specifically, Q-Learning. 
2.3.2) What is Q-Learning? 
Created in 1989 by a PhD student at the Kings College [21], Q-Learning is a ML technique that uses 
unsupervised, RL. Like other RL algorithms, Q-Learning was designed to determine the optimal 
behaviour and performance when interacting with the environment by maximising the total 
cumulative reward to the agent. Using a trial-and-error approach, feedback is provided for each step 
in the exploration of the environment in the form of positive feedback (reward) or negative feedback 
(punishment). If this is done correctly, then the outcome, in theory, should pick the most efficient 
action each time as this action should equate to the best possible reward. 
It should be noted that Q-Learning differs from RL in a couple of ways. Firstly, Q-Learning uses an 
approach called Temporal Difference Learning where feedback is provided for each step in the 
exploration or training cycle instead of only at the end as is the case with Monte-Carlo learning used 
by RL algorithms such SARSA. Secondly, Q-Learning is an off-policy algorithm allowing to the algorithm 
the freedom to behave randomly while still learning the optimal policy with each training cycle.   
2.3.3) How does Q-Learning Work? 
With Q-Learning, the goal is in every state via trial and error is to learn the optimal course of action. 
With this in mind, the following shows step by step how Q-Learning works:- 
Step 1:- As Q-Learning can be used for many applications such as pathfinding and decision making, the 
first step of Q-Learning is to understand the environment Q-Learning will be used in. Looking at a 
pathfinding example, the environment is defined as a series of interlinking paths that could be used 
to model a computer network or a road network. The goal is to find the best path across the network.  
Figure 5:- Showing a small, partial mesh network with edge values and node numbers [80]. 
Figure 5 shows an example network where there are six nodes labelled 0 to 5, connected by edges 
that show the valid actions that can be made to and from each node where each action or link between 
nodes has a value. In this example, the objective is to travel from node two highlighted in yellow to 
node five in green. Knowing this, the topology can be represented in the form of a matrix (R) where 
the Reward Values are stored. Figure 6 shows R for this six-node network, specifically for the 
destination node five as R varies depending on which node is the destination. 
Figure 6:- Showing the R-values displayed as a matrix for the destination node five [80]. 
The R matrix has two main components for utilising the link information between nodes: the State 
down the left-hand side and Action across the top. State in this case means starting or current 
node. Action, are the choices that can be made for that State. For each State/Action pair, the R 
matrix holds a value that reflects the connectivity of the network and if an Action will lead to a goal 
state. In this particular implementation:-  
 -1 means for that State/Action pair, there is no valid move or path link.  
 0 means that State/Action pair represents a valid move or path link but does not lead to the 
destination.  
 100 means that the State/Action pair represents a valid move or path link and does lead to 
the destination.  
Looking at Figure 5, for the link between nodes 2 and 3, the green arrow that represents a valid move 
from node 2 to node 3 has a value of zero. Now looking at Figure 6, it can be seen that for a State 
value of 2 and an Action value of 3, the corresponding R-value matrix is zero. If this exercise is 
repeated, but this time with the State value of 1 and the Action Value of 5, it can be seen in Figure 5 
that the red arrow has a value of 100 (the destination) which again corresponds with the State/Action 
value stored in the R-value matrix in Figure 6. This process is repeated for all State/Action pairs to 
populate the R-value matrix representing the environment that Q-Learning will be implemented in. 
There are two things to note at this point, firstly, that the R-values can be stored in a variety of 
different ways and does not necessarily require the matrix format. Secondly, the values stored for 
each State/Action pair are values designed to allow the reward mechanism to find the most direct 
path. These values could be comprised of latency values, generic values, and so on. Finally, these R-
values could be values looked up from an existing table like the above example or, the values could 
be measured in real time. 
Step 2:- Another value structure is created similar to the R-value matrix called Q. Q uses the same 
State/Action pairing to reference information but in this case, when first created, Q is initialised to 0. 
Again, this can differ depending on the Q-Learning implementation where for instance, the Q-value 
matrix is initialised with 100. The value is subjective and depends on the application and the user. Q, 
like R, can also appear in different structures other than a matrix.  
Figure 7:- Showing the initial Q-values displayed as a matrix for the destination node five [80]. 
Step 3:- Having created the R and Q structures, the next step is the training phase. Q-learning works 
by updating Q with values calculated by a reward formula during a number of training cycles. The 
process for each training cycle works as follows:- 
1. An initial State is selected. When training first starts, this can be the current Source State or 
any other State chosen at random. 
2. From this current State, all the available Actions are listed. 
3. The value of Q for each possible Action is found. The next possible State associated with the 
Action that has the maximum value (or minimum value when dealing with applications that 
require a small value such as latency within a network topology) is selected as the next State. 
If two or more possible States have the same value of Q, one is selected at random. An 
alternative option that can be utilised a fixed percentage of the time is to ignore the State 
with the maximum value and pick a State at random from the available possible States. This 
option can be employed to aid exploration. 
4. Using the reward formula, calculate Q. The reward formula can vary slightly depending on 
how it is implemented. The standard formula however is:- 
(, ) =   (, ) + [(, ) +   ( , )  (, )] 
(Eq. 1) 
Where S is the current State, A is the Action, Qn(S,A) is the new value stored within Q for a 
specific S and A pair. Q(S,A) is the value currently held in Q for that specific S and A pair.  is 
the learning rate which is used to determine to what extent newly acquired information is 
prioritised over existing information. R(S,A) holds the reward for a specific S and A pair.  is 
the discount rate which determines the importance of future rewards and Q(S,A) is all the 
possible Actions corresponding to the available States. 
5. After a new value for Q has been added for the State/Action pair, the next State (or current 
Action) is set as the current State.  
6. Repeat this process from 1) until the destination has been found. This completes one training 
cycle. 
The number of training cycles required to allow the Q-Table to converge is dependent on several 
factors. i) The size and the complexity of the environment. For example, fewer training cycles are 
required in smaller environments with little complexity. ii) The learning rate . A low value of  in the 
reward formula, for example, means that the algorithm will learn little new information while mainly 
exploiting existing prior knowledge. iii)  The discount rate . A low value of  will reduce the importance 
of future rewards, instead primarily focusing on current rewards. Generally, the more training cycles 
employed, the better the values are in the final Q-Table though this is only up to a point as after a 
certain number of training cycles, the values stored in Q have converged and do not change any 
further. It should also be noted that if the number of training cycles used are too few, the values stored 
in Q for each State/Action pair will be less than optimal. 
Step 4:- Once the training phase has been completed, Q is used as a guide for calculating the path 
between the source and the destination using the best Q-values at each State to suggest which Action 
will be the best. This process works in a similar way to the training process. 
1. First, the source is used as the starting point or current State. 
2. From the current State, all available actions are checked. 
3. The current State will select whichever Action has the largest value in Q. This Action becomes 
the next State. 
4. This is repeated for each part of the path until the destination is reached with each part of the 
path being recorded as it goes. 
Assuming the Q-Table for the destination is fully trained containing estimates for each S/A pair 
that have converged, the path selected between the source and the destination should be the 
most optimal path based on the metric used in R to train Q. It should be noted, however, that in 
traditional Q-Learning as well as many variants of Q-Learning, a single training cycle is normally 
followed by the pathfinding process so while the Q-Learning algorithm is still learning, the paths 
selected will initially be sub-optimal and become more efficient over time as each additional 
training cycle will bring the Q-Table closer to convergence. 
2.3.4) The Advantages & Disadvantages of Q-Learning:- 
Q-Learning can be seen to hold many advantages over other ML algorithms including other RL 
approaches. Specifically, Q-Learning is very useful in general as it has several factors that make it 
unique even amongst other RL algorithms.  
1) Q-learning, does not require user supervision. Instead, feedback regarding the algorithms 
actions come in the form of a reward calculated by the Q-Learning algorithms reward formula. 
2) While Supervised and UL techniques require a dataset to learn, RL methods learning directly 
from the environment they are placed in. However, with RL, there is no exact answer. Instead, 
the actions performed are carried out using a reinforcement technique (such as a formula) to 
calculate one step at a time, so the algorithm learns from experience instead of using a 
dataset. This means that Q-Learning can learn on its own without intervention and without 
the continuous need to check and refine the training data to get the desired result [81]. 
3) Assuming there are periodic re-training cycles, Q-Learning can adapt to a changing 
environment. If Q-Learning is being used for pathfinding for example, if one path becomes 
inaccessible, Q-Learning will over time find another path. 
4) Because the Q-Learning algorithm is based on a set of repeated instructions for each step or 
action, Q-Learning is relatively easy to implement.  
5) One substantial advantage that Q-Learning has is that it is a form of RL that does not require 
a model of the Markov Decision Process (MDP) [82] to be able to learn the fully optimal 
policy like many RL techniques do. Instead, Q-Learning takes a different approach called 
Temporal Difference which uses the difference between Qcurrent and Qold to calculate Qnew. 
So, with each State/Action taken, Q will slowly converge to its optimal value. 
6) Thanks to the innate flexibility and general simplicity of Q-Learning, it is an algorithm that can 
be used for many different applications. Such examples include, but are not limited to path 
planning for mobile robots [83], illegal signal localisation using a UAV (Unmanned 
Autonomous Vehicle) [84], a controller to improve a power systems transient stability [85], 
road traffic control algorithms to reduce air pollution by easing congestion [72] and path 
calculation within packet-switched networks [22], Q-Routing. Q-Learning is also often used in 
conjunction with other AI and ML algorithms such as Deep Learning. For example, one paper 
proposed an approach for path planning called DQN. This algorithm combined Q-Learnings 
ability to instantly act (as each possible state/action pair is represented by a score in a Q-
Table) with a Neural Network to save memory and increase reaction time. 
Of course, Q-Learning is not without fault and does have a few disadvantages.  
1. While Q-Learning can adapt to a changing environment, Q-Learning is not able to look ahead 
to find potential problems and the corresponding solutions [81]. 
2. Depending on the size and complexity of an application, the values within a Q-Table can take 
many training cycles to converge on optimal value [86]. 
3. Q-Learning was originally designed to use one metric employing a single objective approach 
which could limit its effectiveness for some applications. A multi-objective approach to 
overcome these limitations has been tried but again results in additional problems. For 
example, scalarization which combines the values of each objective into one value but does 
not represent each objective accurately. Treating each objective separately is more likely to 
produce accurate results but at the cost of increasing complexity [87]. 
2.3.5) Why use Q-Learning? 
When it comes to finding a starting point for a multi-metric, routing algorithm, using an algorithm such 
as DQN or a more advanced algorithm would seem to be a good choice. This is because DQN improves 
on Q-Learning in several different ways. For example, in DQN, the Q-Tables are replaced by a DNN 
which is used to approximate Q estimates making DQN a superior choice where there are a massive 
number of states. Q-Learning, by way of contrast must record the Q estimate for each state so Q-
Tables can become large and cumbersome. DQN also introduces a feature called Experience Replay 
[88] which saves the result of state/action selections or transitions and the resulting Q estimate in a 
large buffer called the Experience Reply Buffer (ERB). So instead of using each individual translation 
to train the DNN, samples randomly selected from the ERB can be used to train the DNN. 
However, despite the improvements that DQN offers, DQN also comes with additional disadvantages. 
As previously discussed, DNN can be very resource intensive. In the case of DQN, this is because the 
DNN requires an input node for each possible single State as well as multiple output nodes for each 
possible Action for that single State with the complexity and size of the hidden layer or layers changing 
depending on the application of the DQN. This also makes implementation a challenge. Finally, 
because DQN uses Experience Reply, DQN is classed as an off-line algorithm and does not learn in real-
time. By way of contrast, Q-Learning is a relatively simple algorithm that runs in real-time. 
Q-Learning also has a number of additional attributes. As previously stated (see section 2.3.1), 
amongst the main types of ML algorithms, RL is better suited to routing problems and from the list of 
RL based algorithms, Q-Learning is one of the most prominent due to the number of advantages it 
offers (see section 2.3.4 ). Because Q-Learning can be used for many different applications, there is a 
lot of support in current literature for Q-Learning. It is unique amongst RL algorithms as it does not 
use a Markov Decision Process, removing the potential challenges caused by using a Markovian model 
and thus, making it easier to implement. Q-Learning can adapt in real-time making it well suited for 
use within a dynamic network environment. Finally, Q-Routing (see section 2.4.1), a variant of Q-
Learning already exists and while Q-Routing uses only a single network metric in its traditional form, 
Q-Routing is a step closer to the multi-metric routing than Q-Learning.  Finally, Q-Routing working in 
tandem with SDN should also help to negate the advantage that DQN has regarding working in large 
scale environments. Because Q-Tables would be stored on a central server or computer, far more 
powerful than in a distributed switch or router, the size of the Q-Table can become very large but still 
be processed quickly. Given the positive attributes that Q-Learning has to offer, it is believed that Q-
Learning would be a suitable basis for a new ML based, multi-metric, routing algorithm. 
2.4) State of the Art:- 
This section gives an overview of Q-Learning for routing (Q-Routing), variants of the Q-Routing 
algorithm from literature and examples of Q-Routing using multiple metrics and being employed 
within an SDN network. Finally, a conclusion on Q-Learning, Q-Routing and the literature reviewed is 
presented. 
2.4.1) Q-Learning for Routing (Q-Routing):- 
Created in 1993, Q-Routing [22] was a variant of Q-Learning designed for routing traffic within a 
computer network. It was a natural extension of Q-Learning, using the network metric latency to 
populate the R-Tables instead of a generic score system. This was a great advantage as it allowed the 
algorithm overtime to approximate the shortest path that reflected the true nature of the network 
instead of finding a sub-optimal path using unrelated generic values. 
Another key difference between Q-Learning and Q-Routing is that Q-Routing is utilised in a 
decentralised manner. In Q-Routing, each network node held Q-Tables containing estimates on how 
to reach every other network node. When a current node sends a packet to the destination node via 
the chosen neighbouring node, that neighbouring node sends back its best estimate on how to reach 
the destination node to the current node. Using a reward formula, the current node then updates its 
Q-Table for that destination node based on the information it received from that neighbouring node. 
However, despite sharing the advantages that Q-Learning shares with Q-Routing (Simplicity, 
adaptability, etc), Q-Routing does have a number of disadvantages:- 
Firstly, On the initiation of a new network, the Q-Tables in each network node are set to their default 
values with no indication on how to reach the destination node. The only information they have access 
to is the link or edge data of the links that are directly connected to that specific node. An accurate 
estimate of the latency from the destination node to the current node can only start to form when 
estimates of the latency start to propagate backwards through the network from the destination node 
after it has been reached. While this process is relatively quick, the time taken for the Q-Tables to 
converge can be affected by several factors, mainly, the size and complexity of the network topology. 
A small network topology will converge faster than a larger network topology and a less complicated 
network such as a partial mesh with converge faster than a full mesh network topology. The overhead 
generated by packets sharing estimates between nodes during this exploration can also contribute to 
the network becoming overloaded, slowing down or preventing network convergence as the Q-Tables 
take longer to receive information about the estimates to each node in the topology. 
Secondly, for large network topologies containing many different network nodes, the memory 
required in each network node to house all the Q-Tables can be prohibitive. For every new node added 
to the network topology, information on this new node must be added to the Q-Table stored on every 
other node including information such as which neighbouring nodes will lead to a specific destination 
node, the Q-Table estimates from each of these neighbouring nodes to the destination, the port 
numbers of the node that lead to these neighbouring nodes, etc. The time taken for each network 
node to update a Q-Table and to select the next node in a path for a packet can also be affected as 
the number of nodes in the network topology increase. 
Finally, because each network node is decentralised, there is the issue of overhead. One attribute of 
Q-Routing is the ability of each network node to receive latency estimates from neighbouring nodes. 
This allows continuous updates to the Q-Tables so the algorithm can learn the optimal network paths 
and continue to adapt to network changes. However, these latency estimates when being sent to the 
current node from the neighbouring node generate overhead in the form of packets. On a network 
with little traffic, this is not a problem but on a congested network, packets containing this latency 
information can be severely delayed. The result is that the Q-Routing algorithm is not able to respond 
to congestion by learning a new path to the destination as the information required to do so has not 
been received.  
Looking at the performance of Q-Routing, the paper that originally presented this algorithm [22] 
demonstrated that on a network with very little network traffic, Q-Routing had an Average Delay Time 
similar to that of the Shortest Path algorithm. As the network traffic increased, the Average Delay 
Time of the Shortest path algorithm increased faster than that of Q-Routing demonstrating Q-Routing 
was able to adapt faster to the congestion caused by the increased network traffic. Eventually, the 
network load reached a point where the Shortest Path algorithm had an Average Delay Time heading 
towards infinity. The Average Delay Time of Q-Routing reached the same point at nearly twice the 
level of traffic than that of the Shortest Path Algorithm.  
So, despite the disadvantages of using Q-Routing, the results showed that Q-Routing was able to 
outperform the Shortest Path algorithm by being able to tolerate higher levels of network load. From 
these results, it can be seen why Q-Routing and the numerous variants become the focus of so much 
research. 
2.4.2) Variations of Q-Routing:- 
Since Q-Routing was first implemented, there has been a great deal of research on modifying Q-
Routing to improve the performance of the algorithm in terms of convergence speed, efficiency, 
memory usage, scalability and smarter path selection. The following algorithms are all variants of Q-
Routing that looked at improving the performance of Q-Routing in some manner.  
2.4.2.1) Simulated Annealing based Hierarchical Q-Routing:- 
Designed for a packet-switched, distributed network, Simulated Annealing based Hierarchical Q-
Routing (SAHQ) [89] is a variant of Q-Routing that was proposed in 2011 and was designed to improve 
on Q-Routing in two ways. The first was to make the algorithm more efficient by reducing the number 
of training cycles for faster convergence when the algorithm was operating under different network 
loads and on different network topologies. The second was to improve the scalability to address the 
problem in Q-Routing regarding the decrease in performance as the network topology size increases. 
The SAHQ algorithm presented looked at tackling these issues in two different ways. 
The first was to introduce a hierarchical model of the network topology. A hierarchical model was 
created by splitting the network topology into segments where the goal was to maximise the number 
of redundant paths between each segment while minimising the number of segments. Once this had 
been done, the next stage was to designate forwarding nodes as either Border Routers or Local 
Routers. A border router was defined as a forwarding node in one segment of the network topology 
that was directly connected to another forwarding node in another segment. Forwarding nodes that 
did not meet these criteria became local routers. When a packet was first created, the first router it 
arrived at would look to see if the destination router or node was in the same network segment as the 
border router. If it was then the conventional Q-Routing algorithm was used to send the packet to the 
destination node. If, however, the destination node was not within the network segment controlled 
by the border router, then the border router from Q-Tables values it has stored would select a border 
router from a directly connected adjacent segment that has the lowest values latency time to the 
destination node. The packet was then sent to this border router instead.  
The second was to use Simulated Annealing as an exploration method for selecting the next router in 
the path to send the packet to. Each border router would calculate their queue waiting times for every 
packet that arrived at the queue of that border router. Each queue was partitioned into levels 
according to the percentage of queue utilisation with several different thresholds. When a new 
threshold was triggered, the boarder router sending the packet would check the queue utilisation of 
other border routers and select a border router with a minimal latency to the destination node with a 
smaller queue utilisation percentage value to reduce the possibility of congestion. Simulated 
Annealing was used as the final step in selecting which alternate border router to send the packet to, 
to take into account the queue utilisation of each border router.  
The result presented showed that for a partial mesh network, SAHQ achieved a lower average delivery 
time than Q-Routing for both variable load and high load traffic over time. This approach does have 
some advantages. The most obvious is that by reducing the network topology into segments, with one 
forwarding node responsible for each segment, the ability for the algorithm to scale increases. The 
Simulated Annealing mechanism to select the next node to deal with congestion based on the 
percentage of queue utilisation for each border router also has obvious benefits. However, the paper 
that presented this algorithm gave little in the way of detail on how to split a network topology into 
segments. For anyone to replicate this research, the average number of nodes per segment is a key 
factor. Another possible issue with this algorithm is the overhead generated when each border router 
is passing the information for queue utilisation percentages. 
2.4.2.2) Full Echo Q-Routing:- 
Full Echo Q-Routing [22] was one of the first variants made to the Q-Routing algorithm designed to 
correct some of the initial weaknesses that exist within the Q-Learning algorithm, primarily, the 
exploration. Because Q-Routing only uses the best estimate from only one neighbouring node to 
update the Q-Table of the current node, it is possible that accurate estimates on how to reach other 
nodes in the network topology could never be achieved if they were initially overlooked. For example, 
if an optimal route was initially given a high estimate in terms of latency, then the Q-Routing algorithm 
is more likely to select a sub-optimal route each time without giving the optimal route a chance for its 
estimates to converge. To address this issue, Full Echo Q-Routing proposed changing the way 
exploration was carried out.  When a node needs to decide on which neighbouring node it should send 
a packet to, instead of sending it to the node that has the best estimate on how to reach the 
destination node, the current node asks all neighbouring nodes for their current estimates on how to 
reach the destination node. This is the Full Echo part of the algorithm. All these estimates are used 
to update the Q-Table of the current node with accurate estimates from all neighbouring nodes. This 
approach not only improved exploration but helped to reduce convergence time. Unfortunately, the 
performance of the algorithm was not as expected. 
On a 6 x 6 partial mesh grid topology with two links between the left and right sides of the network 
topology, Full Echo Q-Routing was tested against Shortest Path and standard Q-Routing. When the 
load of the network was low, both Shortest Path and Full Echo Q-Routing had a similar performance 
in regard to the Average Delivery Time.  However, as the load increased, standard Q-Routing 
performed better than Shortest Path and Full Echo Q-Routing. Both the original research [22] and 
more recent research [90] suggests that the poor performance of Full Echo Q-Routing at high load was 
caused by the algorithm constantly oscillating between the two network links separating the left and 
right side of the network topology. This switching caused instability and, in return, the poor 
performance of Full Echo Q-Routing. 
2.4.2.3) Adaptive Q-Routing Full Echo:- 
Adaptive Q-Routing Full Echo [90] was a variation of Full Echo Q-Routing proposed in literature in 2016 
with the primary goal of improving the exploration ability of the algorithm and to reduce the oscillating 
that Full Echo Q-Routing experienced. Adaptive Q-Routing Full Echo differed from Full Echo Q-Routing 
in two keyways. The first was the introduction of an additional learning rate to the Q-Routing formula. 
If the Q-Value received by the current node originated from a neighbouring node, then the node 
updates its Q-Tables using the standard learning rate, otherwise, the additional learning rate is used 
instead of the standing learning rate. When used, the additional learning rate allowed Adaptive Q-
Routing Full Echo to explore paths that might have been overlooked when the standard learning rate 
was used. The second was that the additional learning rate was dynamic, changing depending on the 
current nodes estimates of the average delivery time to send a packet to the destination node. These 
estimates acted as a feedback mechanism designed to adjust the exploration/exploitation balance as 
part of the learning/training process for each network node. 
Adaptive Q-Routing Full Echo was tested on the same network topology and in the same manner as 
Full Echo Q-Routing. Both the Dual Q-Routing and standard Q-Routing algorithms were used to 
compare the performance, the average delivery time with Adaptive Q-Routing Full Echo. The results 
show that on a network with a low load, Adaptive Q-Routing Full Echo achieved a lower average 
delivery time than the other two algorithms. On a network with a large load, the performance of 
Adaptive Q-Routing Full Echo performance was on par with both Q-Routing and Dual Q-Routing.  
The results for Adaptive Q-Routing Full Echo when the network was under a low load resembled the 
performance of Full Echo Q-Routing. When the network load increased, the average delivery time 
result for Adaptive Q-Routing Full Echo was similar to that of standard Q-Routing. Assuming this result 
was accurate and using Q-Routing as a basis of comparison, this would suggest that Adaptive Q-
Routing Full Echo was able to reduce the number of oscillations between alternate network paths and 
perform better than Full Echo Q-Routing. However, as the authors did not directly include Full Echo 
Q-Routing as one of the algorithms to use as a basis for comparison, it is hard to say this with certainty. 
It is interesting to note that in a later research paper [91] that looked at the creation of a newer Q-
Routing algorithm, the same authors of Adaptive Q-Routing Full Echo do admit that Adaptive Q-
Routing Full Echo was able to perform better than Full Echo Q-Routing but still suffered some routing 
instability when the network was under high loads causing the average delivery time to spike on 
occasion. 
2.4.3.4) Adaptive Q-Routing with Random Echo and Route Memory:- 
Adaptive Q-Routing with Random Echo and Route Memory (AQRERM) [91] was presented in 2017 by 
the same authors of the algorithm Adaptive Q-Routing with Full Echo and as a result, there were a lot 
of similarities between the two algorithms. However, to improve on the performance of Adaptive Q-
Routing with Full Echo, AQRERM was altered in two different ways. 
The first modification was the changing of Full Echo with a different approach, Random Echo. 
Instead of the current node requesting estimates from every neighbouring node, each neighbouring 
node had a chance of being selected. Random Echo was designed to remove the need to calibrate 
the additional learning rate using a variable K that Adaptive Q-Routing Full Echo had implemented. 
This implementation was put into place as it was discovered that when Full Echo was used in the 
initial stages of the learning process, path selection performance was good but when it was used in 
the latter part of the learning process, the high values produced by Full Echo was likely to cause 
instability in the routing leading to oscillations experienced by the Full Echo version of the algorithm. 
The second modification called Route Memory was added to aid in exploration and to reduce the time 
required for the training to research coverage. A packet was added which listed every node that the 
packet had visited. This information became part of the decision-making process as it allowed the 
algorithm to select a node that had not already been visited.  
The AQRERM algorithm was tested on the same grid network topology as Full Echo Q-Routing and 
Adaptive Q-Routing Full Echo against Q-Routing, Dual Reinforcement Q-Routing and Adaptive Q-
Routing Full Echo. According to the paper, the results showed that when the network had a low load, 
AQRERM had the lowest average delivery time converging faster than each of the other Q-Routing 
algorithms by a significant margin. When the network was placed under a high load, the results for 
AQRERM were similar to when the network had a low load with AQRERM achieving a lower Average 
Delivery Time again by a significant margin. In a direct comparison between Adaptive Q-Routing Full 
Echo and AQRERM, as the K value was increased within Adaptive Q-Routing Full Echo, the path 
instability also increased. By contrast, as AQRERM no longer had the K calibration element, AQRERM 
was not affected by this issue and did not suffer from path instability with AQRERM resulting in faster 
convergence and a much lower Average Delivery Time than Adaptive Q-Routing Full Echo. 
The final test that the authors of the paper carried out looked at the effect on the length of the packet 
designed to record the path of the algorithm on the performance of AQRERM. There were, however, 
no definitive answers for this test. For example, when the packet was of size 1, AQRERM converged 
quicker with a lower Average Delivery Time than when the packet size was at any other value. 
However, the next best results were when the packet size was 13 and then the next best result after 
that was when the packet size was 11. By way of contrast, the second slowest Average Delivery Time 
was when the packet size was 3 and the slowest was when the packet size was 5. 
Overall, the AQRERM algorithm seems to be the successful product of an evolutionary process leading 
all the way back to the first Q-Routing algorithm. The results show that this algorithm is faster to 
converge under both low and high loads than the competing algorithms with a much lower average 
delivery time for each packet. The only possible point of concern is the effect that the packet size of 
the path recording packet has on the algorithms performance. There seems to be inconsistency in the 
results and when it comes to discussing this, the authors of the paper are vague on this part of the 
testing. The theoretical benefits of keeping a record of the nodes already visited seems evident so it 
is a shame that the authors of the paper did not spend a little more time investigating the lack of 
consistency in the results or at the very least, explaining it.  
2.4.3.5) Dual Reinforcement Q-Routing:- 
Dual Reinforcement Q-Routing (DRQ-Routing) [23] was an algorithm based on Q-Routing and designed 
to find paths that could sustain a high load while allowing the algorithm to converge quickly resulting 
in a lower average delivery time. In standard Q-Routing, when Node A (the current node) requests the 
latency estimates to the destination node from all the neighbouring nodes, each of these neighbouring 
nodes sends this information to Node A. This allows Node A to use the information to find the next 
step in the path towards the destination and updates its own Q-Tables. The process is described by 
[23] as Forward Exploration. DRQ-Routing expands on this by adding an approach called Backwards 
Exploration. After Node A has received the estimates from the neighbouring nodes and updates its 
own Q-Tables, Node A shares Q-Table information about the traversed path with the neighbouring 
nodes allowing each node to update its own Q-Table. Because exploration is happening on two fronts, 
convergence should be faster. 
The authors of DRQ-Routing tested this algorithm on the same 6x6 irregular grid network topology 
used for Q-Routing, Full Echo Q-Routing, etc and compared the performance of DRQ-Routing against 
Shortest Path and Q-Routing. The results showed that when the network was placed under a low load, 
Shortest Path performed better than the other two algorithms with a lower average delivery time for 
each packet sent. DRQ-Routing came second performing better than traditional Q-Routing. However, 
when the load of the network increased to medium or high, DRQ-Routing achieved a lower average 
delivery time than both Shortest Path and Q-Routing. According to the result, DRQ-Routing was also 
able to sustain higher loads for a longer period than both of the other algorithms.   
Overall, the results for this algorithm were encouraging. The addition of Backwards Exploration, 
assuming the results reported are correct, greatly enhanced the ability for faster convergence when 
the network was experiencing a medium or high load. This is mainly because Backwards Exploration 
uses real values and not estimates to update the neighbouring Q-Tables from Node A after Node A 
itself has updated its own Q-Tables from the neighbouring nodes. This makes Backwards Exploration 
more accurate than Forward Exploration. Also, by using Forward Exploration and Backwards 
Exploration together, exploration is effectively happening twice as fast. However, there are some 
aspects of the DRQ-Routing algorithm that need to be considered. In employing both Forward 
Exploration and Backwards Exploration, the overhead in the network is essentially doubled. This 
could potentially delay or prevent convergence of DRQ-Routing when the network load is high. It is 
true that according to the results that, on this grid topology at least, DRQ-Routing seemed to perform 
well. However, the next question that needs to be considered is how well would the algorithm cope 
on a larger scale network topology with more interconnectivity? If Node A is connected to many more 
neighbouring nodes, what would the effect be on the overhead and the performance regarding 
convergence? The paper that DRQ-Routing was presented in [23] makes a case for the overhead 
stating that the increased overhead would be slight and the affect inconsequential. Unfortunately, the 
paper does not talk about scalability in any way and the effect of the overhead on that scalability.  
2.4.3) Multi-Metric Q-Learning and Q-Learning using SDN:- 
For the research in this Thesis, there were two primary areas of interest. The first area related to Q-
Learning and the ability to change the algorithm to be able to make decisions using more than one 
metric. Q-Routing [22], for example, was designed to use the individual link latencies in combination 
with a reward formula to estimate the overall end-to-end path latency from a source node to a 
destination node. However, considering that there are many different network metrics (delay, 
bandwidth, jitter, packet loss, etc), the ability to select a path based on more than one network metric 
is essential in modern-day routing, especially when specific applications might have set QoS 
requirements. The second area was the use of SDN in conjunction with Q-Routing as, in theory, there 
are several advantages to using Q-Routing within an SDN network. 
Unfortunately, there are few examples in current literature of Q-Learning or Q-Routing using more 
than one metric or SDN working in tandem with Q-Learning or Q-Routing. The following examples look 
at some of the limited research from current literature in using SDN with Q-Routing and for multi-
metric Q-Learning and Q-Routing. 
2.4.3.1) Reinforcement Learning empowered QoS-aware Adaptive Q-Routing in Ad-hoc 
Networks:- 
The Reinforcement Learning empowered QoS-aware Adaptive Q-routing or RL-QAQ [92] was 
introduced by the papers authors in 2020 and was designed to provide discriminated transmission 
for different services with differing QoS requirements as well as reduce the delivery delay and the 
routing overhead. Using Full Echo Q-Routing as the basis of their algorithm, the authors of RL-QAQ 
altered Full Echo Q-Routing in three ways.  
The first was an Adaptive Mechanism for Exploration. This was designed to replace the Full Echo 
part of the Q-Routing algorithm. The goal of which was to reduce the overhead that Full Echo imposed 
on the network topology. Instead of each current node requesting the estimates from each 
neighbouring node, exploration was carried out on a probability basis before selecting the best 
neighbouring node to forward the packet onto. The authors claimed that their approach offered 
different adaptive probabilities for different services or applications. This probability was calculated 
as follows:- 
 = 
i
i
(Eq. 2) 
Where Pi represents the probability of full echo exploration for servicei. Q
iest represents the average 
optimal Q-Value in a Q-Table in a node for any destination node corresponding to the servicei. Q
iest is 
also used to represent the estimation of the link quality for servicei. Q
imax represents the maximum 
value historically generated by Qiest and  represents a positive parameter. Using link delay or latency, 
the probability value of Pi would change depending on current and historical link quality estimations. 
If for example Qiest and Qimax were similar on value, this would suggest that the current link quality 
was close to the historically worst estimate and as a result, the probability of Pi would increase. This, 
in turn, would result in routing exploration closer to that of full echo in order so a path to the 
destination node could be found, albeit with more overhead. 
The second alteration allowed differentiated services for QoS to be applied with an addition that the 
authors of RL-QAQ called QoS Aware Rewards. To apply this differential QoS, the authors of the 
paper modified the Q-Routing reward formula to not only use end-to-end latency, but also the Packet 
Loss Rate (PLR). This was done by adding a new component to the reward formula. The component 
was as follows:- 
(, ) =    (, ) +    
(Eq. 3) 
Where RXI (y,D) represents the reward value of servicei calculated by the current node x based on the 
estimates received from neighbouring nodes (the number of estimates varying depending on the value 
of Pi). dx(y,d) represents the delay from current node x to neighbouring node y. PLRy represents the 
packet loss rate for neighbouring node y and i and i are positive values dynamically changed as 
specified by the QoS requirements of different services. If, for example, servicei was time-sensitive, i 
should be a larger value, i a smaller value where the total of i and i should be no greater than 1. 
Essentially, i and i were weighted values in favour of their respective network metric, latency or PLR 
respectively. 
RXI (y,D) was then integrated into the Q-Routing reward formula in the following way.  
(, ) =  
(, ) +   (
(, ) + min
()
(, )  
(, )) 
(Eq. 4) 
Where QXI (y,D) is the new or updated estimate from node x to node D via neighbouring node y,  is 
the adaptive learning rate for servicei and N(y) is the set of neighbours of the node y. 
The final alteration was a system of tables developed by the authors to not only store Q-Table values 
for each node but to also allow differentiated Q-Tables values depending on the requirements of 
servicei. Like that of AQRERM, the RL-QAQ algorithm also kept track of the nodes already visited to 
speed up convergence and to avoid the accidental creation of a loop.  
The authors selected a partial mesh topology where there were three routes from the start node to 
the destination node where one path had a faulty node so the PLR could be tested fully. Using 
Overhead, Average End-To-End Delay, Selection Proportion (the number of packets selected for a 
certain route to the total number of packets successfully delivered) and Successful Delivery Rate as 
the assessment criteria, the performance of RL-QAQ was compared to that of Full Echo Q-Routing. 
Each source node generated traffic for 10 seconds for two different services rates. First with serviceA 
where  was 0.9 and  was 0.1 and then with serviceB where  was 0.1 and  was 0.9.  
According to the authors of RL-QAQ, the results show that firstly, RL-QAQ had a reduced overhead 
using on average fewer exploration or Echo packets, feedback packets and control packets than that 
of Full Echo Q-Routing for every node within the network topology. Secondly, the results show that 
for a low PLR, the average end-to-end delay for both services of RL-QAQ where approximately the 
same but had a lower average end-to-end delay than that of Full Echo Q-Routing. As the PLR increased, 
serviceA of RL-QAQ had a lower average end-to-end delay than serviceB though both services of RL-
QAQ achieved a lower average end-to-end delay than that of Full Echo Q-Routing. It was also noted 
that both services for Full Echo Q-Routing throughout the PLR experiments had a nearly identical 
average end-to-end delay. This as the authors noted was because Full Echo Q-Routing was not able to 
distinguish between each service and treated them in exactly the same fashion. Thirdly and again using 
the PLR, the result showed that for a low packet loss rate, both services for each algorithm were on 
average more likely to be routed through the route that contained the faulty node. As the PLR 
increased, both services for Full Echo Q-Routing would continue to primary use this faulty route while 
serviceA of RL-QAQ was, on average, slightly more likely to select a different route. By contrast, serviceB 
on average was far more likely to select one of the two paths that did not contain the faulty node. As 
serviceB related to the PLR metric in the Q-Routing formula, selecting a route that reduced the PLR was 
logical. Finally, the percentage of successfully delivered packets was measured as the PLR increased. 
Out of the two algorithms, both services of RL-QAQ achieved a consistently higher packet delivery rate 
than that of Full Echo Q-Routing with serviceA of RL-QAQ having a higher delivery date percentage 
than that of serviceB. 
Overall assuming the results are accurate, the RL-QAQ algorithm would seem to some extent be a 
viable way of combining two network metrics into one formula using weights, the preference of one 
metric can be set over the other. This is important to note as the original Q-Routing algorithm was 
designed only to use one metric, end-to-end delay or latency. This approach could be very useful in 
the circumstances where one metric needs to take priority over another. However, this approach 
would not be suitable in finding a path that needed to meet QoS requirements based on two metrics. 
At best, if the weights were set to 0.5 for each metric in (Eq. 3), it is likely that a path based on 
compromise would be selected with neither QoS requirement being met. This algorithm also 
demonstrates, again according to the results, that it can explore as well as Full Echo Q-Routing but 
resulting in greatly reduced overhead. For further testing, it would be interesting to see if the metric 
PLR, that was used in the reward formula by the authors, could be substituted with a different network 
metric such as bandwidth. 
2.4.3.2) Using SDN and Reinforcement Learning for Traffic Engineering in UbuntuNet 
Alliance:- 
In 2016, the authors of the paper, Using SDN and Reinforcement Learning for Traffic Engineering in 
UbuntuNet Alliance [93] proposed a method to improve bandwidth utilisation and reduce latencies 
using Q-Learning within an SDN controller network by dynamically selecting paths using network data 
obtained using an SDN controller. What made this research especially interesting was firstly, as 
mentioned in the title, the authors of the paper had used SDN and Q-Learning together of which, there 
were few examples in current literature. Secondly, the authors implemented a reward formula using 
an aggregated Q-Learning algorithm that combined link latency, link bandwidth capacity and available 
link bandwidth. To do this, the authors created a variable known as K which aggregated the different 
network metrics. This was created as follows:- 
(, ) = (1 
(, )
(, )
) + (2 
(, )
1000
(Eq. 5) 
Where A1 and A2 were weights, Ba was the actual available bandwidth capacity for use on a link, Bl 
was the total bandwidth capacity of that link, Ll was the latency of the link and 1,000ms was used to 
scale the latency to a fraction of the maximum possible link latency. Unfortunately, the paper does 
not state how 1000ms was selected as a value and why the scaling of the link latency was required. 
R(s,a) which provided the link latency input to the reward formula was replaced with K(s,a) (Equation 
 = (, ) +  (K(s, a) + min(Q(s
, a))  Q(s, a)) 
(Eq. 6) 
Where QNew was the new calculated estimate for the current node on how to reach the destination 
node,  was the learning rate, Q(s,a) was the current estimate and Q(s,a) was all the estimates on 
how to reach the destination node from each of the nodes neighbouring the current node. 
For testing, the authors of the paper created a partial mesh topology in Mininet based on a real optical 
fibre network called the UbuntuNet Alliance which is comprised of Africas National Research and 
Education Network (NREN) with links to cities across the world including London and Amsterdam. 
There were five separate tests carried out in the paper where the goal of each test was to not only 
evaluate the aggregated algorithm for improved path selection but also to evaluate the emulated 
network topology. Of the five tests, the first looked at selecting the best single path based on latency, 
the second, the best single path based on bandwidth, the third, to use multiple paths using latency 
and bandwidth, the fourth, to use multiple paths based on latency and the final test, to use multiple 
paths based on bandwidth. Three metrics were used to measure the performance of each test: 
latency, throughput and jitter. iPerf was used to generate network traffic where each host node in 
turn would randomly select a destination host node sending a flow of traffic that would last 60 seconds 
before ending. 
According to the authors of the paper, the results for each of the assessments metrics were as follows:- 
Throughput: The multipath tests achieved higher throughputs on average than the single path tests. 
However, it was noted by the authors that the total achieved bandwidth was less than the combined 
total of the aggregate paths. It was expected that the fifth test based on bandwidth capacity and using 
multipath would achieve the highest throughput. Unfortunately, this was not the case as the second 
test based on bandwidth capacity and using a single path achieved a higher throughput. The fifth tests 
failure to perform as expected was attributed by the authors to packet loss and packet 
retransmissions. Out of the five tests, it was noted that while tests two and five achieved the highest 
throughputs, each test experienced the highest latencies. Finally, the first test achieved the lowest 
throughput. This result was expected as the first test was designed to use a single path based on 
latency. 
Latency: Out of the five tests, the first test achieved the lowest latency. According to the authors, this 
was the predicted outcome as the first test was designed to use a single path based on latency. The 
second and fifth tests achieved the highest delays as previously discussed. 
Jitter: From the results, the authors of the paper report that from the five tests, the tests using a single 
path, the first two tests experienced the least amount of jitter while each of the tests using multipath, 
the third, fourth and fifth tests experienced significant levels of jitter with the fifth test experiencing 
the highest level of all. The authors believed that using multipath was the cause of the increased jitter 
which is consistent with the results. Finally, out of three multipath tests, the third test using latency 
and bandwidth performed better in terms of jitter than the other two multipath tests. 
Overall, the results were rather mixed and lacking in some detail. Some of the results achieved by the 
authors were expected, such as the first test using a single path and latency having the lowest delay. 
Assuming the routing algorithm selects the path with the smallest end-to-end bandwidth, then this 
result was predictable. By contrast, the second test using a single path achieving a higher throughput 
than the fifth test using multipath as the authors stated was not predicted. This could possibly suggest 
that the approach the authors took needs further investigation. Finally, there was little mention in the 
results of the third test using latency and bandwidth with the exception that it had a better 
performance in terms of jitter than the other multipath tests. This is possibly due to the fact that the 
graphs included in the paper showing the results for throughput and end-to-end delay were pretty 
average. However, more discussion on this multi-metric approach would have been welcome along 
with some additional tests into the capabilities and efficiency of this algorithm using multiple metrics.   
2.4.3.3) Congestion prevention mechanism based on Q-leaning for efficient routing in SDN:- 
Congestion prevention mechanism based on Q-learning for efficient routing in SDN [94] was a paper 
published in 2016 that combined two areas of interest, SDN and Q-Learning. When using the 
unmodified SDN controller OpenDayLight (ODL), the authors of the paper state that the Dijkstra based 
shortest path algorithm would always find the shortest path between a source and destination node 
based on latency but did not take bandwidth into account which could lead to congestion in the 
network. To remedy this, the authors of the paper proposed and created a mechanism using Q-
Learning to prevent congestion. 
The mechanism worked as follows. Every link in the network topology was assigned a threshold value 
set to 80% of the bandwidth capacity of the link. If this threshold was exceeded on any of the links, 
then congestion was considered likely to occur. The ODL SDN controller was used to monitor the 
bandwidth usage on each link. If, for example, a packet flow was being sent from a source to a 
destination node but the traffic on the links in the path did not exceed the pre-set threshold, then the 
original path calculated by the Dijkstra based shortest path algorithm would be used. If, however, any 
of the links exceeded the threshold value, then the SDN controller would implement Q-Learning based 
congestion mechanism. Q-Learning in this implementation did not use values based on network 
metrics. Instead, the Q-Table was initiated with values of 0 while the R-Table was initiated with 
weighted values based on the composition of the network topology where each link in the network 
topology was represented. When the congestion threshold was reached, the R-Table was updated 
with a value of 20 for every congested link in the path and a value of 30 if the destination node was 
attached to that particular link. Once the R-Table had been updated, the Q-Table was updated using 
the standard Q-Learning reward formula. The Q-Table, in turn, was then used to calculate an 
alternative path that in theory would be less congested. 
To test this approach, the authors created a partial emulated mesh topology in Mininet comprised of 
7 host nodes, 6 forwarding nodes, 14 links or edges with a capacity of 800Mbits all controlled using an 
ODL SDN Controller. The first test performed was designed to see if the Q-Learning algorithm would 
select another path when the existing path reached the 80% bandwidth threshold capacity. A file of 
1.7GB was sent from a source hosts to a destination host and according to the authors, over time the 
Q-Learning algorithm selected a path that was not congested. The second test was not that clearly 
explained and seemed to be more of a calibration exercise to determine if the set threshold value of 
80% bandwidth capacity on each link was the correct value. To check this, three different files of 
different sizes, 1GB, 1.7GB and 2.5GB were sent across the network topology using three different 
routing algorithms, Dijkstra's shortest path algorithm, extended Dijkstra and Dijkstra's shortest path 
algorithm using Q-Learning. The results displayed showed the transmission time for each file size for 
each algorithm at three different threshold values of 70%, 80% and 90%. While the authors claim that 
80% was the optimal value in the case of this topology, the actual results showed only a marginal 
difference in the transmission times for each file size for each algorithm between the three different 
threshold values. The final test measured the time taken for each of the three different files to be sent 
across the network for each of the three different algorithms. Assuming the results are accurate, the 
authors show that for the 1GB file size, there was very little difference in the transmission times for 
each algorithm with the Q-Learning approach being slightly quicker in transmitting the file and 
Dijkstra's shortest path algorithm being slightly slower. However, as the file size increased, the 
difference in transmission times becomes more pronounced with Q-Learning becoming noticeably 
faster in transmitting the file and Dijkstra's shortest path algorithm noticeably slower. 
From the results given and again, assuming the results were accurate, the conclusion seems to be that, 
at least in an emulated environment, the employed Q-Learning algorithm can reduce congestion by 
finding an alternative path if given enough time. However, there are a few areas that could benefit 
from further explanation. The first test indicates that over time, Q-Learning will find another path if 
the current path is congested. Unfortunately, there is no indication of how much time this may 
require. The details of the second test which seems to focus on establishing the correct bandwidth 
capacity threshold value for each link is also vague and as previously mentioned, the result presented 
is negligible, showing that a value of 80% is tangibly better than 70% or 90%. Finally, this Q-Learning 
algorithm was tested on a small topology. It would be useful to see how well the algorithm performs 
when utilised on larger and more complex network topologies. 
2.4.3.4) DQR: Deep Q-Routing in Software Defined Networks:- 
In  2020, a paper called Deep Q-Routing in Software Defined Networks [95] was published that 
introduced a new routing algorithm called Deep Q-Routing (DQR). This was implemented in an SDN-
controlled network and based on an existing approach called Deep Q-Network (DQN). DQN was 
proposed to tackle the perceived problem of scalability in standard Q-Routing. The authors of the 
paper stated that Q-Routing only works effectively when the State/Action space is small representing, 
for example, a small network topology. When the size of the State/Action space starts to increase, the 
performance starts to diminish suggesting that Q-Routing by itself is not scalable. DQN was designed 
to combine reinforcement learning, specifically Q-Routing with a Deep Neural Network (DNN). Instead 
of using a Q-Table to approximate Q(s,a), the Q-Table was substituted with a DNN which would 
instead, approximate Q(s,a). Under Q-Routing, as the State/Action space increased in size, 
proportionally so did the Q-Table. By replacing the Q-Table with a DNN, the problems associated with 
an increasingly large Q-Table such as scalability were no longer relevant. However, the authors of the 
paper state that DQN itself is far from perfect. DQN learns the optimal policy based on rewards or 
feedback from the network environment. This means that the policy can become affected, resulting 
in minor Q-Value changes over time. According to the paper, this results in varied correlations and 
data distributions between any target values and Q-Values. Solutions from literature presented by the 
authors of this paper to address this issue were twofold. The first solution was to introduce a 
mechanism called Experience Reply, a buffer that enabled a Deep Reinforcement Learning (DRL) Agent 
to store path experiences and to update the DNN by using random samples from the buffers memory. 
This allowed DQN to learn from both new and old experiences. Secondly, a separate Q-Network was 
used to train the DQN to estimate target values. 
Despite these changes to DQN, the authors of the paper argue that DQN and DRL methods, in general, 
are limited in terms of performance and only used for global offline routing. According to the authors, 
this is because greedy online QoS based routing presents several challenges that DRL algorithms such 
as DQN are poorly suited to deal with. For example, DRL, in general, only considers K-Shortest Paths 
for each source and destination node pair. While not stated in the paper, the authors imply that when 
K-Shortest Path using latency is implemented, more suitable paths meeting the QoS of a flow are 
overlooked. The authors also state that DRL methods struggle to cope with invalid actions and avoiding 
network loops. The algorithm proposed by the authors, DQR was designed to overcomes these 
challenges. Firstly, by being an online algorithm. Secondly, by being QoS aware, considering several 
network metrics (delay, loss, bandwidth) so paths between source and destination nodes could be 
selected based on a single flows QoS requirements. Thirdly, the proposed algorithm would take into 
account the current network state. Finally, the algorithm would address the issues that DRL 
algorithms, in general, struggle with such as loop avoidance. The DQR algorithm was comprised of two 
primary parts. The first was the SDN-controlled network which housed the DQR algorithm as a routing 
application. The SDN controller was used to collect network metric information for the DQR algorithm 
and when DQR had calculated a path, program the forwarding rules into each network node in that 
path. The second was the core algorithm which combined DQN with an enhanced version of 
Experience Reply called Prioritised Experience Replay (PER). While Experience Reply sampled 
experiences without considering their importance, PER took the importance into account where 
temporal difference errors were used to measure the importance of a transition. 
The implementation of DQR was split into parts as follows:- 
 State Space:- The state space in this implementation was the current state of the network 
where each network metric used for QoS was stored in a two-dimensional matrix and scaled 
to increase convergence time. 
 Action Space:- The action space consisted of the network links or edges between each of the 
network nodes.  
 Reward Function:- The reward function was used to approximate Q(s,a) using DNN. As 
previously discussed, DQN replaced the traditional reward formula used by Q-Routing. The 
authors of the paper incorporated additional abilities so the reward function could cope with 
invalid actions, network loops and multiple metric optimisations. Similar to a standard reward 
formula during a training cycle or episode where the DQR algorithm is finding a path to a 
random destination node, the DRL Agent is penalised for poor performance. For example, 
because of the nature of the state space, it is possible for the DRL Agent to pick an invalid 
action for each time step. If it does then it is penalised. This helps the DRL Agent learn valid 
actions. To avoid loops, each training cycle or episode will terminate if the number of time 
steps exceeds the number of links or edges in the network topology. Once the DRL Agent had 
learned to recognise valid actions, the DRL Agent attempts to find a path taking into account 
QoS parameters. Doing this reduced the negative reward the DRL Agent receives.  
 Training:- To train the algorithm, first, a topology or environment was created by the authors 
specifying the number of networks nodes and links or edges. Following this, the PER buffer, 
primary Q-Network and target Q-Network were initialised. Training was made up of a number 
of episodes where each episode was comprised of a number of times steps as the DRL Agents 
works its way to the destination node. For each episode, a source and destination were 
selected randomly. For each time step, an action was selected using an epsilon-greedy 
approach. If the action was valid, then the DRL Agents received a reward and the action was 
executed. If, however, the action was invalid, then the DRL Agents were penalised, the current 
episode was stopped and a new one began. After each training cycle or episode, the transition 
experience was stored in the PER buffer. Following this, a small number of transitions were 
randomly sampled from the PER and the weights that made up part of the DNN were 
optimised using these transitions. The target Q-Network was updated after each time step. 
Each episode ended when the destination was found, if an invalid action was performed or if 
the number of time steps was greater than the number of links or edges in the network 
topology.  
To evaluate the DQR algorithm, the first test compared the performance of DQR to two other 
algorithms, Shortest Path and a RL-based algorithm called QoS-aware Adaptive Routing (QAR). The 
network metrics, end-to-end delay, minimum bandwidth of selected path, end-to-end loss and end-
to-end cost was used to evaluate the performance of each algorithm as well as the average number 
of links activated for selected paths. A partial mesh topology was employed containing 10 forwarding 
nodes where for 1,000 flows, random source and destination node pairs were selected for each flow. 
The results displayed for each destination node showed that for the end-to-end delay, the algorithm, 
Shortest Path achieved the lowest delay for each node with DQR achieving the second lowest and QAR 
achieving the highest. For the minimum bandwidth of a path, DQR found paths that for each 
destination node, had the highest path bandwidth with QAR achieving the second highest and Shortest 
Path the lowest. For the end-to-end loss and end-to-end cost, DQR had the lowest smallest value for 
both with QAR coming second and Shortest Path resulting in the highest amount of loss and cost. 
Finally, for each path calculated, DQR found the path with the fewest links or edges outperforming 
both the other algorithms with Shortest Path selecting the most links/edges overall.  
The second test used a larger mesh topology of 14 forwarding nodes. Three network metrics, end-to-
end delay, average bandwidth and end-to-end cost were used to assess the performance of each of 
the three routing algorithms as employed in the previous experiment. In the test, however, the 
number of source and destination node pairs was designed to start with 20 pairs and then increase 
over time to 100 pairs. The results show that as the number of node pairs increased, Shortest Path 
achieved the lowest end-to-end delay with DQR achieving the second lowest and QAR the highest. 
DQR achieved a marginally larger average bandwidth with the other two algorithms having 
approximately the same result. Finally, the results for DQR showed that it had a marginally lower end-
to-end delay than the other two algorithms with the performance of QAR and Shortest Path again 
being approximately the same. 
The third and final test measured throughput in Mbps against an increasing demand in traffic also in 
Mbps. The topology used in the first test was once again employed for this test. However, only two 
algorithms were used with the performance of DQR being compared to QAR. The results show that as 
the traffic demand increased, DQR consistently outperformed QAR in terms of throughput by a wide 
margin, being able to find paths capable of supporting larger loads. 
Overall, the results suggest that DQR is a superior online algorithm than QAR and Shortest Path, 
demonstrating that a modified DQN can be useful for greedy, real-time routing. However, there are 
two issues that need addressing or clarification. The first is the inclusion of Shortest Path using only 
one metric for the first two tests. It is true that in the delay-based tests, Shortest Path outperformed 
the other two algorithms. However, given that Shortest Path used latency or delay as its only metric 
in the authors implementation, this result was not surprising as Shortest Path did not need to take 
any other network metrics into account when selecting a path. Because DQR and QAR can support 
multiple network metrics, it was strange to compare these algorithms to a routing algorithm that was 
only using delay or latency for pathfinding. Shortest Path in this instance should have either been 
modified to consider additional network metrics or, it should not have been used as it really was not 
a fair comparison. The second issue is scalability. One of the heaviest criticisms mentioned in this 
paper against Q-Routing was that it is not suited to large scale topologies and that DQN solves this 
problem. However, despite the authors mentioning this, none of the tests looked at the performance 
of DQR for larger scale networks. It is true the second test used a 14-node topology instead of a 10 
node one in the first test but the difference in topologies sizes was marginal at best and scalability was 
not the focus of either of the first two tests. The closest the paper comes to this subject regarding 
DQR is when it mentions that on a partial mesh network using 10 forwarding nodes, it took 
approximately 120 training cycles to achieve convergence where the DRL Agent had successfully learnt 
the network topology while also being able to select paths based on QoS parameters. Unfortunately, 
as this was not repeated on topologies of any other size, or, indeed, to any Q-Routing algorithms, it is 
hard to judge if the authors DQR algorithm is scalable.  
2.4.4) Conclusions on Q-Learning:- 
Q-Learning by all accounts is a popular and often used ML algorithm being employed in many different 
areas of study. This is thanks to its simplicity and innate flexibility and despite the advent of more 
advanced and powerful ML techniques such as NN, Q-Learning is still the focus of ongoing research in 
various forms, such as Q-Routing. Q-Routing was an adaptation of Q-Learning designed to make use 
of the path latencies to train the Q-Routing algorithm to find an optimal path using a reward formula. 
Since its creation, Q-Routing has become a field of research in its own right though with fewer papers 
than Q-Learning. In this regard, the literature reviewed looked at addressing different aspects of the 
Q-Routing algorithm to improve the performance of the algorithm or to combat perceived weaknesses 
of Q-Routing as stated by the authors of the papers reviewed:- 
1. Exploration and Convergence:- To enable the Q-Routing algorithm to find the optimal path 
between two points in the network, the algorithm first had to learn the best paths in terms of 
latency or end-to-end delay. This could take many episodes or training cycles depending on 
the size and complexity of the network topology. This convergence could also be delayed or 
prevented altogether if the load on the network was great enough to slow down or prevent 
the passing of packets required to update the Q-Tables on each forwarding node.  
2. Scalability:- Each node in the network topology contained a Q-Table containing information 
and Q estimates on how to reach every other node in the network topology. If a new node 
were added to the network topology, the existing tables in each network node would increase 
in size. This meant that a forwarding node could conceivably reach a stage where it no longer 
had the memory to store the Q-Table as the size increased. This also meant that the time 
taken to update a Q-Table or simply access the data in the Q-Table could reach a point where 
the performance of the algorithm could be impaired as the CPU in the node was not powerful 
enough to update a Q-Table or process information in a timely fashion. 
3. QoS:- The original Q-Routing was designed to find the optimal path based on latency. For 
applications requiring the quickest path, this would have not been a problem but for 
applications sending flows that had to meet multiple, stringent QoS requirements, Q-Routing 
in its original form would not have been suitable due to its one metric design. 
In the case of exploration to aid convergence, four of the reviewed Q-Routing algorithms (Full Echo Q-
Routing [22], Adaptive Q-Routing Full Echo [90], AQRERM [91], Dual Reinforcement Q-Routing [23]) 
looked at increasing the efficiency and the accuracy of the exploration. In regards to scalability, the 
paper on DQR [95] proposed the use of DNN where Q-Tables are replaced with a function while the 
paper on Simulated Annealing [89] introduced a hierarchical model splitting the network topology into 
segments. Finally, several papers including RL-QAQ [92] and DQR [95] introduced methods to include 
additional network metrics so paths could be found that met specific QoS requirements. It should be 
noted that none of the Q-Routing algorithms reviewed had solutions to all three of the challenges 
listed. The failure of these approaches to combat all three challenges is not unexpected as each of the 
individual approaches reviewed was primarily concentrating on single issues. DQR [95], while not 
strictly being a Q-Routing algorithm as it combined Q-Routing with DNN, did tackle two of these 
challenges: scalability and QoS. RL-QAQ [92] also addressed two of these challenges: exploration and 
to a limited extent, QoS.  
Unfortunately, available research into Q-Routing becomes limited as the subject area becomes more 
specific. For example, there was only one case of a Q-Routing variant being utilised in conjunction with 
SDN networking [93]. A second example using an SDN network employed Q-Learning indirectly for 
congestion control [94] while a third example used SDN conjunction with DQR [95]. For variants of Q-
Routing using multiple network metrics, the situation was similar. Finally, for variants of Q-Routing 
utilising SDN and employing multiple metrics, there were only two examples in the reviewed literature 
and if DQR [95] is discounted, only one example, the paper titled Using SDN and Reinforcement 
Learning for Traffic Engineering in UbuntuNet Alliance [93] which in this instance, only produced 
average results when the multi-metric formula was used and which failed to discuss the results in any 
detail. 
Overall, research into Q-Routing has progressed in many different directions, pushing the boundaries 
of what Q-Routing, and indeed Q-Learning had traditionally been able to do with some impressive 
results. It is also evident that, despite this impressive progress, there are some areas that remain 
mostly untouched. Specifically, utilising Q-Routing within SDN using multiple network metrics to meet 
QoS requirements. Given the popularity of Q-Routing and Q-Learning in general, it is likely this will not 
be the situation for much longer with research continuing in a myriad of different areas.  
2.5) Testing Methodology & Network Topologies:- 
While examining the state of the art, it has been interesting to see the different tests conducted and 
the topologies used to evaluate the performance of the algorithms presented. This section looks at 
some of the tests carried out and proposes some additional tests to assess the performance of the 
reviewed and future Q-Learning based routing algorithms. 
2.5.1) Convergence Testing Under Load:- 
For Q-Routing based algorithms using decentralised legacy networks, one of the most common tests 
is a convergence test, normally where the average delivery time of each traffic packet is set against 
the Simulator Time where the network topology is subjected to a low network load which increases 
over time. The first instance of this approach discovered in literature was in the paper on the original 
Q-Routing algorithm published in 1993 [22]. Each simulator step in this instance corresponded to a 
single training cycle or an episode of the Q-Routing algorithm. The network topology used for this test 
was an irregular 6 x 6 node topology where two edges or network links existed between the left and 
right side of the network topology (Figure 8). If the algorithm worked as intended (which it did in the 
case of Q-Routing), as the load of the network increased, the Q-Routing algorithm would switch from 
the shorter, congested path through the middle of the topology to the longer but less congested path 
across the top of the topology where despite taking a longer route, would achieve a lower average 
delivery time than any routing algorithm used as a point of comparison. For researchers into Q-
Routing, this approach is quite popular being used for Adaptive Q-Routing Full Echo [90], Adaptive Q-
Routing with Random Echo and Route Memory [91] and Dual Reinforcement Q-Routing [23]. The main 
difference between each of these was the routing algorithms used for comparison. For example, in 
the original Q-Routing paper, Shortest Path was used to compare the algorithms performance. For 
Adaptive Full Echo Q-Routing, both Dual Q-Routing and the standard Q-Routing algorithm were 
employed while the performance of Dual Reinforcement Q-Routing was measured against standard 
Q-Routing and Full Echo Q-Routing.  
Figure 8:- The irregular 6 x 6 grid network topology used for testing different Q-Routing algorithm variants [90]. 
2.5.2) File Transfer Time:- 
One of the more simplistic tests for routing algorithms is to measure the time taken to send a file of a 
set size from one node to another across a network topology. This is a useful test as it is not difficult 
to implement and allows the user to compare the performance of different algorithms which, when 
testing a new algorithm, can be very insightful. For example, the authors of the paper on congestion 
prevention [94] compared the performance of their Q-Learning algorithm against Dijkstra's Shortest 
Path algorithm and extended Dijkstra. Files of three sizes were sent across a partial mesh network 
topology (Figure 9). The results in this instance showed that the Q-Learning algorithm was finding the 
best routes to avoid congestion while minimising file transfers times, indicating that the authors 
algorithm was working and performing better than the comparative algorithms. This is also a useful 
test when convergence is not an issue. For example, because the actual routing algorithm in the 
congestion prevention paper was based on Shortest Path within an SDN network, there was no need 
for each network node to learn the location and end-to-end delay to every other network node as the 
SDN Controller has already done this when creating a map of the topology. Unfortunately, for routing 
algorithms looking for paths to meet QoS requirements, this test overlooks network metrics such as 
bandwidth capacity and end-to-end delay. 
Figure 9:- Network topology used for the Q-Learning congestion prevention algorithm [94]. 
2.5.3) Metric Performance Assessment:- 
Another common test is to assess the performance of the algorithm by measuring one or more 
network metrics such as the end-to-end delay or latency, the bandwidth or throughput, the packet 
loss, jitter, and so on. This, in essence, is not dissimilar to the convergence test where, in the case of 
convergence testing, the goal was very specific, to measure the average delivery time for each 
simulator step as the load in the network increased to see how well the Q-Routing algorithm was 
converging on a suitable path. The different metrics and how they are used, of course, depend on the 
ultimate goal of those carrying out the test, be it specific or general. In both cases, however, there is 
one obvious advantage. By using several different network metrics for assessment allows the relative 
advantages and disadvantages of each algorithm to be revealed and contrasted with other routing 
algorithms. This approach is also essential when QoS requirements needed to be factored into the 
performance of each algorithm. 
Looking first at [93] where SDN was used in conjunction with Q-Learning altered to support two 
network metrics (latency and bandwidth), three network metrics were used to assess the performance 
of each test carried out using a simulated network designed to replicate any actual international 
network topology used by the UbuntuNet Alliance (Figure 10). Latency, throughput and jitter. In the 
case of Deep Q-Routing [95] using a partial mesh network topology, the metric end-to-end delay, 
average bandwidth, end-to-end cost, end-to-end loss and average latency were all used at one point 
or another. When each metric was used depended on the focus of the test at the time. In both cases, 
the algorithms being discussed had a QoS element to them, so the utilised metrics were used to assess 
the algorithms on this basis. 
Figure 10:- UbuntuNet Alliance Network Topology [93]. 
2.5.4) Computer Performance Characteristics:- 
In some instances, it is useful to monitor the usage of systems resources of an algorithm, or program 
in general to see if it is cost-efficient in terms of the percentage of memory usage, CPU utilisation, and 
so on. Such attributes to can also be used to test the efficiently of routing algorithms in comparison 
to each other. In many cases, testing these attributes might not be relevant if, for example, a 
particularly powerful computer or server is being employed. But in the case of older servers, 
computers or in the development of a new algorithm, testing these attributes might be advisable. 
However, in order for the results to be fair and consistent, each routing algorithm should ideally be 
tested on the same computer or server. If that is not a possibility, then identical computers or servers 
with the same hardware and software configuration.  
2.5.5) Scalability:- 
One of the most often mentioned factors, when it comes to the criticism and performance of routing 
algorithms, especially Q-Routing is the algorithms ability to work efficiently when it is employed on 
larger and more complex network topologies. The limitations of Q-Routing in terms of scalability in 
literature is often mentioned. For example, the paper on Deep Q-Routing [95] states that Q-Routing 
is not scalable and suggest that a DQN was introduced to counter this issue. The paper on Simulated 
Annealing based Hierarchical Q-Routing [89] stated that the performance of Q-Routing decreased as 
the size of the network topology increased. Finally, while not stating scalability directly, the paper on 
Adaptive Full Echo Q-Routing proposed a solution that would increase exploration efficiency leading 
to more accurate Q-Table estimates which should, in theory, improve the algorithms ability to perform 
on larger network topologies. 
Despite the claims made by the authors of these papers, the majority of tests performed in the 
reviewed literature looked at other performance aspects of their respective routing algorithms. When 
scalability was discussed as part of the assessment criteria, it was normally how the routing algorithm 
being presented compared to competing algorithms, such as comparing Full Echo Q-Routing to 
Shortest Path and standard Q-Routing. If, for example, using a small partial mesh network topology of 
10 forwarding nodes, the results showed that Full Echo Q-Routing had a lower average delivery time 
than the other two algorithms as the load on the network increased, these results would be useful. 
However, without repeating the experiment again on a larger network topology, there is no way to 
know if Full Echo Q-Routing would still outperform the other two algorithms. By only using the same 
size topology for all experiments, only part of the story is being told in relation to scalability. The 
obvious solution is to use different network topologies. For example, any Q-Routing based algorithm 
being assessed along with algorithms that are being used for comparison could be implemented on 
several different mesh topologies that increase in size. Alternatively, one size topology could be used 
with different versions of the topology starting as a partial mesh topology (Figure 11) and working up 
to a full mesh topology. Moreover, variants of both approaches could be implemented for a more 
comprehensive evaluation. Any of the forementioned tests carried out on each network topology 
would not only give an indication of the performance of the Q-Routing algorithm compared to the 
algorithms used for comparison, but also, a realistic view of how the performance of the Q-Routing 
based algorithm scales as the network does. 
Figure 11:- Network topology used for testing the DQR algorithm [95]. 
2.6) Application Software:- 
2.6.1) SDN Controllers:- 
When working with SDN-controlled networks, there is a number of different SDN controllers to choose 
from. Table 2 shows a comparison of some of the more prominent SDN controllers that are available. 
However, one of the main challenges is choosing the right SDN controller. From the perspective of the 
user, this could depend on their knowledge of programming languages and the support available for 
each SDN controller. In the case of the former, if the user, for example, was only familiar with Python, 
then from Table 2, only the SDN Controllers NOX, POX and Ryu would be suitable. In the case of SDN 
controller support, as far as it can be seen, both the SDN controllers NOX and Trema are no longer 
supported by the companies who created them. This can be mitigated by community support from 
sources such as GitHub but could still potentially cause issues if a problem were to arise when the 
controllers were being implemented.  
The application of the controller is also important as some SDN controllers are better suited to 
different tasks. For example, a paper [96] comparing the performance of different SDN controllers 
(Ryu, Floodlight, ONOS, OpenDayLight) across three different Mininet topology layouts (Linear, Tree, 
Mesh) determined that Floodlight was more efficient in terms of delay and throughput than the other 
three SDN controllers. The paper suggested that as a result, Floodlight might be a better choice as a 
controller running QoS dependant applications. Floodlight, however, like Ryu are both centralised 
controllers while OpenDayLight and ONOS are both distributed controllers so it is possible these 
results would not hold true if the application called for a distributed controller. 
Another factor to consider is the OpenFlow version required. For a personal project or research, the 
OpenFlow version might not be relevant. If, however, for a commercial application an OpenFlow 
version of 1.5 was required, then from Table 2, only IRIS, Floodlight, ONOS and Ryu would be suitable. 
All of the points discussed are just some of the many factors that should be considered when selecting 
an SDN controller. 
Controller Year Open 
Source 
Language Platform Interface OpenFlow 
Version 
Developer  
NOX [97] [98] 2008 Yes C++, 
Python 
Linux PyQT4 1.0 Nicira / 
VMware 
Beacon [99] 2010 Yes Java Linux, 
Mac OS 
Windows 
Web 1.0  
1.3.2 
Stanford 
University 
IRIS [100] 2014 No Java Linux, 
Mac OS 
Windows 
Web & 
1.0  1.5 IRIS Research 
Team of ETRI 
POX [101] 
[102] 
2012 Yes Python Linux, 
Mac OS 
Windows 
PyQT4 1.0  1.1 Nicira 
Floodlight 
[103] [104] 
2012 Yes Java Linux, 
Mac OS 
Web & 
1.0  1.5 Big Switch 
Networks 
Windows 
OpenDayLight 
[105] [106] 
2013 Yes Java Linux, 
Mac OS 
Windows 
Web 1.0  1.4 The Linux 
Foundation 
(Many  
Contributors) 
ONOS [104] 
[107]  
2015 Yes Java Linux, 
Mac OS 
Windows 
Web 1.0  1.5 The Linux 
Foundation 
(Many  
Contributors) 
Ryu [103] 
[108] 
2013 Yes Python Linux GUI Patch 1.0  1.5 NTT OSRG & 
VA Linux 
OpenMUL 
[109] 
2012 Yes C Linux Web 1.4 KulCloud 
Trema [110] 2011 Yes C/C++ & 
Linux N/A 1.0  1.3 NEC 
Table 2:- Comparison of SDN Controllers. 
2.6.2) Simulation / Emulation Tools:- 
When it comes to testing new approaches in networking such as new protocols, control mechanisms 
and so on, the optimal approach is to use an actual physical network. However, due to limited 
availability and potential cost, this is not always practical. This approach might also not be advisable if 
there are errors or bugs in the work being undertaken as it could cause disruptions to users on an 
active network. In such instances, network simulation or emulation software is extremely useful as a 
simulated network can be created as required for experimental purposes. This section looks at some 
of the network simulation and emulation tools available. 
2.6.2.1) Mininet:-  
Mininet [111] is a network emulator created to be both a network simulation tool for research and a 
development tool designed to a create realistic virtual network for experimentation before 
deployment on real network hardware. The Mininet emulator is open source making it a perfect 
research tool as there is no need to purchase a license. Mininet, unlike other emulators and 
simulators, was designed specifically with SDN in mind. Mininet has several features to make the 
emulation of SDN network environments easy to achieve. For example, Mininet allows the emulated 
network to be controlled by an emulated SDN controller or a real, external SDN controller. Mininet 
supports OpenFlow and can convert real OpenFlow commands issued from an external controller via 
the southbound Interface into emulated OpenFlow commands that the emulated OpenFlow network 
devices can interpret. 
Mininet also includes several other key features including multiple concurrent development allowing 
several users to work on the same topology at the same time; complex topology testing, support of 
non-SDN topologies; can be used straight away without programming, etc. When it comes to creating 
topologies, this can be done in one of two ways. The first is the use of the Command Line Interface 
(CLI) which, using Mininet specific commands, allows the user to create network topologies of varying 
layouts (star, mesh, etc) with the number of hosts and network nodes being specified in the command 
line. The second, Mininet supports a Python API so network topologies can be written in Python and 
imported again using the CLI.  
Regarding network traffic, because Mininet is an emulator, it supports Linux/Unix network 
applications. This means that networks tools such as iPerf [112] or Ping [113] can be used to generated 
network traffic, either written into the Python script or via the CLI for each host node. 
However, despite the advantages that Mininet offers, there are also a few disadvantages that should 
be noted. One paper carrying out research into SDN network simulators [114] noted that Mininet was 
known to generate strange results on some specific network topology sizes. The author of the paper 
was not able to explain why this was the case. It was also noted by the same paper that for larger 
emulated network topologies, Mininet spent a great deal of time setting up the network topology, 
launching the program and releasing resources when they were no longer needed. 
Another criticism levelled at Mininet was that it was designed to emulate packet-switched SDN 
network topologies which makes Mininet unsuitable for those looking to experiment with SDN using 
either optical or wireless networking technology. This problem was partially addressed by a paper 
[115] released in 2020 that looked at creating a version of Mininet called Mininet-Optical that uses an 
SDON controller and emulates optical SDN networks. This, however, was created as a private initiative 
and not by the creators of the original Mininet.  
2.6.2.2) NS-3:-  
NS-3 [116] is a discrete network simulator primarily for research and educational use. It is classed as 
free software and can be used publicly making it a valuable tool. NS-3 supports both IP and non-IP 
networks making it extremely versatile. Its primary focus, however, is on wireless IP simulations 
involving models for Wi-Fi, WiMAX and LTE and comes equipped with a variety of static and dynamic 
routing protocols such as Optimised Link State Routing (OLSR) and Ad-Hoc On-Demand Distance 
Vector (AODV). NS-3 also comes equipped with a real-time scheduler that "facilitates a number of 
simulation-in-the-loop use cases for interacting with real systems." 
NS-3 is based upon the older version NS-2. NS-3s whole system, however, is based upon C++ and can 
use Python to implement any other scripts while NS-2 used C++ for its core system and Tcl script for 
controlling the simulation. The main difference, however, is that NS-3, like Mininet, can be used for 
both network simulation and development where NS-2 was only designed for network simulation 
[117]. 
A problem noted with NS-3 however was that it had poor scalability and did not work as well for 
simulating large scale networks. Also, while having some support for SDN, anecdotal experience from 
2018 showed NS-3 was not really suited to SDN simulations for several reasons. Firstly, NS-3 supported 
only one SDN switch in a simulation. Adding additional switches to the simulation caused the 
simulation to fail. Secondly, simulated full-duplex ethernet links could not be used in conjunction with 
the simulated SDN switch. Thirdly, no external SDN controller could be used with an NS-3 SDN 
simulation. Finally, and unlike Mininet, all traffic was generated via NS-3 making specific traffic 
patterns harder to create.  
2.6.2.3) OMNet++:-  
OMNeT++ [118] itself is not a complete network simulator. It contains a simulation framework that 
can be used for writing simulations but does not contain explicit support for existing network 
hardware or protocols. Though specific simulations can be written or found as separate compatible 
modules that can be added to OMNeT++ such as INet. This framework is a component-based C++ 
simulation library and is primarily used for simulating wired and wireless networks on chip and 
queuing networks. Like NS-3 and Mininet, OMNeT++ is free to use for research and network 
development and can be run on systems using Windows, Linux and Mac OS giving it a wide support 
base and, when compared to other network emulators and simulators, OMNeT++ seems to fair quite 
well. According to one paper [119], OMNeT++ is more scalable and requires fewer resources such as 
memory or CPU utilisation than other network simulators including NS-3. 
There also does not seem to be a limit to what it can perform. Essentially, if it can be programmed 
or, if a module already exists, then there isn't a system it cannot simulate including the majority of 
the features contained within Mininet and NS-3. However, OMNeT++ does require a good working 
knowledge when it comes to programming because while it is true that OMNeT++ can be used to 
simulate many aspects of both wired and wireless networks including protocols, if a module does 
not exist for it, it has to be created from scratch which can be both difficult and time-consuming. 
Anecdotal experience from 2018 shows that this was the case for SDN. A third-party solution was 
created by research students investigating SDN wireless networks [120] but again this was limited in 
several ways similar to that of NS-3 including not being able to use an external SDN controller and 
not being able to receive generated traffic from an external source. 
2.6.2.4) OPNET / Riverbed:- 
OPNET [121] is a network simulator that offers three main functions: network modelling, simulation 
and analysis. It comes equipped with a graphical environment making it relatively easy to use and 
allowing the creation of various models and protocols. OPNET, according to the creators website (now 
purchased by and rebranded as Riverbed) [122], also comes with a number of features including a fast 
discreet simulation engine, a large component library with source code, object-orientated modelling, 
scalable wireless simulations and so on. OPNET can be used for network traffic modelling, protocol 
modelling, queuing networks, validating hardware architectures (wired and wireless) along with an 
array of other abilities. While the versatility of OPNET is impressive, it does lack the ability for actual 
network development that Mininet has, for example. Also, it appears that OPNETs current incarnation 
(Riverbed Modeller) is not opensource as is the case with NS-3 and Mininet with the companys focus 
being on developing and marketing a commercial product. Riverbed, however, does offer a free 
academic version with limited 6 months licenses.  
2.6.2.5) GNS3:- 
GNS3 [123] according to the manufactures website is a free, virtual network environment that seems 
to have been originally designed primarily as a training tool for those looking to take Ciscos CCNA 
certification. GNS3 comes equipped with many different functions. These include creating virtual 
network topologies, real-time network simulations and the ability to create dynamic network maps 
for troubleshooting and proof of concept (POC) testing. GNS3 also offers users the ability to connect 
a virtual network to a real one. According to the information available on the website for GNS3, the 
program also supports network concepts and approaches such as SDN and NFV.   
However, despite these positive points, there are a few disadvantages to GNS3. The first is that while 
the program itself is free to download and use, an IOS image, which allows the user to simulate specific 
vendor network hardware, is needed for some of the programs functionality. Unfortunately, these 
images are hard to find for free and can be costly. However, for those users not interested in sitting 
the CCNA test, the generic simulated hardware should be enough. Finally, there appears to be little 
support for creating optical or wireless network environments. This seems to be confirmed by current 
literature where the research that used GNS3 seemed to be concentrated on packet-switched network 
topologies [124] [125].   
2.7) Literature Review Conclusion:-  
To aid the research discussed in this Thesis, it was necessary to review the available literature on SDN 
networks and Q-Learning to help in the objective of developing a Q-Learning-based routing algorithm 
that can utilise multiple network metrics to find paths that meet specific QoS requirements. This was 
a useful exercise as it revealed the perceived weaknesses of SDN and Q-Learning, the many varied 
approaches to counter these weaknesses, the results of these approaches and, most importantly, the 
unexplored areas of research yet to be investigated or with limited research outcomes. Given the 
focus of the research in this Thesis, the main area of interest was the use of Q-Routing using multiple 
network metrics to find paths between source and destinations nodes that met QoS requirements 
using an SDN network. As previously discussed, only three of the reviewed papers performed research 
in this specific area and while each of these three methodologies and their corresponding results were 
generally positive, each approach also presented challenges. Moreover, it seems that some of the 
advantages of using SDN, such as network topology discovery, were not utilised or at the very least, 
not mentioned in two out of the three papers with additional vagueness about the use of SDN in all 
three. In terms of using Multiple network metrics for QoS, arguably only one paper [93] out of the 
three had a valid solution. Unfortunately, the discussion regarding the results on this specific element 
did little to explain them.  
After reviewing this literature and understanding how Q-Learning (Specifically, Q-Routing) works and 
how SDN networks operate, there appear to be many natural advantages to using Q-Routing for 
pathfinding in an SDN-controlled network to find paths that meet QoS requirements. 
Firstly, thanks to the flexibility of SDN, applications, either pre-existing or user-created (depending on 
the SDN controller) can be implemented to simplify the users experience and to enhance the 
performance of the network. One such application is a tool located in the Management Plane that 
builds up a map of the network topology. Depending on the application, this topology map will show 
which nodes are connected, the port numbers of each node used and the latency and bandwidth of 
each link or edge in the network topology. The application will also label all nodes with unique 
identifiers for future reference. This process is normally implemented when the SDN controller is first 
initialised during a discovery process where the SDN controller queries each network node to find the 
nodes it is connected too. This means that all this topology information is available to the algorithm 
used for routing as the mechanism for routing is another application, also located centrally in the 
Management Plane.  
Secondly, in a distributed network using the standard Q-Routing algorithm, Q-Routing on each 
network node is undertaking two actions. The algorithm is attempting to learn the best path from 
source to destination for each new packet flow that arrives while also slowly updating estimates on 
how to reach each destination node. Essentially, the training phase and the pathfinding are 
implemented concurrently. Assuming the traffic load on the network is not too heavy, the Q-Routing 
algorithm on each network node will eventually generate accurate end-to-end latency estimates 
stored in Q-Tables for reaching every other network node and, as such, be able to find the shortest 
path based on latency achieving convergence. However, during the time required to learn this, the 
paths used are likely to be less than optimal which could compromise network performance. 
Moreover, if there is a QoS element at play, this means that many flows could have unwittingly 
travelled through paths that did not meet the QoS requirements. If, however, the traffic load in the 
network is quite large, then convergence could be delayed or even prevented as the packets sent 
between nodes required by Q-Routing for update information become stuck in traffic.   
SDN offers a unique opportunity in this regard as it could allow the training phase and the pathfinding 
phase to become separate entities. When the SDN controller is first initiated, one of the steps for 
initialisation could be to train the Q-Routing algorithm. Because the algorithm is located centrally and 
because the SDN controller would have already created a topology map, all the information required 
to train Q-Routing would be readily available allowing the algorithm train and learn without having to 
calculate paths from the offset. The algorithm would also not require packets to be swapped between 
nodes containing updates as it did in a distributed network environment. Once the Q-Routing had 
completed training, the SDN controller would finish initialisation and then Q-Routing using its pre-
trained Q-Tables could find paths for incoming flows. Once the path was generated, the SDN controller 
could simply send the forwarding instructions to each node in the calculated path. For a dynamic 
network environment, additional training cycles could be introduced to keep the Q-Tables up to date. 
This would not only allow accurate pathfinding from the start, but also allow the algorithm to adapt 
to changing network circumstances in a similar way as Q-Routing in a distributed network but without 
the initial loss in performance. This approach would also reduce the scope of the Temporal Credit 
Assignment Problem common in RL [79], either completely in the case of pre-training and by a large 
factor in the case of partial re-training. 
Thirdly, one of the key issues for Q-Routing in a distributed network was scalability. Each forwarding 
node in the network contains a Q-Table with the estimates on how to reach every other node in the 
network along with other information such as the connecting neighbouring nodes and the 
corresponding ports. As new network nodes are introduced into the network environment, the Q-
Table increases in size accordingly. However, for each network node, there will be a time where the 
Q-Table becomes too large. The network node will either run out of physical memory, meaning that 
the node can no longer update and adapt to changing network circumstances, or the time required to 
process the information in each Q-Table will become prohibitive as the CPU in the node is no longer 
powerful enough to process the available information in a timely manner resulting in network delays. 
SDN controllers normally operate on computers or servers which generally, have far more available 
resources than a network node. This approach would allow network nodes to concentrate on 
forwarding flows of packets only leaving the SDN controller to the more complex operations that it is 
better suited to handle and allowing Q-Routing to be employed for routing in larger network 
topologies. 
On a related note, because the SDN controller is on a centralised computer or server, the development 
and deployment of a complex, Q-Routing algorithm designed to use multiple network metrics would 
become easier. As discussed, the computer or server has resources that a standard forwarding node 
(such as a switch or router) cannot match. SDN also allows the development of new applications using 
well-known and supported, higher-level programming languages instead of obscure, lower-level 
vendor-specific software which can be limited and difficult to use without specialised training. 
Finally, because the Q-Routing algorithm is operating centrally, as opposed to separately on each 
network node, during both the exploration and pathfinding phases, the SDN controller can easily list 
the nodes already used allowing the Q-Routing algorithm to avoid nodes it has already visited. This 
should allow for faster exploration, faster pathfinding and, it would prevent loops from forming in 
both phases. Using SDN would also avoid the need for additional overhead or increased packet size, 
required by the distributed Q-Routing methods [91] [23] that kept track of the nodes visited, but 
needed to pass this information on to the next node in the exploration process. 
Given this list of potential benefits, using Q-Routing within an SDN network would seem to be the next 
logical step for the RL algorithm. This would allow Q-Routing in existing forms to be utilised as well as 
new variations of Q-Routing (multi-metric) to be developed and tested while making use of the 
advantages that SDN offers. When considering the employment of multiple network metrics using Q-
Routing, the literature would seem to indicate that using a weighted, reinforcement formula should 
be the initial focus of the research. Moreover, while not covered in any of the reviewed literature, the 
use of separate reward formulas for different metrics should also be considered as this approach could 
not be found in current literature. 
Chapter 3:- The SDN Testbed 
3.1) Introduction:- 
To perform experiments on each of the path calculation algorithms developed during the course of 
this research, it was necessary to create a testbed that could host or incorporate each of these 
algorithms so they could be fully tested. This was important as this testbed and any possible algorithm 
variants would be used at every stage during the research. This chapter looks at the key elements that 
went into the testbed. Specific details on implementation and testbed testing can be found in 
Appendix A. 
3.2) Chapter Objectives:- 
The work and research carried out in this chapter had one primary objective, this was to build a test 
platform or testbed (Figure 12) to allow the functionality testing and performance experimentation of 
all the pathfinding algorithms created as the researched progressed. The testbed was composed of 
three main parts: the SDN Controller, the network topologies and the random traffic generation. 
To keep in line with the overall theme of the research objectives, primarily researching and 
implementing faster and more efficient pathfinding algorithms to deal with the exponential expansion 
of the internet and other network environments, the testbed had to meet a number of requirements. 
Figure 12:- Showing an approximation of the SDN Testbed. 
3.2.1) SDN Controller Requirements:- 
One of the main requirements for the testbed was that each path calculation algorithm should be 
utilised within an SDN packet-switched network environment using an OpenFlow compatible 
controller and network devices (switches, routers, etc) because as discussed previously (see section 
2.2.2), SDN networking holds several advantages over traditional decentralised legacy networking 
methods. 
 It has a centralised approach which allows the forwarding instructions for complete paths to 
be programmed into all the corresponding network nodes very quickly without each separate 
node in the path having to request forwarding instructions.  
 An SDN controlled network also allows easier and quicker access to network metric and 
network node information through communication protocols such as OpenFlow.  
 The integration of applications is relatively simple to do as they can be written in any higher-
level language without requiring an underlying knowledge of the network topology. These 
applications also work via the Management Plane through the SDN controller and do not need 
to be programmed individually into each network device. 
 SDN is fast to react to changing network conditions such as a failed network device, a broken 
link, etc. 
Several additional elements were also required as part of the SDN implementation. These were as 
follows:- 
1. The SDN controller would be required to respond to each individual request for forwarding 
instructions from each network node when they requested forwarding instructions on how to 
reach a destination node within the network topology. 
2. As it was possible for many separate flows to be active at one time, the SDN controller would 
not only need to be able to respond to each individual flow request in real time, but also in 
tandem. 
3. The SDN controller would be required to generate random values to simulate QoS metrics 
that an application such as Skype, web browser traffic, or a large file transfer might require. 
4. Instead of the SDN controller being reactive and programming nodes in a path one at a time 
as each node individually requested forwarding instructions, the SDN controller would need 
to be pro-active. This would mean installing forwarding rules into all nodes within a path from 
source to destination as soon as the path had been calculated and without waiting for each 
individual node requesting forwarding instructions. 
5. The SDN controller would need to be able to delete the forwarding instructions from each 
node in the path once the flow utilising that path had finished sending data. 
6. For each path found by the pathfinding algorithms within the SDN controller, the SDN 
controller would need to measure the metric or metrics of that path and see how the path 
compared to the randomly generated QoS metrics generated and mark the path as Active 
or Blocked depending on whether the path met the QoS requirements generated.  
3.2.2) Network Topology & Traffic Generation Requirements:- 
In order to effectively experiment with each pathfinding algorithm created, the SDN controller needed 
to be connected to simulated/emulated or physical network topologies that could generate random 
traffic in some form. The requirements for this part of the testbed were as follows:- 
1. In order to test the performance of each pathfinding algorithm, several mesh network 
topologies of varying sizes (small, medium and large) would be required with variants for each 
topology size based on the Average Mesh Connectivity (AMC) or the number of connections 
per forwarding node ranging from a small AMC value to a full mesh network. 
2. Traffic flows would need to be created on each host node in the network topology at random 
to transmit flows to a random destination and would keep transmitting this flow for a random 
duration.  
3.3) SDN Testbed Operation:-  
Having established the requirements for the testbed, this section discusses how the individual parts 
of the testbed were implemented.  
3.3.2) The Ryu SDN Controller Program:- 
The main SDN program implemented using Ryu was designed to house each of the pathfinding 
algorithms created while carrying out all the functions that were necessary for the smooth operation 
of the SDN controlled network. Figure 13 shows a blocking diagram of the basic operation of the Ryu 
SDN controller which ran as follows: - 
1. First, the controller was initiated allowing the SDN controller to build a topology map of the 
connected network comprised of forwarding nodes and hosts. The SDN controller was then 
ready to process incoming flows generated by the Mininet topology. 
2. When the controller received a flow request for finding a path from a source node in the 
network, using the header information in the flow, it would identify the source and 
destination forwarding nodes. 
3. To simulate QoS requirements that a real flow might require, random QoS metrics (latency, 
bandwidth, or both depending on the path calculation algorithm) were randomly generated 
for this flow. 
4. Next, the pathfinding algorithm would calculate a path between the source and destination 
forwarding nodes.  
5. The path calculated would then be assessed to see if it met the requirements of the randomly 
generated QoS of metrics. If the path met these requirements, then every forwarding node in 
the path was programmed with forwarding instructions by the SDN controller to allow the 
flow to reach the destination node. Once the flow had finished sending data, the forwarding 
instructions programmed into each forwarding node in that path by the SDN controller was 
deleted. 
6. If the path did not meet the QoS requirements, the flow was prevented from being able to 
transmit to the destination node. It should be noted that this did not prevent other flows that 
met the QoS requirements from using part of or all of the same path. 
Figure 13:- Block diagram showing the operation of the SDN controller. 
3.3.3) The QoS Requirements:- 
Each of the path calculation algorithms implemented (K-Shortest Path, Q-Learning and Q-Routing) 
within the SDN controller were designed to use either latency, bandwidth or both metrics for 
pathfinding. To emulate a real-life QoS requirement, the SDN controller would randomly generate a 
value before the pathfinding part of the program for, latency, bandwidth or both depending on the 
pathfinding algorithm. After the algorithm had calculated a path, the path would be tested to see if it 
met the QoS requirement that had been generated. For the algorithms using latency, it was required 
that the end-to-end latency of the path calculated was less than or equal to the QoS latency value. For 
bandwidth, the opposite was true where the bandwidth of the path needed to be greater than or 
equal to the QoS bandwidth value.  
If a path met the QoS requirements, then the path was marked as active and the flow that had 
triggered the request for the SDN controller to find a path between the source and destination nodes 
could transmit packets for the duration of the flow. However, if a path failed to meet the QoS 
requirements, the path was marked as Blocked. This meant that the flow that had triggered the 
request for pathfinding would not be able to send any packets to the destination node as no path 
could be found that met the QoS requirements for that flow. Once the flow had finished, the path was 
made available again. It should be noted that when the path was marked as Blocked, it only 
prevented that one flow from using the path. Other flows that used part or all of the path that had 
met the QoS requirement would not be affected. This QoS requirement was part of each algorithms 
assessment criteria.   
3.3.4) Network Topologies:- 
As part of the evaluation process, it was essential to see how the size of the network topology and the 
AMC or the average number of connections per node affected the percentage of flows blocked by 
each algorithm as this could be a potential factor in determining each algorithms scalability. Therefore, 
three different size network topologies were created with each different size topology having variants 
based on the average number of connections per node. Table 3 shows the topologies created for the 
experiments. 
Topology Avg Number of Connections per Node (Switch) 
10 Switches and 10 Hosts 3 
10 Switches and 10 Hosts 5 
10 Switches and 10 Hosts 7 
10 Switches and 10 Hosts 9 
25 Switches and 25 Hosts 4 
25 Switches and 25 Hosts 8 
25 Switches and 25 Hosts 12 
25 Switches and 25 Hosts 16 
25 Switches and 25 Hosts 20 
25 Switches and 25 Hosts 24 
50 Switches and 50 Hosts 5 
50 Switches and 50 Hosts 12 
50 Switches and 50 Hosts 19 
50 Switches and 50 Hosts 26 
50 Switches and 50 Hosts 33 
50 Switches and 50 Hosts 40 
50 Switches and 50 Hosts 45 
50 Switches and 50 Hosts 49 
Table 3:- Showing the topologies of different sizes and Average No of Connections per Node used in the experiments. 
3.3.5) Network Traffic Generation:- 
To generate network traffic for the testbed, the following process was implemented. First, each host 
node was given a random chance to generate traffic. If the host node failed to be selected, it had to 
wait a random period of time in seconds before it could try again to be selected. If a host node was 
selected, it would pick another host node at random to act as the destination for the traffic generated. 
Once a destination node had been selected, a random number was generated to act at the length of 
time the traffic flow would last. This process occurred simultaneously on each host node within the 
network so at any one time, all the host nodes could be waiting for the opportunity to send traffic, all 
the host nodes could be actively sending traffic or, more realistically, some host nodes would be 
sending traffic while others waited to do so.   
It should be noted that, before adopting this approach, several traffic generation methods based on 
existing distribution models were considered. For example, using a Poisson distribution [126] would 
have been suitable as the interarrival times between packets generated are exponentially distributed. 
The Poisson distribution is also better suited if the arrivals are from a large number of independent 
sources (Poisson sources), in this case, traffic generating host nodes. Another model considered was 
the Pareto Distribution Process [127] which produces independent and identically distributed (IID) 
interarrival times. However, these distribution models are generally better employed for traffic 
analysis, whereas the focus of the research presented here was on pathfinding algorithm optimisation 
and improvement.  
3.3.6) K-Shortest Path:- 
To assess the results of each Q-Routing algorithm, it was necessary to have an algorithm to act as a 
basis of comparison. In this regard, K-Shortest Path was selected (please see [128] for the Yens K-
Shortest Path Pseudocode). This section discusses the reasons for choosing K-Shortest Path, finding 
the value of K, and alternatives to K-Shortest Path. 
3.3.6.1) Why K-Shortest Path was Selected:- 
Out of the different Shortest Path based routing algorithms available, it was decided to use Yens K-
Shortest Path [20] (based on Dijkstras Shortest Path), along with variations of the algorithm as a basis 
for comparison for each of the Q-Routing, pathfinding algorithms created during the course of this 
research. There were several reasons for this:- 
1) Shortest Path based routing algorithms (Dijkstra [16], Bellman [17], Ford [18], etc) are the 
most commonly used algorithms in routing. This is true in both distributed routing (Link State 
and Distance Vector) and centralised approaches such as SDN and as such, is a realistic 
approach to act as a source of comparison. 
2) The complexity of Dijkstras Shortest Path algorithm compared to others such as Bellman-Ford 
is low making it relatively easy to implement and to modify [129]. The goal was to create a Q-
Routing based algorithm capable of pathfinding using multiple network metrics to find paths 
to meet set QoS criteria. This meant that any algorithm used as a basis of comparison would 
also need to be able to find a path using the same network metrics. 
3) Yens K-Shortest Path provides a loop less solution. This means that nodes already visited are 
not visited again speeding up the pathfinding process and avoiding endless loops. 
4) Dijkstras Shortest Path algorithm can be used to find a path between a single source node 
and a single destination node or a single source node and multiple destination nodes [129]. 
While Dijkstras Shortest Path algorithm is not designed to work with edges with negative 
values [130] as other shortest path algorithms such Bellman-Ford does, negative edges is not 
generally an issue within computer networks. 
5) Dijkstras Shortest Path algorithm is efficient enough to be used for large problems such as 
pathfinding in larger, more densely connected network topologies [130].  
6) The paper [20] that presented Yens K-Shortest Path algorithm claimed that the algorithms 
computational upper bound increases only linearly with the value of K making the algorithm 
extremely efficient. Not only is this good for implementation, this also is a useful assessment 
criterion, as any multi-metric Q-Routing algorithm that can perform more efficiently (for 
example, regarding pathfinding time) will have reached a significant benchmark.  
3.3.6.2) Selecting the K-Value:- 
The value of K within Yens K-Shortest Path [20] implementation is the number of unique paths found 
between set source and destination nodes by the algorithm where (depending on the notation), N=1 
refers to the most optimal path found. If, for example, K is set to 7, then the algorithm will return 7 
paths organised by most optimal to least optimal. If, however, 7 unique paths do not exist, then the 
algorithm will return the maximum number of paths it can find. This means that for larger network 
topologies with many unique paths, a large value of K can be used without fear of the algorithm not 
operating correctly. The feature was useful during the creation and testing of the SDN testbed. Initially, 
a default value of K=250 was selected as it was sufficiently large enough to return all paths on each of 
the different size topologies with varying AMC values. However, while this approach worked and 
allowed initial testing of Q-Routing algorithm, it lacked efficiency. 
To assess the effect of altering the value of K and to determine the optimal K-Value, a series of 
experiments were undertaken. Using the largest test topology (50 Switches and 50 Hosts) with the 
highest AMC value (49), the value of K for each K-Shortest Path algorithm was altered, and the 
resulting average percentage of flows blocked, and the average time taken to find a path was 
recorded. The results were compared to the results of the equivalent Q-Routing algorithms. While the 
optimal K-Value differed depending on the Q-Routing algorithm it was compared against, it was 
determined that a K-Value between 150 and 250 was required for K-Shortest Path to perform as well 
as Dual-Metric, Multi-Estimate, Pareto Q-Routing (please see section 6.3.2) in terms of the percentage 
of flows blocked. For full experiment details, please see sections 4.4.2.2, 5.4.2.2 and 6.4.2, and for the 
respective results, please see sections 4.4.3.4, 5.4.3.4 and 6.4.3.2. 
3.3.6.3) Alternative K-Shortest Path Methods:- 
As previously stated, Yens K-Shortest Path algorithm [20] was selected to represent standard routing 
during the research carried out in this Thesis for a number of different reasons (please see section 
3.3.6.1). However, it should be noted that there are alternative K-Shortest Path approaches, such as 
Edge Disjoint Paths (EDP) and Node Disjoint Paths (NDP) [131]. 
In Yens K-Shortest Path algorithm, it is possible for each path to share individual edges/links or 
nodes/vertices with each other. If at least one node or link in the path is different from those in each 
other path returned by the algorithm, then that path is considered unique. By way of contrast, K-
Shortest Path disjointed algorithms do not share this characteristic. For example, EDP will return 
several paths between the source and destination node. However, with the exception of the links 
connected to the source and destination node, no links used in one path will be used again in any 
other path found. Similarly, for NDP, with the exception of the source and destination nodes, the 
nodes used in one path will not be used again in any additional paths the algorithm finds. 
The obvious advantage is that each path is wholly unique. Using routing techniques based on either 
EDP or NDP could be a viable method for ensuring that each unique flow is given a separate path. This 
would be especially useful for meeting QoS requirements based on bandwidth. However, the 
disadvantage of using EDP or NDP is that the number of paths found would be far fewer than those 
returned by Yens K-Shortest Path. This might not be an issue, but it is possible that many links that 
have free bandwidth capacity would be overlooked. If, for example a flow requiring a QoS bandwidth 
of 10Mbs was assigned to a path that could support a maximum bandwidth of 50Mbs, then using 
either EDP or NDP based routing algorithms would mean a waste of a path or even links within a path 
that could support an additional 40Mbps which would be a vast waste of networks resources, possibly 
resulting in undesired outcomes such as congestion. 
Yens K-Shortest Path in comparison, can be utilised to meet QoS requirements based on bandwidth 
while maximising networking resources. This is why Yens K-Shortest Path algorithm and those similar 
to it such as Lawler (a modified version of Yens algorithm) [132], Katoh [133] and Hoffman [134] are 
considered the standard for K-Shortest Path and where Yens K-Shortest Path is often used as a 
baseline for the testing of new graph theory solutions and routing algorithms [135]. 
3.4) SDN Testbed Limitations:-  
The SDN testbed implemented was essential as it allowed for the testing of each routing algorithm (Q-
Routing and K-Shortest Path based) to be developed and tested. However, while the SDN testbed was 
not the primary focus of the research performed in this Thesis, the limitations of the testbed in terms 
of realism should be noted. This section looks at the limitations of different elements of the SDN 
testbed and suggests possible improvements that could be made to improve the SDN testbed in 
future. 
3.4.1) Topology:- 
To test the effectiveness of each pathfinding algorithm developed, it was necessary to create a series 
of mesh topologies varying in size and AMC (Table 3). Each topology represented a generic, packet-
switched network where a single host was connected to each forwarding node. While this approach 
was useful for testing each algorithm, it lacked some of the realism of real-world network topologies. 
Types of Network: In networking, there are many different types of network including LAN, WAN, 
Campus Area Network (CAN), Metropolitan Area Network (MAN), Storage Area Network (SAN), to 
name but a few, where each type of network differs in the area covered, number of users connected, 
and the number and types of services available. Because each type of network does display different 
characteristics, a generic model, such as the topologies used in the SDN testbed do not entirely reflect 
any one type of network. For example, a small home-based LAN may have several devices (desktops, 
laptops, tablets, smartphones, etc) connected to a forwarding device such as a router. A larger LAN 
might also include switches to increases the networks connectivity but overall, there are few 
forwarding devices and a LAN topology is likely to be switch based, not a partial mesh. A LAN will then 
typically connect to a larger network such as a WAN to enable Internet access. Arguably, the 
topologies created for the SDN testbed could be described as WAN based with end users but lacks the 
definition. This is because there is no explicit separation between the WAN Core Network (home to 
the optical fibre cables that carries mass amounts of data across a religion) and the smaller networks 
(MAN, CAN, LAN) where the end users are located.  
Given this, it is important that an emulated topology reflects the physical characteristics of one or 
more specific network types to some degree. 
Limited Traffic Generation: For each topology created for the SDN testbed, to generate traffic, a single 
host was connected to each forwarding node as Mininet allowed the generation of traffic from each 
host using iPerf. This allowed for multiple traffic flows to be created at the same time. However, there 
was one key issue with this approach. The number of traffic flows created were dependent on the 
number of hosts as each host could only generate one flow. As a host in a real-network can generate 
multiple traffic streams (normally packet-based), the approach used for the SDN testbed was not 
realistic.  
The solution for future topologies generated for Mininet would be to make sure that the number of 
hosts attached to each forwarding node is greater than one, ideally, a random number of hosts to 
allow flexibility. This way, not only is the topology more realistic (normally, many network devices are 
connected to a single forwarding device), but this would also allow for the creation of multiple traffic 
flows and the possibility of multiple flows from the same source and destination, forwarding node 
pairs.  
3.4.2) Traffic Models:- 
As previously discussed (see section 3.3.5), to enable traffic in the SDN testbed, a mechanism was 
created to create network traffic flows of random lengths between random source and destination 
node pairs at random intervals. However, while traffic generation was not the core focus of the 
research, it should be noted that the mechanism used for traffic generation did not reflect existing 
traffic models. This is important as accurate traffic models can be used to assess a number of different 
factors within a network [136]:- 
1. To properly dimension network resources to a set level of QoS. Traffic models are also 
essential for estimating bandwidth and buffers resources to estimate acceptable levels of 
packet loss and delay probability.  
2. To verify network performance using specific traffic controls. For example, testing the 
performance of a network using a packet scheduling algorithm from different traffic scenarios. 
3. Admission control. Traffic control models can be used to test admission strategies designed 
to maintain a certain level of QoS. 
Given this, the addition of a Continuous-Time Source Model (Traditional Poisson process, on/off, 
Stochastic Fluid model, etc), a Discrete-Time Source Model (Time Series, Box-Jenkins methodology), 
or even an Application-Specific Model (Web-Traffic, Peer-to-Peer traffic, Video) would increase the 
accuracy and functionality of the SDN testbed while making the measured results for each pathfinding 
algorithm more realistic in real-world terms. 
3.4.3) Flow-Based vs Packet-Based:- 
One of the assumptions utilised for the creation of traffic, was that traffic would be flow-based instead 
of packet-based and as such, random traffic flows were created. The primary reason for this 
assumption was that SDN architecture is defined by four principles (briefly discussed in section 2.2.2) 
[15]. The second of these principles is that forwarding decisions are flow-based instead of destination-
based where in the context of SDN and OpenFlow, a flow is defined as a sequence of packets between 
the source and destination where each individual packet within a flow receives identical service policy 
treatment at each forwarding node. The flow abstraction used allows for unifying behaviour across 
different types of network devices (routers, switches, firewalls, middleboxes, etc). This allows the 
programming of flows to become extremely flexible, limited only by the capabilities of the 
implemented flow tables.  
However, within global distributed networks, flow-based traffic has limitations. For example, in 
packet-switched routing, each packet is treated as a separate entity, regardless if the packet is part of 
a flow or not. This means that each packet in a flow can in theory, be sent to the destination via 
different routes and once a forwarding node has processed and forwarded a packet, it can forget 
about it. By contrast, flow-based routing requires that each forwarding node between the source and 
destination treat each packet of that flow exactly the same, meaning that each forwarding device has 
to allocate resources and memory to ensure that each packet in the flow is forwarded in the exact 
same fashion as all others until that flow is completely finished. While this might be achievable in a 
network domain controlled by single policy, it is not feasible in traditional, distributed networks as 
each network domain is likely to operate a different policy. It should be noted however, that SDN 
offers options that are unavailable in distributed networking.  
Flow-Based Routing: One of the advantages of SDN, is that because it is centralised and can control 
the forwarding operations of each network device, it is possible to easily develop a universal policy 
within the network domain controlled by the SDN controller. For example, for the Adaptive, Dual-
Metric, Multi-Estimate, Pareto, Q-Routing algorithm (see section 6.3.3) and its K-Shortest Path 
counterpart (see section 6.3.1) within the SDN testbed, the SDN controller kept a record of each 
random traffic flow between each random source and destination pair and the QoS bandwidth 
requirement for that flow. This meant that the SDN controller working with the routing algorithm was 
able to direct new flows to avoid part of a path or full paths that did not have the bandwidth capacity 
to support additional flows. This allowed for a reduced risk in congestion and once a flow had finished 
flowing, the SDN controller would update its records to reflect the real-time bandwidth capacity 
available along that path. If such a policy could be implemented within a single domain making use of 
SDN, then as SDN becomes more prevalent, it is possible that flow-based traffic could become more 
common place allowing flows to be transmitted across many different network domains. 
In theory, this might be partly achievable in many modern-day networks globally. While, most 
distributed WAN switches and routers are designed for packet-based traffic, many have multiple 
tables and as such, each table can be allocated to a header field which, when aggregated together, 
can mimic a flow table. Essentially, a flow can be defined using a combination of header fields. Even if 
the switch or router is not OpenFlow compatible, an SDN controller can still be used in conjunction 
with NetConf to program these network devices for flow-based policy. This means that more individual 
network domains could be altered to support flow-based traffic. 
Packet-Based Routing: While traffic generation focused on using flow-based traffic, it is important to 
consider how the SDN testbed and the pathfinding algorithms would react if packet-based traffic was 
implemented instead. In the flow-based implementation, each random flow created would transmit 
between the source and destination nodes for a random period of time, pre-set between two 
variables, for example, between 1 and 35 seconds, depending on the size of the topology used. As 
each flow was treated separately, it could be argued that two flows of 1 second were treated in a 
similar fashion as two separate packets would be. Discounting the flow duration entirely and treating 
each flow as a separate packet could also arguably represent packet-based traffic within this SDN 
testbed so in theory, packet-based traffic could work quite comfortably with the routing algorithms in 
this testbed.  However, this is just speculation. The most obvious solution would be to alter the SDN 
testbed for packet-based traffic. This could be done in two ways:- 
1. Currently, when the pathfinding algorithm returns a path between source and destination 
nodes to meet QoS requirements of a flow, each forwarding node within the path is given 
forwarding instructions by the SDN controller on how to forward packets within that flow for 
the flows entire duration. Once the flow is completed, the forwarding instructions are 
removed from each forwarding node and any new flow must request a new path between 
source and destination nodes from the SDN controller. However, instead of the SDN controller 
carrying out this process for the duration of the flow, the controller could be modified to find 
a path on a packet-by-packet basis. This way, it would no matter that the traffic generation 
was flow-based, as the SDN controller would be dealing with each packet within each flow 
separately. 
2. Another approach would be to alter the traffic generation part of the SDN testbed to send 
individual packets instead of flows. This would force the SDN controller to consider each 
packet individually where each packet was treated as a flow of one packet. 
Out of the two approaches, the first would represent a more accurate representation but as along as 
the same approach was used for both the Q-Routing algorithm and its corresponding K-Shortest Path 
counterpart, either approach would be useful in assessing the performance of each Q-Routing 
algorithm compared to K-Shortest Path using packet-based traffic.   
3.5) SDN Testbed Conclusion:-  
The overall goal of the SDN testbed was to allow for the creation and testing of new, centralised 
routing algorithms, specifically centralised Q-Routing algorithms while making the advantages of a 
centralised SDN approach available to each routing algorithm implemented. To do this, the SDN 
testbed incorporated a number of facilities including the abilities to import custom generated mesh 
network topologies, generate traffic and record information to compare and contrast results between 
each Q-Routing algorithm and their K-Shortest Path counterparts. 
The outcome was that the SDN testbed successfully met the initial requirements (as stated in section 
3.2.1). However, while the initial requirements were fulfilled, the SDN testbed lacked some of the 
realism of modern-day networks (please see section 3.4  for full details). For example, while the mesh 
topologies created and employed did vary in size and connection density (AMC), they were generic 
and didnt represent any specific network type. Each host was only capable of creating one traffic flow 
at one time and while traffic in the testbed was created randomly, traffic generation was not based 
on any particular traffic model. Finally, the SDN testbed was designed primarily for flow-based traffic 
and only considered packet-based traffic to a lesser degree.  
Overall and despite these limitations, the SDN testbed fulfilled its primary purpose and enabled the 
incremental development and experimentation that led to the successful creation of the final routing 
algorithm, Adaptive Dual-Metric, Multi-Estimate, Pareto Q-Routing (please see section 6.3.3).  
Chapter 4:- The Implementation and Improvement of Q-Learning for 
Optimal Pathfinding in an SDN controlled mesh network 
4.1) Introduction:- 
The focus of the research in this chapter was to investigate, utilise and improve on the performance 
of the RL ML algorithm, Q-Learning and its derivative, Q-Routing, all within an SDN, packet-switched 
network environment. First, this chapter looked at implementing Q-Learning and Q-Routing within 
static network topologies using the network metric latency. The performance of these two algorithms 
was compared to an equivalent heuristic pathfinding algorithm, K-Shortest Path also using latency. 
Secondly, a new Q-Routing algorithm using the network metric path bandwidth was implemented 
again using static network topologies and compared to a K-Shortest Path equivalent. Finally, Q-Routing 
with latency and Q-Routing with bandwidth are applied to a dynamic network topology and once more 
compared to the equivalent K-Shortest algorithm.  
4.2) Chapter Objectives:- 
The goal of the research carried out in this Chapter was to first demonstrate how Q-Routing could be 
implemented within an SDN network, secondly, how Q-Routing could be as effective as K-Shortest 
Path in making routing decisions and finally, how Q-Routing could perform better than K-Shortest Path 
in some regards. To this end, there were three primary objectives:- 
1. The first was to implement Q-Learning and Q-Routing and compare their performance to that 
of K-Shortest Path with both algorithms using the network metric latency. 
2. The second objective was to develop a new derivative of Q-Routing using bandwidth and 
compare the performance of this new algorithm to the K-Shortest Path equivalent. 
3. The final objective was designed to implement adaptive forms of Q-Routing with latency and 
Q-Routing with bandwidth in a dynamic network. 
All of the algorithms written for this research, Q-Learning, Q-Routing and K-Shortest Path were 
implemented within an SDN packet-switched network testbed specifically designed and created to 
test these algorithms where the forwarding tables from paths calculated could be passed onto the 
relevant Open Flow compatible forwarding devices (nodes) and where the performance data for each 
algorithm could be recorded.  
4.3) Theory and Implementation of the Pathfinding Algorithms:-  
4.3.1) K-Shortest Path using Latency within the Core SDN Controller:- 
Algorithm Background:- The first path calculation algorithm implemented in the SDN Controller 
program was K-Shortest path based on Yens [20] shortest path algorithm using latency as the metric. 
Instead of the algorithm returning just the shortest path between the source and destination, K-
Shortest path returned all the possible paths between the source and destination nodes and ranked 
them from shortest to longest based on the corresponding latencies for those paths. The Python 
implementation of Yens K-shortest path algorithm, developed by Guilherme Maia [137] in 2014 was 
used to implement the K-Shortest Path algorithm in the Ryu controller.  
Implementation:- Figure 14 shows how K-Shortest Path works within the SDN controller program. 
After the forwarding nodes connected to the destination and source host nodes are found, the K-
Shortest Path algorithm was used to find all paths (depending on the value of K) between the source 
and destination nodes. Each path found was ranked by latency from the path with the lowest latency 
to the path with the highest latency where N=0 corresponded to the path with the lowest latency, 
N=1 to the path with the second lowest latency, and so on.  
Figure 14:- Implementation of the K-Shortest Path Algorithm using Latency. 
Once all the paths had been returned, the latency of the quickest path was checked to see if the value 
was less than or equal to the randomly generated QoS latency. If the latency of the path was greater 
than the randomly generated QoS latency, the path was marked as Blocked and could not be used. 
Because the first path checked, N=0 was the path with the lowest latency, if that failed to meet the 
random QoS latency requirement, it was assumed that none of the additional paths discovered 
between source and destination nodes (N=1, N=2, N=) was suitable and could be discarded. Thus, all 
the paths failed to meet the QoS service requirements. 
However, if the latency of the fastest path was less than or equal to that of the randomly generated 
QoS latency value, then from the list of paths found, the path with the end-to-end latency value that 
was less than but closest to the value of the randomly generated QoS latency was selected. The 
obvious solution would have been to use the path with the smallest latency every time, but this 
solution allowed for a more granular approach assigning paths that matched the requirements of the 
random QoS latency without sending all flows through the same path each time. 
4.3.2) K-Shortest Path using Bandwidth within the Core SDN Controller:- 
Algorithm Background:- K-Shortest Path using bandwidth was an adaptation of K-Shortest Path using 
latency implemented previously. Like that of the latency version, it was implemented within the main 
body of the SDN Controller program and worked in a similar way to that of K-Shortest Path using 
latency. However, instead of looking for the path with the smallest latencies, it looked for paths with 
the largest bandwidths.  
Implementation:- Figure 15 shows how K-Shortest Path with bandwidth operates as part of the SDN 
controller program. This algorithm operated in a similar way to that of K-Shortest Path using latency. 
Apart from the network metric used, there was one other key difference. In this version of the 
algorithm, out of the K-Paths calculated, the path with the overall maximum bandwidth corresponding 
to N=0 was selected instead of a more granular approach as used by K-Shortest Path using latency.  
Figure 15:- Implementation of the K-Shortest Path Algorithm using Bandwidth. 
4.3.3) Q-Learning for Path Calculation using Latency within the SDN Controller:- 
Algorithm Background:- The third path calculation algorithm implemented in the main programming 
body of the SDN Controller program was Q-Learning [21] using latency. The Python implementation 
of the Q-Learning algorithm used in the Ryu controller was loosely based on [138] developed in 2016 
as a number of changes was required before this implementation could be used (please see Appendix 
C.1.1 for more details). 
Implementation:- Figure 16 shows how the Q-Learning pathfinding algorithm worked within the 
controller program (please see Appendix C.1.2 for the pseudocode). When the SDN controller was 
initialised, an R structure was created for each possible destination forwarding node in the network 
where the R structure for each of these nodes contained values. -1 meant that there was no valid 
move or link between two nodes, 0 meant that a valid move or link did exist and 100 meant that a 
valid move or link had been found that lead to the destination node. This way, the topology of the 
network could be represented in for each destination node. After the controller had completed the 
process of creating the R structures for each destination node, it would wait for a path calculation 
request from an incoming flow. 
Figure 16:- Implementation of the Q-Learning Path Calculation Algorithm using Latency. 
Once the controller had received a flow request, it would identify the source and destination 
forwarding nodes and pass this on to the Q-Learning algorithm. Q-Learning would take this 
information and for the destination node create a Q structure, similar to that of the R structure accept 
Q was created as an empty structure with a 0 value for each State/Action pair entry. The training 
process using a reward formula was then used to train Q. 
For this Q-Learning implementation, it was noted that when the standard Q-Learning formula was 
used for training the Q-Tables and these Q-Tables were used for pathfinding, the algorithm was 
unlikely to find the optimal path between the source and destination nodes. This was because R did 
not contain any environmental information such as link latencies of the network topology. Instead, R 
used a generic point system. To remedy this, the original Q-Learning formula was modified to add data 
from the environment, in this instance, the latency of networks links. The result was (Eq. 7). 
(, ) = (, ) + ([(, . )]) 
(Eq. 7) 
Where Q(S,A) was where the formula would store a calculated value for that State/Action pair, R(S,A) 
contained the value pertaining to a link-state for a State/Action pair, G was the learning rate, Q(S,.) 
was the list of Q-values from the current state to all neighbouring network nodes,  lw was a weighted 
default and ll was the latency of the path link that the Q-Learning algorithm was training with at that 
time.  
This modification was made after a little trial and error to incorporate an element of the network into 
the Q-Learning environment so the results from the Q-Learning process would reflect the nature of 
the network in respect to latency. The proposed alternative was to instead leave the formula as it was 
and populate R with the link latencies in the network so Q would be trained using real network values. 
However, as this method was essentially Q-Routing (see section 4.3.4), it was decided to concentrate 
on the first approach.  
After the training had been completed and the path calculated between the source and the 
destination, the end-to-end latency of the path was checked. If the end-to-end path latency was less 
than or equal to the randomly generated QoS latency then this path was marked as active and main 
program would install forwarding instructions on the nodes in the path. However, if the latency of the 
path was greater than the QoS latency, the Q-Learning algorithm would re-train Q and calculate the 
path between the same source and destination switch X more times where after each recalculation, 
the lw value in the modified reward formula would increment by a set amount. The reason for these 
actions were as follows:- 
 Recalculating the path between the same source-destination node pair X times allowed the 
Q-Learning algorithm to replicate in a sense the K-Shortest path algorithm which returned 
multiple paths.  
 Because of the way the Q-Learning training works, it was highly likely that if a path between 
two switches was recalculated X times, the same path would be returned multiple times. To 
increase the chances of a different path being calculated, the value lw in the reward formula 
was incremented after each new path calculation. Each new path found along with that paths 
end-to-end latency was recorded. 
Once the additional training cycles had been completed, from the paths found, the path with the 
shortest end-to-end latency was checked to see if it met the latency QoS requirements. If it did, it was 
marked as active and used as the path for the flow, otherwise, it was marked as blocked. 
4.3.4) Q-Routing for Path Calculation using Latency within the SDN Controller:-:- 
Algorithm Background:- The fourth path calculation algorithm implemented in the SDN main program 
was Q-Routing [22] using latency. The Python implementation of the Q-Routing algorithm used in the 
Ryu controller was originally based on an implementation created by Luyuan Shi [139] in 2017 though 
major modifications were required to ensure that the algorithm ran more in keeping with that of 
traditional Q-Routing (please see Appendix C.2.1 for more details). 
Implementation:- In Figure 17, the implementation of Q-Routing within the main SDN Controller 
program is shown (please see Appendix C.2.2 for the pseudocode). Q-Routing, as previously 
mentioned, is a derivative of Q-Learning, designed specifically for routing, finding paths based on 
latency. The key difference, however, is that Q-Routing uses environmental information to train Q for 
each destination node. This implementation of Q-Routing with latency was designed to create and 
train Q for every destination node in the network as soon as the SDN Controller program was initiated. 
This pre-training approach made sense as the topologies used to test the algorithms were static and 
thus were not required to adapt to network changes. This not only allowed for faster path generation 
and quicker convergence when compared to traditional, distributed Q-Routing, but also used fewer 
system resources. 
The pathfinding part of Q-Routing with Latency was designed to be implemented after the main SDN 
Controller program has returned the IDs of the source and destination nodes. Once this information 
had been received, Q-Routing was implemented, and a path found. Once a path had been found, the 
end-to-end latency of the path was measured and compared to the randomly generated QoS latency 
value. If this random value was larger than or equal to the path latency, then the path was marked as 
active and the nodes in the path were programmed with the relevant forwarding instructions. 
Otherwise, if the random QoS was less than that of the end-to-end latency value of that path then 
that path was marked as blocked and the blocking procedure for that path was implemented.  
Figure 17:- Implementation of the Q-Routing Path Calculation Algorithm using Latency. 
4.3.5) Q-Routing for Path Calculation using Bandwidth within the SDN Controller:- 
Algorithm Background:- The fifth path calculation algorithm implemented in the SDN Controller 
program was Q-Routing using bandwidth. This algorithm was based on the Q-Routing with latency 
algorithm and was implemented within the SDN network in the same way. The main difference was 
the introduction of a new formula, derived from the Q-Routing formula designed to use latency. 
Implementation:- In current literature, the majority of published research referred to Q-Routing using 
the latency for the training of Q-Tables and pathfinding. The main reason for this was that Q-Routing 
was designed with latency in mind where the Q-Table for a set destination node using the reward 
formula would fill the Q-Table with approximate end-to-end latency values from any node in the 
network to the destination node. However, when researching Q-Routing, nothing could be found in 
current literature where Q-Routing used bandwidth as the only metric. Given the purpose of the 
research being carried out, the following algorithm was created (please see Appendix C.3 for the 
pseudocode). 
Figure 18 shows the basic structure of the algorithm. The main difference between using latency and 
bandwidth is essentially how they were measured. When measuring the latency of a path end-to-end, 
the latency of that path is simply the total of the latencies of each path segment. However, when 
measuring the maximum bandwidth capacity of a path end-to-end, the path link in the path with the 
lowest capacity bandwidth represents the maximum bandwidth of the path. This difference can be 
seen in how Q-Routing is applied. Q-Routing using latency during the training phase fills the Q-Table 
with end-to-end latency approximations from any network node to the destination node. Q-Routing 
using bandwidth by contrast has to approximate the maximum bandwidth capacity between every 
network node and the destination node by finding the path link with the lowest bandwidth capacity. 
This meant that the Q-Routing formula for latency needed to be altered. The resulting formula was as 
follows:- 
(, ) = (1  )Q(S, D) +  Max(Min(B(S, N), Q(N, D))) 
(Eq. 8) 
Where QNew(S,D) was the new Q-value between S the source node and D the destination node, Q(S,D) 
was the existing Q-value between the source and destination nodes,  is the learning rate, B(S,N) is 
the bandwidth between the source node and N, the neighbouring node and Q(N,D) is the Q-value 
between the neighbouring node and the destination node. The key difference between the Q-Routing 
with latency formula and the Q-Routing with bandwidth one was the latter part of the equation. 
Instead of adding B(S,N) and Q(N,D) together as done in Q-Routing with latency for each neighbouring 
node to the current node and then finding the which of these has the lowest latency value, the latter 
part of the Q-Routing with bandwidth formula instead compares B(S,N) and Q(N,D) looking to see 
which has the lowest value for the bandwidth. This process is repeated from the current node to all 
neighbouring nodes creating a list of minimum bandwidth values between B(S,N) and Q(N,D). Finally, 
from the list of minimum bandwidth values, the list value that has the largest bandwidth is selected. 
This is then added to the first part of the Q-Routing formula and used to generate the new Q-Table 
value during the training process.  
Figure 18:- Implementation of the Q-Routing Path Calculation Algorithm using Bandwidth. 
4.3.6) Adaptive Q-Routing for Path Calculation using Latency within the SDN Controller:- 
Algorithm Background:- The sixth path calculation algorithm was an adaptation of Q-Routing using 
latency designed to adapt to changes in network conditions such as a link between nodes going down 
or a link latency value changing.  
Implementation:- The implementation of Adaptive Q-Routing was based on the implementation of 
the previously discussed algorithm Q-Routing using latency (please see Appendix C.4 for the 
pseudocode). There were, however, two differences. The first was the introduction into the adaptive 
version of the algorithm of an additional training cycle before the pathfinding phase (Figure 19).  
Figure 19:- Implementation of the Adaptive Q-Routing Algorithm using Latency. 
When a request for a path calculation was received by the SDN controller from a randomly generated 
flow, the ID of the destination host was extracted from this request and then the identity of the 
forwarding node connected to the destination host was retrieved. Knowing the ID of the destination 
host, the Q-table for this destination host was trained again for a single cycle allowing Q for the 
destination node to update for any changes in the network topology such as a link going down or the 
latency link value changing. Once the training cycle was completed, path finding could go ahead 
resulting in a path that reflected the true nature of a changing network topology. This additional 
training cycle was carried out every time a new random flow was generated. 
The second difference between this algorithm and Q-Routing with latency was the introduction of a 
mechanism to randomly generate link failures. The SDN controller increased the latency of a random 
link by 10,000ms, effectively simulating a link break. At any one time, there could be up to four random 
link breaks. After a set period of time, the link would be restored to normal. While this was more the 
purview of the SDN controller than the algorithm itself, both elements ran in the same 
implementation.  
 4.3.7) Adaptive Q-Routing for Path Calculation using Bandwidth within the SDN 
Controller:- 
Algorithm Background:- The final path calculation algorithm developed in this chapter was a variation 
of Adaptive Q-Routing for Path Calculation using Latency and Q-Routing using Bandwidth.  
Implementation:- The implementation of this algorithm was based on two previous algorithms 
implemented (please see Appendix C.5 for the pseudocode). The first was Q-Routing using bandwidth 
which provided the bandwidth-based reward formula used for training Q for each destination node. 
The second was the addition of the adaptive element, the same element that was used by Adaptive 
Q-Routing using latency to add an additional training cycle as previously described.  
Figure 20:-  Implementation of the Adaptive Q-Routing Algorithm using Bandwidth. 
Figure 20 shows the operation of Adaptive Q-Routing with Bandwidth where an additional training 
cycle is added before pathfinding and apart from the metric being different, the process for this 
algorithm was the same as Adaptive Q-routing using Latency.  
Regarding the introduction of link failures, instead of adding an additional high latency to a link as 
described in Adaptive Q-Routing using latency, for Adaptive Q-Routing using bandwidth, the 
bandwidth values of the random links selected were reduced to 0Mb and then later restored to their 
pre-set values. 
4.3.8) Comparison of each single metric routing algorithms complexity:- 
As part of the assessment process, it was necessary to look at the complexities of each routing 
algorithm, specifically, the complexities in relation to time. Table 4 shows a comparison of the time 
complexities for the training and pathfinding implementations (where relevant) of each single metric 
algorithm. 
Algorithm Name Time Complexity 
Training Pathfinding 
K-Shortest Path using Latency N/A (2) [140] 
K-Shortest Path using Bandwidth N/A (2) [140] 
Q-Routing using Latency (3) () 
Q-Routing using Bandwidth (3) () 
Adaptive Q-Routing using Latency (3) () 
Adaptive Q-Routing using Bandwidth (3) () 
Table 4:- Showing a comparison between the time complexities for each single metric routing algorithm. 
For both the of the K-Shortest Path algorithms and for each Q-Routing algorithm, a worse case time 
complexity was assumed. For each Q-Routing algorithm, an additional assumption was made that N 
was proportional to T where N was the number of nodes in the network topology and T was the 
number of training cycles in the training phase. After considering the pseudocode ((Appendix C) 
(where relevant)) for each Q-Routing algorithm and because of the similarities between each 
implementation, the resulting time complexity for each Q-Routing algorithm was O(N3) for the training 
phase and O(N) for the pathfinding phase. By way on contrast, Yens K-Shortest Path which only has 
the pathfinding element had a time complexity of O(N2).  
While the training time complexity for each Q-Routing algorithm was greater than that of Yens K-
Shortest Path, as previously mentioned, the training was designed to take place prior to the network 
becoming active. Therefore, when comparing the pathfinding time complexity between each Q-
Routing algorithm and the equivalent K-Shortest Path algorithm,  Table 4 shows that each Q-Routing 
was not as complex as K-Shortest Path. 
4.4) Experiment Design and Results:- 
This section discusses the experiments designed to test the pathfinding algorithms implemented 
within an SDN network, how they were tested, the settings used for each of the experiments and the 
results produced for each of the experiments.  
4.4.1) Core SDN Controller Settings with Pathfinding Algorithms:- 
The optimal variable values for the Core SDN Controller program and the path calculation algorithms 
can be found in the appendix in section B.1. 
4.4.2) Experimental Procedure: - 
To test the performance of each path calculation algorithm, a series of experiments were designed.  
The first experiment was the comparison of each Q-Routing algorithm against the equivalent K-
Shortest Path algorithm where the percentage of blocked paths were compared using static network 
topologies.  
The second experiment examined the effect of changing the K-Value (the number of paths returned) 
in each K-Shortest Path algorithm to see how altering this value affected the time required for each K-
Shortest Path algorithm to calculate a path and how the blocking percentage changed as the K-Value 
was altered again using static network topologies. 
The final experiment comprised of two separate tests was designed to explore the adaptability of the 
Adaptive Q-Routing algorithms in dynamic network topologies and compare the performance in terms 
of the percentage of blocked paths and the time taken to find a path against the equivalent K-Shortest 
Path algorithms. 
4.4.2.1) Experiment 1: K-Shortest Path, Q-Learning & Q-Routing Path Blocking Performance 
Tests:- 
In total, seven different path calculation algorithms were written for this phase of the research where 
each different K-Shortest Path algorithm was designed to act as a point of comparison against the 
equivalent Q-Learning or Q-Routing algorithms. Table 4 shows each Q-Routing algorithm variant and 
the equivalent K-Shortest algorithm.  
K-Shortest Path Algorithm Equivalent Q-Routing Algorithm 
K-Shortest Path using Latency Q-Learning using Latency 
K-Shortest Path using Latency Q-Routing using Latency 
K-Shortest Path using Latency Adaptive Q-Routing using Latency 
K-Shortest Path using Bandwidth Q-Routing Using Bandwidth 
K-Shortest Path using Bandwidth Adaptive Q-Routing using Bandwidth 
Table 5:- Showing each K-Shortest Path algorithm and the equivalent Q-Learning / Q-Routing algorithm. 
The algorithms competed against each other by comparing the percentage of flows that were blocked. 
This worked as follows:-  
1. A test topology was selected. 
2. The Core SDN Controller program was initiated with one of the path calculation algorithms.  
3. Using the Mininet generated topology (the same topology as used by the SDN Controller), a 
source host node was randomly selected along with a random destination node. The former 
would then send UDP traffic to the latter. 
4. The SDN Controller program using the selected pathfinding algorithm found a path between 
the random source and destination host nodes. 
5. The path was then checked to see if it met the randomly generated QoS value. 
6. If the path met the QoS requirements, then each forwarding node in the path was 
programmed with forwarding instructions by the SDN controller and the path was then used 
to send UDP data from source to destination host nodes for the duration of the flow. If, 
however, the path failed to meet the QoS requirements, the path for that flow is blocked 
preventing the source host node sending UDP data to the destination host node. This blocking 
only lasts for the duration of the flow.  
7. The active or blocked status is recorded in a file for the path. 
For one run, the active or blocked status of approximately 2,000 randomly generated flow paths 
was recorded. If, for example, 300 of the paths had not met the QoS requirements and had been 
blocked, then the blocking percentage for path or flows would be:- 
15% = 100 
(Eq. 9) 
To ensure an average result, each run was repeated five times for each pathfinding algorithm on each 
network topology size. 
4.4.2.2) Experiment 2:- K-Shortest Path Performance Tests (Path Calculation Time and 
Blocking):- 
The first experiment was designed to compare the percentage of flows blocked of each Q-Routing 
Algorithm against its K-Shortest Path counterparts. The K-Value, as previously stated, for each K-
Shortest Path Algorithm was set to 250. This meant that if available, K-Shortest Path would return up 
to 250 different paths between the source and the destination host nodes. By contrast, each Q-
Routing algorithm only returned one path with comparable results. However, what would happen to 
the performance of the K-Shortest Path algorithm if the K-Value was altered? To answer this, two tests 
were created.  
The first of these two tests looked at how changing the K-Value affected the pathfinding time for the 
K-Shortest Path algorithms. For each of the different K-Shortest Path algorithms, the K-Value was 
initially set to a value of 1 and was increased in separate tests to the default value of 250. For each K-
Shortest Path algorithm and each different K-Value, 1,000 traffic flows were randomly generated 
where the time to calculate the path was recorded for each flow to ensure an accurate average value. 
The results for the K-Shortest Path algorithms were then compared to the equivalent Q-Routing 
algorithms. 
The second test was essentially the same as the first except instead of measuring the time to find a 
path, the objective was to find the percentage of flows that each K-Shortest Path algorithm blocked 
as the K-Value was altered and compare these results to the equivalent Q-Routing algorithms. Both 
tests were carried out on a 50 Host, 50 Switch emulated topology with an average mesh connectivity 
of 49 as the relative complexity and density of this topology allowed each algorithm to be tested more 
thoroughly. 
Both of these tests were performed on the same Linux server to ensure that the results were 
consistent throughout. 
4.4.2.3) Experiment 3:- Adaptive Q-Routing Performance Tests in a Dynamic Network 
Topology:- 
The first two experiments were designed to investigate the performance of different aspects of each 
algorithm. Firstly, by comparing the blocking performance of Q-Learning and Q-Routing to K-Shortest 
Path and secondly, by investigating the effect of changing the K-Value on the performance of each K-
Shortest algorithm in comparison with Q-Routing. 
A paper from 2013 [141] introducing Software-Driven WAN (SWAN), a new method to boost the 
utilization of inter-datacenter networks discussed the idea of centrally allocating networks paths and 
the pre-processing  of paths for routing algorithms such as K-Shortest Path so the routing algorithm 
would not need to calculate a new path for every flow from the source to the destination. This 
approach reflected the Q-Routing algorithms used in the first two experiments as both Q-Routing 
using Latency and Q-Routing using Bandwidth trained their Q-Tables to be able to find each 
destination node in the network topology as soon as the SDN controller program was launched. This 
meant that, in theory, K-Shortest Path in a static network environment could find a path in the same 
amount of time or faster than Q-Routing with a blocking percentage that was equal to or better than 
that of Q-Routing. However, this pre-processed form of this routing algorithm could only really work 
in a static network topology.  
The third experiment was designed to showcase the effectiveness of Q-Routing by changing the 
algorithm. Introducing a dynamic element to both the Q-Routing algorithms and the network 
topology. Each Q-Routing algorithm was altered to include an additional training cycle to the initial 
training that would re-train the Q-Table for the destination of every new flow request that the SDN 
controller received allowing each Q-Routing algorithm to adapt to network changes. K-Shortest Path, 
in contrast, could not pre-process and would be required to find all paths for the K-Value being used. 
To test the effectiveness of these adaptive Q-Routing algorithms, two tests were implemented.  
The first test was implemented on a custom Mininet network topology (Figure 21) which had two host 
nodes, one used as the source (H1) and the other as the destination (H2). The QoS values for both 
latency and bandwidth were fixed for each incoming flow to 45ms and 80Mb respectively.  
Figure 21:- A custom topology to test Q-Routing's ability to adapt to changes in a dynamic network. 
To meet these QoS requirements, there were only two paths that could be utilised for each flow, (S1-
S2-S3-S4-S5) and (S1-S6-S10-S11-S6). This was true for both Q-Routing with latency and Q-Routing 
with bandwidth as the topology was designed that way. Of the two paths, the first was the optimal 
path with the lowest latency and the highest bandwidth. Each flow was created on the host node H1 
and transmitted traffic to host node H2. To see how well both Q-Routing algorithms could adapt, links 
were broken and restored in order at intervals forcing each Q-Routing algorithm to adapt and find an 
alternative path. The first link break was set to a flow count of 10 with each subsequent link restore 
or link break taking effect in 50 flow increments thereafter. The results of this test for each Q-Routing 
algorithm were compared to the equivalent K-Shortest Path algorithms. 
The second test was designed to measure how long each adaptive Q-Routing algorithm took to find a 
path and the percentage of flows blocked compared to the equivalent K-Shortest Path algorithms. The 
test was performed on the same topology as used in the second experiment (50 Host, 50 Switch, 
Average Mesh Connectivity of 49) where 1,000 traffic flows were randomly generated for each 
algorithm. For the K-Shortest Path algorithms, the K-Value was set to 250. A mechanism was 
introduced to break and restore links at random in the topology with up to four links broken at any 
one time.  
4.4.3) Experimental Results: - 
4.4.3.1) Experiment 1, Result Comparison for K-Shortest Path vs Q-Learning with Latency:- 
The first of the path blocking performance tests carried out for the first experiment focused on how 
Q-Learning performed in comparison to K-Shortest Path with each algorithm using latency. Table 5, 
shows the percentage of flows accepted and blocked for each algorithm. Overall, it is clear that the K-
Shortest Path algorithm achieved a lower percentage of flows blocked or blocking percentage than Q-
Learning though the difference was more pronounced depending on the size of the topology. 
It was also noted that for both algorithms, at the AMC per node increased, the percentage of flows 
blocked would decrease across all three topologies. However, the results were more pronounced in 
the case of K-Shortest Path. 
Figure 22, Figure 23 and Figure 24 show the results for the 10 Host and 10 Switch, 25 Host and 25 
Switch and the 50 Host and 50 Switch topologies respectively in the form of a box and whisker plot. 
On all three topologies for each AMC value, K-Shortest Path with latency blocked fewer flows on 
average than Q-learning though not by a large margin and the gap between the percentage of flows 
blocked remained mostly consistent throughout with little variance for each AMC value though the 
difference in variance differed slightly by topology size. This can be seen by the shape of the 
distribution for the results in each of the figures. From the lowest AMC value to the largest: for the 10 
Host and 10 Switch topology, the difference in the percentage of flows blocked between K-Shortest 
Path and Q-Learning varied between 3.18  4.51%; For the 25 Host and 25 Switch topology, the 
difference varied between 6.91  6.35% and for the 50 Host and 50 Switch topology; the difference 
varied between 5.85  8.97%. 
    K-Shortest Path Q-Learning 
Topology 
Average 
Accepted 
Flows 
Blocked 
Flows 
Accepted 
Flows 
Blocked 
Flows 
Connectivity 
Per Node  %  %  %  % 
10H10S 3 78.39 21.61 75.21 24.79 
10H10S 5 75.44 24.56 71.81 28.19 
10H10S 7 86.02 13.98 83.54 16.46 
10H10S 9 89.76 10.24 85.25 14.75 
25H25S 4 61.99 38.01 55.08 44.92 
25H25S 8 76.62 23.38 72.72 27.28 
25H25S 12 84.18 15.82 78.54 21.46 
25H25S 16 87.72 12.28 80.66 19.34 
25H25S 20 90.26 9.74 82.62 17.38 
25H25S 24 91.43 8.57 85.08 14.92 
50H50S 5 67.08 32.92 61.23 38.77 
50H50S 12 82.54 17.46 75.59 24.41 
50H50S 19 86.84 13.16 77.56 22.44 
50H50S 26 88.76 11.24 79.32 20.68 
50H50S 33 88.42 11.58 80.13 19.87 
50H50S 40 90.89 9.11 82.11 17.89 
50H50S 45 91.17 8.83 81.39 18.61 
50H50S 49 91.73 8.27 82.76 17.24 
Table 6:- Showing the average blocking % results for K-Shortest Path vs Q-Learning using Latency. 
Figure 22:- Showing a Box & Whisker Plot for the Blocking Results for Q-Learning vs K-Shortest Path in a 10 Host & 10 
Switch Topology using Latency. 
Figure 23:- Showing a Box & Whisker Plot for the Blocking Results for Q-Learning vs K-Shortest Path in a 25 Host & 25 
Switch Topology using Latency. 
Figure 24:- Showing a Box & Whisker Plot for the Blocking Results for Q-Learning vs K-Shortest Path in a 50 Host & 50 
Switch Topology using Latency. 
4.4.3.2) Experiment 1, Result Comparison for K-Shortest Path with Latency vs Q-Routing 
with Latency:- 
The second of the path blocking performance tests focused on how Q-Routing performed in 
comparison to K-Shortest Path with each algorithm using latency. Table 6 shows the percentage of 
flows accepted and blocked for each algorithm. The results show that there is little difference in the 
percentage of flows blocked between each algorithm for each topology where K-Shortest blocked a 
lower percentage of flows in some instances and Q-Routing in others.  
    K-Shortest Path Q-Routing 
Average 
Accepted 
Flows 
Blocked 
Flows 
Accepted 
Flows 
Blocked 
Flows 
Topology 
Connectivity 
Per Node  %  %  %  % 
10H10S 3 78.39 21.61 77.58 22.42 
10H10S 5 75.44 24.56 76.03 23.97 
10H10S 7 86.02 13.98 84.89 15.11 
10H10S 9 89.76 10.24 90.05 9.95 
25H25S 4 61.99 38.01 58.43 41.57 
25H25S 8 76.62 23.38 75.43 24.57 
25H25S 12 84.18 15.82 85.82 14.18 
25H25S 16 87.72 12.28 88.06 11.94 
25H25S 20 90.26 9.74 90.34 9.66 
25H25S 24 91.43 8.57 91.13 8.87 
50H50S 5 67.08 32.92 67.09 32.91 
50H50S 12 82.54 17.46 81.68 18.32 
50H50S 19 86.84 13.16 86.82 13.18 
50H50S 26 88.76 11.24 88.61 11.39 
50H50S 33 88.42 11.58 88.7 11.30 
50H50S 40 90.89 9.11 90.7 9.30 
50H50S 45 91.17 8.83 90.79 9.21 
50H50S 49 91.73 8.27 91.94 8.06 
Table 7:- Showing the average blocking % results for K-Shortest Path vs Q-Routing using Latency. 
Figure 25, Figure 26 and Figure 27 show the results for the 10 Host and 10 Switch, 25 Host and 25 
Switch and the 50 Host and 50 Switch topologies respectively in the form of a box and whisker plot. 
For each different topology and for each AMC value, the figures show that, as previously mentioned, 
the percentage of flow blocked by each algorithm were on average approximately the same. This is 
evident when looking at the difference in the percentage of flows blocked. For the 10 Host and 10 
Switch topology, the difference in the percentage of flows blocked by each algorithm between the 
lowest and highest AMC was 0.81  0.29%; for the 25 Host and 25 Switch topology it was 3.56  0.3% 
and for the 50 Host and 50 Switch topology it was 0.01  0.21%. 
The shape of the distribution also remained consistent between the two algorithms for each of the 
different topologies. However, it was noted that the variance between the results for the Q-Routing 
algorithm was greater than that of K-Shortest Path. In Figure 25 for the 10 Host and 10 Switch 
topology, this is noticeable though in Figure 26 for the 25 Host and 25 Switch topology, the variance 
in the Q-Routing results becomes less pronounced and in Figure 27 for the 50 Host and 50 Switch 
topology, the variance in the Q-Routing has become similar to that of K-Shortest Path. 
Figure 25:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in a 10 Host & 10 Switch  
Topology using Latency. 
Figure 26:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in a 25 Host & 25 Switch 
Topology using Latency. 
Figure 27:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in a 50 Host & 50 Switch 
Topology using Latency. 
4.4.3.3) Experiment 1, Result Comparison for K-Shortest Path vs Q-Routing with 
Bandwidth:- 
The third of the path blocking performance tests once focused on how Q-Routing performed in 
comparison to K-Shortest path. This time, however, each algorithm was using the metric bandwidth. 
Table 7 shows the percentage of flows that were accepted and blocked for the two algorithms. Overall, 
the results were very similar for each different topology size and each AMC value. The exception to 
this was for a low AMC Value: Q-Routing had a higher percentage of blocked flows than K-Shortest 
Path. This was true on all three different topologies. However, as soon as the AMC Value increased, 
the percentage of flows blocked by the Q-Routing algorithm also decreased to values similar to K-
Shortest Path. 
Figure 28, Figure 29 and Figure 30. show the results for the 10 Host and 10 Switch, 25 Host and 25 
Switch and the 50 Host and 50 Switch topologies respectively in the form of a box and whisker plot. 
Apart from the difference between the two algorithms for the lowest mesh connectivity, the main 
difference between the two algorithms across all three topology sizes was the variance in the results 
as Q-Routing with bandwidth tended to have a slightly higher variance than that of K-Shortest Path. 
However, this variance reduced as the AMC for each topology increased. Otherwise, the figures show 
that the percentage of flows blocked by the Q-Routing with bandwidth was virtually identical to that 
of K-Shortest Path with bandwidth with matching distribution shapes across all three topologies for 
both algorithms.  
    K-Shortest Path Q-Routing 
Average 
Accepted 
Flows 
Blocked 
Flows 
Accepted 
Flows 
Blocked 
Flows 
Topology 
Connectivity 
Per Node  %  %  %  % 
10H10S 3 85.92 14.08 78.74 21.26 
10H10S 5 96.14 3.86 96.25 3.75 
10H10S 7 99.87 0.13 99.71 0.29 
10H10S 9 99.83 0.17 99.94 0.06 
25H25S 4 85.18 14.82 83.02 16.98 
25H25S 8 96.43 3.57 96.50 3.50 
25H25S 12 95.65 4.35 99.38 0.62 
25H25S 16 98.76 1.24 99.61 0.39 
25H25S 20 97.75 2.25 99.95 0.05 
25H25S 24 97.54 2.46 99.51 0.49 
50H50S 5 86.73 13.27 74.64 25.36 
50H50S 12 96.05 3.95 96.66 3.34 
50H50S 19 97.66 2.34 99.45 0.55 
50H50S 26 99.02 0.98 99.79 0.21 
50H50S 33 99.4 0.60 99.82 0.18 
50H50S 40 99.02 0.98 99.91 0.09 
50H50S 45 98.9 1.10 99.96 0.04 
50H50S 49 99.11 0.89 99.97 0.03 
Table 8:- Showing the average blocking % results for K-Shortest Path vs Q-Routing using Bandwidth. 
Figure 28:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in a 10 Host & 10 Switch 
Topology using Bandwidth. 
Figure 29:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in a 25 Host & 25 Switch 
Topology using Bandwidth. 
Figure 30:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in a 50 Host & 50 Switch 
Topology using Bandwidth. 
4.4.3.4) Experiment 2, K-Shortest Path Performance Tests (Path Calculation Time and 
Blocking):- 
The first test of the second set of experiments looked at how the performance of the K-Shortest Path 
algorithm was affected when the K-Value was changed from its default value of 250, specifically, how 
the time to find a path was affected. As the Q-Routing with latency and the Q-Routing with bandwidth 
algorithms were not affected by the K-Value, the time taken to find a path for each algorithm was 
used as a basis for comparison for the respective K-Shortest Path algorithms for each different K-
Value. Table 8 shows the results for this test. 
 Latency Bandwidth 
K-Value K-Shortest 
Path (ms) 
Q-Routing 
K-Shortest 
Path (ms) 
Q-Routing 
1 0.06 0.008 0.05 0.012 
5 0.11 0.008 0.09 0.012 
10 0.18 0.008 0.16 0.012 
50 0.93 0.008 0.79 0.012 
100 1.93 0.008 1.58 0.012 
150 2.2 0.008 2.53 0.012 
250 5.05 0.008 3.99 0.012 
Table 9:- Showing a comparison of the average times required to calculate a path for each of the K-Shortest Path and Q-
Routing algorithms when the K-Value is changed. 
From Table 8, the time taken to find a path is proportional to the K-Value with the quickest path 
calculation time for both K-Shortest Path algorithms being achieved when the K-Value was 1. Figure 
31 illustrates this further. As the K-Value increases, the time taken to find a path continues to rise 
exponentially for each K-Shortest Path algorithm where for a K-Value of 250, the time required to find 
a path for K-Shortest Path with latency on average is 5.05s and for K-Shortest Path with bandwidth - 
3.99s. These contrast greatly with the equivalent Q-Routing results of 0.008s for Q-Routing with 
latency and 0.012s for Q-Routing with bandwidth.   
Figure 31:- Showing the relationship between the K-Value and the time to calculate a path. 
The second test, as previously mentioned, was similar to the first but instead looked at how changing 
the K-Value affected the percentage of flows blocked by each K-Shortest path algorithm. Table 9 
shows the average results and Figure 32. 
 Latency Bandwidth 
K-Value K-Shortest 
Q-Routing K-Shortest 
Q-Routing 
1 45.67 11.64 44.57 0 
5 23.04 11.64 15.15 0 
10 17.11 11.64 8.86 0 
50 12.01 11.64 2.89 0 
100 11.1 11.64 1 0 
150 10.83 11.64 0.59 0 
250 10.34 11.64 0.48 0 
Table 10:- Showing a comparison of the percentages of flows blocked by each K-Shortest Path compared to the equivalent 
Q-Routing algorithms. 
From these results, it can be seen that for a low K-Value, the percentage of paths blocked by each K-
Shortest Path algorithm is very high with K-Shortest Path with latency blocking 45.67% of flows and K-
Shortest Path with bandwidth blocking 44.57% of flows compared to Q-Routings 11.64% and 0% for 
latency and bandwidth respectively. The percentage of flows blocked, however, decreases 
exponentially as the K-Value increases reaching a point where the performance of each K-Shortest 
Path algorithm is similar to their Q-Routing algorithm counterparts. 
Figure 32:- Showing the relationship between the K-Value and the percentage of flows blocked by K-Shortest Path. 
These results show that for a small K-Value, each K-Shortest Path algorithm is faster at path calculation 
than when using a large value though not as fast as Q-Routing. For a small K-Value it is also true that 
the percentage of flows blocked by each K-Shortest Path algorithm is very high. The corollary of this, 
of course is that for a large K-Value, the time to calculate a path is significantly longer for K-Shortest 
Path but the percentage of flows blocked is in line with that of Q-Routing. 
4.4.3.5) Experiment 3, Adaptive Q-Routing Performance tests in a Dynamic Network:- 
The third experiment split into two different tests was designed to test the adaptiveness of both Q-
Routing with latency and Q-Routing with bandwidth, both within a dynamic network.  
The results of the first test are shown in Figure 33. This test was implemented on a custom test 
topology, designed to show the number of flows required for each Q-Routing algorithm to adapt to a 
link failure in the network topology. From Figure 33, it can be seen that the adaptive versions of Q-
Routing with latency and Q-Routing with bandwidth for the first two link breaks and the fourth in the 
topology able to adapt instantly, finding another route that matched the QoS requirements. For the 
third link break, however, Q-Routing with latency took two training cycles / flows to adapt while Q-
Routing with Bandwidth took four. K-Shortest Path by contrast did not require time to adapt.  
Figure 33:- Showing the number of flows required for each algorithms adaptation. 
The second and final test of the third experiment was designed to test the adaptive Q-Routing 
algorithms on the 50 Host and 50 Switch topology with an AMC of 49 where at any one time, four links 
could be down forcing the adaptive Q-Routing algorithms to update their Q-tables and find alternative 
paths. The results were compared to K-Shortest Path using a K-Value of 250. 
Algorithm Percentage of Flows 
Accepted (%) 
Percentage of Flows 
Blocked (%) 
Average Time to 
Calculate Path (S) 
K-Shortest Path with 
Latency 
87.09 12.91 4.83 
Q-Routing with 
Latency 
86.94 13.06 0.008 
K-Shortest Path with 
Bandwidth 
98.96 
1.04 1.75 
Q-Routing with 
Bandwidth 
98.24 
1.76 0.011 
Table 11:- Showing the average path calculation times and percentage of flows accepted and blocked. 
Table 10 and Figure 34 show the results of this test. From these results, it can be seen that both 
adaptive Q-Routing algorithms were sustainably faster to calculate a path than their K-Shortest Path 
counterparts even after taking the time for additional Q-Table training time into account. K-Shortest 
Path with latency on average took 4.83s to calculate a path compared to 0.008s for Q-Routing with 
latency while K-Shortest Path with bandwidth took 1.75s compared to 0.011s for Q-Routing with 
bandwidth. These results also show that in terms of the percentage of flows blocked, the performance 
of the adaptive Q-Routing algorithms was very similar, with Q-Routing with Latency blocking 0.15% 
more than K-Shortest Path with latency and Q-Routing with bandwidth blocking 0.72% more than K-
Shortest Path with bandwidth.   
Figure 34:- Showing the Average Path Calculation Time against the Average Percentage of Flows Blocked for each 
algorithm. 
4.5) Discussion:- 
In this section, the results of the experiments are analysed and discussed with reference to the 
relevant research papers. 
4.5.1) Discussion of Q-Learning and Q-Routing Algorithms regarding the Percentage of 
Flows Blocked:- 
Q-Learning Algorithm With Latency:- The first phase as discussed previously was the implementation 
of Q-Learning using the network metric latency for pathfinding in an SDN network environment. As 
there were very few examples of Q-Learning being utilised for pathfinding in SDN, this was the logical 
place to start. 
The challenge with the original version of Q-Learning and indeed, this specific implementation was 
that it was designed to utilise Q and R tables that held arbitrary values and not values that were 
directly linked to the environment such as the link or edge values within a network topology.  This 
meant that Q-Learnings could be used to find a path between two network nodes but the path that 
was returned might not be the optimal path. To rectify this, the reward formula was modified to 
include link latency. So, within a single training cycle, as the algorithm was learning how to find a set 
destination node from a random start node, the latency between each node in the path would be used 
to update the Q-Table for the destination node. When Q was fully trained, an element of the actual 
network was used to influence the training. However, because R in this implementation was filled with 
values that did not correlate to the network environment, the addition of the link latency to the 
reward formula only produced a marginal improvement as the learnt policy that did not accurately 
reflect the performance of K-Shortest Path that it was designed to emulate. This could be seen when 
the percentage of flows blocked for this algorithm was compared to that of K-Shortest Path which had 
a lower blocking percentage. K-Shortest Path had an advantage in this regard as, depending on the K-
Value, K-Shortest Path could find many paths between the source and the destination and then select 
the optimal path to meet any QoS requirements. Q-Learning based algorithms by comparison only 
calculate one path between the source and destination nodes.   
In an attempt to equal the performance of K-Shortest Path, the Q-Learning algorithm was altered so 
it would be forced to recalculate the path a set number of times and store these additional path results 
and their corresponding latencies if the first path found failed to meet the QoS requirements. While 
the idea was good in theory, in practice it did not always produce alternative routes between the 
source and destination nodes. The same path could be found repeatedly, even if there were many 
alternative paths available. The result, however, was it did increase the chances of finding a better 
path, even if only by a small percentage.  
The cost, however, was that the time required to calculate a path increased noticeably, especially on 
large network topologies. This was not the only factor that affected path finding times. For example, 
before Q for a destination node could be used to find a path, the Q-Table required training for that 
destination node and was re-trained completely every time a forwarding node requested a path to 
the destination node. Of course, this was not a negative thing as it would be an advantageous 
approach in a dynamic network environment where links could break, forwarding nodes failing or new 
nodes being introduced to the network. For this implementation, however, constant re-training was 
not required and resulted in greater path finding times. Finally, this Q-Learning implementation used 
a matrix to store both the Q-Tables for each destination node and the R values so as the number of 
nodes in the network increased, the size of the matrices also increased in an exponential fashion 
resulting in longer training and path finding times.  
Despite the challenges that Q-Learning represented, the implementation performed moderately well 
as the difference between the blocking results for K-Shortest Path and the Q-Learning were not that 
great with Q-Learning achieving on average a 4% increased blocking rate for the 10 Host and 10 Switch 
topologies, a 6% increased blocking rate for the 25 Host and 25 Switch topologies and an 8.5% 
increased blocking rate for the 50 Host and 50 Switch topologies. 
Q-Routing Algorithm With Latency:- The next phase was the implementation of Q-Routing. Q-Routing 
was based on Q-Learning but was designed specifically to be used for routing which meant that actual 
metrics from the network environment were used to populate R. The fact that Q-Routing was tailored 
for network routing was evident from the learnt policies, evident in each of the converged Q-Tables 
for each destination node and the overall results where the performance of this algorithm was on par 
with that of K-Shortest Path with less than a 1% difference on average between the blocking results 
of the two algorithms.  
The implementation of Q-Routing with latency, as previously discussed was based on an existing 
version created by Luyuan Shi [139] but required a number of changes to make it suitable for this 
research. First, it was necessary to change the way the algorithm received the source and destination 
node information as originally this had been entered manually. Secondly, the traditional program had 
used a different representation of the topology so this had to be altered to reflect the Grotto 
Networking [142] topology system used throughout this research. Third, the structure of Q was 
changed adapted to reflect what was believed to be a truer representation of Q-Routing. This was 
done by changing the structure of Q so it stored latency estimates from all nodes in the network to 
the destination nodes instead of a structure identical to R that contained individual link estimates. 
Fourth, the pathfinding element was changed to use this new structured Q for pathfinding and finally, 
the Q-Table for each destination node was only trained once when the main SDN Controller program 
was launched instead of being constantly re-trained for every new flow. However, the times for this 
are not reported here. 
This implementation of Q-Routing held several advantages over the previous Q-Learning algorithm. 
First, as the learnt policy was able to replicate the results of K-Shortest Path with virtually identical 
performance, this Q-Routing algorithm did not require a function to recalculate the path a set number 
of times to find a path to meet the QoS requirements as used in Q-Learning. Second, because 
dictionaries were used to store the Q-Tables and R environmental information, the algorithm was able 
to scale better and run smoothly on larger network topologies without delays in the path calculation 
times. Finally, using dictionaries instead of a matrix structure prevented the possibility of the algorithm 
finding paths that did not exist within the network topology. While this was not a common problem, 
it was a possibility and happened on occasion when implementing Q-Learning. Combining these 
advantages of using SDN, such as Q being trained once for each destination node, the resulting 
algorithm was faster, producing better results than Q-Learning, consistent with the result of K-
Shortest Path.  
Q-Routing Algorithm With Bandwidth:- After Q-Routing with latency, Q-Routing with bandwidth was 
the next logical step. This was required as it was a key piece required for implementing a new Q-
Routing algorithm using latency and bandwidth. As previously discussed, this implementation was 
based on the Q-Routing using latency algorithm where the main difference was the adapted reward 
formula that used bandwidth instead of latency to train Q. 
When comparing the percentage of the percentage of flows blocked with that of K-Shortest Path using 
bandwidth, it can clearly be seen that there is little difference in the results with Q-Routing using 
bandwidth with the algorithm performing as well as K-Shortest Path and in some instances, 
performing better by a small margin though this can be attributed to statistical variance given the 
nature of the blocking tests.  
However, it was noted that when the topology with the smallest AMC value was used for each 
different size topology, the policy learnt by the trained Q-Tables did not produce a blocking result 
percentage as low as K-Shortest Path. During the blocking experiments, Q-Routing on average blocked 
7% more flows on the 10 Host and 10 Switch topology, 2% more flows on the 25 Host and 25 Switch 
topology and 12% more flows on the 50 Host and 50 Switch topology. These results suggested that Q-
Routing with bandwidth is not suited to network topologies with minimal connectivity and if there are 
more path available during the training process, there will be more path choices available in the 
pathfinding phase. For anything more than a minimal AMC value, this algorithm shared all the 
advantages of Q-Routing with latency while performing as well as K-Shortest Path with bandwidth. 
4.5.2) Discussion of K-Shortest Path Performance Tests (Path Calculation Time and 
Percentage of Paths Blocked):- 
The results of both tests were very interesting. The results showed that in order for each K-Shortest 
Path algorithm to give equal or superior performance to the Q-Routing equivalent, a high K-Value of 
between 150 to 250 was required. A high K-Value, however, resulted in noticeably longer times to find 
paths. For example, when K=250, K-Shortest Path with bandwidth took on average 3.99s to find a path 
compared to Q-Routing with bandwidth that took 0.012s. Reducing the K-Value did reduce the amount 
of time required to find a path, but it increased the percentage of paths blocked as there were fewer 
path options that met the QoS requirements to choose from. When the K-Value for K-Shortest Path 
with latency was reduced to K=5, the time to find a path dropped to 0.11s which, while faster than 
5.05s when K=250, was still slower than the 0.008s that Q-Routing with latency took to find a path. 
The percentage of flows blocked also increased from 10.34% to 23.04% becoming noticeably worse 
than the 11.64% produced by Q-Routing with latency. 
4.5.3) Discussion of Adaptive Q-Routing (Pathfinding Time and Percentage of Paths 
Blocked):- 
The previous algorithms had all been implemented with static network environments in mind which 
was suitable for the earlier experimentation and the development of Q-Routing using bandwidth. The 
next stage was to allow Q-Routing to be adapt to a changing network environment. This also important 
for two reasons. Firstly, as previously mentioned, standard pathfinding algorithms such as K-Shortest 
Path, in theory, could pre-process or calculate all network paths reducing the need to calculate a new 
path for every new flow [141]. Secondly, a static network environment is not realistic in real network 
applications.  
Adaptive Q-Routing Algorithm With Latency:- Adaptive Q-Routing with latency introduced an 
additional training cycle for each incoming flow in addition to the pre-trained Q. This was done to 
allow the algorithm to adapt to changes in the network topology in real time.  
The results of the first test from the third experiment illustrated that adaptive Q-Routing using Latency 
adapted almost instantly requiring only a single additional training cycle to find the next best optimal 
path after a link was broken. The exception to this was Link 3 (Figure 21) causing a small delay which 
required two training cycles for the algorithm to adapt and find a new path. This was caused by the 
time taken for the estimates from the node closest to the broken link to update and for the estimate 
to propagate backwards to each node in the path allowing a new path to be calculated.  
This algorithms ability to adapt quickly was further illustrated in the final test. The results clearly show 
that not only did adaptive Q-Routing perform as well as K-Shortest Path in regard to the percentage 
of flows blocked, adaptive Q-Routing was also significantly faster for pathfinding.  
Adaptive Q-Routing Algorithm With Bandwidth:- Adaptive Q-Routing with bandwidth was identical 
to Adaptive Q-Routing With latency with only the metric used being different and was implemented 
for the same reasons. 
The results of the third experiment were also similar as for the first test, adaptive Q-Routing with 
bandwidth was able to adapt to each link breaking instantly, again with the exception of Link 3 (Figure 
21) causing a small delay which required four training cycles for the algorithm to adapt and find a new 
path. It is suspected that this algorithm might have taken longer to adapt as (Figure 21) was a topology 
that had a low AMC Value. This would complement the results from the second experiment which 
showed that Q-Routing using bandwidth blocked more flows on average than the K-Shortest Path 
algorithm when the AMC of the network was at its lowest. This would suggest that the percentage of 
flows blocked by Q-Routing with bandwidth could have been reduced if more training cycles were 
introduced for the training of Q for each possible destination node.  
Despite this longer adaption period for the algorithm, adaptive Q-Routing with bandwidth in the final 
test of experiment three performed superbly, adapting to the dynamic network in real time. This is 
evident from the results where the difference in the percentage of flows blocked by this algorithm is 
less than 1% of the K-Shortest Path equivalent algorithm. Adaptive Q-Routing with bandwidth was 
also much faster to find a path resulting with an average pathfinding time in the milli-seconds 
compared to seconds as per the results for K-Shortest. 
4.5.4) Discussion of Q-Routing Convergence:- 
For each Q-Routing algorithm presented in this chapter and the rest of the Thesis (including 5.3.4,  
5.3.5, 6.3.2, and 6.3.3), it was important to make sure that the Q-Tables for each algorithm had 
converged. Convergence in this case meant that the Q-Table estimates for each Q-Routing algorithm 
accurately reflected the latency and bandwidth of the network topology being used at the time after 
training was completed. In this regard, convergence was not an issue for any of these algorithms 
where convergence was reached after a set number of training cycles. The exception to this was Q-
Learning (discussed in section 4.5.1) and Q-Routing using Latency, Total Link Bandwidth and Free Link 
Bandwidth (discussed in section 5.3.2), both of which were unable to converge due to the nature of 
the reward formulas employed. 
It should be noted that the number training cycles required for each algorithm and for each different 
size network topology was not recorded. Initial testing for each algorithm was primarily carried out on 
the largest and densest network topology of 50 Switches and 50 Hosts with an AMC of 49. Given this, 
if the number of training cycles were sufficient to ensure that the Q-Tables for each algorithm were 
fully converged on largest and densest topology, then convergence would be guaranteed on each 
smaller topology. Full experimental setting for each algorithm can be found in Appendix B. However, 
in short, for the Q-Routing algorithms presented in section 4.3 and for Amalgamation and Total Score 
Q-Routing presented in sections 5.3.4 and 5.3.5 respectively, 150 training cycles were required for the 
Q-Tables of each algorithm and for each metric (latency and bandwidth) to reach convergence. By way 
of contrast, Dual-Metric, Multi-Estate, Pareto Q-Routing algorithms (see section 6.3.2) and Adaptive 
Dual-Metric, Multi-Estate, Pareto Q-Routing (see section 6.3.3) required 350 training cycles to 
complete initial training since each algorithm was looking for multiple, tuple estimates as opposed to 
a single estimate. 
4.5.5) Discussion Summary:- 
From the experiment results, it is clear that Q-Routing remains a powerful ML technique and should 
not be ruled out for the following reasons:- 
 Q-Routing with latency and the newly developed Q-Routing with bandwidth (both the static 
and adaptive versions for each algorithm) had performance on par with their K-Shortest Path 
equivalents having learnt the policy successfully in the training phase and employed the policy 
in the pathfinding phase. This is supported by the fully converged Q-Tables for each 
destination node. 
 All the Q-Routing algorithms could, on average, find paths faster than the K-Shortest Path 
versions using the same metric. This outcome is supported by an analysis of the time 
complexity of each algorithm. 
 Each Q-Routing algorithm needed to only train the Q-Table once for each destination when 
the SDN Controller program was initialised. This feature allowed for faster pathfinding times. 
The adaptive Q-Routing algorithms also required only an additional training cycle for each 
incoming flow to adapt to changing network conditions with comparable blocking results to 
K-Shortest Path while still finding each path significantly faster. 
 In terms of scalability, K-Shortest Paths had to find all the paths between the source and 
destination nodes with the pathfinding time increasing exponentially as the topology size and 
the number of connections per node also increased. Using a smaller K-Value did decrease the 
pathfinding times but risked compromising overall performance as the number of calculated 
paths between the source and destination nodes that met the QoS of requirements was 
reduced. In contrast, not only was Q-Routing faster for pathfinding, but the results would also 
imply that Q-Routing, at least using single network metrics was scalable. This would suggest 
that Q-Routing could be a viable replacement for larger networks topologies or topologies 
with a high number of connections per node.  
Additional research into Q-Routing is required to look at the limits of scalability and to investigate a 
new approach of using multiple metrics for smarter path selection. However, it is clear that Q-Routing, 
when combined with the inherent advantages of an SDN controller (building a global topology map, 
complete end to end path calculation using this topology) is a powerful tool that could greatly improve 
or enhance network routing in future. 
4.6) Chapter 4 Conclusion:- 
There were several objectives for the research carried out in this chapter. The first was to investigate 
and understand the theory behind Q-Learning, how it worked and how to implement it within an SDN 
network and compare its performance to a K-Shortest Path algorithm. The second objective was to 
use Q-Routing with Latency, building on the knowledge gained from the first objective and the using 
this knowledge to create a new Q-Routing variant, Q-Routing with Bandwidth. Both Q-Routing 
algorithms had their performance compared with the K-Shortest Path equivalent algorithms. Finally, 
building upon the first two objectives, the goal of the third objective was to alter each of the Q-Routing 
algorithms to adapt to a dynamic network environment in real time. 
Overall, all three objectives set out in this chapter were a successfully met. Admittedly the first 
objective was simply a matter of research, but this was a steppingstone to the second objective which 
allowed for the understanding required to implement Q-Routing using Latency and create a new 
variant, Q-Routing using Bandwidth. Both algorithms performed as well as their K-Shortest Path 
counterparts for the percentage of paths blocked and both Q-Routing algorithms outperformed K-
Shortest Path in path calculation times, even when the K-Value for the K-Shortest Path algorithms was 
lowered, resulting in more flows blocked by the K-Shortest Path algorithms.  
The third objective, to create adaptive Q-routing algorithms was also a success adapting almost 
instantly to changes in the network environment, calculating complete paths for each incoming flow 
to meet the QoS requirements faster than the equivalent K-Shortest Path algorithms while 
maintaining comparable results for the percentage of flows blocked. 
So, to conclude, the research undertaken in this Chapter was successful and provided a great insight 
into RL and specifically, Q-Learning for network routing. This was important as the next chapter 
(Chapter 5) builds on this research to further develop Q-Learning for routing in packet-switched 
networks. 
Chapter 5:- The introduction of Multiple Network Metrics into Q-
Routing for Pathfinding 
5.1) Introduction:- 
The research carried out so far into Q-Routing as demonstrated in the previous chapter (Chapter 4) 
showed that Q-Routing utilised within an SDN network environment has the potential to be very useful 
in terms of fast and reliable pathfinding when compared to a well-known and well-used pathfinding 
algorithm such as K-Shortest Path. However, one of the key limitations of Q-Routing is its inability to 
use multiple network metrics to find a path between two nodes. Q-Routing as previously discussed 
was designed to be used with latency. In the previous chapter, the research conducted allowed for 
the creation of a bandwidth version of the algorithm which was tested and worked to great effect. 
Unfortunately, in an ever-evolving digital world, new network and internet applications may have QoS 
requirements for more than one network metric such as latency, bandwidth, jitter, packet loss, etc. 
The research carried out in this chapter looked at different approaches to the application of multiple 
network metrics utilised within the Q-Routing algorithm to find a path that would meet the QoS 
requirements of a specific flow.  
5.2) Chapter Objectives:- 
Building on the research performed in Chapter 4, the aim of the research in this chapter was to evolve 
the Q-Routing algorithm to use more than one network metric for pathfinding. The purpose was to 
implement a more practical algorithm that could be used to select a path based on multiple QoS 
requirements as dictated by an internet or network application. This improvement to the algorithm 
was also necessary to showcase how Q-Routing could be as effective as K-Shortest Path for pathfinding 
in some areas and more effective in others. With this in mind, this chapter looked at three different 
methods for implementing Q-Routing to using multiple metrics:- 
1. The first method was based on an existing implementation [93] that used three different 
network metrics, Latency, Total Link Bandwidth (TLB) and the Free Link Bandwidth (FLB). The 
reward formula was altered to add all three metrics as ratios which produced one Q-Table 
used for pathfinding. 
2. The second implementation used a combination method to combine two network metrics, 
Latency and Bandwidth in the pathfinding phase using separately trained Q-Tables for 
Latency and Bandwidth. 
3. The third and final method was similar to the second. However, instead of using a 
combination method in the pathfinding phase, a scoring system was employed. 
Each of the Q-Routing algorithms developed along with their K-Shortest Path equivalents was 
implemented within the same SDN packet-switched network testbed as demonstrated in Chapter 3. 
5.3) Q-Routing Multi-Metric Algorithm Development and Implementation :-  
For each of the multi-metric algorithms and the equivalent K-Shortest Path algorithms created, the 
SDN testbed discussed in Chapter 3 to host and test the algorithms from the Chapter 4 was also 
employed for the algorithms developed in this chapter. It should also be noted that the QoS 
mechanism and the collection of edge/link metrics for Q-Table training and pathfinding were also the 
same. 
5.3.1 ) K-Shortest Path using Latency, Total Link Bandwidth & Free Link Bandwidth:- 
Algorithm Background:- This algorithm was designed to find paths using latency, TLB and FLB and was 
written to be used as a basis of comparison for a Q-Routing algorithm using the same three metrics. 
This allowed paths to calculated considering the bandwidth that was actually available in real-time 
instead of using only the total bandwidth capacity of a link. The algorithm was adapted from K-
Shortest Path using latency, discussed in the previous Chapter 4. 
Implementation:- The plan for this algorithm was to build upon the previous K-Shortest Path with 
latency algorithm by not only adding an additional metric (bandwidth), but also taking into account 
the available bandwidth capacity of a path before using it. This way, the algorithm was more likely to 
find a path that would meet the latency and bandwidth QoS requirements. 
This algorithm was also designed to be proactive and more dynamic by taking the QoS requirements 
into account. Instead of finding a path and checking to see if the path met the QoS requirements for 
latency and bandwidth after the path had been calculated, the algorithm used the QoS values as part 
of the pathfinding process. Figure 35 shows the implementation of this K-Shortest Path algorithm. For 
an incoming flow request between the source and destination nodes, the algorithm would find many 
paths between the source and destination nodes depending on the K-Value. The paths and their 
corresponding latencies were then filtered based on the QoS latency value. The paths that had a 
latency less than or equal to the QoS latency value were saved for the next phase while the paths that 
failed to meet this QoS latency requirement were filtered out. If all paths failed to meet the QoS 
latency requirement then the path with the smallest latency was marked as the current path.  
Figure 35:- Implementation of the K Shortest Path Algorithm using Latency, TLB & FLB for Path Finding. 
From the list of paths that met the latency requirement, the next stage was to find the maximum 
bandwidth capacity for each path and filter out any paths that did not meet the QoS bandwidth value. 
Those that did, were stored in a list. If none of the paths met the QoS requirements for bandwidth 
then from the list of the paths, the path with the largest bandwidth was selected. 
Finally, from the list of paths that met both the QoS latency and bandwidth criteria, each link was 
checked to make sure there was enough free bandwidth capacity to meet the QoS bandwidth 
requirement. For testing the algorithm and to keep track of the FLB, a database for bandwidth was 
created that tracked the bandwidth used for each link/edge in the network topology either subtracting 
or adding the QoS bandwidth value generated for each flow from all the links in a set path where the 
total free capacity for a single link at any one time was calculated using (Eq. 10). 
() = ()   ()
  ()
(Eq. 10) 
Where Bf(L) was the Free bandwidth Capacity of that path link, Bmax(L) was the maximum 
bandwidth capacity of path link L, Flows(L) represents the set of flows using link L and BQoS was the 
QoS bandwidth value for a given flow. Attempting to measure the FLB in real time for each network 
link was briefly considered as an alternative to a database, however, given the stage of algorithm 
development and the research focus, it was considered to be unnecessary.  
If every link in the path met the requirement for the bandwidth QoS, the path was deemed acceptable 
and put into a final list, otherwise, it was discarded. If none of the paths had enough free bandwidth 
capacity, the path with the smallest latency was selected. If multiple paths met all the QoS 
requirements, then the path with the smallest latency was selected.  
Once a path had been returned by the K-Shortest Path algorithm, it was tested to make sure that it 
met the QoS requirement. If the path did then it was marked as Active and the forwarding nodes in 
the calculated path would be programmed with the required forwarding instructions to reach the 
destination node. If, however, the path did not meet the QoS requirements, that path was marked as 
Blocked and could not be used by the flow that requested that path to the destination node. 
Assuming the path had met the QoS requirements, once the flow had finished, the SDN controller 
would remove the forwarding instructions for that path from each forwarding node in the path. 
Finally, to keep the free link bandwidth database up to date, the QoS bandwidth that had been 
removed from each link in the path previously was added back. 
5.3.2) Q-Routing using Latency, Total Link Bandwidth & Free Link Bandwidth:- 
Algorithm Background:- The first multi-metric Q-Routing algorithm implemented was based on an 
existing implementation presented in a paper [93] which was the only example of a Q-Learning 
algorithm using latency in combination with TLB and FLB within an SDN Network in literature.  
Implementation:- This version of the Q-Routing algorithm using the metrics latency, TLB and FLB was 
based upon two algorithms used previously: Q-Routing using latency and K-Shortest Path using 
latency, TLB and FLB. This algorithm was designed to combine these metrics in the training phase after 
the main SDN controller program had been initiated. The same path selection process as Q-Routing 
with latency was used for finding the path for a flow between source and destination nodes based on 
the Q-Table trained as a result of the combination of these metrics (please see Appendix C.6 for the 
pseudocode). 
From the K-Shortest Path algorithm, the mechanism for checking if the links of a path have free 
bandwidth capacity was implemented along with the Bandwidth Database and the ability to update 
the Bandwidth Database. This ability to lookup the FLB of a link or measure the free bandwidth of 
that link was important as a value for real-time free bandwidth capacity were required in the Q-
Routing reward formula and it was also used as part of the QoS checking. 
From the Q-Routing using latency algorithm, most of the implementation was the same. The main 
difference was the creation of an additional data structure similar to R. However, whereas R held the 
latency values of each link in the network, this new data structure (RBandwidth) held the bandwidths of 
each link in the network topology. This addition was required as individual RBandwidth values also made-
up part of the Q-Learning formula used for training the Q-Tables for each destination node. 
The Q-Routing algorithm (Figure 36) was implemented after the switches for the source and 
destination host nodes have been identified. The first step was to create the data structures for Q, R 
and RBandwidth which were passed into the Q-Routing function. The second step was to start the training 
phase where Q was trained for each destination node in the network using the reward formula. The 
reward formula in this implementation was different than the one previously utilised as it was 
designed to allow three metrics to be used, instead of one: Latency, TLB and FLB. This was based on 
the reward formula used in Using SDN and Reinforcement Learning for Traffic Engineering in 
UbuntuNet Alliance [93] where the standard Q-Learning formula was altered by adding an 
aggregation of the latency and the two bandwidth values. The formula as it was applied in the Q-
Routing implementation using latency only [139] was as follows:- 
 = (, ) +  (R(s, a) + min(Q(s
, a))  Q(s, a) 
(Eq. 11) 
Where QNew was the updated Q value for the current State / Action pair, " was the learning rate, 
R was the link latency for the current State / Action pair, min(Q(s, a)) was the lowest value of all 
possible actions for the current State and Q was the current Q value for the State/Action pair. 
The idea was to use a variation of this approach with Q-Routing to see if Q-Routing with latency, TLB 
and FLB in combination could be as effective as K-Shortest Path using the same metrics. To modify this 
formula, it was first necessary to create the aggregation function. Using the aggregation function from 
the Q-Learning formula [93] as a template, ratios were created for both bandwidth and latency. 
(, )
(, )
(Eq. 12) 
Where Br was the bandwidth ratio, Ba was the actual free measured/simulated bandwidth 
capacity available for use on that link and Bl was the total bandwidth capacity of that link. 
(, )
(Eq. 13) 
Where Lr was the Latency Ratio, Ll was the latency of the link and n is a pre-set number. In the 
case of the [93], it was an arbitrary value set to 1,000.  
(, ) = (1  ) + (2  ) 
(Eq. 14) 
The aggregation function was created out of the respective ratios where K was the aggregation 
formula and A1 and A2 were weights added to allow refinement of the formula. As with the 
latencies, the aggregation formula mirrored the formula used in [93], with the exception that weights 
were added to this formula. If the value of both weights were set to 1 then K was identical to the 
aggregation formula used in [93]. Using K, the Q-Routing formula was written as follows:- 
 = (, ) +  (K(s, a) + min(Q(s
, a))  Q(s, a)) 
(Eq. 15) 
After the new Q-Routing formula was implemented and the training phase had been completed using 
this formula, the next stage was for the Q-Routing algorithm to use the trained Q-Tables to calculate 
a path between the source and destination nodes. This pathfinding was again carried out in a similar 
way to that of the equivalent K-Shortest Path algorithm where the path was checked to make sure 
that it met the QoS requirements proactively during the path calculation phase. Once done, this 
calculated path was returned to the main program function where the final stage was to check if the 
path meet the QoS criteria set.  
Figure 36:- Implementation of the Q-Routing Algorithm using Latency & TLB & FLB for Path Finding. 
The QoS check was very similar to that of the comparative K-Shortest Path algorithm. The key 
difference was that Q-Routing only produced one path between the source and the destination while 
K-Shortest path produced many depending on the K-Value. This one path produced by Q-Routing was 
first checked to make sure it supported the QoS latency requirement. Assuming it did, the TLB of the 
path was checked against the QoS bandwidth value and finally, assuming the path met the QoS 
bandwidth requirement, the FLB of each link in the path was checked to make sure that each link had 
enough available bandwidth to support the QoS bandwidth requirement. If that path had met all the 
QoS requirements, then the path was marked as Active. If, however the path had failed to meet any 
of the QoS criteria, the path was marked as Blocked.  
5.3.3) K-Shortest Path using Latency and Bandwidth:- 
Algorithm Background:- This version of K-Shortest Path was designed to find paths using only latency 
and bandwidth, the results of which would act as a point of comparison for two Multi-Metric Q-
Routing algorithms variants (Amalgamation and Scoring), both of which were designed to use latency 
and bandwidth. 
Implementation:- The implementation of K-Shortest Path using latency and bandwidth was essentially 
the same as the previous three metric version. They key difference however was that this version was 
designed without FLB in mind. So, after pro-actively checking and filtering all the paths that K-Shortest 
Path returned for latency and then bandwidth, the links of the path would not be checked to see if 
each link could support the QoS Bandwidth requirement. Figure 37 shows the implementation of this 
K-Shortest Path algorithm. 
Figure 37:- Implementation of the K-Shortest Path Algorithm using Latency & Bandwidth for Path Finding. 
5.3.4) Amalgamation Q-Routing using Latency and Bandwidth:- 
Algorithm Background:- After Q-Routing using latency, TLB and FLB, a new approach was undertaken. 
While the algorithm was under development, it was decided to use two metrics, latency and 
bandwidth and instead of training Q with a combination of metrics, it was also decided to combine 
latency and bandwidth in the pathfinding phase by amalgamating the values. 
Implementation:- When tested, the performance of Q-Routing using latency, TLB and FLB failed to 
match the performance of the equivalent K-Shortest Path algorithm. The problem with this approach 
was combining the metrics in the reward formula to make a single value estimate that in fact 
represented three different values (see section 5.5.1).  
For the next stage of the research, it was decided to let the Q-Tables for each possible destination 
node in the network topology train using a single metric and to concentrate on using the metrics 
latency and bandwidth together in the pathfinding stage. Two different approaches were undertaken. 
The first described in this section used an Amalgamation method (please see Appendix C.7 for the 
pseudocode). The second described in the following section 5.3.5 used a Scoring method. 
Figure 38:- Implementation of the Amalgamation Q-Routing Algorithm using Latency & Bandwidth Path Finding. 
In the training phase, the Amalgamation Q-Routing algorithm was based on both Q-Routing with 
Latency and Q-Routing with Bandwidth. Instead of combining the metrics together as a single value 
and storing them in a Q-Table for each destination node, two Q-Tables were trained individually for 
each destination node. One for latency and one for bandwidth. This was a logical approach because 
the results showed that both algorithms could for the most part perform as well as their K-Shortest 
Path equivalents. It should also be noted that like the first implementations for Q-Routing with Latency 
and Q-Routing with Bandwidth, the Q-Tables were trained for each destination node once when the 
SDN controller program was first activated. An adaptive version of this algorithm could be created 
later depending on how the first version of this algorithm performed. Once the training of the two Q-
Tables for each possible destination node had taken place and the SDN controller program was ready 
to respond to flow requests, the algorithm was ready to calculate paths (Figure 38).  
When the SDN controller received a request for a path for an incoming flow, the source and 
destination nodes were passed on to the path calculation part of the Amalgamation Q-Routing 
algorithm along with the randomly generated QoS latency and bandwidth values. The early part of the 
pathfinding process was the same as that of Q-Routing using Latency and Q-Routing using Bandwidth. 
From the current or start node, the latency and bandwidth link values (stored in R) were combined 
with the trained Q-Tables values for the current nodes estimate on how to reach the destination node. 
The Latency estimate was added to the R latency value and for the bandwidth, the minimum 
bandwidth value was selected between the estimate stored in Q and the link value stored in R. This 
was done for each neighbouring node to the current or start node. However, instead of selecting the 
next node based on the combined latency value or the maximum bandwidth, the values were 
combined as follows (Eq. 16):-  
 = (  )   
(Eq. 16) 
Where Tv represented the total combined value,  a weighted value, Lv the latency value and Bv the 
bandwidth value. Once this process had been completed for each of the latency and bandwidth value 
pairs from the current node/start node to each destination node, all of these Tv values were stored in 
a list. The Tv with the smallest value was selected from that list and the corresponding neighbouring 
node was selected as the next node in the path towards the destination. This process was then 
repeated for each node in the path until the destination node had been found. Once the destination 
node had been found, the complete path was returned to the SDN controller program. 
Regarding the QoS, this algorithm like K-Shortest Path using Latency and Bandwidth took a proactive 
response. After the link values for latency and bandwidth between the current node and each 
neighbouring node had been combined with the estimates from that neighbouring node to the 
destination, these updated latency and bandwidth values pairs representing the values from the 
current node to the destination via a neighbouring node were checked against the randomly 
generated QoS latency and bandwidth values. If either the latency or bandwidth failed to meet their 
respective QoS requirements, the corresponding neighbouring node was removed as a possible next 
node. Only when both the latency and bandwidth values meet the respective QoS values was the 
corresponding neighbouring node kept as possible choice for the next node. 
5.3.5) Total Score Q-Routing using Latency and Bandwidth:- 
Algorithm Background:- Like the previous algorithm, Total Score Q-Routing using Latency and 
Bandwidth was an alternative approach to Q-Routing using Latency, TLB and FLB for combining 
multiple network metrics. The results of this algorithm were compared against K-Shortest Path using 
Latency and Bandwidth. 
Implementation:- The implementation of this algorithm (please see Appendix C.8 for the 
pseudocode) was essentially the same as the Amalgamation Q-Routing algorithm when it came to the 
training of the Q-Tables for latency and bandwidth for each destination node and the early part of the 
path selection process using the fully trained Q-Tables. However, instead of amalgamating the 
combined latency and bandwidth values for R (link values) and Q (estimate from the neighbouring 
node to the destination) from the current node to each neighbouring node, a scoring system was 
implemented.  
Figure 39:- An example of how the scoring process worked. 
Using a hypothetical example, in Figure 39 where the current node is S1, there were five possible 
choices as the next node in the path, S2  S6 as each of these nodes were neighbours to the current 
node. From each link between the current node and the neighbouring node, the new latency and 
bandwidth estimates updated by R (from the current node to the destination) are stored in a table by 
their node ID (Table 11). After this has been completed for all the nodes directly connected to S1, 
points were awarded based on the latency and bandwidth values. In the case of latency, the 
neighbouring node that has the lowest latency was given one point, the second lowest latency is given 
two points, and the process continues for each latency value. For the bandwidth, the reverse was true 
where the largest bandwidth value was awarded 1 point, the second largest, two points and so on.  
Latency Bandwidth Latency & 
Bandwidth 
Neighbouring 
Node ID 
Latency Value 
Points Bandwidth Value 
(Mbits) 
Points Total Score 
S2 10 3 70 4 7 
S3 25 4 90 3 7 
S4 5 1 150 1 2 
S5 7 2 45 5 7 
S6 65 5 145 2 7 
Table 12:- Showing the points awarded for the Latency and Bandwidth values for each neighbouring node. 
Table 11 was the result showing the number of points that each latency and bandwidth value were 
awarded individually and the total score for each neighbouring node. From this table, it can be seen 
that node S4 achieved the lowest score with a total value of two as the latency was the lowest out 
of all the available options and the bandwidth value was the largest. This was done on purpose for the 
example to demonstrate the principle. It very easily could have been that the bandwidth scored one 
point, but latency scored three points depending on the value giving a total score of four which, 
depending on the latency and bandwidth values for each of the other neighbouring nodes, could have 
been a winning score. This was also true if both the latency and bandwidth values were not the lowest 
or largest respectively, but had average values compared to all the latency and bandwidth values for 
each neighbouring node. If two or more neighbouring nodes had the same lowest combined score, 
the next node was selected at random from those points. 
This scoring mechanism allowed the next node in a path to be selected while keeping a balance 
between finding a path with the lowest latency and a path with the largest bandwidth, two metrics 
opposed to each other. In the case of the example above, it is clear that from Table 11, the next node 
selected in the path would have been S4 having the total lowest score. Once S4 had become the 
current node, the above process would repeat for each step in the path until the destination node had 
been found. Figure 40 shows the implementation of this algorithm. 
The final aspect of note for this algorithm was that it used the pro-active QoS mechanism similar to 
that of K-Shortest Path using Latency and Bandwidth and Amalgamation Q-Routing using Latency and 
Routing. Once the R value for latency and bandwidth from the current node to each neighbouring 
node had been combined with the Q estimates from the neighbouring node to the destination node, 
the values were checked against the QoS values. If either the latency, the bandwidth or both values 
from the current node to a neighbouring node did not meet the QoS requirements, that neighbouring 
node was removed as a possible contender for the next node. If in the case that all neighbouring nodes 
were not viable options as the next node, an arbitrary path was found between the source and 
destinations which would later be marked as Blocked when the latency and the bandwidth of the 
path were checked to make sure that the path met the QoS requirements. 
Figure 40:- Implementation of the Total Scoring Q-Routing Algorithm using Latency & Bandwidth Path Finding. 
5.3.6) Comparison of each multi-metric routing algorithms complexity:- 
Table 13 shows a comparison of the time complexities for the training and pathfinding 
implementations (where relevant) of each multi-metric and dual-metric algorithm.  
Algorithm Name Time Complexity 
Training Pathfinding 
K-Shortest Path using Latency, Total Link 
Bandwidth & Free Link Bandwidth 
N/A (2) [140] 
K-Shortest Path using Latency and Bandwidth N/A (2) [140] 
Q-Routing using Latency, Total Link 
Bandwidth & Free Link Bandwidth 
(3) (2) 
Amalgamation Q-Routing using Latency and 
Bandwidth 
(3) () 
Total Score Q-Routing using Latency and 
Bandwidth 
(3) () 
Table 13:- Showing a comparison between the time complexities for multi-metric routing algorithm. 
Overall, each Q-Routing algorithm had the same time complexity as those in section 4.3.8. The one 
exception to this the Q-Routing using Latency, Total Link Bandwidth and Free Link Bandwidth 
algorithm. The reason for this was that the algorithm completely re-trained the Q table for the current 
destination node for each new traffic flow. The result was a pathfinding time complexity on par with 
K-Shortest Path. 
5.4) Experiment Design and Results:- 
In this section, the experiments carried out to test the performance of each of the dual metric path 
algorithms implemented are discussed along with the experiment settings and the results in 
comparison with the K-Shortest Path equivalent algorithms. 
5.4.1) Core SDN Controller Settings with Path Calculation Algorithms:- 
The optimal variable values for the Core SDN Controller program and the path calculation algorithms 
can be found in the appendix in section B.2. 
5.4.2) Experimental Procedure:- 
Each of the dual metric algorithms created was tested in a similar way as the experiments carried out 
in 4.4.2.  
5.4.2.1) Experiment 1: K-Shortest Path & Q-Routing Path Blocking Performance Tests:- 
For the research performed in this chapter, five different pathfinding algorithms were created. The 
two K-Shortest Path algorithms were designed to act as bases of comparison for the Q-Routing 
algorithms. Table 12 shows each multi-metric Q-Routing algorithm variant and the equivalent K-
Shortest Path algorithm.  
K-Shortest Path Algorithm Equivalent Q-Routing Algorithm 
K-Shortest Path using Latency, Total Link 
Bandwidth & Free Link Bandwidth 
Q-Routing using Latency, Total Link Bandwidth 
& Free Link Bandwidth 
K-Shortest Path using Latency & Bandwidth Amalgamation Q-Routing using Latency and 
Bandwidth 
K-Shortest Path using Latency & Bandwidth Total Score Q-Routing using Latency and 
Bandwidth 
Table 14:- Showing each K-Shortest Path algorithm and the equivalent Multi-Metric Q-Routing algorithms. 
The test performed designed to measure the percentage of flows blocked of each Q-Routing algorithm 
was the same as previously carried out in section 4.4.2.1. 
5.4.2.2) Experiment 2:- K-Shortest Path Performance Tests (Path Calculation Time and 
Blocking):- 
The second series of tests performed in this chapter, similar to those carried out in 4.4.2.2 was 
designed to measure the performance of each of the multi-metric K-Shortest Path algorithms.  
5.4.3) Experimental Results: - 
5.4.3.1) Experiment 1, Result Comparison for K-Shortest Path using Latency, Total Link 
Bandwidth & Free Link Bandwidth vs Q-Routing using Latency, Total Link Bandwidth & 
Free Link Bandwidth:- 
The first of the blocking experiments in the chapter compared the percentage of flows blocked by Q-
Routing using Latency, Total Link Bandwidth and Free Link Bandwidth against an equivalent K-Shortest 
Path algorithm. Table 13 shows the percentage of flows that were accepted and blocked for the two 
algorithms. Looking at Table 13, it is clear that the K-Shortest algorithm outperformed the Q-Routing 
algorithm by a significant margin, where the difference in the percentage of flows blocked increased 
as the AMC value became higher. This was the case across all three different topology sizes. The closest 
Q-Routing in this experiment came to matching the performance of K-Shortest Path was on the 
smallest topology (10 Hosts and 10 Switches) when the AMC was at its lowest value of 3. Q-Routing 
on average blocked 59.98% of flows compared to K-Shortest Path which achieved a slightly smaller 
blocking percentage of 57.27%. 
Figure 41, Figure 42 and Figure 43 show the results for the 10 Host and 10 Switch, 25 Host and 25 
Switch and the 50 Host and 50 Switch topologies respectively in the form of a box and whisker plot 
showing the percentage of flows blocked against the AMC. In the case of K-Shortest Path, each figure 
shows that as the value of the AMC increased, the percentage of flows blocked by the algorithm 
decreased exponentially. The figures also show that this is also the case for Q-Routing with a few 
notable discrepancies.  
    K-Shortest Path Q-Learning 
  Average Mesh 
Accepted 
Flows 
Blocked 
Flows 
Accepted 
Flows 
Blocked 
Flows 
Topology 
Connectivity 
Per Node  %  %  %  % 
10H10S 3 42.73 57.27 40.02 59.98 
10H10S 5 67.68 32.32 42.32 57.68 
10H10S 7 80.94 19.06 61.32 38.68 
10H10S 9 85.8 14.2 64.15 35.85 
25H25S 4 33.19 66.81 28.06 71.94 
25H25S 8 60.60 39.40 42.04 57.96 
25H25S 12 73.54 26.46 45.01 54.99 
25H25S 16 79.94 20.06 51.80 48.20 
25H25S 20 82.55 17.45 52.26 47.74 
25H25S 24 82.36 17.64 55.02 44.98 
50H50S 5 34.94 65.06 25.65 74.35 
50H50S 12 68.49 31.51 43.53 56.47 
50H50S 19 77.45 22.55 49.78 50.22 
50H50S 26 82.43 17.57 52.79 47.21 
50H50S 33 83.24 16.76 53.34 46.66 
50H50S 40 83.72 16.28 55.44 44.56 
50H50S 45 84.45 15.55 58.45 41.55 
50H50S 49 85.77 14.23 59.54 40.46 
Table 15:- Showing the average blocking % results for K-Shortest Path vs Q-Routing using Latency & Total Link Bandwidth & 
Free Link Bandwidth. 
Firstly, there is a significant difference in the percentage of flows blocked with this difference 
increasing as the AMC is increased on each topology. However, this is less noticeable on the 50 Host 
and 50 Switch topology. Secondly, for certain AMC values on each different size topology, the 
difference in the percentage of flows blocked between Q-Routing and K-Shortest Path seems to spike, 
breaking the exponential pattern. For example, on the 10 Host and 10 Switch topology when the AMC 
is 5, referring to the average results from Table 13, the difference in the percentages of flows blocked 
is higher at 25.6% compared to 19.62% when the AMC is 7 and 21.65% when the AMC is 9. Other 
prominent examples can be seen in Figure 42 when the AMC is 12 and in Figure 43 when the AMC is 
33. Finally, the figures show that across each of the topologies, there was a discrepancy in the variance 
between the two algorithms with Q-Routing showing more variance in each box and whisker plot for 
each AMC value (on average) than that of K-Shortest Path. 
Figure 41:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in a 10 Host 10 Switch 
Topology using Latency, Total Link Bandwidth & Free Link Bandwidth. 
Figure 42:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in a 25 Host 25 Switch 
Topology using Latency, Total Link Bandwidth & Free Link Bandwidth. 
Figure 43:- Showing a Box & Whisker Plot for the Blocking Results for Q-Routing vs K-Shortest Path in a 50 Host 50 Switch 
Topology Using Latency, Total Link Bandwidth & Free Link Bandwidth. 
5.4.3.2) Experiment 1, Result Comparison for K-Shortest Path using Latency & Bandwidth vs 
Amalgamation Q-Routing using Latency & Bandwidth:- 
The second blocking experiment in this chapter compared the percentage of flows blocked for 
Amalgamation Q-Routing using the metrics latency and bandwidth against the performance of the 
equivalent K-Shortest Path algorithm. Table 14 shows the average percentage of flows that were 
accepted and blocked for the two algorithms. In the case of Amalgamation Q-Routing, the percentage 
of flows blocked was greater on average than of K-Shortest Path. Table 14 also shows that as the AMC 
value increased in each of the three topologies, the difference in the percentage of flows blocked also 
increased between the two algorithms with the smallest percentage gap occurring for each topology 
when the AMC value was at its lowest.  
Figure 44, Figure 45 and Figure 46 show the results for the 10 Host and 10 Switch, 25 Host and 25 
Switch and the 50 Host and 50 Switch topologies respectively in the form of a box and whisker plot 
showing the percentage of flows blocked against the AMC. In the case of K-Shortest Path, each figure 
shows that as the value of the AMC increased, the percentage of flows blocked by the algorithm 
decreased exponentially. The figures also show that this was also the case for Q-Routing though some 
minor discrepancies were apparent. 
    K-Shortest Path Q-Routing 
 Average Mesh 
Accepted 
Flows 
Blocked 
Flows 
Accepted 
Flows 
Blocked 
Flows 
Topology 
Connectivity 
Per Node  %  %  %  % 
10H10S 3 42.18 57.82 39.82 60.18 
10H10S 5 67.13 32.87 58.06 41.94 
10H10S 7 81.52 18.48 73.36 26.64 
10H10S 9 85.52 14.48 73.1 26.9 
25H25S 4 34.33 65.67 28.72 71.28 
25H25S 8 61.13 38.87 41.70 58.30 
25H25S 12 72.89 27.11 43.45 56.55 
25H25S 16 80.39 19.61 46.77 53.23 
25H25S 20 82.34 17.66 44.52 55.48 
25H25S 24 84.08 15.92 45.49 54.51 
50H50S 5 34.18 65.82 27.34 72.66 
50H50S 12 67.23 32.77 36.42 63.58 
50H50S 19 77.35 22.65 37.64 62.36 
50H50S 26 84.99 15.01 38.47 61.53 
50H50S 33 85.98 14.02 38.63 61.37 
50H50S 40 86.41 13.59 40.15 59.85 
50H50S 45 86.5 13.50 40.51 59.49 
50H50S 49 85.97 14.03 40.66 59.34 
Table 16:- Showing the average blocking % results for K-Shortest Path vs Amalgamation Q-Routing using Latency & 
Bandwidth. 
Firstly, the results for the 10 Host and 10 Switch and 50 Host and 50 Switch topologies for Q-Routing 
resulted in similar curves to that of K-Shortest Path with the difference in the percentage of flows 
blocked remaining fairly consistent after the curve started to flatten. For example, from  Table 14, the 
percentage gap difference between K-Shortest Path and Q-Routing for the 50 Host and 50 Switch 
topology was 46.52% when the AMC was 26 and 45.31% when the AMC was 49. However, the Q-
Routing results for the 25 Host and 25 Switch topology were more pronounced with the difference 
increasing from 33.62% when the AMC was 16 to 38.59% when the AMC was 25. 
Finally, each of the figures show that across each of the topologies, there was a difference in the 
variance between the two algorithms with Q-Routing showing more variance in each box and whisker 
plot for each AMC value (on average) than that of K-Shortest Path. 
Figure 44:- Showing a Box & Whisker Plot for the Blocking Results for Amalgamation Q-Routing vs K-Shortest Path in a 10 
Host 10 Switch Topology using Latency & Bandwidth. 
Figure 45:- Showing a Box & Whisker Plot for the Blocking Results for Amalgamation Q-Routing vs K-Shortest Path in a 25 
Host 25 Switch Topology using Latency & Bandwidth. 
Figure 46:- Showing a Box & Whisker Plot for the Blocking Results for Amalgamation Q-Routing vs K-Shortest Path in a 50 
Host 50 Switch Topology using Latency & Bandwidth. 
5.4.3.3) Experiment 1, Result Comparison for K-Shortest Path using Latency & Bandwidth vs 
Total Score Q-Routing using Latency & Bandwidth:- 
The third and final blocking experiment in this chapter compared the percentage of flows blocked for 
Total Score Q-Routing using the metrics latency and bandwidth against the performance of the 
equivalent K-Shortest Path algorithm. Table 15 shows the average percentage of flows that were 
accepted and blocked for the two algorithms. In this instance, the percentage of flows blocked by 
Total Score Q-Routing was on average greater than that of the equivalent K-Shortest Path algorithm. 
These results were similar to those of 5.4.3.2. 
Figure 47, Figure 48 and Figure 49 shows the results for the 10 Host and 10 Switch, 25 Host and 25 
Switch and the 50 Host and 50 Switch topologies respectively in the form of a box and whisker plot 
showing the percentage of flows blocked against the AMC. The results for K-Shortest Path in this 
instance were the same as the results from the previous experiment (see section 5.4.3.2) as this 
algorithm was used as a basis for comparison for both Amalgamation Q-Routing and Total Score Q-
Routing. 
    K-Shortest Path Q-Learning 
  Average Mesh 
Accepted 
Flows 
Blocked 
Flows 
Accepted 
Flows 
Blocked 
Flows 
Topology 
Connectivity Per 
Node  %  %  %  % 
10H10S 3 42.18 57.82 40.3 59.7 
10H10S 5 67.13 32.87 53.07 46.93 
10H10S 7 81.52 18.48 67.68 32.32 
10H10S 9 85.52 14.48 70.21 29.79 
25H25S 4 34.33 65.67 27.99 72.01 
25H25S 8 61.13 38.87 40.64 59.36 
25H25S 12 72.89 27.11 40.42 59.58 
25H25S 16 80.39 19.61 46.74 53.26 
25H25S 20 82.34 17.66 46.56 53.44 
25H25S 24 84.08 15.92 52.3 47.70 
50H50S 5 34.18 65.82 25.62 74.38 
50H50S 12 67.23 32.77 33.02 66.98 
50H50S 19 77.35 22.65 37.14 62.86 
50H50S 26 84.99 15.01 38.52 61.48 
50H50S 33 85.98 14.02 41.52 58.48 
50H50S 40 86.41 13.59 41.3 58.70 
50H50S 45 86.5 13.50 41.43 58.57 
50H50S 49 85.97 14.03 40.42 59.58 
Table 17:- Showing the average blocking % results for K-Shortest Path vs Total Score Q-Routing using Latency & Bandwidth. 
For Q-Routing, each of the three figures shows that as the value of the AMC increased, the percentage 
of flows blocked by the algorithm decreased exponentially. However, like the results of Amalgamation 
Q-Routing, these results were not entirely consistent and followed a similar trend.  For both the 10 
Host and 10 Switch and 50 Host and 50 Switch topologies, the figures show after reaching a set value 
for the AMC, 5 and 26 respectively, the difference in the percentage of flows blocked did not change 
radically. Looking at the 50 Host and 50 Switch topology for example and using the average results 
from Table 15, when the AMC was 26, the difference in the percentage of flows blocked was 46.47% 
and when the AMC was 49, the difference was 45.55%. However, in contrast to the results from the 
10 Host and 10 Switch and 50 Host and 50 Switch topologies, the Q-Routing results for the 25 Hosts 
and 25 Switch topology were inconsistent. From Figure 48, it can be seen that the difference in the 
percentage of flows between K-Shortest Path and Q-Routing tended to vary. Looking again at the 
average results from Table 15, when the AMC was 12, the difference in the percentage of flows 
blocked was 32.47%. When the AMC was 16, the difference in the percentage was 33.65%. When the 
AMC was 20, the difference in the percentage was 35.78% and finally, when AMC was 24, the 
percentage difference was 31.78%. Admittedly the difference in the percentage of flows blocked did 
not alter as radically as the results showed for Amalgamation Q-Routing for the 25 Host and 25 Switch, 
but this percentage difference was on average greater than the percentage differences for the other 
two topology sizes. 
Finally, each of the figures shows that across each of the topologies, there was a difference in the 
variance between the two algorithms with Q-Routing showing more variance in each box and whisker 
plot for each AMC value (on average) than that of K-Shortest Path. This echoed the results of the 
previous two multi-metric Q-Routing algorithms. 
Figure 47:- Showing a Box & Whisker Plot for the Blocking Results for Total Score Q-Routing vs K-Shortest Path in a 10 Host 
10 Switch Topology using Latency & Bandwidth. 
Figure 48:- Showing a Box & Whisker Plot for the Blocking Results for Total Score Q-Routing vs K-Shortest Path in a 25 Host 
25 Switch Topology using Latency & Bandwidth. 
Figure 49:- :- Showing a Box & Whisker Plot for the Blocking Results for Total Score Q-Routing vs K-Shortest Path in a 50 
Host 50 Switch Topology using Latency & Bandwidth. 
5.4.3.4) Experiment 2, K-Shortest Path Performance Tests (Path Calculation Time and 
Blocking):- 
The first test of the second set of experiments conducted in this chapter looked at the relationship of 
the K-Value for each K-Shortest Path algorithm in regard to the time required to find a path between 
the source and destination nodes. The K-Value was initially set to a value of 1 increasing after each 
test to the default value of 250 with the time required to find a path recorded for each K-Value. The 
results were then compared to the equivalent Q-Routing algorithm. Regarding the Q-Routing 
algorithms, it should be noted that as the K-Value was a part of the K-Shortest Path algorithms only. 
The time required to calculate a path for each Q-Routing algorithm remained consistent regardless of 
the changing K-Value. 
Table 16 shows the time required to find a path for each algorithm for each value of K. From Table 16, 
it is clear that both Amalgamation and Total Score Q-Routing were capable of finding a path faster 
than the equivalent K-Shortest Path algorithm. The closest K-Shortest Path came to matching the 
performance was when the K-Value was set to 1 with K-Shortest Path achieving a result of 0.05 
seconds which was slightly higher than the 0.02 seconds achieved by both of the dual metric Q-Routing 
algorithms. 
 Latency, Total Link Bandwidth & 
Free Link Bandwidth 
Latency & Bandwidth 
K-Value K-Shortest 
Path (s) 
Q-Routing (s) K-Shortest 
Path (s) 
Amalgamation Q-
Routing (s) 
Total Score Q-
Routing (s) 
1 0.09 0.33 0.05 0.02 0.02 
5 0.09 0.33 0.1 0.02 0.02 
10 0.16 0.33 0.17 0.02 0.02 
50 0.76 0.33 1.56 0.02 0.02 
100 1.58 0.33 1.76 0.02 0.02 
150 2.33 0.33 2.36 0.02 0.02 
250 4 0.33 4.04 0.02 0.02 
Table 18:- Showing a comparison of the average times required to calculate a path for each of the Multi-Metric K-Shortest 
Path and Q-Routing algorithms when the K-Value is changed. 
Regarding the Q-Routing using Latency, Total Link Bandwidth and Free Link Bandwidth, the equivalent 
K-Shortest Path algorithm fared slightly better. For the K-Values 1, 5 and 10, K-Shortest Path took on 
average 0.09 seconds, 0.09 seconds, 0.16 seconds respectively, faster than the 0.33 seconds required 
by the Q-Routing algorithm. However, as soon as the K-Value increased to 50, K-Shortest Path became 
slower to calculate a path taking 0.76 seconds compared to 0.33 seconds required by Q-Routing. 
Figure 50 shows the time taken to find a path against the K-Value for each algorithm. From Figure 50, 
it is clear to see that as the K-Value increased, the time taken to find a path also increased for both of 
the K-Shortest Path algorithms, similar to the results from 4.4.3.4. 
Figure 50:- Showing the relationship between the Multi-Metric K-Value algorithms and the time to calculate a path 
compared to the equivalent Q-Routing algorithms. 
The second test of the second experiment was similar to the first test but instead looked at how the 
change in the K-Value affected the percentage of flows blocked by each K-Shortest Path algorithm in 
contrast to the equivalent Q-Routing algorithms. Table 17 shows the percentage of flows blocked for 
each algorithm for each value of K. 
 Latency, Total Link Bandwidth 
& Free Link Bandwidth 
Latency & Bandwidth 
K-Value K-Shortest 
Q-Routing K-Shortest 
Amalgamation 
Q-Routing 
Total Score 
Q-Routing 
1 48.57 48.18 48.23 60.95 60.34 
5 25.09 48.18 24.64 60.95 60.34 
10 19.34 48.18 21.35 60.95 60.34 
50 16.64 48.18 16.35 60.95 60.34 
100 15.41 48.18 15.01 60.95 60.34 
150 14.77 48.18 14.68 60.95 60.34 
250 14.06 48.18 11.95 60.95 60.34 
Table 19:- Showing a comparison of the percentages of flows blocked by each Multi-Metric K-Shortest Path compared to 
the equivalent Q-Routing algorithms. 
From Table 17, the first thing to note is that there is an inverse relationship between the K-Value and 
the percentage of flows blocked. As the K-Value increases in value, the percentage of flows blocked 
decreases. This relationship can be seen in Figure 51, a graph showing the percentage of flows blocked 
against the increasing K-Value for each multi-metric path calculation algorithm. This relationship is 
true for both of the K-Shortest Path algorithms.  
Figure 51:- Showing the relationship between the K-Value and the percentage of flows blocked by the Multi-Metric K-
Shortest Path algorithms compared to the equivalent Q-Routing algorithms. 
Secondly, from Table 17 and Figure 51, it is clear to see both K-Shortest Path algorithms, regardless of 
the K-Value achieved a lower percentage of flows blocked than the equivalent Q-Routing algorithms. 
There was one exception to this. When the K-Value was set 1, Q-Routing using Latency, Total Link 
Bandwidth and Free Link Bandwidth achieved a blocking percentage of 48.18% while K-Shortest Path 
using the same metrics achieved a slightly higher blocking percentage of 48.57%. 
5.5) Discussion:- 
In this section, the results of the experiments are analysed and discussed with reference to research 
papers where relevant. 
5.5.1) Discussion of the Multi-Metric Q-Routing Algorithms regarding the Percentage of 
Flows Blocked:- 
Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth:- As previously discussed, 
the first approach in implementing a Q-Routing algorithm that used multiple network metrics was 
based on existing research [93] that used RL within an SDN network environment for traffic 
engineering. While the application in the paper was different, the approach seemed like a viable one. 
The research had used a Q-Routing based algorithm that used multiple network metrics, latency, TLB 
and FLB where the latter was the real-time available bandwidth of the network path link between the 
current node and the next. These network metrics were aggregated together in a variant of the Q-
Learning formula (see section 5.3.2). The results from the paper claimed average success for this 
method when comparing the results to single path and multi-path approaches, achieving a lower-
than-average latency and an average throughput in comparison.  
It should be noted that the partial mesh network topology used for experimentation in the paper was 
smaller in size and had limited path options between source and destination nodes. However, the 
algorithm implemented in this chapter was judged by different criteria. Firstly, the algorithm was 
assessed by the percentage of flows that were Blocked or Active depending on the randomly 
generated QoS values for latency and bandwidth. Secondly, this Q-Routing algorithm was tested in 
topologies for different sizes with different values of mesh connectivity ranging from a partial mesh 
to a full mesh network topology. 
As the results show, this multi-metric Q-Routing algorithm failed to match the performance of the 
percentage of flows blocked in contrast with the results of K-Shortest Path. After a period of 
assessment, it was concluded that the policy learnt by this Q-Routing algorithm could never perform 
as well as K-Shortest Path. There were two reasons for this. Firstly, the scalarised reward formula took 
the values of multiple network metrics and generated one value that was used in the reward formula 
to train the Q table for a set destination during the training phase of the algorithm. After aggregation, 
there was no way for the policy that had been learnt to establish if the aggregated Q-Value value 
meant a link with low latency and high bandwidth or vice versa during the pathfinding phase. In 2008, 
a paper was published on Multi-Objective Reinforcement Learning (MORL) [143] which stated that 
unfortunately, whilst scalarised MORL is simple, it suffers from a fundamental flaw. Any system based 
on a linear combination of the objectives is incapable of finding solutions which lie in a concave region 
of the Pareto front. While the research into the Q-Routing algorithm presented here did not include 
a Pareto Front, the papers criticism of the linear combination of the objectives matched the findings 
for this pathfinding algorithm, as stated above. In contrast, the K-Shortest Path equivalent algorithm 
treated latency and bandwidth separately, so the results are not entirely comparable to Q-routing 
using the same metrics. Secondly, the reward formula used min to find the lowest value of Q for all 
neighbouring nodes. This would work for latency but was not compatible with the bandwidth element 
of the formula where max would have been more appropriate. 
There was one final point to note. The closest that this Q-Routing algorithm came to equalling the 
results of K-Shortest Path was on the smallest topology employed (10 Host and 10 Switch), when the 
AMC value was at its lowest value of 3. The difference in the blocking percentage between the two 
algorithms was 2.71%. This result was more in line with the moderate success reported in the paper. 
In both cases, small, low mesh density topologies were used. This would suggest that this algorithm is 
better suited to smaller topologies with lower AMC values in general. Alternatively, due to the limited 
number of path options between the source and destination nodes, it could be, for the majority of 
flows, that the Q-Routing algorithm consistently selected the same routes as K-Shortest Path. This too 
would explain the difference in the percentage of flows blocked between the two algorithms and why 
the difference increased on each of the three different size topologies as the AMC value. 
Amalgamation Q-Routing Using Latency and Bandwidth:- The second multi-metric algorithm 
implemented as previously discussed (see section 5.3.4) was different in a number of ways to that of 
Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth. Firstly, only two network 
metrics, latency and bandwidth were employed. This was a practical decision to aid algorithm 
development where if successful, additional network metrics could be introduced. Secondly, instead 
of training the Q-Table for a destination node using by combining latency and bandwidth together, 
the Q-Tables for Latency and Bandwidth were separate entities. This approach was based on the work 
carried out on the single metric Q-Routing algorithms from 4.3 and used because as the results for the 
algorithm Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth showed, combining 
multi-metrics in one Q-Table did not produce results comparable to the equivalent K-Shortest Path 
algorithm. Finally, instead of selecting a route based on a single, minimal value in the pathfinding 
phase as was the case for Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth, 
this algorithm would use the separately trained Q-Tables for latency and bandwidth. In the pathfinding 
phase, the amalgamation algorithm would try to find the optimal path using latency and bandwidth 
values using a simple formula. This formula would combine the two values in a way completely 
different than that used by Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth 
in the training phase. Unfortunately, after the completion of the first experiment, it was clear that the 
percentage of flows blocked by this algorithm was greater across all three different size topologies 
regardless of the AMC value than that of the equivalent K-Shortest Path algorithm.  
After assessing the results, it was established that this algorithm failed to match the performance of 
the K-Shortest Path algorithm for two reasons.  
The first was a similar reason to that of Q-Routing Using Latency, Total Link Bandwidth and Free Link 
Bandwidth. Similar because the issue was no longer in the training phase but, in the path finding phase 
instead. Whereas before, Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth 
could not distinguish between latency and bandwidth values when combined in the training phase, 
the same issue arose in Amalgamation Q-Routing in the pathfinding phase despite the two metrics 
being combined using a different method. Essentially, while accurate policies had been learnt by the 
algorithm resulting in fully converged Q-Tables for each destination node, these polices were being 
distorted in the pathfinding phase. The algorithm could either select a path based on latency or 
bandwidth. However, because the value used for path decision making was a combination of both 
metrics, the inevitable result was the selection of a suboptimal path for both metrics. 
The second reason related to the conflicting nature of the latency and bandwidth Q-Table estimates. 
The estimates calculated separately for latency and bandwidth for each destination node in the 
topology were accurate when used on their own but contradictory when used in tandem. If, for 
example, the current node in the pathfinding process was Node A, with Nodes B and Nodes C as 
neighbouring nodes leading to the destination node, it was perfectly possible that the Q-Table for 
latency would indicate that Node B would be best choice to reach the destination while the Q-Table 
for Bandwidth would contradict this and indicated Node C. It was also possible that the Q-Tables for 
both metrics would agree individually on the next node in the path to the destination but diverge 
further down the path. Given both issues, it was always unlikely that Amalgamation Q-Routing would 
be able to match the performance of K-Shortest Path. 
Total Scoring Q-Routing Using Latency and Bandwidth:- After the failure of the two previous multi-
metric algorithms to match the performance of the equivalent K-Shortest Path algorithms, the third 
multi-metric algorithm was designed to take a slightly different approach. The Total Score Q-Routing 
Using Latency and Bandwidth was similar to Amalgamation Q-Routing as it used the separately trained 
Q-Tables for latency and bandwidth as used in Chapter 4. This training method had proven to produce 
accurate estimates in the pathfinding phase and find comparable paths to K-Shortest Path, at least 
when a single metric was used. The key difference between Amalgamation and Scoring was the 
method used for path selection. While Amalgamation Q-Routing combined the latency and bandwidth 
values using a formula, Total Score Q-Routing assigned points to the latency and bandwidth values for 
each possible next step or node, with the lowest and highest latency and bandwidth values 
respectively being given a single point with the point value incrementing as the latency value increased 
and the bandwidth decreased. The neighbouring node that had the lowest combined score was 
selected as the next stop. 
However, the results like those of Amalgamation Q-Routing failed to equal those of the equivalent K-
Shortest Path algorithm. After analysing the algorithm and its performance, two reasons were 
identified for the algorithms inability to meet the performance of K-Shortest Path. The first was the 
scoring system: The low score representing a neighbouring node did not automatically mean that the 
Q-Table estimate for latency was the lowest and the bandwidth the highest. A low score could for 
example have meant that there was a low latency value but a low or average value bandwidth. A 
different neighbouring node could have had a larger bandwidth value but with a latency that was only 
slightly higher than that of the latency used to make up the low score. The flaw in this mechanism 
meant that it was possible for the algorithm to find suboptimal paths. The second was the same as 
the issue had affected Amalgamation Q-Routing, the conflicting nature between latency and 
bandwidth. For both reasons, it was highly unlikely that Total Score Q-Routing would have been able 
to perform as well as K-Shortest Path. 
5.5.2) Discussion of Multi-Metric K-Shortest Path Performance Tests (Path Calculation 
Time and Percentage of Paths Blocked):- 
Looking first at the K-Value in regard to the time required to find path, it is clear that K-Shortest Path 
using latency and bandwidth was not able to find a path as fast as either Amalgamation or Total Score 
Q-Routing. Even when the K-Value was set to 1, K-Shortest Path on average took 0.05 seconds 
compared to the 0.02 seconds required by both Amalgamation and Total Score Q-Routing.  
The result for K-Shortest Path Using Latency, Total Link Bandwidth and Free Link Bandwidth was 
slightly better as it could find paths faster on average than the equivalent Q-Routing algorithm when 
the K-Value was set to 10 or a lower value. When the K-Value was 10, K-Shortest Path could calculate 
a path in 0.16 seconds compared to the 0.33 seconds required by Q-Routing. The reason for this was 
due to the fact that Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth trained 
the Q-Table for the destination node in real time using 300 training cycles for each flow request to 
arrive in order to accommodate the Free Link Bandwidth for each link in the path. It was possible to 
take a similar approach to the Adaptive Q-Routing algorithms (Chapter 4), combining pre-trained Q-
Tables and continuous single training cycle updates, reducing the time taken to find a path. However, 
as the Q-Routing algorithm failed to perform as well as the K-Shortest Path equivalent due to the 
reasons stated previously, further development of this Q-Routing algorithm did not seem beneficial. 
Despite this, however, when the K-Value was set to a value of 50, K-Shortest Path took longer on 
average to find a path, 0.76 seconds on average compared to the 0.33 seconds on Q-Routing.   
In regard to the K-Value and the percentage of flows blocked, K-Shortest Path outperformed each of 
the Q-Routing algorithms for all values of K. There was one exception to this. When the K-Value was 
set to 1, Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth achieved a slightly 
lower percentage of flows blocked at 48.18% compared to K-Shortest Paths 48.57%. 
5.5.3) Discussion Summary:- 
After an analysis of the results, there are several observations that can be made:  
 The combining of network metrics in either the training phase or pathfinding phase of the Q-
Routing algorithms, specifically Q-Routing Using Latency, Total Link Bandwidth and Free Link 
Bandwidth and Amalgamation Q-Routing Using Latency and Bandwidth, is not a feasible 
approach. While Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth 
achieved a lower percentage of flows blocked on average than that of Amalgamation Q-
Routing, the percentage of flows blocked were still greater and failed to match the 
performance of K-Shortest Path using the same network metrics. 
 While the Total Score Q-Routing Using Latency and Bandwidth did not employ a formula in 
the path selection phase of the algorithm using a scoring system, the compromise required 
between latency and bandwidth led to sub-optimal path selections. The separate Q-Tables for 
latency and bandwidth also lead to conflicting path selection choices when choosing the next 
step or neighbouring node in the path between source and destination nodes.  
 For each of the three multi-metric Q-Routing algorithms, the closest that each algorithm came 
to matching the performance of the percentage of flows blocked by the equivalent K-Shortest 
Path algorithms was when the AMC was at the lowest value for each size topology. It is 
believed that this was due to fewer path options being available in each topology which meant 
that each of the Q-Routing algorithms was more likely to find the same paths as the K-Shortest 
Path algorithms. 
 K-Shortest Path was used as a basis of comparison for each of the three multi-metric Q-
Routing algorithms. However, it was not really a fair comparison. For example, K-Shortest Path 
using latency and bandwidth would find a list of different full paths based on latency that met 
the QoS latency requirement, then from this list select a path that met the QoS bandwidth 
requirement. In contrast, the multi-metric Q-Routing algorithms in either the training or 
pathfinding phases (depending on the algorithm) were attempting to combine multi-metrics 
into a one value to find a single path which, as the results show, often failed to meet the QoS 
requirements for either latency or bandwidth.  
 Despite the failure of each multi-metric Q-Routing algorithm to perform as well as their K-
Shortest Path algorithm counterparts, overall, Q-Routing, especially when the Q-Tables were 
pre-trained, was still able to find a path faster than K-Shortest Path as shown by the results 
and as indicated by the pathfinding time complexity of each algorithm. 
There are two primary conclusions that can be drawn from these results and the observations made. 
Regarding the training phase for any future multi-metric Q-Routing algorithm, creating and training 
separate Q-Tables for each network metric for every destination node is essential. This will allow path 
decisions in the pathfinding phase to be made based on QoS requirements with individual metric 
values that represent the real network topology conditions opposed to combined values that cannot 
be reconciled with the QoS requirements. Finally, the current methods of compromise for pathfinding 
between latency, bandwidth in the pathfinding phase do not allow for the optimal path to be selected, 
even when the separate Q-Tables for all metrics and for each destination node are known to be 
accurate. A method to compromise between opposing metrics such as latency and bandwidth is 
required. However, such a system would need to take into account not just the estimates from the 
neighbouring node to the destination but also, estimates further down each potential path to the 
destination to allow the optimal path to be found for any source and destination node pair.  
5.6) Chapter 5 Conclusion:- 
The overall objective for the research carried out in this chapter was to build upon the successful 
research completed in Chapter 4. The goal was to use Q-Learning and to create a version of the Q-
Routing pathfinding algorithm that was capable of using multiple network metrics (latency and 
bandwidth) where the path calculated would need to meet the requirements of randomly generated 
QoS metrics to simulate the real-life QoS metrics required by network applications. The performance 
of equivalent K-Shortest Path algorithms was used as a basis of comparison. Three separate multi-
metric Q-Routing algorithms were implemented. The first using Latency, Total Link Bandwidth & Free 
Link Bandwidth was based on existing research presented in a paper [93] while the other two using 
Latency and Bandwidth built on research carried out in the previous research chapter (Chapter 4). 
For the percentage of flows blocked, all three algorithms achieved a higher blocking percentage on 
average on each different size topology and for each different AMC than the equivalent K-Shortest 
Path algorithms. For Q-Routing Using Latency, Total Link Bandwidth and Free Link Bandwidth, this was 
due to the combining of the metrics with the reward formula in the training phase of the algorithm 
and the subsequent issue of using min or max for a single combined value that represented two 
conflicting metric values. For Amalgamation Q-Routing Using Latency and Bandwidth, this was due to 
the combination of metrics in the pathfinding phase and for Total Score Q-Routing using the same 
metrics, the problem was the compromise between metrics that resulted in suboptimal path 
calculation. Despite these results however, Amalgamation and Total Score Q-Routing were able to find 
paths faster than K-Shortest Path for all K-Values while Q-Routing Using Latency, Total Link Bandwidth 
and Free Link Bandwidth was able to calculate paths faster than K-Shortest Path for most values 
despite its lack of pre-training and its constant Q-Table training for every new flow request. 
Overall, despite the mixed results, there were some successes and more importantly, some interesting 
discoveries. Specifically, on what approaches do not work when attempting to use conflicting, multiple 
network metrics together in a single algorithm. 
Chapter 6:- Dual Metric, Multi Estimate, Pareto Q-Routing 
6.1) Introduction:- 
By utilising the successful outcomes from the research of the single metric Q-Routing algorithms 
(Chapter 4) and by analysing the results from the initial attempts to  implement multi-metric Q-
Routing algorithms (Chapter 5), the focus of this research in this chapter was to look at a multi-
estimate implementation of a multi-metric Q-Routing algorithm for both static and dynamic network 
environments. Once again as part of a centralised SDN environment. As with the previous chapters, 
the results for each test for the Q-Routing algorithms were compared against an equivalent, dual 
metric, K-Shortest Path algorithm.  
6.2) Chapter Objectives:- 
The aim of the research in this chapter was to build upon the work carried out in the previous two 
chapters, employing what had been proven to work and learning from what did not, to create a dual 
metric algorithm, utilised within SDN that could perform as well as K-Shortest Path. Specifically, there 
were two chapter aims:-  
1. The first was to implement a Dual Metric, Multi-Estimate, Pareto, Q-Routing algorithm and 
compare the performance results against a Dual-Metric, K-Shortest Path algorithm. 
2. The second was to alter the algorithm to allow it to adapt to a changing network 
environment with additional tests performed and the results once again compared to those 
of K-Shortest Path. 
As with the research in the previous chapters, the algorithms were implemented within the same SDN 
packet-switched testbed, created for this research. 
6.3) Q-Routing Multi-Metric Algorithm Development and Implementation:-  
6.3.1) K-Shortest Path using Latency and Bandwidth:- 
Algorithm Background:- This dual metric version of K-Shortest Path was designed to find routes 
between source and destination nodes to meet QoS requirements using latency and bandwidth. The 
performance results for this algorithm would act as a basis of comparison for the Dual Metric, Multi-
Estimate, Pareto Q-Routing algorithm. The implementation of this this K-Shortest Path version was 
identical to the version used in 5.3.3.  
6.3.2) Dual Metric, Multi-Estimate, Pareto Q-Routing:- 
Algorithm Background:- The research on the multi-metric, Q-Routing algorithms in Chapter 5 revealed 
the weaknesses of each of the algorithms and the reasons for their failure to perform as well as their 
K-Shortest Path counterparts. The Dual Metric, Multi-Estimate, Pareto Q-Routing algorithm presented 
in this chapter was designed to address these issues by incorporating existing elements from previous 
research that was proven to work and by adding new elements:- 
Separate Latency and Bandwidth Values:- The results of the research carried out in Chapter 5 show 
that combining the latency and bandwidth values, either in the training phase using a modified reward 
formula or in the pathfinding phase lead to inferior results. This was further illustrated by the results 
for the research in Chapter 4 where single metric Q-Routing performed as well as K-Shortest Path in 
terms of the percentage of flows blocked. In this algorithm, the latency and bandwidth values are 
never combined and always maintained as distinct, separate values. 
Multi, Tuple Pair Estimates:- One of the criticisms that literature has levelled against Q-Learning, is its 
inability to look ahead for potential problems [80] as Q-Learning only concentrates on the best 
immediate action at the current time. For Q-Routing, this means that it relies on the estimates from 
the nodes neighbouring the current node to select the next node in the path. The algorithm is not able 
to see past the next node. This was not an issue when Q-Routing was using a single metric. However, 
as highlighted by the research in Chapter 5, if two metrics are being utilised for pathfinding for a path 
that must meet QoS requirements where each metric is of equal importance, the standard Q-Routing 
approach is not suitable. This is because it is possible for one metric, such as latency, to suggest one 
course of action and bandwidth, another a different course of action. Even if both the latency and 
bandwidth values agree on the next node, it is highly likely that further down the path to the 
destination node, this conflict will occur again. To counter this, an alternative solution was required 
where the algorithm creates multiple estimates of latency and bandwidth, tuple pairs. Instead of the 
Q-Table for the destination node only storing one estimate for every other network node on how to 
reach the destination node, each network node can store multiple estimates as these estimates 
propagate backwards through the network when training is being undertaken. Once training is 
completed, each neighbouring node to the current node would contain many estimates on reaching 
the destination node where each estimate is a tuple containing the latency and bandwidth estimate 
values for the same path to the destination node, not conflicting paths. 
Separate Reward Formulas:- In 5.3.2, one of the issues identified was the use of a reward formula for 
multiple metrics. Once the metrics had been combined, the single estimate created was not optimised 
for either latency or bandwidth. This meant that a Q-Table for a destination node trained using such 
a reward formula produced sub-optimal results in terms of the percentage of flows blocked when 
compared to the equivalent K-Shortest Path algorithm. However, as demonstrated by the research in 
Chapter 4, single metric reward formulas did not have this problem. In this algorithm, the single metric 
Q-Routing reward formulas for latency and bandwidth established in Chapter 4 were used in tandem 
for Q-Table training. 
Implementation:- While employing elements from previous Q-Routing algorithms such as single 
metric reward formulas, the overall implementation of the Dual Metric, Multi-Estimate, Pareto Q-
Routing algorithm (please see Appendix C.9 for the pseudocode) was different from anything 
implemented in this research before. This was necessary as previous attempts, both in this research 
(Chapter 5) and current literature [93] [92] to implement a dual metric Q-Routing algorithm failed as 
these algorithms either prioritised one metric over another or combined metrics into one value, 
resulting in paths that were sub-optimal for either latency or bandwidth. To be able to use dual metrics 
within Q-Routing, a new approach was required. The following is an overview of how the algorithm 
was implemented to meet the dual metric challenge. Each phase of the algorithm for the training and 
the pathfinding phases are discussed separately.  
Training / Exploration:- Before training can commence, the Q-Tables for each potential destination 
node in the network topology needs to be created. Normally in standard Q-Routing, this would be an 
empty structure with pre-filled default values such as 0 for latency. In the case of this algorithm, the 
Q-Tables were pre-filled with 0 for latency and 500 for bandwidth. For bandwidth, this was needed 
as the Q-Routing with bandwidth reward formula required initial, large bandwidth values in order to 
work. Th value of 500 was selected as it was larger than any single edge value in any of the topologies 
used for testing.  However, during the implementation of this algorithm, it was discovered that adding 
the following two additional modifications to the Q-Table for each destination node increased overall 
performance. 
1. The first addition was for all the links/edges directly connecting nodes to the destination node 
to be pre-filled with the actual link values instead of default values. By doing this, overall 
convergence of the Q-Table and the number of cycles required to train the Q-Table for a 
destination node were reduced. 
2. The second addition was the introduction of a mechanism to calculate the mean values for 
both latency and bandwidth for the links/edges of all nodes (not including host nodes) directly 
connected to the destination node. These mean values were then used to populate the Q-
Table for the destination node for all nodes not directly connected to the destination node. 
This addition was added as it was discovered that default, pre-filled bandwidth values 
prevented the Q-Table for a destination node from fully converging. If the default bandwidth 
value was larger than the bandwidth value of any link connected to the destination node, the 
combining of the new and old estimates using a reward formula later on: i) reduced the 
number of accurate estimates created, ii) created estimates with latency and bandwidth 
values that did not reflect the actual network topology as each estimate was linked as a 
latency, bandwidth tuple pair. 
Once created, the first stage to train the Q-Table for a destination node was to select a forwarding 
node at random to act as the starting or continuation point for training. This node would become the 
Current Node. Having selected a Current Node, the next stage was to combine the link values from 
the Current Node to the neighbouring nodes with the neighbouring nodes estimates on how to reach 
the destination node. Figure 52 is an example that shows the Current Node, the tuple pair link value 
to each neighbouring node and the existing estimate from each neighbouring node to the destination 
node.  
Figure 52:- Showing how multiple estimates are created for the Q-Table of a Destination node. 
Once the Current Node (S1) has been selected, new, multiple latency and bandwidth (L,B) tuple 
estimates are created by combining the link information between S1 and the neighbouring nodes (S2, 
S3, S4, S5, S6) with each existing estimate from that neighbouring node to the destination node, SD. 
For example, if the link information between S1 and S2 is combined with the existing estimate 
between S2 and SD, the following is the result:- 
1 = (1 , 1)  Q2(L2, B2) 
(Eq. 17) 
Where NE1 represents the new estimate value and where the latency (L) and bandwidth (B) values 
are combined as follows:- 
 = 1 + 2 ,    = min (1, 2)  
(Eq. 18) 
This process is repeated for each of the neighbouring nodes resulting in five new tuple estimates (NE1, 
NE2, NE3, NE4, NE5). As multiple training cycles are completed and the estimates propagate backwards 
from node to node, it is possible for each neighbouring node to contain more than one estimate on 
how to reach SD from that neighbouring node.  
To prevent loops from forming and to increase convergence speed, a list is used to keep track of the 
nodes already visited where the Current Node is added to the list for each step in the training cycle. 
As a result, it is necessary to create two separate lists of tuple estimates. The first, called the Filtered 
Estimate List or FEL, removes from the list of new tuple estimates those estimates that correspond 
to nodes already visited. After a Pareto filtering process, FEL is used for selecting the next node in the 
path towards the destination node. 
The second list, called "Complete Estimate List" or CEL, is the completed list of tuple estimates without 
any filtering. This complete list, also, after undergoing a Pareto filtering process, is used for updating 
the existing estimates in the Q-Table for the destination node for the Current Node. The CEL list was 
required as it was discovered during testing, estimates corresponding to visited nodes removed from 
the FEL list were required to achieve a more complete list of estimates. 
The second stage is to reduce the number of estimates that have been collected. While each of these 
estimates represents latency and bandwidth values for reaching SD via the corresponding 
neighbouring node related to that estimate, some estimates are clearly inferior to others and can be 
removed without affecting the performance of the algorithm. A filter is required, ideally leaving the 
tuple estimates containing low latency and high bandwidth values or something close to this if no such 
estimate exists. To do this, a Multi-Objective Optimisation (MOO) approach is employed called a 
Pareto-Optimal Front resulting in a set of solutions that define the best trade-off between competing 
variables, in this case, latency and bandwidth. 
Figure 53:- Showing a Pareto Front comprised of the points in Figure 52. 
For any estimate to establish dominance over another, the objectives of that estimate (latency and 
bandwidth in this case) should be no worse than the objectives of the estimate it is trying to dominate 
with at least one objective being better. If one or more objective is superior, then that estimate can 
be said to have dominated the estimate with one of more inferior objectives [144]. Continuing the 
example and using the CEL tuple estimates, from Figure 52, all five estimates have been treated to 
MOO resulting in three estimates (NE1, NE2, NE4) estimates that dominate the other two estimates (NE3, 
NE5). These three dominant estimates are used to create the Pareto-Optimal Front. Figure 53 shows 
the estimates that made up the Pareto Front connected by a red line and the estimates with inferior 
latency and/or bandwidth values that have been dominated. 
As mentioned, both sets of tuple estimates (FEL, CEL) go through the Pareto Front Process. For the 
CEL list, because the Pareto Front Process removes those estimates which were dominated by the 
other estimates in the CEL list, using the Pareto filtered CEL list does not hamper the results as using 
the FEL list does. 
The third stage using the FEL set of tuple estimates is designed to identify the "Next Node" in the 
training/exploration process. When training first starts and the Current Node is also the Start Node, 
the FEL and CEL sets are identical as no nodes have been visited at this point. Continuing the above 
example and to illustrate the exploration process, FEL is defined as containing two tuple estimates 
(NE1, NE4). If there is only one tuple estimate, then the node associated with it is automatically 
designated as the "Next Node". If there are multiple estimates, then one is selected at random, and 
the node associated with the estimate is designated as the "Next Node". Following the example, if the 
tuple estimate (NE4) was randomly selected, the forwarding node would be S5 designated as the "Next 
Node". 
It should be noted that the random selection of the Next Node is only used primarily for the first step 
of the training cycle, to aid exploration and to establish a threshold based on bandwidth. In the first 
step, when the Next Node has been selected, the bandwidth value of the estimate is designated Bmax. 
Once the first step in the training cycle is complete and the Next Node is renamed as the Current Node 
for the next step, Bmax is used to determine which node is selected as the Next Node. From the tuple 
estimates available, only the estimates that contain a Bandwidth value equal to or larger than Bmax are 
considered. The surviving estimates are then ranked by latency which also ranks them by bandwidth 
due to the nature of the Pareto Front Process. Finally, the neighbouring node that corresponds to the 
first ranked estimate is selected as the Next Node. Because the bandwidth value in the tuple estimates 
increases for each step closer to the destination node, this process can be used reliably to find a direct 
path between the Start node and the destination node. If none of the tuple estimates contains a 
bandwidth value larger than Bmax, a neighbouring node is selected at random with Bmax being updated 
to the bandwidth value of the tuple estimate corresponding to that neighbouring node. 
The fourth stage is designed to update the Q-Table estimates for reaching the destination node from 
the perspective of the "Current Node". The Pareto filtered CEL set of tuple estimates is used in this 
instance because, in order for many accurate estimates to emerge after the training/exploration phase 
is complete, all tuple estimates on how to reach the destination node via each neighbouring node 
need to be included, regardless if that node has already been visited or not in a training cycle. 
To create new estimates for the Current Node, the existing tuple estimates for the Current Node are 
combined with the new tuple estimates in the CEL list based on the number of estimates that each 
contain using a case statement as demonstrated in Figure 54. Continuing the example, if there are 
two current estimates stored in the Destination Nodes Q-Table for the Current Node (EE1,EE2) and the 
Pareto filtered CEL list of make up the new estimates (NE1, NE2, NE4), then using Figure 54 as a guide, 
the estimates are combined as follows: i) The estimates containing the lowest latencies from each 
estimate list are combined (EE1, NE1). ii) The estimates containing the highest latencies from each list 
are combined (EE2, NE4). iii) The remaining new estimate from the CEL list (NE2) is combined with the 
current estimate with the closest latency that is less than or equal to the remaining new estimate 
which, for this example is EE1, resulting in EE1, NE2. 
Like that of the traditional Q-Routing, the current and new estimates are combined using a reward 
formula. In the case of this algorithm, two reward formulas are used; the traditional Q-Routing formula 
[22] that was employed in 4.3.4 for the latency element of each tuple estimate and a version of the 
traditional formula, derived to use bandwidth as utilised in 4.3.5 for the bandwidth element of each 
tuple estimate. The result is the creation of many, accurate estimates without the need to combine 
every existing estimate with every single new estimate in the CEL list.  
Both the latency and bandwidth parts of the new tuple estimates are calculated in tandem. After the 
new tuple estimates for the Current Node have been created, they are put through a filter to delete 
similar estimates and then, these tuple estimates are stored in the Q-Table, replacing all existing 
estimates for the Current Node in the Q-Table for the destination node. 
Figure 54:- Showing how the current and new tuple estimates for the Current Node are combined. 
The Final stage is to set the Next Node as the Current Node for the next step in the training cycle. All 
these stages are repeated for each step until the destination node has been reached. Once the 
destination has been reached, the training cycle has been completed where the number of training 
cycles varies depending on the size and complexity of the network topology. Once training / 
exploration has been completed in its entirety, the Q-Table should hold multiple, dual metric, accurate 
estimates from each network node in the Q-Table for the destination node. This differs from the single 
estimate and single metric approach of traditional Q-Routing. Table 18 shows a comparison between 
the two for an example Q-Table for SD. 
Forwarding Nodes in 
Topology 
Single Estimate, Single 
Metric Value 
Multi-Estimate, Dual Metric 
Values 
S1 L1 (L1,B1), (L1,B1), (L1,B1) 
S2 L2 (L2,B2), (L2,B2) 
S3 L3 (L3,B3), (L3,B3), (L3,B3), (L3,B3), (L3,B3) 
S4 L4 (L4,B4), (L4,B4), (L4,B4), (L4,B4) 
S5 L5 (L5,B5), (L5,B5), (L5,B5) 
S6 L6 (L6,B6) 
. . . 
. . . 
. . . 
SD N/A N/A 
Table 20:- Showing how multiple estimates are stored in a Q-Table for SD for the Dual Metric, Multi-Estimate, Pareto Q-
Routing algorithm (Right-hand Side) in comparison to traditional Q-routing (Left-hand Side). 
Pathfinding:- The implementation of the Pathfinding phase (Figure 55) of the algorithm is virtually 
identical to the Training/Exploration phase of the algorithm but with two key differences. 
Figure 55:- Implementation of the Pathfinding phase of Dual Metric, Multi-Estimate, Pareto Q-Routing. 
The first is the inclusion of the random QoS values generated by the SDN controller in the Next Node 
selection process. After the Pareto Front Process has been completed using the FEL list of tuple 
estimates, the tuple estimates are checked to see if they meet the QoS requirements for latency and 
bandwidth. If not, the neighbouring nodes associated with those estimates are rejected as the possible 
Next Node. If none of the estimates meets the QoS requirements, then the node associated with the 
tuple estimate that contains the largest bandwidth value is selected. 
The second difference is that each step ends after the Next Node has been selected. The Q-Tables 
have already been fully trained by this point and are only used for pathfinding without the need to 
update them. 
6.3.3) Adaptive Dual Metric, Multi-Estimate, Pareto Q-Routing:- 
The previous version of the Dual Metric, Multi-Estimate, Pareto Q-Routing algorithm was designed to 
be employed on static network topologies where nothing ever changed. No nodes or links ever failed. 
However, real-world networks can experience technical issues where for example, a node does fail, or 
a link becomes congested. To counter these issues, a version of the algorithm was implemented, 
designed to adapt to changing network conditions (please see Appendix C.10 for the pseudocode). 
Every time the SDN controller receives a request for forwarding instructions for reaching the host 
attached to a destination node from a source host attached to another node, the Q-Table for the 
destination node is re-trained where the number of re-training cycles is set to one but can be increased 
as required. This re-training takes place before the Q-Routing algorithm is used to find a path. This 
allows the re-training to partially update the pre-trained Q-Table, allowing the Pathfinding phase to 
find a path that takes into account the networks current state. Apart from the re-training element, 
there is no difference between this algorithm and the previously discussed, Dual Metric, Multi-
Estimate, Pareto Q-Routing algorithm. 
6.3.4) Comparison of the time complexity between Dual-Metric, Multi-Estimate, Pareto Q-
Routing and K-Shortest Path 
Table 21 shows a comparison of the time complexities for the training and pathfinding 
implementations (where relevant) of each dual-metric algorithm.  
Algorithm Name Time Complexity 
Training Pathfinding 
K-Shortest Path using Latency and Bandwidth N/A (2) [140] 
Dual-Metric, Multi-Estimate, Pareto Q-
Routing using Latency and Bandwidth 
(3) () 
Adaptive Dual-Metric, Multi-Estimate, Pareto 
Q-Routing using Latency and Bandwidth 
(3) () or (2) 
Table 21:- Showing a comparison between the time complexities for each dual-metric routing algorithm. 
For both of the Dual-Metric, Multi-Estimate, Pareto Q-Routing algorithm, the time complexity for 
training is the same as each previous Q-Routing algorithm. This is because the underlying structure in 
the implementation is also the same. However, while the static version of the Dual-Metric, Multi-
Estimate, Pareto Q-Routing algorithm has pathfinding time complexity of O(N), the time complexity 
of the adaptive version depends on the number of cycles used for re-training. If one cycle is used, then 
the time complexity is O(N). However, if more than one cycle is used for re-training, then the time 
complexity becomes O(N2), the same as the equivalent K-Shortest Path algorithm. 
6.4) Experiment Design and Results:- 
This section looks at the experiments undertaken to test the performance of each of the dual metric 
pathfinding algorithms, the experimental settings and the results from each of the experiments.  
6.4.1) SDN Controller Settings for Path Calculation Algorithms:- 
The optimal variable values for the Core SDN Controller program and the path calculation algorithms 
can be found in the appendix in section B.3. 
6.4.2) Experimental Procedure:- 
Three experiments were performed to test the overall performance of the Dual Metric, Multi-
Estimate, Pareto Q-Routing algorithm, similar to those experiments undertaken Chapter 4. The first 
experiment was the comparison of the Q-Routing algorithm against the equivalent K-Shortest Path 
algorithm where the percentage of blocked paths was compared using static network topologies (see 
section 4.4.2.1). The second experiment looked at the performance in terms of the percentage of 
flows blocked and the time required to find a path when the K-Value was changed in the K-Shortest 
Path algorithm (see section 4.4.2.2). These results were compared to Q-Routing.  
The two tests of the third and final experiment was slightly different to those discussed in section 
4.4.2.3. The first test was designed to test the algorithms ability to adapt to a changing network 
environment in real-time as it was in 4.4.2.3. However, this test was more comprehensive than the 
one previously performed in 4.4.2.3. Firstly, links were broken and restored every 10 flows instead of 
50. Secondly, the test lasted longer as more link breaks were introduced in combination with other 
link breaks (Figure 56). Finally, the test was repeated for the Q-Routing algorithm with the number of 
training cycles being increased from 1 initially to 5. 
The results of this test were compared to the results from the equivalent, Dual Metric, K-Shortest Path 
algorithm which used a K-Value of 250. 
Figure 56:- A custom topology to allow the testing of Q-Routing's ability to adapt to link changes in a dynamic, partial mesh 
network topology. 
The second test was again similar to the test carried out in 4.4.2.3 but with a few key differences. First, 
for the Q-Routing algorithm, the test was repeated with the first run using a single re-training cycle 
and the second, two re-training cycles. Secondly, the test was performed for different K-Values for the 
K-Shortest Path algorithm starting with a K-Value of 1 and increasing until 250. Thirdly, a mechanism 
was introduced to break and restore links at random in the topology where it was possible for up to 
ten links broken at any one time. Finally, the SDN controller for both algorithms were modified to take 
into account the real-time bandwidth usage for each, concurrent flow sent in the network topology. 
This meant that both algorithms could make path choices based on the actual available bandwidth 
and not just the overall bandwidth capacity of a link or a path. 
6.4.3) Experimental Results for Chapter 6:- 
6.4.3.1) Experiment 1, Comparison of the Blocking Percentage Results between Dual Metric 
K-Shortest Path and Dual Metric, Multi-Estimate, Pareto, Q-Routing:- 
This series of path-blocking performance tests were designed to compare the percentage of flows 
blocked between Dual Metric, Multi-Estimate, Pareto Q-Routing to the equivalent Dual Metric, K-
Shortest Path algorithm. Table 19 shows the percentage of flows that were accepted and blocked for 
the two algorithms. Taking into account the statistical discrepancies expected due to the nature of 
how the tests were performed, the results for Q-Routing are consistently similar to those of K-Shortest 
Path where, depending on the topology sizes and the AMC, the blocking percentage for Q-Routing is 
sometimes higher and sometimes lower. Typically, the deviation is within 1% of the equivalent K-
Shortest Path result. Notable exceptions to this include a 2.12% deviation on the 10 Host and 10 Switch 
topology, for an AMC of 3 where Q-Routing achieved a blocking percentage of 57.01% while the result 
for K-Shortest Path was 59.13% and a deviation of 1.5% on the 50 Host and 50 Switch topology for 
an AMC of 33 where the result for Q-Routing was 15.47% and K-Shortest Path, 13.97%. 
Table 22:- Showing the average results for the percentage of flows blocked for Dual Metric K-Shortest Path and Q-Routing. 
Figure 57, Figure 58 and Figure 59 show the results for the percentage of flows blocked for the 10 
Host and 10 Switch, 25 Host and 25 Switch and the 50 Host and 50 Switch topologies respectively in 
the form of a box and whisker plot. The shape of the distribution for both routing algorithms was 
virtually identical for both algorithms across all each of the three topologies of different sizes showing 
that Q-Routing on average was able to perform as well as K-Shortest Path. The main difference in the 
results was the variance of the Q-Routing box plots compared to those of K-Shortest Path. For each 
topology, when the AMC value was low, the variance between the results for Q-Routing was quite 
pronounced. However, this variance decreased as the AMC value increased suggesting that as more 
paths options became available, Q-Routing was able to produce more consistent results. In contrast, 
the variance for K-Shortest Path overall was less than Q-Routing but was not affected by the AMC 
value.  
Figure 57:- Showing the Box & Whisker Plot results for the percentage of flows blocked for the Dual-Metric Q-Routing and 
K-Shortest Path algorithms from a 10 Host 10 Switch Topology. 
Figure 58:- Showing the Box & Whisker Plot results for the percentage of flows blocked for the Dual-Metric Q-Routing and 
K-Shortest Path algorithms from a 25 Host 25 Switch Topology. 
Figure 59:- Showing the Box & Whisker Plot results for the percentage of flows blocked for the Dual-Metric Q-Routing and 
K-Shortest Path algorithms from a 50 Host 50 Switch Topology. 
6.4.3.2) Experiment 2, K-Shortest Path Performance Tests (Path Calculation Time and 
Blocking):- 
The second experiment was comprised of two tests designed to assess the performance of the Dual 
Metric, K-Shortest Path algorithm when the K-Value was altered from the default value of 250. 
Specifically, how changing the K-Value affected the percentage of flows blocked and the time to find 
a path. The results were compared to those of the Dual Metric, Multi-Estimate, Pareto, Q-Routing 
algorithm. As Q-Routing was not affected by the K-Value, the results for algorithm were used as a 
bases of comparison for K-Shortest Path. 
K-Value K-Shortest Path (ms) Pareto, Dual Metric Q-
Routing (ms) 
1 0.05 0.37 
5 0.09 0.37 
10 0.17 0.37 
50 0.8 0.37 
100 1.63 0.37 
150 2.54 0.37 
250 4.59 0.37 
Table 23:- Showing a comparison between Dual-Metric K-Shortest Path and Q-Routing between the average times required 
to find a path for each K-Value. 
The average results for the first test shown in Table 20 clearly show a proportional relationship 
between the K-Value and the time taken to find a path as the time required to find a path increases 
with the K-Value. Figure 60 further illustrates this point. For K-Shortest Path to find a path as fast as 
Q-Routings 0.37s, a K-Value between 50 taking 0.8s and 10 taking 0.17s is required.  
Figure 60:- Showing the relationship between the K-Value and the time to calculate a path for both Dual Metric Algorithms. 
For the second test, the time to find a path was replaced by the average percentage of flows blocked 
for Dual Metric, K-Shortest Path as the K-Value increased. Table 21 shows the average percentage of 
flows blocked for each K-Value and Figure 61 shows a graph of the relationship between the K-Value 
and the percentage of flows blocked. 
K-Value K-Shortest Path (%) Pareto, Dual Metric Q-
Routing (%) 
1 50.0935 
14.53 
5 24.0918 14.53 
10 21.1413 14.53 
50 17.2217 14.53 
100 15.3398 14.53 
150 14.8253 14.53 
250 14.4775 14.53 
Table 24:- Showing a comparison between Dual-Metric K-Shortest Path and Q-Routing between of the average percentage 
of flows blocked for each K-Value. 
When the K-Value is 1, the percentage of flows blocked is at 50.09%, meaning that just over half of all 
paths found did not meet the QoS requirements generated by the SDN controller. By comparison, Q-
Routing achieved a result of 14.53%. As the K-Value is increased, the percentage of flows blocked 
begins to reduce significantly with a result of 24.09% when K=5, 17.22% when K=50, 14.83% when 
K=150 and 14.48% when K=250, extremely close to Q-Routings 14.53%.   
Figure 61:- Showing the relationship between the K-Value and the percentage of flows blocked by Dual Metric K-Shortest 
Path and Q-Routing. 
The results (Figure 62) from these tests for Dual Metric, K-Shortest Path show that for a small K-Value, 
the algorithm is faster at finding a path between source and destination host nodes than when a large 
K-Value is used. However, as the K-Value decreases, the percentage of flows blocked increases. In 
contrast, the large K-Value allows K-Shortest Path to match the Q-Routing result for the percentage 
of flows blocked but at a greatly increase pathfinding time. Overall, the results show that Dual Metric, 
K-Shortest Path is unable to perform as well as Dual Metric, Multi-Estimate, Pareto, Q-Routing. The 
results of these tests are consistent with those performed in Chapter 4. 
Figure 62:- Showing the time to find a path against the percentage of flows blocked for Dual Metric K-Shortest Path for 
different K-Values compared to Dual Metric Q-Routing. 
6.4.3.3) Experiment 3, Adaptive, Dual Metric Q-Routing Performance tests in a Dynamic 
Network:- 
Similar to the tests performed in Chapter 4, the third experiment in this chapter was made up of two 
different tests designed to test how well the adaptive version of the Dual Metric, Multi-Estimate, 
Pareto, Q-Routing algorithm dealt with changes within a dynamic network environment. 
The first test was designed to see how long the adaptive version of the Q-Routing algorithm took to 
adapt to link breaks in the network topology for different number of re-training cycles where the 
results for K-Shortest Path was used as a basis of comparison. Overall, the results (Figure 63) show 
that the Q-Routing algorithm was very quick to adapt to a changing network topology. Adaptive Q-
Routing was quick to find an alternative, viable route that met the QoS requirements (if such a path 
existed) where the results mirrored those of K-Shortest Path. 
There were, however, two occasions where Q-Routing was not able to adapt instantly (between flows 
90-100 and 130-140). The link faults generated in these instances were closer to the destination node 
than the current node. This meant that the updated estimates relating to the link breaks took longer 
to propagate backwards to the current node causing a delay in adaptation. Though, as the results also 
show, it was possible to reduce this adaptation delay by increasing the number of re-training cycles 
within Q-Routing, reducing the number of flows required for the Q-Routing algorithm to adapt and to 
find a viable path meeting the QoS requirements. 
Figure 63:- Showing the number of flows required for Adaptive, Dual-Metric Q-Routing to adapt to network changes 
compared to Dual-Metric, K-Shortest Path. 
The second test of the third experiment was designed to test the performance of the Adaptive version 
of Dual Metric, Multi-Estimate, Pareto Q-Routing in terms of the percentage of flows blocked and the 
time required to find a path between source and destination nodes. Like the test undertaken in 
Chapter 4, this test used the 50 Host and 50 Switch topology with an AMC 49. There were, however, 
two distinct differences. At any one time in the topology, it was possible for up to ten links to be 
broken whereas this test in Chapter 4 had only used four. The topology in this instance was also 
designed to consider the real-time bandwidth availability of each link. This meant that once a path 
had been found between source and destination nodes, the bandwidth utilised by that flow to meet 
the QoS bandwidth requirement was taken away from the total bandwidth capacity of each link 
limiting the number of flows each link could support at one time, reflecting real packet-switched 
network topologies. Once the flow had ended, the utilised bandwidth would be re-added. 
The test was initially carried with 1 re-training cycle, then repeated with 2 re-training cycles. The 
results of these tests were compared to the Dual-Metric, K-Shortest Path algorithm using the same 
topology where the K-Value started at 1 and was increased over time to 250. 
Table 22 and Figure 64 shows the average results for the percentage of flows blocked and pathfinding 
times for each algorithm. The results show that the Dual Metric, Multi-Estimate, Pareto, Q-Routing 
algorithm was able to match the performance of the Dual Metric K-Shortest Path algorithm while 
being able to find paths noticeable faster. Using 2 re-training cycles, the percentage of flows blocked 
for Q-Routing was 14.21% taking 2.3s. For K-Shortest Path, when the K-Value was 250, the percentage 
was 14.53% taking nearly twice as long at 4.42s. Reducing the K-Value to 150 allowed K-Shortest Path 
to decrease the time required to find a path to 2.56s. This, however, was still slower than Q-Routing 
and resulted in an increased blocking percentage of 15.58%. To be able to find paths as fast as Q-
Routing, a K-Value of between 100  150 is required but at the cost of an increased percentage of 
flows blocked. In contrast, using only 1 re-training cycle for Q-Routing gave a reduced pathfinding time 
of 1.58s but resulted in an increased blocking percentage of 15.70%. for K-Shortest Path to complete 
with this based on time to find a path, a K-Value of between 50 and 100 is required, resulting in 
blocking percentages of 19.53% and 18.42% respectively. A noticeable increase on Q-Routings 15.70%.   
Algorithm Percentage of 
Flows 
Accepted (%) 
Percentage of Flows 
Blocked (%) 
Average Time to 
Calculate Path (S) 
K-Shortest Path, K =1 40.11 59.88 0.05 
K-Shortest Path, K =5 63.70 36.30 0.09 
K-Shortest Path, K =10 68.38 31.62 0.17 
K-Shortest Path, K =50 80.47 19.53 0.82 
K-Shortest Path, K =100 81.58 18.42 1.71 
K-Shortest Path, K =150 84.41 15.58 2.56 
K-Shortest Path, K =250 85.47 14.53 4.42 
Q-Routing x 1 Training Cycles 84.30 15.70 1.58 
Q-Routing x 2 Training Cycles 85.79 
14.21 2.3 
Table 25:- Showing the percentage of flows blocked and the path calculation times for both pathfinding algorithms. 
Finally, the relationship between the percentage of flows blocked and the time taken to find a path is 
demonstrated in Figure 64 with an exponential decay curve. As the K-Value decreases, the time 
required to find a path also decreases, resulting in an increased blocking percentage. These results are 
consistent with those in Chapter 4 and the results of the second experiment (Figure 62) in this chapter. 
Figure 64:- Showing the Path Calculation Time against the Percentage of Flows Blocked for each algorithm for different K-
Values and Re-Training cycles. 
6.5) Discussion:- 
In this section, the results of the experiments performed are analysed and discussed with reference 
to the relevant research papers. 
6.5.1) Dual Metric, Multi-Estimate, Pareto, Q-Routing and the Path Blocking Results:- 
The implementation of the Dual Metric, Multi-Estimate, Pareto, Q-Routing algorithm was a new 
approach, bringing together a collection of technical methods including the use of a centralised SDN 
Controller, a Pareto Front, dual reward formulas, and multi-estimates. The aim was to allow Q-Routing 
to be able to find a path between source and destination forwarding nodes to meet specific QoS 
requirements for latency and bandwidth. The performance of this Q-Routing algorithm was compared 
to an equivalent K-Shortest Path algorithm, altered to use the same two network metrics for 
pathfinding.  
When the results are compared for the percentage of flows blocked, the results show clearly that the 
performance of Q-Routing was overall consistent with that of K-Shortest Path indicating that the 
policies learnt in the training phase were able to accurately reflect K-Shortest Path. There were some 
discrepancies where Q-Routing blocked fewer flows than K-Shortest Path (i.e. 10 Host and 10 Switch, 
AMC of 3) or where K-Shortest Path blocked fewer flows than Q-Routing (i.e. 25 Host and 25 Switch, 
AMC of 4). In the case of the 50 Host and 50 Switch topology (excluding the result for when the AMC 
value was 19 where the Q-Routing result was lower), the blocking percentage of K-Shortest Path for 
each AMC value was slightly less than the equivalent Q-Routing values. It should be noted that the 
difference between the K-Shortest Path and Q-Routing was never more than 1.5% at its highest and 
0.26% at its lowest. Including the value for when the AMC value was 19, the average difference 
between the blocking percentages for K-Shortest Path and Q-Routing was 0.64%. Given the nature of 
the tests in the first experiment, this statistical variance is not unexpected. 
6.5.2) Dual-Metric, K-Shortest Path Performance Tests (Path Calculation Time and 
Percentage of Paths Blocked):- 
Similar to that of Chapter 4, the results for the second experiment show that in order for Dual Metric, 
K-Shortest Path to perform as well as Dual Metric, Multi-Estimate, Pareto, Q-Routing, a K-Value of 250 
was required, resulting in a blocking percentage of 14.48%, 0.05% lower than the 14.53% achieved by 
Q-Routing. However, for a K-Value of 250, the time required to find a path between two forwarding 
nodes took on average 4.59s, over four seconds longer compared to the 0.37s achieved by Q-Routing. 
For K-Shortest Path to be able to find a path faster than Q-Routing, a K-Value of between 10 and 50 is 
required taking 0.17s and 0.8s respectively. This, however, results in a blocking percentage of 21.14% 
when the K-Value is 10 and 17.22% when the K-Value is 50. It is clear that the Dual Metric, Multi-
Estimate, Pareto, Q-Routing algorithm is noticeably faster than Dual Metric, K-Shortest Path for 
pathfinding with performance that is in par with K-Shortest Path in terms of the percentage of flows 
blocked. 
6.5.3) Adaptive, Dual-Metric, Multi-Estimate, Pareto, Q-Routing (Path Calculation Time 
and Percentage of Paths Blocked):- 
This version of the Dual-Metric, Multi-Estimate, Pareto, Q-Routing algorithm was designed to allow 
the algorithm to adapt, to changing network circumstances (faulty links between two nodes, the 
latency value or bandwidth capacity of a link changing, the addition of new links, etc), updating its Q-
Tables which could then be used to find a path meeting QoS requirements. 
The first test in the third experiment was designed to test the algorithms ability to adapt to changes 
in the network topology. The results (Figure 63) of this test show that the adaptive version of Q-
Routing was, for the most part, as fast as the equivalent K-Shortest Path algorithm in adapting to link 
failures while updating the learnt policy. There were two exceptions to these results, from flows 90-
100 and 130-140, which took longer to adapt than K-Shortest Path. The generated link failures in both 
cases were in closer proximity to the destination node than other link breaks. This meant that the 
updated estimates relating to these link breaks took longer to propagate backwards, up the path 
towards the start node which could then use the freshly updated Q-Table for the destination node to 
select a path that did not have a link failure. However, as shown in the results, by using additional re-
training cycles, it was possible to speed up the backward propagation of estimates, allowing the 
algorithm to adapt faster to link faults. Looking at when five re-training cycles were used, Q-Routing 
performed noticeably better than when either one, or two re-training cycles were used as policy was 
update faster. For example, between flows 130 and 140, Q-Routing using five re-training cycles 
mirrored K-Shortest Path exactly. For the discrepancies at flows 70 and 90, it is believed that this is 
caused by oscillation between two paths, with one path meeting the QoS requirements and one not. 
When a link is restored or broken, it is possible that the estimates for the path meeting the QoS 
requirements paths to be similar to the path that does not meet the QoS requirements. This can result 
in Q-Routing oscillating between the two paths until the estimates have firmly settled [22].  
The second test of the third experiment was designed to test the performance of the adaptive Q-
Routing algorithm in a dynamic network environment where the real-time bandwidth availability of 
each link in the network was accounted for and where up to ten links failures could exist at one time. 
When using one training cycle, the percentage of flows blocked by Q-Routing was 15.70%, taking 1.58s 
on average to find a path. In comparison, K-Shortest Path with a K-Value of 250 achieved a blocking 
percentage of 14.53%, taking 4.42s. While this result was significantly slower than Q-Routing, the 
percentage of flows blocked was 1.17% less. However, when Q-Routing was used with two re-training 
cycles, the percentage of flows blocked decreased to 14.21%, taking 2.3s. Not only was the percentage 
of flows blocked on par with that of K-Shortest Path, but Q-Routing also remained faster than K-
Shortest Path by 2.12s. By contrast, in order for K-Shortest Path to find a path as fast as adaptive Q-
Routing, a K-Value of between 100 and 150 was required, resulting in pathfinding times of 1.71s and 
2.56s respectively. The disadvantage of this was that when the K-Value was 150, the blocking 
percentage decreased to 15.58%. Decreasing the K-Value further to 100 resulted in a blocking 
percentage of 18.42%.  
Overall and despite requiring two re-training cycles, Dual-Metric, Multi-Estimate, Pareto, Q-Routing 
was able to update policy and adapt to real-time network changes, performing as well as Dual Metric, 
K-Shortest Path in terms of the percentage of flows blocked while still being able to find a path faster 
between the source and destination nodes. These results are consistent with the results of the tests 
performed in the second experiment.   
6.5.4) Discussion Summary:- 
After reviewing the results of the experiments performed in this chapter for the Dual Metric, Multi-
Estimate, Pareto, Q-Routing algorithm, there are several observations that can be made, supported 
by these results:- 
 Both versions of the Q-Routing algorithm (static and adaptive) had performance on par with 
the Dual Metric, K-Shortest Path algorithm regarding the percentage of flows blocked. As in 
Chapter 4 and Chapter 5 (where relevant) the policy to emulate K-Shortest Path was 
successfully learnt in the training phase (confirmed by accurately trained Q-Tables) and 
employed without issue in the pathfinding phase. 
 While the adaptive version of Q-Routing was not as fast as the static version when it came to 
pathfinding, both Q-Routing algorithms were able to find a path faster than K-Shortest Path. 
 These results show that it is possible for Q-Routing to find a path based on two metrics 
without preferencing one metric over the other nor compromising overall performance. 
 As was the case in Chapter 4, the Pre-training of the Q-Tables for each destination node 
reduced the time required to find a path without affecting the performance of the Q-Routing 
algorithms. 
 For the adaptive version of the Q-Routing algorithm, using a single or multiple re-training 
cycles allowed the Q-Routing algorithm to adapt to a changing network topology while 
performing as well as K-Shortest Path overall. 
 In regard to scalability, Q-Routing continued to match the performance of K-Shortest Path on 
each different topology size for each different AMC value. As the results show, on the largest 
topology of 50 Hosts and 50 Switches with an AMC of 49, Q-Routing in both static and 
dynamic network environments was able to find a path faster between network nodes 
noticeably quicker than K-Shortest Path. While reducing K-Shortest Paths K-Value did allow 
for paths to be found faster, as the K-Value went down, the percentage of paths blocked 
increased. Overall, the results suggest that this multi-metric Q-routing algorithm is scalable. 
SDN was instrumental in the successful implementation of this Q-Routing algorithm. The advantages 
that SDN offered, including access to a complete network topology map upon initiation and 
centralised information created presented opportunities (such as Q-Table pre-training) that were not 
easily available in distributed networking. SDN also helped Q-Routing in terms of scalability as the 
server or computer where the SDN controller is located has access to increased memory, allowing 
larger Q-Tables to be stored than would be possible on a forwarding node such as a router or switch. 
A computer or server also is much faster at processing data than a forwarding node, allowing paths to 
be found faster using the large Q-Table information. 
6.6) Chapter 6 Conclusion:- 
The research in this chapter focused on two primary objectives. After having analysed the research 
outcomes from Chapter 4 and Chapter 5, the first objective was to learn from these outcomes and to 
implement a non-linear, dual metric Q-Routing algorithm, named Dual-Metric, Multi-Estimate, Pareto 
Q-Routing that could successfully find a path to support the QoS requirements for both latency and 
bandwidth equally. The second objective was to modify this Q-Routing algorithm so it could adapt to 
a dynamic network environment by re-training the Q-Tables for destination nodes when required.  
Overall, it is clear from the results presented that both objectives have been accomplished. In the case 
of the first object, the Dual-Metric, Multi-Estimate, Pareto Q-Routing algorithm was able to find a path 
between two nodes using both latency and bandwidth as network metrics to meet QoS requirements. 
The performance for the percentage of flows blocked after considering statistic discrepancies matched 
the performance of the Dual Metric, K-Shortest Path algorithm. However, K-Shortest Path took 
noticeably longer to find path than Q-Routing. Reducing the K-Value did reduce the time required for 
K-Shortest Path to find a path but as previously discussed, increased the percentage of flows blocked 
by K-Shortest Path. 
In the case of the second objective, the results in many respects were similar to that of the first 
objective. Not only was the percentage of flows blocked on par between the adaptive version of the 
Dual-Metric, Multi-Estimate, Pareto Q-Routing algorithm and Dual Metric, K-Shortest Path, but again, 
the adaptive version of Q-Routing was faster to find a path than K-Shortest Path. Altering the K-Value 
achieved the same result as discussed previously. The key difference, of course, was that the adaptive 
version of Q-Routing was able to adapt successfully to a changing network environment while 
maintaining equal performance to K-Shortest Path in the respects discussed above.  
So, to conclude, based on the tests performed and the results presented, both objectives were 
completed successfully. These tests and the subsequent results show that it is possible; i) for 
centralised, SDN, Q-Routing to use more than one network metric, ii) to find a path given equal 
importance to each metric, iii) for dual metric, Q-Routing to perform as well as dual metric K-Shortest 
Path, iv) for dual metric, Q-Routing to find a path faster than dual metric, K-Shortest Path, v) finally, 
for Q-Routing to accomplish all of this while taking into account the real-time bandwidth of each 
network link within the network topology and adapting to unexpected changes to the network 
topology.  
Chapter 7:- Conclusion and Future Work 
7.1) Conclusion:- 
The primary objective for the research performed in this Thesis was to design and implement a Q-
Routing based algorithm within a centralised, SDN controlled network environment, capable of finding 
paths (if available) to meet multiple QoS requirements of a network application. To achieve this 
outcome, the research was split into three different phases. 
The first phase (Chapter 4) was designed to implement single metric Q-Routing algorithms (Q-Routing 
using latency, Q-Routing using bandwidth) both for static and dynamic network environments. The 
second phase (Chapter 5) was designed to look at three different methods (Q-Routing using latency, 
total link bandwidth and free link bandwidth, Amalgamation Q-Routing using latency and bandwidth, 
Total Score Q-Routing using latency and bandwidth) for implementing a multi-metric Q-Routing 
algorithm. The final phase (Chapter 6) focused on the implementation and testing of the Dual Metric, 
Multi-Estimate, Pareto, Q-Routing algorithm in both static and dynamic network environments. The 
following is a summary of the main outcomes, key points and advances in knowledge relating to these 
three research phases. For reference, the detailed conclusions for each phase can be found at the end 
of each of the corresponding chapters (see sections 4.6, 5.6 and 6.6). 
Q-Routing using Bandwidth: One of the successful outcomes of Chapter 4 was the creation and 
implementation of single metric Q-Routing using bandwidth instead of latency for both static and 
dynamic network environments. This was unique as the literature review did not reveal any examples 
of similar Q-Routing algorithms, either in distributed or SDN networks at the time of review. This 
outcome was also important as it was eventually required as part of the successful implementation of 
the Dual Metric, Multi-Estimate, Pareto, Q-Routing algorithm as demonstrated in the final phase of 
the research (Chapter 6). 
Separation of the Training and Pathfinding Phases: Originally mentioned earlier in the Thesis as a 
theoretical concept (see sections 1.3 and 2.7), one of the key research aims was to use the advantages 
of SDNs centralised approach to improve the overall efficiency of the Q-Routing algorithm in general. 
As SDN had access to a map of the topology, Q-Routing using this information could pre-train all Q-
Tables before the network was active, thus saving on the time required for Q-Routing to achieve 
convergence. This concept was put into practise for the majority of the Q-Routing algorithms. The test 
results (4.4.3, 6.4.3) for the percentage of flows blocked show that pre-training the Q-Tables allowed 
both the single metric algorithms and the Dual Metric, Multi-Estimate, Pareto, Q-Routing algorithm 
respectively to perform as well as the equivalent K-Shortest Path algorithms as soon as the network 
was initiated. While the Amalgamation Q-Routing and Total Score Q-Routing algorithms presented  
Chapter 5 failed to perform as well as the equivalent K-Shortest Path algorithms, it should be noted 
that this was due to how the multiple metrics were combined in the pre-training and not due to the 
pre-training itself. 
Adaptation: In order for Q-Routing using pre-trained Q-Tables to be effective in a dynamic network 
environment, it was necessary to add adaptive element to the algorithm so after network initiation, 
the Q-Tables could be updated to cope with any changes to the network topology. This took the form 
of re-training cycles which were implemented to partially re-train the Q-Table for the destination node 
of a flow, just before the pathfinding phase. The adaptive test results for the single metric algorithms 
(see section 4.4.3.5) and the Dual Metric, Multi-Estimate, Pareto, Q-Routing algorithm (see section 
6.4.3.3) show that not only did this concept work, the algorithms performed as well as their K-Shortest 
Path equivalents regarding the percentage of flows blocked. These adaptive Q-Routing algorithms 
were also able to find a path faster than the K-Shortest Path equivalent algorithms.  
Combining Multiple Metrics: One of the key discoveries that eventually lead to the successful 
outcomes in Chapter 6 was how to successfully use multiple metrics for Q-Routing based pathfinding. 
The research undertaken in Chapter 5 explored three different methods on how to combine multiple 
metrics in Q-Routing, either in the training phase in one reward formula or in the pathfinding phase. 
While the reasons for this differed (see section 5.6), the overall conclusion, supported by literature 
[143] show that combining multiple metrics will produce sub-optimal outcomes. However, by treating 
each metric as separate entities in both the training and pathfinding phases, it was possible to create 
a dual metric, Q-Routing based algorithm that could successfully perform as well as the equivalent K-
Shortest Path algorithm.   
Multiple, Tuple Pair Estimates: In Chapter 5, both the Amalgamation and Total Score Q-Routing 
algorithms used separate Q-Tables for latency and bandwidth in the training phase. However, this 
separation of values in the training phase led to challenges in the pathfinding phase, mainly the 
conflicting nature of selecting a path using competing, and sometimes contradictory metrics (see 
section 5.6). By having one estimate solution for each metric, this ongoing conflict led to sub-optimal 
routing performance. The use of tuple pair estimates, where each tuple pair estimate was made up of 
latency and bandwidth (L,B) resolved this conflict. As each tuple pair estimate represented the 
estimate for the same path to the destination node for both metrics, there was no conflict between 
metrics. Creating multiple tuple estimates, refined by a MOO approach in the form of a Pareto Front 
allowed for multiple, valid estimates that could be used for QoS based pathfinding. The successful 
outcomes of Chapter 6 effectively demonstrated the efficacy of this overall approach. 
Pathfinding Times: From the experiments performed, the results clearly show that for all the Q-
Routing algorithms (both static and dynamic), Q-Routing in general was faster at pathfinding than K-
Shortest Path while matching the performance of K-Shortest Path in terms of the percentage of flows 
blocked. This outcome was also supported by current literature [23]. The exception to this was the 
multi-metric, Q-Routing based algorithms of Chapter 5. As stated in section 5.6, these three algorithms 
were unable to match the performance of the equivalent K-Shortest Path algorithms in terms of the 
percentage of flows blocked. However, it should be noted that despite the Q-Routing using latency, 
total link bandwidth and free link bandwidth algorithm not undertaking any pre-training, K-Shortest 
Path required a K-Value of 10 or lower to be able to find a path faster that Q-Routing using latency, 
total link bandwidth and free link bandwidth. It should also be noted that even when the K-Value was 
set to 1, both Amalgamation Q-Routing and Total Score Q-Routing were still able to find a path quicker 
than then equivalent K-Shortest Path algorithms.  
Q-Routing Performance: In terms of the percentage of flows blocked, it is clear from the results that 
Q-Routing in general can perform as well as K-Shortest Path when it comes to finding a path to meet 
QoS requirements. This is true for both single metric Q-Routing and dual metric Q-Routing as 
evidenced by the results for Chapter 4 and Chapter 6 respectively, for both static and dynamic variants 
of the Q-Routing algorithms.  
Given the results and outcomes presented in this Thesis, the primary goal of creating a multi-metric-
based routing algorithm within a centralised SDN controller network topology has been successfully 
achieved. Moreover, the resulting algorithm, Dual Metric, Multi-Estimate, Pareto, Q-Routing conforms 
to the specifications as defined in section 1.3. While the multi-metric algorithms of the second 
research phase (Chapter 5) failed to perform as well as the equivalent K-Shortest Path algorithms in 
terms of the percentage of flows blocked, the reasons for these failures provided a valuable learning 
curve. The understanding gained from the second research phase, combined with the successful 
completion of the first research phase (Chapter 4), helped to define the direction for the research in 
the final phase (Chapter 6), including the inclusion of novel concepts such as multiple estimates. 
In conclusion, the Dual Metric, Multi-Estimate, Pareto, Q-Routing algorithm performs as well as K-
Shortest Path for QoS based pathfinding while taking less time to do so. Given this, the successful 
implementation of this algorithm demonstrates a possible solution to the challenge presented by the 
increase in short-term and long-term internet usage. While real-world testing and additional 
refinement of the algorithm maybe required, it is believed that in time, ML based algorithms such as 
the Dual Metric, Multi-Estimate, Pareto, Q-Routing algorithm could become a viable alternative to 
heuristic algorithms such as K-Shortest Path. 
7.2) Future Work:- 
In regard to future research relating to the work undertaken in this Thesis, there are several avenues 
to explore that could potentially increase the utility and efficiency of the Dual Metric, Multi-Estimate, 
Pareto Q-Routing algorithm.    
QoS Soft Limits: In the routing algorithm presented in Chapter 6 (Dual Metric, Multi-Estimate, Pareto 
Q-Routing), randomly generated QoS values were used to filter estimates during each step in the 
pathfinding phase. Only these neighbouring nodes to the current node that had tuple estimates that 
met both the latency and bandwidth QoS requirements were considered as possible next nodes. It 
should be noted that hard limits were used to decide which nodes met the QoS criteria and which 
didnt. This meant that a potential path option could be removed because, one metric might just miss 
the QoS requirement. For example, for an application that has to meet certain QoS requirements 
(Latency = 10ms, Bandwidth = 90Mbits), if one of the tuple estimates for reaching the destination 
node from via a neighbouring node had a latency value of 5ms and a bandwidth of 89Mbits, that 
estimate and the corresponding neighbouring node would be rejected. 
To increase the number of paths options and the overall flexibility of the algorithm, a soft limit 
approach could be used introducing an element of compromise. Using the above example, a soft limit 
approach would mean that the neighbouring node associated with the tuple estimate containing a 
latency of 5ms and a bandwidth of 89 Mbits would be accepted as a possible option as the next node. 
Given the low latency, might turn out to be the most efficient option overall. There are several 
approaches to implementing this. One idea is to accept estimates that are within a certain tolerance 
threshold of the QoS requirements where the threshold value could be increased or decreased 
depending on the nature of the network applications being used. Another option is to use fuzzy logic 
to decide if a node associated with a tuple estimate should be accepted or not. A paper based on the 
research presented in this thesis [26] investigated the use of fuzzy logic in tandem with the Dual 
Metric, Multi-Estimate, Pareto, Q-Routing algorithm for this purpose. Preliminary results confirmed 
that fewer traffic flows were blocked if the QoS requirements were relaxed. 
Network Metrics: The Dual Metric, Multi-Estimate, Pareto, Q-Routing algorithm presented was 
designed to use two metrics, latency and bandwidth. In the case of the adaptive version of this 
algorithm, the real-time available bandwidth of each link/edge within the specific path. Despite the 
overall success of this algorithm, additional research (time permitting) would have looked at 
introducing a third metric. This would have allowed paths to be found between source and destination 
nodes that would meet the specific QoS requirements of network applications that required more 
exacting standards. Future work could look at continuing the research presented in this vein by adding 
additional metrics such as jitter, packet loss and error rate to the algorithm. 
Technological Heterogeneity: The focus of the research presented in this Thesis was the use of Q-
Routing within SDN in packet-switched networks. Packet-switched networks still play an important in 
networks across the world, especially home and small business environments. However, as new 
infrastructure is installed or upgraded to incorporate optical fibre and wireless technologies (4G, 5G, 
Wi-Fi, etc), the reliance on packet-switched networking technology is declining. This means that 
routing algorithms designed for packet-switched networks either need to be replaced or upgraded to 
cope with the reality of technological network heterogeneity. 
In terms of the Dual Metric, Multi-Estimate, Pareto, Q-Routing algorithm, future work could look at 
creating a version designed for optical or wireless routing. SDN for both optical and wireless 
technologies (SDON [59] and SDWN [57] respectively) are active field of research so adding the Dual 
Metric, Multi-Estimate, Pareto, Q-Routing algorithm to these platforms would seem feasible. Existing 
network metrics used in packet-switched networks could be substituted for values specific to optical 
and wireless technologies:- 
 Space: Number of Interfaces on the device (ports, antennas, etc). 
 Frequency: Wireless frequency.  
 Wavelength: Optical Wavelength. 
 Time: Time Division Multiplexing (TDM) or similar multiplexing methods. 
While the viability of this approach or similar ones would need to be tested, this is an area worth 
exploring in a greater detail. 
Faster Convergence: One of the challenges that Q-Routing faces is the time required to train the Q-
Tables for each destination node. This is an issue for both distributed and centralised Q-Routing. While 
the advantages that SDN offers does allows for faster convergence, there are some additional 
approaches that could be utilised to reduce the number of training cycles required in the training 
phase and decrease the overall convergence time. For example, DRQ-Routing [23] uses Backwards 
Exploration where the current node updates the nodes that neighbour it with Q-Table information 
about the that path already travelled (see section 2.4.3.5). AQRERM [91] replaced Full Echo with 
Random Echo where, instead of the current node requesting estimates from every neighbouring 
node, each neighbouring node had a random chance of being selected to supply an estimate to the 
current node (see section 2.4.3.4). Dual Metric, Multi-Estimate, Pareto, Q-Routing by contrast, was 
based on the original Q-Routing algorithm [22]. Future work in this regard could include improving the 
overall efficiency of the algorithm by experimenting with methods such as those stated to decrease 
convergence time. 
Additional Reinforcement Learning Approaches: The focus of the research presented centred on the 
use of Q-Learning as the core of a new multi-metric routing algorithm in a centralised SDN network 
environment. There are, however, alternative RL algorithms that would be worth investigating in 
future. For example, DQN was briefly covered in section 2.3.5 as an alternative to Q-Learning but was 
not considered for two reasons. First, it was overly complex for the purpose at hand, contradicting the 
simplicity planned for the multi-metric algorithm. Secondly, DQN was originally designed as an off-line 
algorithm which meant real-time adaption would not have been possible. 
However, there has been much research into DQN since then, making it more suitable as an avenue 
for future research for multi-metric routing. If, for an example, a routing algorithm using more than 
two metrics was required, DQNs complexity, along with the scalability offered by the algorithms 
reward function (which replaces the Q-Tables used by Q-Learning) could be more suited to a multi-
metric routing problem. A recent paper published in 2020 [94] (as previously discussed) that looked 
at DQN for routing created an online version of DQN, this allowing for the possibility of real-time 
adaptation to changing network conditions. 
Apart from DQN and Q-Learning, there are other RL that could be investigated for suitability including 
SARSA, an RL algorithm similar to that of Q-Learning but uses an on-policy approach and DDPG, an RL 
algorithm better suited to problems where the action space is continuous rather than discreet, making 
it suitable for large scale applications.    
Improving the SDN Testbed to increase model realism and accuracy: As previously discussed (please 
see section 3.4), the SDN testbed had a number of limitations that affected the realism of the 
platform. Future work on the SDN testbed could increase the platforms realism by considering and 
implementing the following aspects:- 
 Packet-based traffic: The SDN testbed currently is designed to create flow-based traffic. 
However, adding the ability to generate packet-based traffic (more commonly used in real life 
networks) would add a degree of realism to the model. 
 Traffic per host: Currently, only one traffic flow can be generated by each host in a Mininet 
topology at one time. As a host is capable of generating multiple traffic flows at one time, this 
is not realistic. To remedy this within the current model, additional hosts could be connected 
to the same switch as the original host is connected too. This way, it would be possible to 
generate more than one traffic flow between the same source and destination node pair at 
the same time. 
 Traffic Models: While traffic is generated on random hosts at random time intervals, traffic 
generation within the SDN testbed is not based on any actual models. Different traffic models 
could be employed (depending on the network type) to further increase the realism of the 
overall platform. 
 Network Type: The mesh topologies created for the SDN testbed were generic in nature and 
did not reflect any specific network type. To remedy this, topologies created in future could 
either be design to emulate real-life network topologies or at least, specific network types 
such as WANs, LANs, MANs, etc. 
References:- 
[1] B. M. Leiner, R. E. Kahn, and J. Postel, A Brief History of the Internet, ACM SIGCOMM 
Comput. Commun. Rev., vol. 39, no. 5, p. 10, 2009. 
[2] J. Johnson, Activities performed online by individuals in Great Britain in 2020, Statista, Nov. 
10, 2020. https://www.statista.com/statistics/275805/internet-activities-performed-in-great-
britain/ (accessed Jul. 28, 2021). 
[3] Cisco Annual Internet Report (20182023) White Paper, Cisco, Mar. 09, 2020. 
https://www.cisco.com/c/en/us/solutions/collateral/executive-perspectives/annual-internet-
report/white-paper-c11-741490.html (accessed Jul. 27, 2021). 
[4] WHO Director-Generals opening remarks at the media briefing on COVID-19 - 11 March 
2020, World Health Organization, Mar. 11, 2020. https://www.who.int/director-
general/speeches/detail/who-director-general-s-opening-remarks-at-the-media-briefing-on-
covid-19---11-march-2020 (accessed Jul. 30, 2021). 
[5] First Day of Stay at Home Order in the United States, timeanddate.com, 2021. 
https://www.timeanddate.com/holidays/us/lockdown-day-1 (accessed Jul. 30, 2021). 
[6] Lockdown leads to surge in TV screen time and streaming, OFcom, Aug. 05, 2020. 
https://www.ofcom.org.uk/about-ofcom/latest/features-and-news/lockdown-leads-to-surge-
in-tv-screen-time-and-streaming (accessed Jul. 30, 2021). 
[7] UK internet use doubles in 2020 due to pandemic, BBC News, Dec. 30, 2020. 
https://www.bbc.co.uk/news/technology-55486157 (accessed Jul. 30, 2021). 
[8] Keeping the Internet up and running in times of crisis, OECD, May 04, 2020. 
https://www.oecd.org/coronavirus/policy-responses/keeping-the-internet-up-and-running-
in-times-of-crisis-4017c4c9/#section-d1e279 (accessed Jul. 31, 2021). 
[9] M. Candela, V. Luconi, and A. Vecchio, Impact of the COVID-19 pandemic on the Internet 
latency: A large-scale study, Sci. Direct, vol. 182, Dec. 2020, doi: 
10.1016/j.comnet.2020.107495. 
[10] C. Knowles, Internet outages drastically increased during COVID-19 lockdowns, report finds, 
IT Brief, Aug. 07, 2020. https://itbrief.co.nz/story/internet-outages-drastically-increased-
during-covid-19-lockdowns-report-finds (accessed Aug. 02, 2021). 
[11] A. Bergman and J. Iyengar, How COVID-19 is affecting internet performance, Fastly, Apr. 08, 
2020. https://www.fastly.com/blog/how-covid-19-is-affecting-internet-performance 
(accessed Aug. 03, 2021). 
[12] F. Chee, YouTube, Amazon Prime forgo streaming quality to relieve European networks, 
Reuters, Mar. 20, 2020. https://www.reuters.com/article/us-health-coronavirus-youtube-
exclusive-idUSKBN2170OP (accessed Aug. 04, 2021). 
[13] D. Brake, Lessons From the Pandemic: Broadband Policy After COVID-19, ITIF, Jul. 13, 2020. 
https://itif.org/publications/2020/07/13/lessons-pandemic-broadband-policy-after-covid-19 
(accessed Aug. 03, 2021). 
[14] Telstra CEO Andy Penn is encouraging families working from home to spread out internet use 
as a way to cope with sluggish networks, B&T Magazine, Mar. 19, 2020. 
https://www.bandt.com.au/telstra-boss-recommends-rationing-internet-use-as-network-
strains-under-increased-load/ 
[15] D. Kreutz, F. M. Ramos, P. Esteves Verissimo, C. Esteve Rothenberg, S. Azodolmolky, and S. 
Uhlig, Software-defined networking: A comprehensive survey, Proc. IEEE, vol. 103, no. 1, pp. 
1476, 2015. 
[16] E. Dijkstra, A note on two problems in connexion with graphs, Numer. Math., vol. 1, pp. 269
271, Dec. 1959, doi: https://doi.org/10.1007/BF01386390. 
[17] R. Bellman, On a routing problem, Quart Appl Math, vol. 16, pp. 8790, 1958. 
[18] L. Ford, Network Flow Theory, 1956, vol. 923. 
[19] C. Hopps, Analysis of an Equal-Cost Multi-Path Algorithm, IETF, Nov. 2000. 
https://datatracker.ietf.org/doc/html/rfc2992 (accessed Jan. 17, 2022). 
[20] J. Yen, Finding the K Shortest Loopless Paths in a Network, Manag. Sci., vol. 17, no. 11, pp. 
712716, Jul. 1971. 
[21] C. Watkins, Learning from delayed rewards, Kings College, London, 1989. Accessed: Dec. 27, 
2018. [Online]. Available: http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf 
[22] J. Boyan and M. Littman, Packet Routing in Dynamically Changing Networks: A Reinforcement 
Learning Approach, in Proceedings of the 6th International Conference on Neural Information 
Processing Systems, Denver, Colorado, Nov. 1993, pp. 671678. 
[23] S. Kumar and R. Miikkulainen, Dual Reinforcement Q-Routing: An On-Line Adaptive Routing 
Algorithm, Smart Eng. Syst. Neural Netw. Fuzzy Log. Data Min. Evol. Program., vol. 7, 1997. 
[24] D. Harewood-Gill, T. Martin, and R. Nejabati, The Performance of Q-Learning within SDN 
Controlled Static and Dynamic Mesh Networks, Ghent, Belgium, 2020, pp. 185189. doi: 
10.1109/NetSoft48620.2020.9165530. 
[25] D. Harewood-Gill, T. P. Martin, and R. Nejabati, Q-Routing Using Multiple QoS Metrics in 
SDN, presented at the UKCI 2021, Aberystwyth, UK, 2021. 
[26] T. P. Martin and D. Harewood-Gill, Q-Routing with Multiple Soft Requirements, presented at 
the UKCI 2021, Aberystwyth, UK, 2021. 
[27] A. Tanenbaum and D. Wetherall, Computer Networks, 5th ed. Harlow: Pearson Education, 
2013. 
[28] Link State Routing Definition, The Linux Information Project, Nov. 01, 2005. 
http://www.linfo.org/link_state_routing.html (accessed Feb. 09, 2021). 
[29] W. Odom and C. Hintz, IPv4 Routing Protocol Concepts, Cisco Press, Dec. 03, 2014. 
https://www.ciscopress.com/articles/article.asp?p=2262897&seqNum=2 (accessed Feb. 09, 
2021). 
[30] A. Gelberger, N. Yemini, and R. Giladi, Performance Analysis of Software-Defined Networking 
(SDN), in 2013 IEEE 21st International Symposium on Modelling, Analysis and Simulation of 
Computer and Telecommunication Systems, San Francisco, Aug. 2013, pp. 389393. doi: 
10.1109/MASCOTS.2013.58. 
[31] P. H. Isolani, J. A. Wickboldt, C. B. Both, J. Rochol, and L. Z. Granville, Interactive monitoring, 
visualization, and configuration of OpenFlow-based SDN, in 2015 IFIP/IEEE International 
Symposium on Integrated Network Management (IM), Ottawa, 2015, pp. 207215. doi: 
10.1109/INM.2015.7140294. 
[32] English Dictionary, [Online], Collins. 
http://www.collinsdictionary.com/dictionary/english/abstraction (accessed Feb. 11, 2021). 
[33] N. McKeown et al., OpenFlow: enabling innovation in campus networks, ACM SIGCOMM 
Comput. Commun. Rev., vol. 38, no. 2, pp. 6974, 2008, doi: 10.1145/1355734.1355746. 
[34] R. Chua, SDN Controller Wars 2.0  ON.LAB & Juniper Re-Ignite the Open-Source 
Battleground, SDX Central, Dec. 21, 2013. 
https://www.sdxcentral.com/articles/editorial/controller-onlab-juniper-open-source-sdn-
battleground-part1/2013/12/ (accessed Feb. 11, 2021). 
[35] OpenFlow, 2020. https://www.opennetworking.org/sdn-resources/openflow/57-sdn-
resources/onf-specifications/openflow?layout=blog. (accessed Oct. 07, 2020). 
[36] I. Turus, OpenFlow Technology Investigation:- Vendors Review on OpenFlow 
implementation, presented at the Copenhagen, NORDUnet, Nov. 21, 2012. Accessed: Oct. 
08, 2020. [Online]. Available: https://www.terena.org/activities/netarch/ws1/slides/turus-
openflow-211112-JRA1.pdf 
[37] F. N. Farias, J. J. Salvatti, P. Victor, and A. Abelem, Integrating legacy forwarding environment 
to OpenFlow/SDN control plane., in APNOMS, Hiroshima, 2013, pp. 13. 
[38] OpFlex: An Open Policy Protocol. Cisco, Apr. 2015. Accessed: Oct. 09, 2020. [Online]. 
Available: http://www.cisco.com/c/en/us/solutions/collateral/data-center-
virtualization/application-centric-infrastructure/white-paper-c11-731302.pdf 
[39] VMware NSX The Network Virtualization Platform. VMware, 2020. Accessed: Oct. 09, 2020. 
[Online]. Available: 
http://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/products/nsx/vmw
are-nsx-datasheet.pdf 
[40] M. Bjorklund, J. Schoenwaelder, P. Shafer, K. Watsen, and R. Wilton, NETCONF Extensions to 
Support the Network Management Datastore Architecture. Internet Engineering Task Force 
(IETF), Mar. 2019. Accessed: Oct. 09, 2020. [Online]. Available: 
https://tools.ietf.org/html/rfc8526 
[41] R. Enns, Network Configuration Protocol (NETCONF), Internet Engineering Task Force (IETF), 
Jun. 2011. https://tools.ietf.org/html/rfc6241 (accessed Oct. 09, 2020). 
[42] C. Chappell, Creating the Programmable Network:  The Business Case for NETCONF/YANG  in 
Network Devices. tail-f, Oct. 2013. Accessed: Oct. 08, 2020. [Online]. Available: 
http://www.tail-f.com/wordpress/wp-content/uploads/2013/10/HR-Tail-f-NETCONF-WP-10-
08-13.pdf 
[43] Contrail Architecture White Paper. Juniper Networks, Sep. 2015. Accessed: Oct. 09, 2020. 
[Online]. Available: https://www.juniper.net/us/en/local/pdf/whitepapers/2000535-en.pdf 
[44] S. Linnerz, Overview of Juniper Networks Contrail, Xantaro Service Intergration, Feb. 27, 
2019. https://www.xantaro.net/en/tech-blogs/contrail/ (accessed Oct. 09, 2020). 
[45] M. Pavlovich, Configure NETCONF/YANG and Validate Example for Cisco IOS XE 16.x 
Platforms, Cisco, May 08, 2020. https://www.cisco.com/c/en/us/support/docs/storage-
networking/management/200933-YANG-NETCONF-Configuration-Validation.html (accessed 
Oct. 08, 2020). 
[46] R. Donato, An Introduction to NETCONF/YANG, Fir3net, Oct. 30, 2020. 
https://www.fir3net.com/Networking/Protocols/an-introduction-to-netconf-yang.html 
(accessed Oct. 09, 2020). 
[47] L. Mller, R. Oliveira, M. Luizelli, L. Gaspary, and M. Barcellos, Survivor: An enhanced 
controller placement strategy for improving SDN survivability, Austin, Dec. 2014, pp. 1909
1915. doi: 10.1109/GLOCOM.2014.7037087. 
[48] N. Dharma, M. Muthohar, J. Prayuda, K. Priagung, and D. Choi, Time-based DDoS detection 
and mitigation for SDN controller, Busan, 2015, pp. 550553. doi: 
10.1109/APNOMS.2015.7275389. 
[49] G. Yao, J. Bi, and L. Guo, On the cascading failures of multi-controllers in Software Defined 
Networks, Goettingen, 2013, pp. 12. doi: 10.1109/ICNP.2013.6733624. 
[50] W. Aly, LBFTFB fault tolerance mechanism for software defined networking, Ras Al Khaimah, 
2017, pp. 15. doi: 10.1109/ICECTA.2017.8251995. 
[51] Y. Liu, H. Gu, X. Yu, and J. Zhou, Dynamic SDN Controller Placement in Elastic Optical 
Datacenter Networks, in 2018 Asia Communications and Photonics Conference (ACP), 
Hangzhou, 2018, pp. 13. doi: 10.1109/ACP.2018.8596219. 
[52] H. Naning, R. Munadi, and M. Effendy, SDN controller placement design: For large scale 
production network, in 2016 IEEE Asia Pacific Conference on Wireless and Mobile 
(APWiMob), Bandung, Jan. 2017, pp. 7479. doi: 10.1109/APWiMob.2016.7811452. 
[53] Y. Jimnez, C. Cervell-Pastor, and A. Garca, On the controller placement for designing a 
distributed SDN control layer, in 2014 IFIP Networking Conference, Trondheim, 2014, pp. 1
9. doi: 10.1109/IFIPNetworking.2014.6857117. 
[54] C. Bi, X. Luo, T. Ye, and Y. Jin, On precision and scalability of elephant flow detection in data 
center with SDN, in 2013 IEEE Globecom Workshops (GC Wkshps), Atlanta, 2013, pp. 1227
1232. doi: 10.1109/GLOCOMW.2013.6825161. 
[55] J. Raychev, D. Kinaneva, G. Hristov, and P. Zahariev, Optimizing SDN Control Plane Scalability 
by Efficient Switch to Controller Migration, in 2019 27th National Conference with 
International Participation (TELECOM), Sofia, 2019, pp. 4245. doi: 
10.1109/TELECOM48729.2019.8994893. 
[56] L. Csikor, M. Szalay, G. Rtvri, G. Pongrcz, D. Pezaros, and L. Toka, Transition to SDN is 
HARMLESS: Hybrid Architecture for Migrating Legacy Ethernet Switches to SDN, IEEEACM 
Trans. Netw., vol. 28, no. 1, pp. 275288, Jan. 2020, doi: 10.1109/TNET.2019.2958762. 
[57] M. Jany, N. Islam, R. Khondoker, and M. Habib, Performance analysis of OpenFlow based 
software defined wired and wireless network, in 2017 20th International Conference of 
Computer and Information Technology (ICCIT), Dhaka, 2017, pp. 16. doi: 
10.1109/ICCITECHN.2017.8281814. 
[58] H. Alshaer and H. Haas, Software-Defined Networking-Enabled Heterogeneous Wireless 
Networks and Applications Convergence, IEEE, vol. 8, pp. 6667266692, Apr. 2020, doi: 
10.1109/ACCESS.2020.2986132. 
[59] A. Thyagaturu, A. Mercian, M. McGarry, M. Reisslein, and W. Kellerer, Software Defined 
Optical Networks (SDONs): A Comprehensive Survey, IEEE Commun. Surv. Tutor., vol. 18, no. 
4, pp. 27382786, Jul. 2016, doi: 10.1109/COMST.2016.2586999. 
[60] M. Alabarce, A. Bravalheri, and P. Mario, INSPIRING-SNI: Investigating SDN Programmability 
Improving Optical South- and North-Bound Interfaces, in 2020 22nd International Conference 
on Transparent Optical Networks (ICTON), Bari, 2020, pp. 14. doi: 
10.1109/ICTON51198.2020.9203409. 
[61] M. Birk et al., The OpenROADM initiative, IEEEOSA J. Opt. Commun. Netw., vol. 12, no. 6, pp. 
C58C67, Mar. 2020, doi: 10.1364/JOCN.380723. 
[62] Open ROAD MSA, 2016. http://openroadm.org/ (accessed Oct. 26, 2020). 
[63] M. Bjorklund, YANG - A Data Modeling Language for the Network Configuration Protocol 
(NETCONF), Internet Engineering Task Force (IETF), Oct. 2020. 
https://tools.ietf.org/html/rfc6020 (accessed Oct. 26, 2020). 
[64] Net2Plan, Net2Plan The Open-Source Network Planner, 2020. 
http://www.net2plan.com/index.php (accessed Oct. 26, 2020). 
[65] M. Mosahebfard, J. Vardakas, K. Ramantas, and C. Verikoukis, SDN/NFV-Based Network 
Resource Management for Converged Optical-Wireless Network Architectures, in 2019 21st 
International Conference on Transparent Optical Networks (ICTON), Angers, 2019, pp. 14. 
doi: 10.1109/ICTON.2019.8840347. 
[66] Cambridge Wireless, Top Providers of SDN Services, CW Connecting the Digital World, Jan. 
28, 2020. https://www.cambridgewireless.co.uk/news/2020/jan/28/top-providers-sdn-
services/ (accessed Oct. 27, 2020). 
[67] K. Wakefield, A guide to the types of machine learning algorithms and their applications, 
SAS, 2021. https://www.sas.com/en_gb/insights/articles/analytics/machine-learning-
algorithms.html (accessed Aug. 23, 2021). 
[68] S. Valcheva, Supervised vs Unsupervised Learning: Algorithms and Examples, Intellspot, 
2021. https://www.intellspot.com/unsupervised-vs-supervised-learning/ (accessed Aug. 23, 
2021). 
[69] I. Goodfellow, J. Shlens, and C. Szegedy, Explaining and Harnessing Adversarial Examples, 
presented at the ICLR, San Diego, CA, USA, 2015. Accessed: Aug. 23, 2021. [Online]. Available: 
https://arxiv.org/pdf/1412.6572.pdf 
[70] J. Kim, S. Cha, M. Ryu, and M. Jo, Pre-training Framework for Improving Learning Speed of 
Reinforcement Learning based Autonomous Vehicles, in 2019 International Conference on 
Electronics, Information, and Communication (ICEIC), Auckland, New Zealand, 2019, pp. 12. 
doi: 10.23919/ELINFOCOM.2019.8706441. 
[71] G. Ravindra Padalkar, S. Dinkar Patil, M. Mallikarjun Hegadi, and N. Kailash Jaybhaye, Drug 
Discovery using Generative Adversarial Network with Reinforcement Learning, in 2021 
International Conference on Computer Communication and Informatics (ICCCI), Coimbatore, 
India, pp. 13. doi: 10.1109/ICCCI50826.2021.9402449. 
[72] A. Maipradit, J. Gao, T. Kawakami, and M. Ito, Adaptive Traffic Control Algorithm Based on 
Back-Pressure and Q-Learning, in 2019 IEEE Intelligent Transportation Systems Conference 
(ITSC), Auckland, 2019, pp. 19951999. doi: 10.1109/ITSC.2019.8917179. 
[73] Y. Zhang and Y. Dong, Single Image Dehazing via Reinforcement Learning, in 2020 IEEE 
International Conference on Information Technology,Big Data and Artificial Intelligence 
(ICIBA), Chongqing, China, pp. 123126. doi: 10.1109/ICIBA50161.2020.9277382. 
[74] F. Li, W. Shao, Q. Zhou, and J. Zhao, Interference Avoidance Scheme Based on Reinforcement 
Learning, in 2020 IEEE 3rd International Conference on Information Systems and Computer 
Aided Education (ICISCAE), Dalian, China, 2020, pp. 221224. doi: 
10.1109/ICISCAE51034.2020.9236792. 
[75] S. Arora, Supervised vs Unsupervised vs Reinforcement, Aitude, Jan. 29, 2021. 
https://www.aitude.com/supervised-vs-unsupervised-vs-reinforcement/ (accessed Aug. 25, 
2021). 
[76] Advantages of Reinforcement Learning  Artificial Intelligence, Codez Up, May 13, 2020. 
https://codezup.com/advantages-of-reinforcement-learning-artificial-intelligence/ (accessed 
Aug. 25, 2021). 
[77] A. Joyin, Pros And Cons Of Reinforcement Learning, Pythonistaplanet, 2020. 
https://pythonistaplanet.com/pros-and-cons-of-reinforcement-learning/#comment-2118 
(accessed Aug. 25, 2021). 
[78] S. Gupta, Advantages and Disadvantages of different types of machine learning algorithms, 
Asquero, Aug. 16, 2020. https://www.asquero.com/article/advantages-and-disadvantages-of-
different-types-of-machine-learning-algorithms/ (accessed Aug. 23, 2021). 
[79] F. Woergoetter and B. Porr, Reinforcement learning, Scholarpedia, 2008. 
http://www.scholarpedia.org/article/Reinforcement_learning (accessed Aug. 25, 2021). 
[80] J. McCullock, Q-Learning, Step-By-Step Tutorial, 2012. http://mnemstudio.org/path-finding-
q-learning-tutorial.htm (accessed Nov. 11, 2020). 
[81] L. While, Artificial Intelligence:- Reinforcement Learning, University of Western Australia, 
2003. Accessed: Dec. 01, 2020. [Online]. Available: 
http://teaching.csse.uwa.edu.au/courses/CITS4211/Lectures/wk7.pdf 
[82] J. Zico-Kolter, Introduction to Reinforcement Learning, presented at the icaps 2018, The 
Netherlands, Jun. 24, 2018. Accessed: Dec. 01, 2020. [Online]. Available: http://icaps18.icaps-
conference.org/fileadmin/alg/conferences/icaps18/summerschool/lectures/Lecture5-rl-
intro.pdf 
[83] I. Goswami, P. Das, A. Konar, and R. Janarthanan, Conditional Q-learning algorithm for path-
planning of a mobile robot, in 2010 International Conference on Industrial Electronics, Control 
and Robotics, Orissa, 2010, pp. 2327. doi: 10.1109/IECR.2010.5720165. 
[84] S. Wu, Illegal radio station localization with UAV-based Q-learning, IEEE, vol. 15, no. 12, pp. 
122131, Dec. 2018. 
[85] L. Zhou, A. Swain, P. Naik, and N. Nair, A dynamic fuzzy q-learning controller to improve 
power system transient stability, in 2016 IEEE International Conference on Power System 
Technology (POWERCON), Wollongong, 2016, pp. 16. doi: 
10.1109/POWERCON.2016.7753910. 
[86] S. Manju and M. Punithavalli, An Analysis of Q-Learning Algorithms with Strategies of Reward 
Function, in International Journal on Computer Science and Engineering, Feb. 2011, vol. 3, pp. 
814820. Accessed: Nov. 23, 2020. [Online]. Available: 
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.301.6263&rep=rep1&type=pdf 
[87] K. V. Moffaert and A. Now, Multi-Objective Reinforcement Learning using Sets of Pareto 
Dominating Policies, J. Mach. Learn. Res., vol. 15, no. 1, pp. 34833512, Jan. 2014, doi: 3663-
3692. 
[88] W. Fedus et al., Revisiting Fundamentals of Experience Replay, vol. 119. PMLR, 2020. 
Accessed: Dec. 31, 2021. [Online]. Available: 
https://proceedings.mlr.press/v119/fedus20a.html 
[89] A. Lopez and D. Heisterkamp, Simulated Annealing Based Hierarchical Q-Routing: A Dynamic 
Routing Protocol, in 2011 Eighth International Conference on Information Technology: New 
Generations, Las Vegas, 2011, pp. 791796. doi: 10.1109/ITNG.2011.138. 
[90] Y. Shilova, M. Kavalerov, and I. Bezukladnikov, Full Echo Q-routing with adaptive learning 
rates: A reinforcement learning approach to network routing, in 2016 IEEE NW Russia Young 
Researchers in Electrical and Electronic Engineering Conference (EIConRusNW), Saint 
Petersburg, Russia, 2016, pp. 341344. doi: 10.1109/EIConRusNW.2016.7448188. 
[91] M. Kavalerov, Y. Shilova, and Y. Likhacheva, Adaptive Q-Routing with random echo and route 
memory, in 2017 20th Conference of Open Innovations Association (FRUCT), St. Petersburg, 
2017, pp. 138145. doi: 10.23919/FRUCT.2017.8071304. 
[92] J. Du, X. Huang, F. Wu, and S. Leng, Reinforcement Learning Empowered QoS-aware Adaptive 
Q-Routing in Ad-hoc Networks, in 2020 International Wireless Communications and Mobile 
Computing (IWCMC), Limassol, 2020, pp. 551556. doi: 10.1109/IWCMC48107.2020.9148532. 
[93] J. Chavula, M. Densmore, and H. Suleman, Using SDN and reinforcement learning for traffic 
engineering in UbuntuNet Alliance, in 2016 International Conference on Advances in 
Computing and Communication Engineering (ICACCE), Durban, South Africa, 2016, pp. 349
355. doi: 10.1109/ICACCE.2016.8073774. 
[94] S. Kim, J. Son, A. Talukder, and C. S. Hong, Congestion prevention mechanism based on Q-
leaning for efficient routing in SDN, in 2016 International Conference on Information 
Networking (ICOIN), Kota Kinabalu, Malaysia, Jan. 2016, pp. 124128. doi: 
10.1109/ICOIN.2016.7427100. 
[95] S. Jalil, M. Rehmani, and S. Chalup, DQR: Deep Q-Routing in Software Defined Networks, in 
2020 International Joint Conference on Neural Networks (IJCNN), Glasgow, 2020, pp. 18. doi: 
10.1109/IJCNN48605.2020.9206767. 
[96] A. Arahunashi, S. Neethu, and H. Ravish Aradhya, Performance Analysis of Various SDN 
Controllers in Mininet Emulator, in 2019 4th International Conference on Recent Trends on 
Electronics, Information, Communication & Technology (RTEICT), Bangalore, 2019, pp. 752
756. doi: 10.1109/RTEICT46194.2019.9016693. 
[97] S. Rao, SDN Series Part Three: NOX, the Original OpenFlow Controller, The New Stack, Dec. 
15, 2014. https://thenewstack.io/sdn-series-part-iii-nox-the-original-openflow-controller/ 
(accessed Nov. 04, 2020). 
[98] N. Gude et al., NOX: Towards an operating system for networks, ACM SIGCOMM Comput. 
Commun. Rev., vol. 38, no. 3, pp. 105110, Jul. 2008, doi: 10.1145/1384609.1384625. 
[99] D. Erickson, The Beacon OpenFlow Controller, in Proceedings of the second ACM SIGCOMM 
workshop on Hot topics in software defined networking, Stanford University, Aug. 2013, pp. 
1318. doi: 10.1145/2491185.2491189. 
[100] B. Lee, S. Park, J. Shin, and S. Yang, IRIS: The Openflow-based Recursive SDN controller, in 
16th International Conference on Advanced Communication Technology, Pyeongchang, 2014, 
pp. 12271231. doi: 10.1109/ICACT.2014.6779154. 
[101] S. Kaur, J. Singh, and N. Ghumman, Network Programmability Using POX Controller, in 
International Conference on Communiction,Computing & Systems, Punjab, Aug. 2014, vol. 1. 
doi: 10.13140/RG.2.1.1950.6961. 
[102] H. Noman and M. Jasim, POX Controller and Open Flow Performance Evaluation in Software 
Defined Networks (SDN) Using Mininet Emulator, in 3rd International Conference on 
Sustainable Engineering Techniques, Baghdad, 2020, vol. 881. doi: 10.1088/1757-
899x/881/1/012102. 
[103] R. Chouhan, M. Atulkar, and N. Nagwani, Performance Comparison of Ryu and Floodlight 
Controllers in Different SDN Topologies, in 2019 1st International Conference on Advanced 
Technologies in Intelligent Control, Environment, Computing & Communication Engineering 
(ICATIECE), Bangalore, 2019, pp. 188191. doi: 10.1109/ICATIECE45860.2019.9063806. 
[104] A. Eljack, A. Hassan, and H. Elamin, Performance Analysis of ONOS and Floodlight SDN 
Controllers based on TCP and UDP Traffic, in 2019 International Conference on Computer, 
Control, Electrical, and Electronics Engineering (ICCCEEE), Khartoum, 2019, pp. 16. doi: 
10.1109/ICCCEEE46830.2019.9071189. 
[105] Z. Khattak, M. Awais, and A. Iqbal, Performance evaluation of OpenDaylight SDN controller, 
in 2014 20th IEEE International Conference on Parallel and Distributed Systems (ICPADS), 
Hsinchu, 2014, pp. 671676. doi: 10.1109/PADSW.2014.7097868. 
[106] OpenDayLight, The Linux Foundation Projects, 2018. https://www.opendaylight.org/ 
(accessed Nov. 09, 2020). 
[107] T. Vachuska et al., ONOS - Open Network Operating System, ONF, 2020. 
https://opennetworking.org/onos/ (accessed Nov. 09, 2020). 
[108] Build SDN Agiley, Component-Based Software Defined Networking Framework, 2017. 
https://ryu-sdn.org/ (accessed Nov. 09, 2020). 
[109] Open Mul, High Performance SDN, 2017. http://www.openmul.org/ (accessed Nov. 09, 
2020). 
[110] A. Lara, A. Kolasani, and B. Ramamurthy, Network Innovation using OpenFlow: A Survey, 
IEEE Commun. Surv. Tutor., vol. 16, no. 1, pp. 493512, 2014, doi: 
10.1109/SURV.2013.081313.00105. 
[111] Mininet Team, Mininet:- An Instant Virtual Network on your Laptop (or other PC), Mininet:- 
An Instant Virtual Network on your Laptop (or other PC), 2018. http://mininet.org/ (accessed 
Oct. 27, 2020). 
[112] iPerf - The ultimate speed test tool for TCP, UDP and SCTP, 2020. https://iperf.fr/ (accessed 
Oct. 29, 2020). 
[113] K. Murata et al., A quality measurement tool for high-speed data transfer in long fat 
networks, Split, 2016. doi: 10.1109/SOFTCOM.2016.7772111. 
[114] S. Wang, Comparison of SDN OpenFlow network simulator and emulators, Funchal, 2014. 
doi: 10.1109/ISCC.2014.6912609. 
[115] B. Lantz, A. Daz-Montiel, J. Yu, C. Rios, M. Ruffini, and D. Kilper, Demonstration of Software-
Defined Packet-Optical Network Emulation with Mininet-Optical and ONOS, San Diego, 2020. 
[116] What is ns-3, ns-3, 2020. https://www.nsnam.org/about/what-is-ns-3/ (accessed Nov. 01, 
2020). 
[117] N. Kamoltham, K. Nakorn, and K. Rojviboonchai, From NS-2 to NS-3 - Implementation and 
evaluation, in Computing, Communications and Applications Conference, Hong Kong, Feb. 
2012, pp. 3540. doi: 10.1109/ComComAp.2012.6153999. 
[118] OMNeT++, 2020. https://omnetpp.org/ (accessed Nov. 01, 2020). 
[119] M. Khan, H. Hasbullah, and B. Nazir, Recent open source wireless sensor network supporting 
simulators: A performance comparison, in 2014 International Conference on Computer, 
Communications, and Control Technology (I4CT), Langkawi, 2014, pp. 324328. doi: 
10.1109/I4CT.2014.6914198. 
[120] N. Gray, T. Zinner, S. Gebert, and T. Phuoc, Simulation Framework for Distributed SDN-
Controller Architectures in OMNeT++, in International Conference on Mobile Networks and 
Management, United Arab Emirates, Oct. 2016, vol. 191, pp. 318. doi: 10.1007/978-3-319-
52712-3_1. 
[121] M. Chen, Y. Miao, and I. Humar, Introduction to OPNET Network Simulation, in Introduction 
to OPNET Network Simulation, Singapore: Springer, 2019, pp. 77153. 
[122] RIVERBED MODELER, Riverbed, 2020. 
https://www.riverbed.com/gb/products/steelcentral/steelcentral-riverbed-modeler.html 
(accessed Nov. 02, 2020). 
[123] GNS3, 2020. https://www.gns3.com/software (accessed Nov. 02, 2020). 
[124] A. Nugroho, Y. Dian Safitri, and T. Setyawan, Comparison analysis of software defined 
network and OSPF protocol using virtual media, in 2017 IEEE International Conference on 
Communication, Networks and Satellite (Comnetsat), Semarang, 2017, pp. 106111. doi: 
10.1109/COMNETSAT.2017.8263582. 
[125] S. Sirijaroensombat, C. Nangsue, and C. Aswakul, Development of Software-Defined Mesh 
Network Emulator Testbed for DDoS Defence Study, in 2019 IEEE 4th International 
Conference on Computer and Communication Systems (ICCCS), Singapore, 2019, pp. 468472. 
doi: 10.1109/CCOMS.2019.8821667. 
[126] A. Mohamed and A. Agamy, A Survey on the Common Network Traffic Sources Models, Int. 
J. Comput. Netw., vol. 3, no. 2, pp. 103115, 2011. 
[127] S. Ghani and F. Iradat, Loss Probability in Networks with Pareto Distributed Traffic, Kuala 
Lumpur, Mar. 2011, pp. 355360. 
[128] Yens algorithm, Wikipedia, Oct. 20, 2022. https://en.wikipedia.org/wiki/Yen%27s_algorithm 
(accessed Feb. 01, 2022). 
[129] S. Sryheni, Dijkstras vs Bellman-Ford Algorithm, Baeldung, Aug. 25, 2021. 
https://www.baeldung.com/cs/dijkstra-vs-bellman-ford (accessed Aug. 28, 2021). 
[130] R. Venkat, PATH FINDING - Dijkstras Algorithm. Indiana State University, Dec. 13, 2014. 
Accessed: Aug. 28, 2021. [Online]. Available: 
http://cs.indstate.edu/~rjaliparthive/dijkstras.pdf 
[131] R. Ananthalakshmi Ammal, P. C. Sajimon, and V. C. S S, Canine Algorithm for Node Disjoint 
Paths, in Advances in Swarm Intelligence, Cham, 2020, pp. 142148. 
[132] E. Lawler, A Procedure for Computing the K Best Solutions to Discrete Optimization Problems 
and Its Application to the Shortest Path Problem, INFORMS, vol. 18, no. 7, pp. 401405, Mar. 
1972. 
[133] N. Katoh, T. Ibaraki, and H. Mine, An efficient algorithm for K shortest simple paths, 
Networks, vol. 12, no. 4, pp. 411427, Dec. 1982. 
[134] W. Hoffman and R. Pavley, A Method for the Solution of the Nth Best Path Problem, ACM, 
vol. 6, no. 4, pp. 506514, Oct. 1959, doi: https://doi.org/10.1145/320998.321004. 
[135] A. Brander and S. Sinclair, A Comparative Study of k-Shortest Path Algorithms, in 
Proceedings of UKPEW95, John Moores University, Liverpool, 1995, pp. 370379. Accessed: 
Feb. 01, 2022. [Online]. Available: 
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.54.3286&rep=rep1&type=pdf 
[136] T. Chen, Network Traffic Modeling, vol. 3. John Wiley & Sons, Inc., 2012. Accessed: Jan. 07, 
2022. [Online]. Available: https://engweb.swan.ac.uk/~tmchen/papers/hcn-traffic-
modeling.pdf 
[137] G. Maia, k_shortest_paths.py, GithubGist, Sep. 2014. 
https://gist.github.com/guilhermemm/d4623c574d4bccb6bf0c 
[138] K. Kastner, Painless Q-Learning Tutorial implementation in Python, GithubGist, Mar. 2016. 
https://gist.github.com/kastnerkyle/d127197dcfdd8fb888c2 
[139] L. Shi, Reinforcement-Learning-in-Path-Finding, GithubGist, Sep. 2017. 
https://github.com/shiluyuan/Reinforcement-Learning-in-Path-Finding 
[140] E. Bouillet, G. Ellinas, J. Labourdette, and R. Ramamurthy, Path routing in mesh optical 
networks, 1st ed. Chichester, England: John Wiley & Sons, Inc., 2007. 
[141] C.-Y. Hong, S. Kandula, R. Mahajan, and M. Zhang, Achieving high utilization with software-
driven WAN, Hong Kong, Aug. 2013, pp. 1526. 
[142] G. Bernstein, SDN Fun, Grotto Networking, 2019. https://www.grotto-
networking.com/SDNfun.html 
[143] P. Vamplew, J. Yearwood, R. Dazeley, and A. Berry, On the Limitations of Scalarisation for 
Multi-objective Reinforcement Learning of Pareto Fronts, in AI 2008: Advances in Artificial 
Intelligence, Berlin, Heidelberg, 2008, pp. 372378. 
[144] S. Sudhoff, Lecture 9: Multi-Objective Optimization, Purdue University, 2007. Accessed: Aug. 
31, 2021. [Online]. Available: https://engineering.purdue.edu/~sudhoff/ee630/Lecture09.pdf 
[145] A. Chhabra, An expedient introduction to Mininet, Aug. 31, 2017. 
http://www.anshumanc.ml/networks/2017/08/31/mininet/ (accessed Nov. 02, 2020). 
[146] Build SDN Agilely, Ryu SDN Framework, 2019. https://osrg.github.io/ryu/ 
[147] T. Dickey, Synopsis, Xterm, 2021. https://invisible-island.net/xterm/ (accessed Jul. 06, 2021). 
[148] Ping, Oracle, 2013. https://docs.oracle.com/cd/E26505_01/html/816-5166/ping-1m.html 
(accessed Jul. 06, 2021). 
[149] The Collaboration Platform for API Development, Postman. https://www.postman.com/ 
(accessed Jul. 06, 2021). 
Appendix A) SDN Testbed Implementation & Testing:- 
A.1) SDN Testbed Implementation:- 
The following section discusses the specific details of how the SDN testbed was implemented.  
A.1.1) The Emulation Environment Tools:- 
A.1.1.1) Mininet:- 
After a review of the emulation and simulation packages that were available for producing network 
topologies (see section 2.6.2), it was decided that Mininet [111] would be the most suitable choice 
for a number of reasons:- 
1. Out of the available simulation and emulation tools available, Mininet is specifically designed 
to emulate networks using SDN. 
2. As an emulator, Mininet is a program which exactly replicates the working of a device and 
uses processes or abstractions that are inherently used by the original device. A simulator 
only models these processes, and tries to model the original device based on some 
assumptions [145]. This makes Mininet a more realistic option for emulating a network. 
3. Mininet is very popular so there is a lot of support both in terms of documentation and 
example topology Python code. 
4. Because Mininet is written in Python, additional Python libraries and tools are easier to 
integrate with the Mininet environment.  
5. While Mininet comes with its own emulated controller, external controllers such as Open 
Daylight and Ryu can be used instead. This was a very important factor in the 
implementation of all the SDN controllers created for K-Shortest Path and Q-Learning.  
6. Mininet is able to emulate large and complex networks on a simple laptop or desktop. This 
meant that the development of each algorithm did not require a state-of-the-art computer.  
A.1.1.2) Ryu SDN Controller:- 
From amongst the many SDN Controllers available (see section 2.6.1), it was decided that Ryu [146] 
would be the most suitable for several reasons:- 
1. Like Mininet, Ryu is written in Python making it flexible so adding the required functionality 
for the controller algorithm became easier. 
2. Ryu supports OpenFlow versions 1.0 to 1.5. 
3. Also, like Mininet, Ryu has a lot of support documentation and example programs to refer to. 
A.1.2) Collection of the Network Metrics:- 
In order to be able to evaluate if a path met the QoS requirements generated, it was required that the 
metrics of the path be assessed. In a real network, metrics such as latency and bandwidth would be 
measured or calculated in real-time as the network topology would be dynamic. However, for the 
purposes of the experiments carried out in this research, a different approach was taken. As each 
topology used to assess the path calculation algorithms was randomly generated, complete with 
latency and bandwidth metrics, when the SDN controller program was initialised, the latency and 
bandwidth for every link in the topology were collected and stored in a structure called R where these 
values could be found later when needed to test the QoS requirements and for Q-Routing path 
estimation. 
A.1.3) Mininet Emulation Program:- 
Mininet is a very versatile emulation tool that offers a number of advantages. Mininet is traditionally 
used to create network topologies where each topology is written using Python. However, in the case 
of the testbed, Mininet was not only used to import different network topologies but also generate 
the traffic required for the testbed.  
A.1.3.1) Mininet Main Program:- 
The main Mininet program was based on an existing implementation written by Dr Bernstein [142]. 
Instead of each topology being written in a separate Mininet file, the Mininet program was able to 
import .json files that contained the necessary information to emulate a network environment 
including the hosts along with their corresponding ids, IPs and Mac addresses, the forwarding nodes 
with their ids, the links between host and forwarding nodes with the latency and bandwidth values 
and the port number so the link would be connected to the correct host of forwarding nodes. The 
Mininet program used the information stored within the .json file and converted it into a topology 
that Mininet could then emulate. 
A.1.3.2) Network Traffic Implementation:- 
In Mininet, when traffic needed to be sent from one host to another, the standard procedure was to 
open a terminal called Xterm [147] for the host nodes that you wished to send traffic from and use a 
network tool such as Ping [148] to emulate network traffic. This approach is normal in network 
topologies that do not contain many host nodes but is not practical in larger network topologies or 
when you need each host node to be able to see traffic at random. Instead of using this approach, the 
main Mininet program was altered to generate random traffic using a network tool called iPerf [112]. 
Once the main Mininet program was started, iPerf was used to create a client and server on each host 
node in the network topology. When a node was randomly selected to transmit traffic for a random 
period of time, the iPerf client on the host node would send a flow of User Datagram Protocol (UDP) 
packets to the sever on the destination host node.  
Regarding the actual data being sent, this in itself was not important as the sending of the data acted 
as a trigger, forcing each forwarding node within the topology connected to the client host node to 
request forwarding instructions from the SDN controller. This in turn, using one of the pathfinding 
algorithms would generate a path and program all the forwarding nodes in that path with the relevant 
forwarding instructions so the traffic flow would be able to reach its destination. Out of the two 
protocols that iPerf used for traffic creation, TCP and UDP, UDP was selected as it gave more 
comprehensive results.  
If UDP was used by iPerf for traffic creation, once the flow had been completed, a report from the 
server was available from the destination host node. This report was useful for testing and debugging 
both the SDN controller and the network topologies. For the SDN controller, if there was no status 
report available, then the forwarding instructions had not been programmed correctly. In the case of 
the topologies, if there was no report, it could be that there was a bad link between two nodes within 
that topology. The report from the server also included a lot of information such as the IP addresses 
of the source and destination host nodes, the port numbers, the transmission time, the amount of 
data sent, the throughput, delay, packet loss, etc. TCP on the version of iPerf used did not support the 
server giving a report after a flow had completed. 
A.1.3.3) Topology Traffic Generation Settings: - 
To ensure that the traffic generation rate was consistent for each pathfinding algorithm, certain values 
in the traffic generation function of the main Mininet program and topology importer were altered 
depending on the size of the topology that was being used at the time. This was done to ensure that 
the SDN Controller program, when using each of the path calculation algorithms, in turn could respond 
to every one of the traffic generation requests created by the random traffic generation without 
overwhelming the controller or forcing Mininet to stop working. While this was not a problem on the 
smaller topologies, on the larger topologies (where each host node was cable of generating traffic) or 
the topologies with a large number of average connections between nodes, it could on occasions 
become an issue. 
 The following are the traffic settings used for each topology size. 
 10 Switches and 10 Hosts:- 
 Random Interval Between Traffic Generation Attempts: 2  5 secs 
 Random Flow Duration:- 3  15 secs 
 Random Probability for Host to Generate Traffic (if X = 0):- 0  3  
25 Switches and 25 Hosts:- 
 Random Interval Between Traffic Generation Attempts: 2  12 secs 
 Random Flow Duration:- 3  30 secs 
 Random Probability for Host to Generate Traffic (if X = 0):- 0  7 
50 Switches and 50 Hosts:- 
 Random Interval Between Traffic Generation Attempts:  3  20 secs 
 Random Flow Duration:- 4  35 secs 
 Random Probability for Host to Generate Traffic (if X = 0):- 0  15 
A.1.3.4) Operation of the Main Mininet Program:- 
The main Mininet program, once completed, contained all the required elements to import different 
network topologies very quickly and to generate random traffic on each topology. The following is a 
summary of how the main Mininet program operated:- 
1. Primary Mininet program started. 
2. A network topology file was then imported by Mininet. This file contained all the necessary 
information required to emulate the network topology lists of including hosts, forwarding 
nodes, links between nodes, port numbers, Mac and IP addresses. A number of topology files 
were created to represent different network sizes and the AMC of each topology. 
3. Once the network topology had loaded, both a client and host server were started on each 
host node within the network topology. 
4. For each host node (source), a random destination host node was selected. However, in order 
for each source host node to be allowed to generate traffic, a random number was generated 
for that source host node ranging from 0 to X where X changed depending on the size of the 
topology and the number of hosts in it. If the random number generated came back as 0, then 
that host source node was allowed to generate traffic, otherwise, the source host node would 
wait a random period of time (between 0 and N seconds where N depended on the topology 
size) before trying again. 
5. Once the random number generator returned a 0 for a particular source host node, another 
value was generated to represent the length of time that the flow of traffic generated would 
transmit for. For experimentation purposes, this normally ranged from 0 to M seconds 
depending on the size of the topology.   
6. The source host node client using iPerf would then transmit a UDP flows to the server on the 
randomly selected destination host node for the M seconds.  
7. Once the flow finished sending and assuming the flow had been able to find the randomly 
selected destination host node, the server on this destination node issued an iPerf flow 
statistics report. 
8. The source node would then repeat the process from step 4. 
A.1.3.5) Topology Creation and Importation:- 
Each individual topology was generated using a topology program specifically written in Python for 
the purpose. Depending on the AMC value and the number of host and forwarding nodes, this Python 
program created a topology with random links between forwarding nodes with random latency and 
bandwidth values for each link. For the latency, the value would be randomly selected between 5  
100ms. For Bandwidth, it was 10-200Mbit. This Python topology generator also assigned IP and Mac 
address, port numbers and node IDs all in the format required by the main Mininet program. Each 
topology was then saved as a .json file and could be imported into the Mininet program when needed. 
A.2) Operational Testing of the SDN Testbed:-  
During and after its development, the testbed underwent various checks to ensure that it was 
functioning as intended. Individual checks and tests were carried out on each of the individual 
elements that made up the testbed. 
A.2.1) SDN Controller Tests:- 
As previously mentioned, testing on each element of the Ryu SDN controller program was carried out 
during development. However, it was only after the SDN controller program was completed could it 
be tested in full.  
To do this, firstly, the path finding algorithm K-Shortest Path, using Latency as the network metric, was 
implemented within the SDN controller as a pathfinding algorithm was required. In this regard, K-
Shortest Path was perfect as it is often used in some variant and straight forward to implement. 
Secondly, a small network topology (Figure 65) was created and emulated using Mininet. Every facet 
of this topology was well known so it could be used to make sure that the SDN controller was operating 
as intended. Assuming that a flow was sent from H1 to H4, the topology also had a low latency and 
high bandwidth path (S1, S2, S5, S7, S4) as well as a high latency path with a low bandwidth capacity 
(S1, S3, S6, S8, S4). 
Figure 65:- Topology for Testing the SDN Controller. 
There were many different elements of the SDN controller program that were tested but the following 
were the most important.  
Responding to requests from forwarding nodes:- The first test was to make sure that the SDN 
controller would respond to forwarding nodes asking for forwarding instructions. Ping in Mininet was 
used to create traffic on the host node, forcing the forwarding node connected to the host node to 
request forwarding instructions from the SDN controller. If the SDN controller successfully received 
and interpreted this request, the next part of the controller program would automatically be triggered. 
This process was tested on every host node and all instances, the SDN controller received each 
forwarding request and successfully identified the IPs address of the source and destination host 
nodes. 
Finding the optimal Path (K-Shortest Path):- The next test was to make sure that the SDN controller 
program could take the source and destination node IP addresses from the forwarding request and 
find a path using the pathfinding algorithm. This involved finding the forwarding nodes connected to 
both the source and destination host nodes and finding the path between them. K-Shortest Path was 
used as the pathfinding algorithm for this part of the SDN controller testing. Ping through Mininet was 
used to create traffic between a set host and destination node pair. The path calculated was then 
compared to Figure 13 to make sure it was indeed the shortest. For all source and destination node 
pairs, the SDN controller using K-Shortest Path was able to find the shortest path. 
Measuring the Latency / Bandwidth of the selected Path:- As this was an essential part of the 
assessment criteria for each path calculation algorithm, it was important to know that the SDN 
controller program could accurately find the end-to-end latency and the maximum bandwidth of a 
path once it had been calculated. Figure 14 was used as a point of comparison to make sure that the 
latency and bandwidth values returned by the SDN controller were accurate.  
Checking if the Path met the QoS requirement:- The latency and/or bandwidth returned by the SDN 
controller for a calculated path needed to be compared to randomly generated QoS metrics for that 
path. As mentioned previously, if a path met the QoS requirements, it was marked as Active, 
otherwise, it was marked as Blocked. To ensure that this part of the SDN controller programming 
was operating correctly, if a path was marked as Blocked for example, the random QoS metrics were 
compared to the returned metrics of the path manually. 
Installing the forwarding rules:- Once a path had been calculated by the path calculation algorithm 
operating within the SDN controller program, the forwarding nodes that corresponded to the nodes 
in the path required forwarding instructions. To make sure that these forwarding rules were installed 
into each forwarding node correctly, iPerf through Mininet was used. For a fixed source and 
destination host node pair, if the forwarding instructions were correctly installed, once the flow had 
finished then the server report generated by iPerf for the destination node would show that the flow 
successfully reached the destination host node, citing flow statistics. Otherwise, after a set period, the 
server report would return a report stating that the server had not received any packets of data.  
Postman [149] was also used to make sure forwarding rules were installed on each forwarding node 
in the path. 
Removing the forwarding:- After a flow had finished between the source and destination hosts node, 
the SDN controller program was designed to remove the forwarding instructions for that flow from 
each forwarding node in the path calculated. To check this, iPerf was used to create a flow between 
the same source and destination host node pair where each forwarding node had just had the 
forwarding instructions deleted. If the SDN controller programmed was triggered into responding to 
a new request for flow instructions, it meant that the existing flow instructions had successfully been 
removed. Otherwise, the SDN controller would not need to do anything and the iPerf server report 
for the destination host node would show a successful flow transmission. Postman was also used to 
check that the forwarding instructions had been removed from each node in the expired flows path. 
A.2.2) Mininet Emulator, Traffic Generator & Topology Testing:- 
Once the SDN controller program had been tested and verified as working, testing the additional 
elements was quick and straightforward. 
Mininet Emulator:- To ensure that the Mininet Emulator was loading topology files correctly, the test 
topology in Figure 14 was created in .json format as each facet of the topology was known as 
previously mentioned. Ping was then used to test every link and to make sure that all hosts and 
forwarding nodes were present. 
Traffic Generation:- To test that each host node would generate traffic using iPerf and each server 
host node would generate a server report, a variation of the traffic generator in the Mininet Emulator 
was created. However, instead of random host nodes generating traffic at random times, each host 
node transmitted a UDP flow for a fixed time period to every other host node in the network in 
sequence. For example, H1 would send a UDP flow firstly, to H2, then H3 and so on. Once H1 had 
transmitted to all other host nodes, the process would repeat but using node H2. The destination node 
server report was used to verify that traffic was being generated by each source host and being 
received by each destination host node. 
Topology:- Each topology file as previously mentioned was randomly generated in the .json format 
to work with the Mininet Emulator program used. To make sure that each topology file was 
complete without any errors, the sequential traffic generator using iPerf used to test the Traffic 
Generator program was implemented on each topology through the Mininet Emulator as the server 
on each destination node would give a report once the flow had finished. 
Appendix B) Experimental Settings:- 
B.1) Chapter 4 SDN Controller Settings for Path Calculation Algorithms:- 
During the experimentation, the variables that were used within the Core SDN Controller program and 
the pathfinding algorithms were changed over time to get the best results. The following are the 
optimal variable values for the Core SDN Controller program and the path calculation algorithms.  
Core SDN Controller Program:- 
 QoS Latency Random Value (where applicable):- 0  200ms 
 QoS Bandwidth Random Value (where applicable):- 5  100Mb 
K-Shortest Path (all):- 
K-Value = The maximum number of paths found between the source and destination up to and 
including the value of K.  
 Experiment 1:- K = 250 
 Experiment 2:- K = 1  250 in steadily increasing steps 
 Experiment 3:- K = 250 
Q-Learning with Latency 
 Latency Weight (Lw):- 2 
 No of training cycles:- 500 
 The Learning Rate:- 0.7 
Q-Routing with Latency & Adaptive Q-Routing with Latency:- 
 No of training cycles:- 150 
 The Learning Rate ():- 0.8 
 Exploration Value ():- 0.1 
Q-Routing with Bandwidth & Adaptive Q-Routing with Bandwidth:- 
 No of training cycles:- 150 
 The Learning Rate ():- 0.8 
 Exploration Value ():- 0.1 
B.2) Chapter 5 SDN Controller Settings for Path Calculation Algorithms:- 
The experimental variables for the Core SDN Controller and the K-Shortest Path algorithms were the 
same as stated in section B.1. 
 for the applicable experiments. The following are the optimal variable values for the Q-Routings 
algorithms presented in this chapter.  
Q-Routing using Latency, Total Link Bandwidth & Free Link Bandwidth:- 
Regarding the experimental reward formula used in this algorithm, a calibration phase was required 
to find the best values to get the best result for Q. This was performed on a topology of 25 Hosts and 
25 Switches with an AMC of 4. The values that were experimented with included the Bandwidth 
Weight A1, Latency Weight A2 and Latency ratio. These do not necessarily represent the optimal 
values, however, in the time available, these values did give the best results for the algorithm. 
 No of training cycles:- 1,000 
 The Learning Rate ():- 0.7 
 Bandwidth Weight A1:- 0.7 
  Latency Weight A2:- 0.3 
 Latency Ratio Value:- 10 
Amalgamation Q-Routing using Latency and Bandwidth:- 
 No of training cycles:- 150 
 The Learning Rate ():- 0.8 
 Exploration Value ():- 0.1 
Total Score Q-Routing using Latency and Bandwidth:- 
 No of training cycles:- 150 
 The Learning Rate ():- 0.8 
 Exploration Value ():- 0.1 
B.3) Chapter 6 SDN Controller Settings for Path Calculation Algorithms:- 
The experimental variables for the Core SDN Controller and the K-Shortest Path algorithms were the 
same as stated in section B.1 for the applicable experiments. The following are the optimal variable 
values for the Q-Routings algorithms presented in this chapter.  
Dual Metric, Multi-Estimate, Pareto Q-Routing:- 
 No of training cycles:- 350 
 The Learning Rate ():- 0.9 
Adaptive, Dual Metric, Multi-Estimate, Pareto Q-Routing:- 
 No of training cycles:- 350 
 No of re-training cycles:- Ranging from 1  5 for Experiments 2 and 3. 
 The Learning Rate ():- 0.9 (For both training and re-training) 
Appendix C) Q-Routing Algorithm Pseudo Code and Additional 
Implementation Details (where relevant):- 
C.1) Section 4.3.3, Q-Learning Implementation & Pseudo Code:- 
C.1.1) Additional Implementation Details for Q-Learning: 
The Q-Learning implementation used in the SDN testbed was based on an existing Python based 
algorithm created by Kyle Kastner [138] in 2016. However, several modifications to this 
implementation were required for it to become usable in the SDN testbed and to engage in continuous 
pathfinding.  
1. The R-matrix that held the rewards used to decide valid moves needed to be created. In the 
Kastner [138] implementation, R was a matrix that had been manually written into the code 
for a fixed destination node. However, as there were many possible destination nodes, it was 
required to alter the implementation to include a mechanism that would generate a 
corresponding R-Matrix for each possible destination node based on whether a move was 
valid, invalid or led to the destination node. Using the information in the topology file along 
with NetworkX tools, all the links between forwarding nodes in the network were extracted 
and stored in a list. A blank matrix was created, a destination node was picked and based on 
that destination node and using pre-determined R values (-1 for no valid move, 0, for a valid 
move, 100 for the destination), the list of links was used as a guide to populate the R matrix 
for that destination. The process for creating the R matrices for each possible switch 
destination started after the Core SDN Controller program was initialised making one R matrix 
for each possible destination.  
2. The Kastner [138] implementation of Q-Learning was designed to run only once and was not 
designed for continuous use with multiple sources and destinations. When used, the source 
and destination nodes needed to be added manually. This issue was corrected simply enough 
by having the main program function of the Ryu Controller pass the source and destination 
router IDs into the Q-Routing setup function. 
C.1.2) Q-Learning Pseudo Code: 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  W weight used in Q-learning 
  T  number of training cycles 
Output : Q the converged Q-table 
Initialise R, an NxN reward table where N= |S|, the number of switches 
FOR iS, j S 
 Rij  -1 if (i, j) not connected 
   100 if i, j connected and i == d or j==d 
   0 if i, j connected but neither is d 
ENDFOR 
Initialise Q, an NxN matrix   
FOR iS, jS  
 Qij  0  
ENDFOR 
Train Q  
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d  
  update Q(current, d) using reward table R, weight W and   
 using formula Eq.7 in thesis 
  currentSw  randomly selected neighbour of currentSw 
 ENDWHILE 
Return Q, the trained Q table  
NB because the graph is connected, the training step will eventually terminate. 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
Q  the converged Q-table 
Output : FP  the full path between s and d 
Find a Path using Trained Q 
Initialise FP (s)   
currentSw  s 
 WHILE currentSw  d 
currentSw  select neighbour with lowest latency estimate  
add neighbour to end of FP 
 ENDWHILE 
Return FP, the full path between s and d 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  W weight used in Q-learning 
  T  number of training cycles 
  LQoS  latency quality of service value 
Output : PATH/STATUS best path and its status (active of blocked) 
Initialise Q 
Q    QTraining(S,E,s,d,W,T) 
find a path  
FP   Pathfinding(s, d, Q) 
find its latency 
TL   SUM of latency for each edge in FP 
IF TL <= LQoS  
 RETURN FP / Active 
 pathlist   {FP} 
 REPEAT T times 
  Increase value of W by 1  
  Q    QTraining(S,E,s,d,W,T) 
  FP   Pathfinding(s, d, Q) 
  ADD FP to pathlist   
 ENDFOR 
 FIND FP in pathlist with lowest total latency 
 IF total latency of FP <= LQoS 
  RETURN FP / Active 
  RETURN FP / Blocked 
 ENDIF  
ENDIF  
NB, as this was an initial investigation, the algorithm complexity was not analysed. 
C.2) Section 4.3.4, Q-Routing with Latency Implementation & Pseudo Code:- 
C.2.1) Additional Implementation Details for Q-Routing with Latency: 
The Q-Routing with Latency algorithm used in the SDN testbed was loosely based on an existing, 
Python implementation created by Luyuan Shi in 2017 [139]. However, a number of alterations were 
needed to bring the Luyuan Shi [139] implementation of the algorithm into line with a traditional Q-
Routing approach within a centralised, SDN environment. The following are the main alterations made 
to the Luyuan Shi [139] Q-Routing implementation:-  
1. The Luyuan Shi [139] adaptation of Q-Routing was designed to run only once and was not 
designed for continuous use with multiple sources and destinations. When used, the source 
and destination nodes needed to be added manually. This issue was corrected simply enough 
by having the main program function of the Ryu Controller pass the source and destination 
router IDs into the Q-Routing setup function. 
2. The Luyuan Shi [139] implementations creation of R was not originally compatible with the 
information located within the topology file imported into the SDN controller. The Luyuan Shi 
[139] Q-Routing implementation collected information from a topology file that was created 
in a different way and which contained less information in general than the imported 
topology file used by the SDN controller. This segment of the Luyuan Shi [139] 
implementation was altered. Using a For Loop within a For Loop, R was created as a 
dictionary within a dictionary containing all the links between switches within the network 
but changed into the format that made the Luyuan Shi [139] Q-Routing implementation with 
the imported topology file. Once this structure was created, using a NetworkX tool and the 
source and host switch IDs, the latency for each link was retrieved from the topology file and 
stored against the relevant links within R.  
3. In the Luyuan Shi [139] implementation, the Q-Table was created in the same way as R, a 
dictionary of dictionaries which was a universal Q-Table that was used for all destination 
nodes. The main difference was a default latency value of 100 was added to each link. 
However, this didnt accurately represent Q-Routing. To remedy this, a Q-Table for a specific 
destination node was created as a single dictionary with each key representing each node 
within the network and when trained, the value assigned to each key would represent the 
approximate latency value from that node to the destination node. The default latency value 
for each node in each Q dictionary for each destination where first created was 0. Each single 
dictionary for each destination was then stored in one overall dictionary. 
C.2.2) Q-Routing with Latency Pseudo Code: 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration
Output :  Q all converged Q-tables 
  PR full path record between s and d 
Initialise R, an NxN matrix   
FOR (i,j)  E 
 Rij = latency of edge(i,j) 
ENDFOR 
Initialise Q, an NxN matrix   
FOR iS, jS  
  Qij  100 
ENDFOR 
Initialise PR (s), used to prevent looping as each node can only be visited once 
Train Q for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours are in PR 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   V <- random value in [0,1]  
IF V <= TH 
  currentSw  randomly selected neighbour of currentSw  
currentSw  neighbour of currentSw with lowest R & Q 
combined latency estimate 
   ENDIF 
update Q(current, d) using reward table R, and using Q-Routing 
reward formula[22] 
add neighbour to end of PR 
set selected neighbour as currentSw 
  ENDIF 
 ENDWHILE 
Return Q, the trained Q table 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
Q  the converged Q-table 
Output :  FP  the full path between s and d 
Find a Path using Trained Q 
Initialise FP (s) 
Initialise PR (s), used to prevent looping as each node can only be visited once     
currentSw  s 
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours have been visited 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
currentSw  select neighbour with lowest latency estimate  
add neighbour to end of FP 
set selected neighbour as currentSw 
 ENDWHILE 
Return FP, the full path between s and d 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration 
  LQoS  latency quality of service value     
Output : PATH/STATUS best path and its status (active of blocked) 
Main Program Initialisation 
Initialise Q (performed once for each destination switch when main program starts) 
Q    QTraining(S,E,s,d,T,TH) 
Main Program for each random s,d pair generated 
Find a path  
FP   Pathfinding(s, d, Q) 
find its latency 
TL   SUM of latency for each edge in FP 
IF TL <= LQoS  
 RETURN FP / Active 
 RETURN FP / Blocked 
ENDIF  
C.3) Section 4.3.5, Q-Routing with Bandwidth Pseudo Code:- 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration
Output :  Q all converged Q-tables 
  PR full path record between s and d 
Initialise R, an NxN matrix   
FOR (i,j)  E 
 Rij = bandwidth of edge(i,j) 
ENDFOR 
Initialise Q, an NxN matrix   
FOR iS, jS  
  Qij  100 
ENDFOR 
Initialise PR (s), used to prevent looping as each node can only be visited once   
Train Q for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours are in PR 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   V <- random value in [0,1]  
IF V <= TH 
  currentSw  randomly selected neighbour of currentSw  
currentSw  neighbour of currentSw with largest R & Q 
Combined bandwidth estimate 
   ENDIF 
update Q(current, d) using reward table R, and using formula Q-
Routing with bandwidth reward formula, Eq.8 in Thesis 
add neighbour to end of PR 
set selected neighbour as currentSw 
  ENDIF 
 ENDWHILE 
Return Q, the trained Q table 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
Q  the converged Q-table 
Output :  FP  the full path between s and d 
Find a Path using Trained Q 
Initialise FP (s)   
Initialise PR (s), used to prevent looping as each node can only be visited once 
currentSw  s 
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours have been visited 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
currentSw  select neighbour with largest bandwidth estimate  
add neighbour to end of FP 
set selected neighbour as currentSw 
 ENDWHILE 
Return FP, the full path between s and d 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration 
  BQoS  bandwidth quality of service value    
Output : PATH/STATUS best path and its status (active of blocked) 
Main Program Initialisation 
Initialise Q (performed once for each destination switch when main program starts) 
Q    QTraining(S,E,s,d,T,TH) 
Main Program for each random s,d pair generated 
Find a path  
FP   Pathfinding(s, d, Q) 
find its bandwidth 
TB   the edge with the lowest bandwidth in FP 
IF TB <= BQoS  
 RETURN FP / Blocked 
 RETURN FP / Active 
ENDIF 
C.4) Section 4.3.6, Adaptive Q-Routing with Latency Pseudo Code:- 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration
Output :  Q all converged Q-tables 
  PR full path record between s and d 
Initialise R, an NxN matrix   
FOR (i,j)  E 
 Rij = latency of edge(i,j) 
ENDFOR 
Initialise Q, an NxN matrix   
FOR iS, jS  
  Qij  100 
ENDFOR 
Initialise PR (s), used to prevent looping as each node can only be visited once 
Train Q for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours are in PR 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   V <- random value in [0,1]  
IF V <= TH 
  currentSw  randomly selected neighbour of currentSw  
currentSw  neighbour of currentSw with lowest R & Q 
combined latency estimate 
   ENDIF 
update Q(current, d) using reward table R, and using Q-Routing 
with latency reward formula[22] 
add neighbour to end of PR 
set selected neighbour as currentSw 
  ENDIF 
 ENDWHILE 
Return Q, the trained Q table 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
Q  the converged Q-table 
Output :  FP  the full path between s and d 
Find a Path using Trained Q 
Initialise FP (s) 
Initialise PR (s), used to prevent looping as each node can only be visited once     
currentSw  s 
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours have been visited 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
currentSw  select neighbour with lowest latency estimate  
add neighbour to end of FP 
set selected neighbour as currentSw 
 ENDWHILE 
Return FP, the full path between s and d 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration 
  LQoS  latency quality of service value     
Output : PATH/STATUS best path and its status (active of blocked) 
Main Program Initialisation 
Initialise Q (performed once for each destination switch when main program starts) 
Q    QTraining(S,E,s,d,T,TH) 
Main Program for each random s,d pair generated 
Perform single retraining cycle for destination switch 
Q(D)    QTraining(S,E,s,d,T=1,TH) 
Find a path  
FP   Pathfinding(s, d, Q) 
find its latency 
TL   SUM of latency for each edge in FP 
IF TL <= LQoS  
 RETURN FP / Active 
 RETURN FP / Blocked 
ENDIF  
C.5) Section 4.3.7, Adaptive Q-Routing with Bandwidth Pseudo Code:- 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration
Output :  Q all converged Q-tables 
  PR full path record between s and d 
Initialise R, an NxN matrix   
FOR (i,j)  E 
 Rij = bandwidth of edge(i,j) 
ENDFOR 
Initialise Q, an NxN matrix   
FOR iS, jS  
  Qij  100 
ENDFOR 
Initialise PR (s), used to prevent looping as each node can only be visited once   
Train Q for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours are in PR 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   V <- random value in [0,1]  
IF V <= TH 
  currentSw  randomly selected neighbour of currentSw  
currentSw  neighbour of currentSw with largest R & Q 
Combined bandwidth estimate 
   ENDIF 
update Q(current, d) using reward table R, and using formula Q-
Routing with bandwidth reward formula, Eq.8 in Thesis 
add neighbour to end of PR 
set selected neighbour as currentSw 
  ENDIF 
 ENDWHILE 
Return Q, the trained Q table 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
Q  the converged Q-table 
Output :  FP  the full path between s and d 
Find a Path using Trained Q 
Initialise FP (s)   
Initialise PR (s), used to prevent looping as each node can only be visited once 
currentSw  s 
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours have been visited 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
currentSw  select neighbour with largest bandwidth estimate  
add neighbour to end of FP 
set selected neighbour as currentSw 
 ENDWHILE 
Return FP, the full path between s and d 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration 
  BQoS  bandwidth quality of service value    
Output : PATH/STATUS best path and its status (active of blocked) 
Main Program Initialisation 
Initialise Q (performed once for each destination switch when main program starts) 
Q    QTraining(S,E,s,d,T,TH) 
Main Program for each random s,d pair generated 
Perform single retraining cycle for destination switch 
Q(d)    QTraining(S,E,s,d,T=1,TH) 
Find a path  
FP   Pathfinding(s, d, Q) 
find its bandwidth 
TB   the edge with the lowest bandwidth in FP 
IF TB <= BQoS  
 RETURN FP / Blocked 
 RETURN FP / Active 
ENDIF 
C.6) Section 5.3.2, Q-Routing using Latency, Total Link Bandwidth & Free 
Link Bandwidth Pseudo Code:- 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration
Output :  Q all converged Q-tables of scalarised latency & bandwidth values 
  PR full path record between s and d 
Initialise RL, an NxN matrix for latency values 
Initialise RB, an NxN matrix for bandwidth values 
FOR (i,j)  E 
 RLij = latency of edge(i,j) 
 RBij = bandwidth of edge(i,j) 
ENDFOR 
Initialise BD, an NxN matrix of the real-time available bandwidth for each edge  
FOR (i,j)  E 
 BDij = bandwidth of edge(i,j) 
Initialise Q, an NxN matrix   
FOR iS, jS  
  Qij  100 
ENDFOR 
Initialise PR (s), used to prevent looping as each node can only be visited once   
Train Q for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours are in PR 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   V <- random value in [0,1]  
IF V <= TH 
  currentSw  randomly selected neighbour of currentSw  
currentSw  neighbour of currentSw with lowest Q 
estimate 
   ENDIF 
update Q(current, d) using reward table RL, RB, DB for edge 
between currentSw and neighbour and using Q-Routing reward 
formula Q-Routing, Eq.11 in Thesis 
add neighbour to end of PR 
update real-time bandwidth value in DB between currentSw and 
neighbour 
set selected neighbour as currentSw 
  ENDIF 
 ENDWHILE 
Return Q, the trained Q table 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
Q the converged Q-table of scalarised latency and 
bandwidth values 
Output :  FP  the full path between s and d 
Find a Path using Trained Q 
Initialise FP (s)   
Initialise PR (s), used to prevent looping as each node can only be visited once 
currentSw  s 
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours have been visited 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
currentSw  select neighbour with lowest combined Q estimate 
add neighbour to end of FP 
update real-time bandwidth value in DB between currentSw and 
neighbour 
set selected neighbour as currentSw 
 ENDWHILE 
Return FP, the full path between s and d 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration 
LQoS  latency quality of service value 
  BQoS  bandwidth quality of service value 
Output : PATH/STATUS best path and its status (active of blocked) 
Main Program Initialisation 
Main Program for each random s,d pair generated 
Initialise Q 
Q    QTraining(S,E,s,d,T,TH) 
Find a path  
FP   Pathfinding(s, d, Q) 
find its latency 
TL   SUM of latency for each edge in FP 
find its bandwidth 
TB   the edge with the lowest bandwidth in FP 
IF TL <= LQoS 
 IF TB >= BQoS 
  IF each edge in FP has enough real-time bandwidth 
   RETURN FP / Active 
   RETURN FP / Blocked 
  ENDIF 
  RETURN FP / Blocked 
 ENDIF 
 RETURN FP / Blocked 
ENDIF 
C.7) Section 5.3.4, Amalgamation Q-Routing using Latency & Bandwidth 
Pseudo Code:- 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration
Output :  QL all converged Q-tables of latency estimates 
QB all converged Q-tables of bandwidth estimates 
  PR full path record between s and d 
Initialise RL, an NxN matrix for latency values 
Initialise RB, an NxN matrix for bandwidth values 
FOR (i,j)  E 
 RLij = latency of edge(i,j) 
 RBij = bandwidth of edge(i,j) 
ENDFOR 
Initialise QL, an NxN matrix for latency estimates 
Initialise QB, an NxN matrix for latency estimates    
FOR iS, jS  
  QLij  0 
QBij  500 
ENDFOR 
Initialise PR (s), used to prevent looping as each node can only be visited once   
Train QL for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours are in PR 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   V <- random value in [0,1]  
IF V <= TH 
  currentSw  randomly selected neighbour of currentSw  
currentSw  neighbour of currentSw with lowest RL & QL 
Combined bandwidth estimate 
   ENDIF 
update QL(current, d) using reward table RL, and using Q-
Routing with latency reward formula[22] 
add neighbour to end of PR 
  ENDIF 
 ENDWHILE 
Return QL, the trained Q table for latency estimates 
Train QB for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours are in PR 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   V <- random value in [0,1]  
IF V <= TH 
  currentSw  randomly selected neighbour of currentSw  
currentSw  neighbour of currentSw with largest RB & QB 
Combined bandwidth estimate 
   ENDIF 
update QB(current, d) using reward table RB, and using formula 
Q-Routing with bandwidth reward formula, Eq.8 in Thesis 
add neighbour to end of PR 
set selected neighbour as currentSw 
  ENDIF 
 ENDWHILE 
Return QB, the trained Q table for bandwidth estimates 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
QL  all converged Q-tables of latency estimates 
QB  all converged Q-tables of bandwidth estimates 
Output :  FP  the full path between s and d 
Find a Path using Trained QL and QB 
Initialise FP (s)   
Initialise PR (s), used to prevent looping as each node can only be visited once 
currentSw  s 
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours have been visited 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
currentSw  select neighbour with lowest combined QL & QB 
estimate using Eq.16 to combine them 
add neighbour to end of FP 
set selected neighbour as currentSw 
 ENDWHILE 
Return FP, the full path between s and d 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration 
LQoS  latency quality of service value 
  BQoS  bandwidth quality of service value 
Output : PATH/STATUS best path and its status (active of blocked) 
Main Program Initialisation 
Initialise QL (performed once for each destination switch when main program starts) 
QL    QTraining(S,E,s,d,T,TH) 
Initialise QB (performed once for each destination switch when main program starts) 
QB    QTraining(S,E,s,d,T,TH) 
Find a path  
FP   Pathfinding(s, d, QL, QB) 
find its latency 
TL   SUM of latency for each edge in FP 
find its bandwidth 
TB   the edge with the lowest bandwidth in FP 
IF TL <= LQoS 
 IF TB >= BQoS 
RETURN FP / Active 
  RETURN FP / Blocked 
 ENDIF 
 RETURN FP / Blocked 
ENDIF 
C.8) Section 5.3.5, Total Score Q-Routing using Latency & Bandwidth Pseudo 
Code:- 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration
Output :  QL all converged Q-tables of latency estimates 
QB all converged Q-tables of bandwidth estimates 
  PR full path record between s and d 
Initialise RL, an NxN matrix for latency values 
Initialise RB, an NxN matrix for bandwidth values 
FOR (i,j)  E 
 RLij = latency of edge(i,j) 
 RBij = bandwidth of edge(i,j) 
ENDFOR 
Initialise QL, an NxN matrix for latency estimates 
Initialise QB, an NxN matrix for latency estimates    
FOR iS, jS  
  QLij  0 
QBij  500 
ENDFOR 
Initialise PR (s), used to prevent looping as each node can only be visited once   
Train QL for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours are in PR 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   V <- random value in [0,1]  
IF V <= TH 
  currentSw  randomly selected neighbour of currentSw  
currentSw  neighbour of currentSw with lowest RL & QL 
Combined bandwidth estimate 
   ENDIF 
update QL(current, d) using reward table RL, and using Q-
Routing with latency reward formula[22] 
add neighbour to end of PR 
  ENDIF 
 ENDWHILE 
Return QL, the trained Q table for latency estimates 
Train QB for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours are in PR 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   V <- random value in [0,1]  
IF V <= TH 
  currentSw  randomly selected neighbour of currentSw  
currentSw  neighbour of currentSw with largest RB & QB 
Combined bandwidth estimate 
   ENDIF 
update QB(current, d) using reward table RB, and using formula 
Q-Routing with bandwidth reward formula, Eq.8 in Thesis 
add neighbour to end of PR 
set selected neighbour as currentSw 
  ENDIF 
 ENDWHILE 
Return QB, the trained Q table for bandwidth estimates 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
QL  all converged Q-tables of latency estimates 
QB  all converged Q-tables of bandwidth estimates 
Output :  FP  the full path between s and d 
Find a Path using Trained QL and QB 
Initialise FP (s)   
Initialise PR (s), used to prevent looping as each node can only be visited once 
currentSw  s 
 WHILE currentSw  d 
  Find all unvisited neighbours to currentSw 
  IF all neighbours have been visited 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
currentSw  select neighbour with lowest combined total score 
add neighbour to end of FP 
set selected neighbour as currentSw 
 ENDWHILE 
Return FP, the full path between s and d 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration 
LQoS  latency quality of service value 
  BQoS  bandwidth quality of service value 
Output : PATH/STATUS best path and its status (active of blocked) 
Main Program Initialisation 
Initialise QL (performed once for each destination switch when main program starts) 
QL    QTraining(S,E,s,d,T,TH) 
Initialise QB (performed once for each destination switch when main program starts) 
QB    QTraining(S,E,s,d,T,TH) 
Find a path  
FP   Pathfinding(s, d, QL, QB) 
find its latency 
TL   SUM of latency for each edge in FP 
find its bandwidth 
TB   the edge with the lowest bandwidth in FP 
IF TL <= LQoS 
 IF TB >= BQoS 
RETURN FP / Active 
  RETURN FP / Blocked 
 ENDIF 
 RETURN FP / Blocked 
ENDIF 
C.9) Section 6.3.1, Dual-Metric, Multi-Estimate, Pareto Q-Routing Pseudo 
Code:- 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration
Output :  Q all converged Q-tables of scalarised latency & bandwidth values 
  PR full path record between s and d 
Initialise RL, an NxN matrix for latency values 
Initialise RB, an NxN matrix for bandwidth values 
FOR (i,j)  E 
 RLij = latency of edge(i,j) 
 RBij = bandwidth of edge(i,j) 
ENDFOR 
Initialise Q, an NxN matrix for multiple latency and bandwidth tuple estimates 
(L,B) 
FOR iS, jS  
  Qij  (0,500) 
ENDFOR 
Initialise PR (s), used to prevent looping as each node can only be visited once   
Find the next switch in the path towards d from currentSw 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
FEL  Find all unvisited neighbours to currentSw 
combine Q & R values for currentSW & each neighbour in FEL 
PFEL  Pareto Front Filter to find dominant values in FEL and 
corresponding switches 
IF no of neighbouring switches in PFEL to currentSw is 1 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
  ELSE IF no of neighbouring switches in PFEL to currentSw is 0 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   IF V <= TH 
    delete selected neighbour of currentSw from PFEL 
   ENDIF 
   IF currentSw = s 
    select random neighbour to currentSw from PFEL 
Bmax  bandwidth edge value between currentSw and 
neighbour in PFEL 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
select neighbour with highest bandwidth between 
currentSw and that neighbour 
update Bmax with this bandwidth value 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
   ENDIF 
  ENDIF 
 ENDWHILE 
Train Q for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  CEL  Find all neighbours to currentSw 
combine Q & R values for currentSW & each neighbour in CEL 
PCEL  Pareto Front Filter to find dominant values in CEL 
IF no of estimates for Q(currentSw) = one & no of values in PCEL >= 
combine single Q(currentSw) estimate with each PCEL value using 
separate Q-Routing with latency formula[22] & Q-Routing with 
bandwidth (Eq.8 in thesis) reward formula 
ELSEIF no of estimates for Q(currentSw) >= two & no of values in PCEL  
= one 
find the closest Q(currentSw) estimate that is less than equal 
to single PCEL value 
combine using separate Q-Routing with latency formula[22] & Q-
Routing with bandwidth (Eq.8 in thesis) reward formula 
filter out similar combined values with 5% tolerance 
replace Q(currentSw) estimates with new filtered, combined 
value estimates  
ELSEIF no of estimates for Q(currentSw) & PCEL values >= two 
combine lowest latency Q(currentSw) estimate and PCEL value 
with each other using separate Q-Routing with latency 
formula[22] & Q-Routing with bandwidth (Eq.8 in thesis) reward 
formula 
combine highest latency Q(currentSw) estimate and PCEL value 
with each other using separate Q-Routing with latency 
formula[22] & Q-Routing with bandwidth (Eq.8 in thesis) reward 
formula 
for remaining Q(currentSw) estimates and PCEL values, combine 
each Q(currentSw) estimate with the closest PCEL value based on 
latency that is greater than or equal to the Q(currentSw) 
estimate using separate Q-Routing with latency formula[22] & Q-
Routing with bandwidth (Eq.8 in thesis) reward formula 
filter out similar combined values with 5% tolerance 
replace Q(currentSw) estimates with new filtered, combined 
value estimates  
  ENDIF 
 ENDWHILE 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
Q the converged Q-table of scalarised latency and 
bandwidth values 
Output :  FP  the full path between s and d 
Find a Path using Trained Q 
Initialise FP (s)   
Initialise PR (s), used to prevent looping as each node can only be visited once 
Find the next switch in the path towards d from currentSw 
currentSw  s  
WHILE currentSw  d 
FEL  Find all unvisited neighbours to currentSw combine Q & R values for 
currentSW & each neighbour in FEL 
PFEL  Pareto Front Filter to find dominant values in FEL and corresponding 
switches 
IF no of neighbouring switches in PFEL to currentSw is 1 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
 ELSE IF no of neighbouring switches in PFEL to currentSw is 0 
  add currentSw to PR 
  set previous currentSw to currentSW 
  remove previous currentSw from PR 
  IF currentSw = s 
   select random neighbour to currentSw from PFEL 
Bmax  bandwidth edge value between currentSw and neighbour in 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
select neighbour with highest bandwidth between currentSw and 
that neighbour 
update Bmax with this bandwidth value 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
  ENDIF 
 ENDIF 
ENDWHILE 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration 
LQoS  latency quality of service value 
  BQoS  bandwidth quality of service value 
Output : PATH/STATUS best path and its status (active of blocked) 
Main Program Initialisation 
Initialise QL (performed once for each destination switch when main program starts) 
Q    QTraining(S,E,s,d,T,TH) 
Main Program for each random s,d pair generated 
Find a path  
FP   Pathfinding(s, d, Q) 
find its latency 
TL   SUM of latency for each edge in FP 
find its bandwidth 
TB   the edge with the lowest bandwidth in FP 
IF TL <= LQoS 
 IF TB >= BQoS 
  IF each edge in FP has enough real-time bandwidth 
   RETURN FP / Active 
   RETURN FP / Blocked 
  ENDIF 
  RETURN FP / Blocked 
 ENDIF 
 RETURN FP / Blocked 
ENDIF 
C.10) Section 6.3.3, Adaptive, Dual-Metric, Multi-Estimate, Pareto Q-Routing 
Pseudo Code:- 
FUNCTION QTraining 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration
Output :  Q all converged Q-tables of scalarised latency & bandwidth values 
  PR full path record between s and d 
Initialise RL, an NxN matrix for latency values 
Initialise RB, an NxN matrix for bandwidth values 
FOR (i,j)  E 
 RLij = latency of edge(i,j) 
 RBij = bandwidth of edge(i,j) 
ENDFOR 
Initialise Q, an NxN matrix for multiple latency and bandwidth tuple estimates 
(L,B) 
FOR iS, jS  
  Qij  (0,500) 
ENDFOR 
Initialise PR (s), used to prevent looping as each node can only be visited once   
Find the next switch in the path towards d from currentSw 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
FEL  Find all unvisited neighbours to currentSw 
combine Q & R values for currentSW & each neighbour in FEL 
PFEL  Pareto Front Filter to find dominant values in FEL and 
corresponding switches 
IF no of neighbouring switches in PFEL to currentSw is 1 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
  ELSE IF no of neighbouring switches in PFEL to currentSw is 0 
   add currentSw to PR 
   set previous currentSw to currentSW 
   remove previous currentSw from PR 
   IF V <= TH 
    delete selected neighbour of currentSw from PFEL 
   ENDIF 
   IF currentSw = s 
    select random neighbour to currentSw from PFEL 
Bmax  bandwidth edge value between currentSw and 
neighbour in PFEL 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
select neighbour with highest bandwidth between 
currentSw and that neighbour 
update Bmax with this bandwidth value 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
   ENDIF 
  ENDIF 
 ENDWHILE 
Train Q for each possible destination switch 
REPEAT T times 
 currentSw  s  
 WHILE currentSw  d 
  CEL  Find all neighbours to currentSw 
combine Q & R values for currentSW & each neighbour in CEL 
PCEL  Pareto Front Filter to find dominant values in CEL 
IF no of estimates for Q(currentSw) = one & no of values in PCEL >= 
combine single Q(currentSw) estimate with each PCEL value using 
separate Q-Routing with latency formula[22] & Q-Routing with 
bandwidth (Eq.8 in thesis) reward formula 
ELSEIF no of estimates for Q(currentSw) >= two & no of values in PCEL  
= one 
find the closest Q(currentSw) estimate that is less than equal 
to single PCEL value 
combine using separate Q-Routing with latency formula[22] & Q-
Routing with bandwidth (Eq.8 in thesis) reward formula 
filter out similar combined values with 5% tolerance 
replace Q(currentSw) estimates with new filtered, combined 
value estimates  
ELSEIF no of estimates for Q(currentSw) & PCEL values >= two 
combine lowest latency Q(currentSw) estimate and PCEL value 
with each other using separate Q-Routing with latency 
formula[22] & Q-Routing with bandwidth (Eq.8 in thesis) reward 
formula 
combine highest latency Q(currentSw) estimate and PCEL value 
with each other using separate Q-Routing with latency 
formula[22] & Q-Routing with bandwidth (Eq.8 in thesis) reward 
formula 
for remaining Q(currentSw) estimates and PCEL values, combine 
each Q(currentSw) estimate with the closest PCEL value based on 
latency that is greater than or equal to the Q(currentSw) 
estimate using separate Q-Routing with latency formula[22] & Q-
Routing with bandwidth (Eq.8 in thesis) reward formula 
filter out similar combined values with 5% tolerance 
replace Q(currentSw) estimates with new filtered, combined 
value estimates  
  ENDIF 
 ENDWHILE 
FUNCTION Pathfinding 
Inputs :  
  s,d  start and destination switches, s,d S  
Q the converged Q-table of scalarised latency and 
bandwidth values 
Output :  FP  the full path between s and d 
Find a Path using Trained Q 
Initialise FP (s)   
Initialise PR (s), used to prevent looping as each node can only be visited once 
Find the next switch in the path towards d from currentSw 
currentSw  s  
WHILE currentSw  d 
FEL  Find all unvisited neighbours to currentSw combine Q & R values for 
currentSW & each neighbour in FEL 
PFEL  Pareto Front Filter to find dominant values in FEL and corresponding 
switches 
IF no of neighbouring switches in PFEL to currentSw is 1 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
 ELSE IF no of neighbouring switches in PFEL to currentSw is 0 
  add currentSw to PR 
  set previous currentSw to currentSW 
  remove previous currentSw from PR 
  IF currentSw = s 
   select random neighbour to currentSw from PFEL 
Bmax  bandwidth edge value between currentSw and neighbour in 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
select neighbour with highest bandwidth between currentSw and 
that neighbour 
update Bmax with this bandwidth value 
add currentSw to PR  
add neighbour to end of FP 
set selected neighbour as currentSw 
  ENDIF 
 ENDIF 
ENDWHILE 
FUNCTION QFIND (Main Function) 
START 
Inputs : S   set of switches  
  E set of edges (s1, s2) where s1,s2  S   
   (NB the graph (S,E) must be  connected ) 
  s,d start and destination switches, s,d S  
  T  number of training cycles 
  TH Threshold value, typically 0.1 to encourage random exploration 
LQoS  latency quality of service value 
  BQoS  bandwidth quality of service value 
Output : PATH/STATUS best path and its status (active of blocked) 
Main Program Initialisation 
Initialise QL (performed once for each destination switch when main program starts) 
Q    QTraining(S,E,s,d,T,TH) 
Main Program for each random s,d pair generated 
Perform single retraining cycle for destination switch 
Q(d)    QTraining(S,E,s,d,T=1,TH) 
Find a path  
FP   Pathfinding(s, d, Q) 
find its latency 
TL   SUM of latency for each edge in FP 
find its bandwidth 
TB   the edge with the lowest bandwidth in FP 
IF TL <= LQoS 
 IF TB >= BQoS 
  IF each edge in FP has enough real-time bandwidth 
   RETURN FP / Active 
   RETURN FP / Blocked 
  ENDIF 
  RETURN FP / Blocked 
 ENDIF 
 RETURN FP / Blocked 
ENDIF 
