My PhD thesis title - check front page
University of Cambridge
Measurements of B  + decays using
the LHCb Experiment
Hannah Mary Evans
Selwyn College
Supervisor
Prof. Valerie Gibson
This dissertation is submitted for the degree of Doctor of Philosophy
June 2017
Abstract
This dissertation documents a study of very rare B-meson decays at the LHCb
experiment, using data taken during the first experiment run of the Large Hadron
Collider (LHC) and during the second experiment run until September 2016.
The LHCb experiment was designed to test the Standard Model of particle physics
and to search for New Physics effects that go beyond the scope of the Standard Model
through the decay of b hadrons produced in high energy proton-proton collisions
at the LHC. The measurements described in this dissertation are made using data
samples of proton-proton collisions with integrated luminosities of 1.0, 2.0 and
1.4 fb1, collected at centre-of-mass energies of 7, 8 and 13 TeV, respectively.
The branching fractions of the very rare B0  + and B0s  + decays and
the effective lifetime of B0s  + decays are precisely predicted by the Standard
Model and are sensitive to effects from New Physics. New Physics processes could
influence the B0s  + branching fraction and effective lifetime independently,
and therefore the two observables are complementary.
The B0s  + decay is observed with a statistical significance of 7.8 and
the branching fraction is measured to be B(B0s  +) = (3.0  0.6
0.2)  109.
The B0s  + effective lifetime is measured for the first time as 2.04  0.44 
0.05 ps. The B0  + branching fraction is measured as B(B0  +) =
(1.5+1.21.0+0.20.1)  1010 with a statistical significance of 1.6. An upper limit is set for
the branching fraction of B(B0  +) < 3.4  1010 at the 95% confidence level.
All results are consistent with the predictions of the Standard Model.
Declaration
This dissertation is the result of my own work, except where work done in collaboration
with others is specified in the text. No part of it has been submitted for another
qualification at this or any other University. Finally, this dissertation does not exceed
the word limit set by the respective Degree Committee.
Hannah Evans
June 2017
Acknowledgements
I have never been one for effusive speeches or declarations but after almost 4 years
working for my PhD there are many acknowledgements I would like to make. I would
like to thank Valerie Gibson for giving me the opportunity to complete a PhD at
the University of Cambridge, for her guidance throughout my research and for the
repeated reading of this dissertation. To Marc-Olivier Bettler and Harry Cliff, without
whose support and encouragement this PhD would never have been completed and
without whom I would not have had the opportunity to work on one of the flagship
analyses of the LHCb experiment. Thanks also go to the B   LHCb analysis
group for the tireless effort that went into the branching fraction measurements
and for the guidance I received for my work. I have benefited greatly from the
experience of those within this group. To the Science and Technologies Faculties
Council for funding my research, enabling me to spend a year living in Geneva
and to attend international conferences. To Selwyn College for support throughout
my PhD, particularly with respect to the financial support and encouragement I
received from the college during the time I spent training with Cambridge University
Womens Boat Club. Past and present members of the Cambridge HEP Group,
thank you to the good friends Ive made and for making coffee and lunch breaks
entertaining. Particular thanks go to John Hill for the computing infrastructure I
greatly benefited from during my PhD and for putting up with me filling up a lot of
disk space. Thanks also go to Susan Haines for answering my questions and giving
me hope that everything would be OK. To my friends from Oxford and Cambridge,
rowing friends, church friends and physics friends. To list them all would take some
time, but special thanks go to Anouska Bartlett for voluntarily reading through
parts of my dissertation. Finally, I would like to thank my family. Thank you for
coping with me being very absent during my PhD, although you did move to the
opposite side of the country
Preface
In 2013 I started my PhD at the University of Cambridge and now, almost four years
later, it is finally coming to an end. This dissertation describes the research I have
undertaken during those four years; studying B   decays with the LHCb experi-
ment. Two different measurements of these decays are presented; the measurement
of B0  + and B0s  + branching fractions and the measurement of the
B0s  + effective lifetime. These results have been published in reference [1] and
are the first measurements of these decays using data collected during the second
experiment run of the Large Hadron Collider (LHC). My contributions have pre-
dominately been to the effective lifetime measurement, however there is a significant
overlap of the two analysis strategies therefore both measurements are described in
this dissertation.
A short introduction to particle physics is presented in Chapter 1 along with a
summary of the past experimental searches and recent measurements of B0(s)  
decays1. The theoretical motivation for measuring the B0(s)  
+ branching
fractions and the B0s  + effective lifetime is discussed in Chapter 2. Chapter 3
describes the LHC and the LHCb experiment, which provided the data used in the
measurements for this dissertation. The criteria used to identify B0(s)  
+ decays
in LHCb data are described in Chapter 4. This work was carried out over several
years by many members, including myself, of the B   LHCb analysis group. My
contributions are the study of the stripping selection described in Sections 4.3.2.1
and 4.3.2.2 and the criteria used to identify B0s  + decays for the effective
lifetime measurement in Section 4.4.
The measurements of the B0(s)  
+ branching fractions are described in
Chapter 5; this work was performed by members of the B0(s)  
+ LHCb analysis
group and the description focuses in more detail on the parts of the analysis strategy
that are also used for the effective lifetime measurement. My contributions include
the technical aspects of this measurement; producing the ROOT ntuples containing
data and simulated decays and maintaining the stripping selection applied to data.
1Throughout this dissertation B0(s) refers to both the particle and anti-particle states of B
0 and
B0s mesons and B0(s)  
+ refers to both the particle and anti-particle decays of B0 and B0s
mesons into two oppositely charged muons
x Preface
The measurement of the B0s  + effective lifetime and the systematic uncer-
tainties associated with this measurement are described in Chapters 6 and 7. The
work documented in these chapters is the result of my own efforts, although it uses
inputs from the branching fraction measurements; the mass shapes for signal and
background decays, the yields of B0s  J/ decays in data and the expected yields
of signal and background decays in data.
Finally, a summary is given in Chapter 8 of the main results documented in this
dissertation and the future prospects for the branching fraction and effective lifetime
measurements are also discussed.
Table of contents
Abstract iii
Declaration v
Acknowledgements vii
Preface ix
1 Introduction 1
2 Theory of B  +decays; the Standard Model and beyond 7
2.1 B0(s)  
+ decays in the Standard Model . . . . . . . . . . . . . . 7
2.2 B0(s)  
+ Branching Fraction . . . . . . . . . . . . . . . . . . . . 10
2.3 Quark mixing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
2.3.1 Time evolution of the B0(s) . . . . . . . . . . . . . . . . . . . . 15
2.3.2 Impact on the Branching Fraction . . . . . . . . . . . . . . . . 18
2.4 A and the B0s  + effective lifetime . . . . . . . . . . . . . . . 19
2.5 The Standard Model predictions . . . . . . . . . . . . . . . . . . . . . 21
2.6 New Physics models and B0(s)  
+ decays . . . . . . . . . . . . . 21
3 The LHC and the LHCb experiment 25
3.1 The Large Hadron Collider . . . . . . . . . . . . . . . . . . . . . . . . 26
3.2 The LHCb experiment . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.2.1 Tracking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
3.2.2 Particle identification . . . . . . . . . . . . . . . . . . . . . . . 39
3.2.3 Trigger . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
3.2.4 Software and simulation . . . . . . . . . . . . . . . . . . . . . 50
3.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
4 Event selection 55
4.1 Background sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
4.2 Simulated particle decays . . . . . . . . . . . . . . . . . . . . . . . . . 57
4.3 Event selection for the B0(s)  
+ branching fraction measurements 59
xii Table of contents
4.3.1 Trigger requirements . . . . . . . . . . . . . . . . . . . . . . . 60
4.3.2 Cut-based selection . . . . . . . . . . . . . . . . . . . . . . . . 61
4.3.3 Particle identification . . . . . . . . . . . . . . . . . . . . . . . 75
4.3.4 Multivariate Classifiers . . . . . . . . . . . . . . . . . . . . . . 76
4.3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
4.4 Selection for the B0s  + effective lifetime measurement . . . . . 88
4.4.1 Trigger requirements . . . . . . . . . . . . . . . . . . . . . . . 89
4.4.2 Mass range . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
4.4.3 Particle identification . . . . . . . . . . . . . . . . . . . . . . . 90
4.4.4 Multivariate classifier . . . . . . . . . . . . . . . . . . . . . . . 91
4.4.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
5 Measurement of B0(s)  
+ branching fractions 105
5.1 Analysis strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
5.2 B0(s)  
+ mass and BDT PDFs . . . . . . . . . . . . . . . . . . . 108
5.2.1 Mass PDFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
5.2.2 BDT PDFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
5.3 Background mass PDFs and expected yields . . . . . . . . . . . . . . 113
5.3.1 Mis-identified B  h+h decays . . . . . . . . . . . . . . . . 114
5.3.2 Exclusive backgrounds . . . . . . . . . . . . . . . . . . . . . . 115
5.3.3 Combinatorial background . . . . . . . . . . . . . . . . . . . . 116
5.4 Normalisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
5.4.1 B0  K+ and B+  J/K+ yields . . . . . . . . . . . . . 117
5.4.2 Efficiency ratio . . . . . . . . . . . . . . . . . . . . . . . . . . 118
5.4.3 Hadronisation factors . . . . . . . . . . . . . . . . . . . . . . . 119
5.4.4 Normalisation parameters . . . . . . . . . . . . . . . . . . . . 119
5.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
6 Measurement of the B0
 +effective lifetime 125
6.1 Analysis strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
6.2 Mass PDFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
6.3 Decay time distributions . . . . . . . . . . . . . . . . . . . . . . . . . 128
6.3.1 B0s  + decay time PDF . . . . . . . . . . . . . . . . . . . 129
6.3.2 Background decay time PDFs . . . . . . . . . . . . . . . . . . 137
6.4 Measurement strategy . . . . . . . . . . . . . . . . . . . . . . . . . . 141
6.4.1 To fit for  or 1? . . . . . . . . . . . . . . . . . . . . . . . . 142
6.4.2 Optimisation of fit configuration . . . . . . . . . . . . . . . . . 145
6.5 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
Table of contents xiii
7 Systematic uncertainties and cross checks on the effective lifetime153
7.1 Accuracy of the fit . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
7.1.1 Fit stability with  values . . . . . . . . . . . . . . . . . . . 154
7.1.2 B0s  + yield estimation . . . . . . . . . . . . . . . . . . . 154
7.1.3 Overall bias on  . . . . . . . . . . . . . . . . . . . . . . . . 156
7.2 Background contamination . . . . . . . . . . . . . . . . . . . . . . . . 157
7.3 Mass PDF parameters . . . . . . . . . . . . . . . . . . . . . . . . . . 158
7.4 Acceptance function accuracy . . . . . . . . . . . . . . . . . . . . . . 160
7.5 Incorrectly assigned primary vertices and the detector resolution . . . 164
7.6 Combinatorial background decay time model . . . . . . . . . . . . . . 167
7.7 Mix of B0s mass eigenstates . . . . . . . . . . . . . . . . . . . . . . . . 168
7.8 Production asymmetry of B0s and B
s mesons . . . . . . . . . . . . . . 170
7.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
8 Summary and Outlook 173
8.1 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
8.2 Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
Bibliography 179
Appendix A Distributions of input variables for the global BDT 191
Appendix B Multivariate classifier development 195
B.1 Input variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
B.2 Training parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
B.3 Overtraining test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
Chapter 1
Introduction
The Standard Model (SM) [24] of particle physics is a Quantum Field Theory that
describes the building blocks of matter and their interactions. It has been developed
over several decades from a combination of theoretical progress and experimental
discoveries. The SM predicts that all matter is constructed from combinations of
particles called quarks or leptons and their anti-particles. The interactions between
these particles are governed by the strong, weak and electromagnetic forces. There
are a total of 6 quarks (u, d, s, c, t, b) and 6 anti-quarks (u, d, s, c, b, t) in the SM
that can interact via all three forces. There are also 6 leptons (e, , , e, ,
 ) and 6 anti-leptons (e+, +, +, e, ,  ), which, unlike quarks, do not interact
via the strong force. The interactions of each force are described by the exchange of
gauge bosons. The electromagnetic force is mediated by the photon (), the weak
force by the W and Z0 bosons and the strong force by eight gluons (g). The final
particle in the SM is the Higgs boson (H0). It is interactions with the field associated
with this boson that are responsible for the intrinsic masses of the particles. The
properties of the particles in the SM are summarised in Tables 1.1 and 1.2.
The SM can be used to predict how particles will interact and decay. These
predictions have been tested over the past decades and so far the SM has proved
to be extremely successful. However, despite its success, there are a number of
experimental observations that the SM does not explain. In its current form, the
SM cannot explain the observed oscillation of neutrinos between different types [69]
and it does not provide a particle or mechanism that could account for the observed
presence of dark matter and dark energy in the universe [1013]. The SM includes
three fundamental forces but the final force, the gravitational force, is not included
in its framework. Furthermore, at the start of the universe matter and anti-matter
should have been produced in equal amounts but that is not what is observed in the
universe today and the SM does not include a mechanism large enough to account
for this asymmetry [14, 15]. As well as experimental observations there are more
fundamental questions about the SM that are unanswered. For example the SM
2 Introduction
Name Symbol Mass/MeV/c2 Charge / e
Up u 2.2+0.60.4 23
Down d 4.7+0.50.4 13
Charm c 1270  30 23
Strange s 96+84 13
Top t 173210  510  710 23
Bottom b 4180+4030 13
Electron e 0.5109989461 0.0000000031 1
Electron neutrino e < 0.000002 0
Muon  105.6583745  0.0000024 1
Muon neutrino  < 0.000002 0
Tau  1776.86  0.12 1
Tau neutrino  < 0.000002 0
Table 1.1 Mass and electric charge of quarks and leptons in the SM taken from reference [5].
Only particles are listed; anti-particles have the same mass and opposite electric charge as
their corresponding particles. All masses listed are measured values or limits. The quark
masses use the MS renormalisation scheme, apart from the t quark mass that comes from
direct measurements.
Name Symbol Mass/GeV/c2 Charge / e
Photon  0 0
W boson W 80.385  0.015 1
Z boson Z0 91.1876  0.0021 0
Gluons g 0 0
Higgs boson H0 125.09  0.21  0.11 0
Table 1.2 Mass and electric charge of bosons in the SM taken from reference [5]. All
masses listed are measured values except for gluons and the photon. In the SM the gluons
and the photon do not couple to the Higgs field and are therefore massless. An upper limit
has been placed on the photon mass at 1  1018 eV [5] and gluon masses up to a few
MeV/c2 are not excluded.
does not explain why there are very large differences in the coupling strengths of the
electromagnetic, weak and strong forces or why there is a large range in the masses
of quarks and leptons. The examples given here illustrate that despite the success
of the SM it is not sufficient to describe the universe and indicate that it could be
a low energy approximation of a more fundamental theory [16]. A more complete
discussion of the shortcomings of the SM can be found in references [17, 18].
There exist many theories that go beyond the scope of the SM and seek to
explain what the SM cannot. These theories predict the presence of new particles
and phenomena that are collectively called New Physics (NP). At the moment there
is no clear indication of which Beyond the SM (BSM) theory may give the correct
description of the universe and the search for NP is ongoing. The Large Hadron
Collider (LHC) is the latest machine built to study the predictions of the SM and to
search for NP in high energy particle collisions. There are two different approaches
used to search for NP effects at the LHC and other experiments; direct searches and
indirect searches.
Direct searches involve looking for the production of on-shell NP particles and
phenomena in high energy collisions. This type of search is limited by the centre-
of-mass energy of the collisions that dictates the energy available for the creation
of new particles. The Higgs boson was discovered in 2012 by the ATLAS and CMS
collaborations using this type of search [19, 20] but no NP has been observed from
direct searches to date. The lack of observations enables constraints to be placed on
the parameter space of BSM theories.
Indirect searches precisely measure SM processes and look for deviations in the
measured values from the predicted values. Deviations can be caused by the presence
of NP that modifies the SM process. Indirect searches are not as limited by the
centre-of-mass energy as direct searches because NP or SM particles influencing
these processes are off-shell. In a similar way to direct searches, indirect searches
that do not reveal NP place constraints on the parameter space of the theoretical
models. Although indirect searches are yet to reveal any significant deviations from
SM predictions, some interesting anomalies have been seen in measured results in
heavy flavour physics. In b  sll transitions, where  = e or , deviations from
the SM predictions have been seen in measurements of the angular distribution of
B0  K0+ decays [2125], the branching fraction of B0s  + decays [26]
and the ratios R(K) = B
+K++
B+K+e+e [27] and R(K
) = B
0K0+
B0K0e+e [28]. Also
measurements of the ratios R(D) and R(D) for the branching fractions of B0 
D() and B0  D() [2933] differ from the SM predictions. The individual
measurements of these processes are all  2-3 standard deviations from the SM
predictions; however, combining the results from different decays and experiments
increases the significance of the difference. The combined results of different b  sll
4 Introduction
1985 1990 1995 2000 2005 2010 2015
1010
+  0sSM: B
+  0SM: BD0
ARGUS
CMS+LHCb
ATLAS
BaBar
Belle
2012 2014 2016
Fig. 1.1 Results from searches for and measurements of B0  + (red) and B0s  +
(purple) decays. Upper limits are shown without error bars at the 95% confidence level.
The figure is taken from reference [47] and has been updated to include the latest result
from the ATLAS experiment [38].
transitions are 4-5 standard deviations from the SM predictions [34, 35] and the
combined values of R(D) and R(D) measurements from different experiments are
 3.9 standard deviations from the SM predictions [36].
Particle decays and interactions that are suppressed in the SM offer excellent
areas for indirect searches for NP because in these processes the contributions from
BSM theories can be of a similar order of magnitude to contributions from the
SM. The rare decays of B0 and B0s mesons into two oppositely charged muons are
examples of such processes. The purely leptonic final states of these decays lead
to precise theoretical predictions for their branching fractions and the two muons
have an identifiable signature in particle detectors. The search for B0  + and
B0s  + decays began over 30 years ago and the experimental sensitivity to these
decays has dramatically increased since then as shown in Figure 1.1. The latest
experiments to join the search are the ATLAS, CMS and the LHCb experiments [37
47]. The high energy of the pp collisions of the LHC has enabled these experiments
to reach unprecedented sensitivities to B0(s)  
+ decays.
The first evidence for B0s  + decays was found in 2012 by the LHCb
experiment [45]. Since then, the LHCb experiment has measured the B0s  +
branching fraction to be B(B0s  +) = (2.9
1.0)109 at a statistical significance
of 4.0 and placed an upper limit1 on the B0  + branching fraction of B(B0 
+) < 7.4  1010 at the 95% confidence level [46]. These measurements were
1The B0  + branching fraction was measured as B(B0  +) = (3.7+2.52.1)  10
at a significance of 2.0, therefore the CLs method [48] was used to place an upper limit on the
branching fraction.
performed using data collected during 2011 and 2012 at the centre-of-mass energies
of 7 and 8 TeV, respectively. Searches for B0(s)  
+ decays performed by the
CMS experiment using data recorded in the same time period corroborated the
results from the LHCb experiment. The CMS experiment measured the B0s  +
branching fraction to be B(B0s  +) = (3.0
0.9)  109 with a statistical
significance of 4.3 and placed a limit on the B0  + branching fraction of
B(B0  +) < 1.1109 at the 95% confidence level [41]. The combined analysis
of the CMS and LHCb data sets, collected at centre-of-mass energies of 7 and 8 TeV,
resulted in the first observation of B0s  + decays and the first evidence for
B0  + decays [47]. The measured branching fractions were
B(B0s  
+)CMS+LHCb = 2.8+0.70.6  10
9 (1.1)
B(B0  +)CMS+LHCb = 3.9+1.61.4  10
10 (1.2)
with a statistical significance of 6.2 for the B0s and 3.0 for the B0. The ATLAS
experiment also searched for B0(s)  
+ decay using data collected during the
same period [38], measuring the B0s  + branching fraction as
B(B0s  
+)ATLAS = 0.9+1.10.8  10
9 (1.3)
with a statistical significance of 2.0. An upper limit was placed on the B0  +
decay of B(B0s  +) < 4.2  1010 at the 95 % confidence level.
Although it was hoped that large deviations from the SM predictions would
be found in these decays this has not yet been observed. All the measured values
are consistent with the expectations of the SM and have enabled constraints to be
placed on the parameter space available for New Physics models. Nevertheless, the
precision of the measurements allows plenty of room for NP effects to be revealed.
Furthermore, there is some tension between the separate measurements themselves
and the SM prediction as shown in Figure 1.2. Therefore, the study of B0(s)  
decays continues to be a very interesting topic in the search for NP effects.
The observation of B0s  + decays opens the way for other properties of
this decay to be studied. In particular the effective lifetime of B0s  + decays
provides a search for NP complementary to the branching fraction measurement, as
the presence of NP could be revealed in either both or only one of these measurements.
The search for the B0s  + decay is complete and the precise study of this decay
has begun. This dissertation documents the latest study of B0(s)  
+ decays
at the LHCb experiment. Measurements of the B0(s)  
+ branching fractions
and the B0s  + effective lifetime are presented using data collected during pp
collisions with centre-of-mass energies of 7, 8 and 13 TeV.
6 Introduction
Fig. 1.2 Measurements of the B0  + branching fraction and B0s  + branching
fraction from the ATLAS experiment (blue) and the combined analysis of the CMS and
LHCb datasets (grey) alongside the predictions of the SM (red) [38]. The measurements
were performed using data collected during 2011 and 2012 at centre-of-mass energies of
7 and 8 TeV, respectively. The results from the ATLAS experiment are shown when the
branching fractions are constrained to be positive (blue circle) and when no such constraints
are made (blue square).
Chapter 2
Theory of B  +decays; the
Standard Model and beyond
This chapter describes the theoretical motivation for the study of B0(s)  
decays. In the SM these decays are predicted to occur very rarely; Section 2.1
describes why B0(s)  
+ decays are suppressed compared to other decay modes
of B0(s) mesons in the SM. The branching fraction of B
(s)  
+ decays provides a
good observable to compare experimental measurements with predictions of the SM.
The determination of the theoretical predictions of branching fractions is outlined in
Section 2.2 and the discussion is based on references [49, 50]. Quark mixing leads to
oscillations between B0s and B
s states over time and therefore a difference between
the values of the predicted and measured B0s  + branching fractions. These
oscillations and the influence on the branching fractions values are described in
Section 2.3 and follows the material in references [5052]. A parameter, A, arises
from the difference between B0s and B
s mesons, this observable is complementary
to the branching fraction of B0s  + decays in the study of the SM and it
can be measured through the effective lifetime of B0s  + decays as described
in Section 2.4. The SM predictions for B0(s)  
+ branching fractions and the
B0s  + effective lifetime are given in Section 2.5 and the ways in which NP can
influence these observables is briefly discussed in Section 2.6.
2.1 B0(s)  
+ decays in the Standard Model
In the SM, quarks and anti-quarks can be combined in pairs to form mesons that
are held together by the strong force. The neutral B mesons, B0 and B0s , consist
of a b quark combined with a d quark for the B0 and an s quark for the B0s . Their
anti-particles, B0 and B0s, are formed by swapping over which quark in the pair is
the anti-quark. These particles are unstable and exist for  1012 s before decaying
into leptons, lighter mesons or a combination of both. One decay mode is when
8 Theory of B  +decays; the Standard Model and beyond
u, c, t u, c, tB0s
u, c, t
u, c, t
u, c, t
_ _ _
Fig. 2.1 Feynman diagrams for B0s  + decays in the SM via W -box and Z0-penguin
processes. The same diagrams apply to B0  + decays where the s quark is exchanged
for a d quark.
the B0(s) decays into two oppositely charged muons as B
(s)  
+. These decay
modes occur very rarely in the SM compared to other decays modes of the B0(s). The
fraction of B0 and B0s mesons that decay into two muons is  1010 and  109,
respectively. The suppression of B0(s)  
+ decays comes from three sources that
are described in the following.
The first source of suppression is due to the quarks that form the B0 and B0s
mesons. The composite quarks of a B0(s) both have the same charge magnitude,
therefore in the decay B0(s)  
+ only quark flavour and not quark charge changes.
This type of decay is called a flavour changing neutral current (FCNC). These
decays must proceed via the weak force because it is the only interaction in which
quark flavour is not conserved via the exchange of a W boson. However, FCNCs
are forbidden in the SM to occur at the tree level by the GIM mechanism [4].
Therefore B0(s)  
+ decays proceed via more complex diagrams such as W -box
and Z0-penguin diagrams as shown in Figure 2.1. The decays can also proceed
via Higgs-penguin diagrams however the contributions from these diagrams are
negligible [53]. The lack of B0(s)  
+ decays at the tree level causes them to be
suppressed compared to other B0(s) decay modes that can occur at the tree level.
Although the weak force allows quark flavour to change, the coupling strengths
between different quark flavours are not all the same magnitude. This leads to the
second source of suppression for B0(s)  
+ decays. The coupling strengths of
different quarks are described by the Cabibbo-Kobayashi-Maskawa (CKM) matrix [54,
2.1 B0(s)  
+ decays in the Standard Model 9
55]. Quarks can be separated into two types depending on their charge: up-type
quarks include u, c and t; and down-type quarks include d, s and b. The weak force
couples all up-type quarks to the weak eigenstate of the down-type quark in the
same family with the same strength, where the quark families are; u and d, c and s,
t, and b. The weak quark eigenstates are not the same as the mass eigenstates and
the two types of states are related via the CKM matrix as

 = VCKM

 =

Vud Vus Vub
Vcd Vcs Vcb
Vtd Vts Vtb


 , (2.1)
where d, s and b are weak eigenstates and d, s and b are mass eigenstates. The
CKM matrix is a unitary matrix with complex elements that ensure no tree level
FCNCs occur. Each element of the matrix gives the coupling strengths of transitions
between the mass eigenstates of quarks, for example the amplitude of a u quark
changing into a d quark is proportional to |Vud|.
The difference in the coupling strength sizes can be illustrated through the
Wolfenstein parametrisation of the CKM matrix [56], which parametrises the matrix
elements in powers of the small parameter of  = 0.22  |Vus|. The CKM matrix
then becomes
VCKM =

1  12
2  3A( i)
 1  12
2 2A
3A(1   i) 2A 1
+ O(4). (2.2)
This parametrisation shows that the CKM matrix is almost diagonal. For a B0(s) 
+ decay to occur, a single off-diagonal element is needed to describe the quark
transitions in Figure 2.1, thus introducing an additional source of suppression to the
decay. The internal quark lines in Figure 2.1 can have contributions from u, c and t
quarks. However, in the SM the contributions from u and c quarks are negligible
when compared to the t quark. This is due to the large t quark mass compared to
the other quarks, as given in Table 1.1, and because the coupling strength of the b
quark to any quark except the t is extremely small due to additional powers of  in
Equation 2.2.
The final source of suppression of B0(s)  
+ decays comes from the helicities
of the muons in the final state. Both B0 and B0s are spin zero particles and for
angular momentum to be conserved in the decay the spins of the two muons must
be oppositely aligned. This leads to the muons having opposite helicities. The weak
force only couples to left-handed particle states and right-handed anti-particle states.
10 Theory of B  +decays; the Standard Model and beyond
In the high energy limit where particles are massless, negative helicity states are
equal to left-handed states and positive helicity states are equal to right-handed
states. Therefore if the muons were massless the weak interaction could only produce
a  and a + with opposite helicities which cannot conserve angular momentum
in B0(s)  
+ decays. Muons are not massless, therefore B0(s)  
+ decays
can occur but are suppressed because m  MB(s) [5], leading to one of the helicity
states of the muons always being disfavoured.
Overall B0(s)  
+ decays are highly suppressed within the framework of the
SM compared to other decay modes of B0(s) mesons. Therefore these decays offer
excellent processes in which to search for NP because the contribution of BSM
theories to these decay rates can be of a similar order of magnitude to those from
the SM.
2.2 B0(s)  
+ Branching Fraction
The branching fraction of a particle decay offers an excellent observable through
which predictions of the SM can be compared to measured values. The B0(s)  
branching fraction is defined as the fraction of the total number of B0(s) particles that
decay into two muons. It can be calculated from the time-dependant decay rate,
(B0(s)(t)  
+), which is the probability per unit of time that a B0(s) decays into
two muons, as
B(B0(s)  
+) 
(B0(s)(t)  
+) + ( B0(s)(t)  +)
(B0(s)) + (B
. (2.3)
where (B0(s)(t)  +) is defined in an analogous way to (B0(s)(t)  
+),
(B0(s)) is the total decay rate for B
(s) mesons and (B
(s)) is the total decay rate
for B0(s) mesons. The SM predictions are calculated from the prompt decay rate
which ignores any evolution with time of B0(s) mesons. The branching fractions are
calculated using [57]
B(B0(s)  
+)th =
B(s)
(B0(s)(t)  
+)
, (2.4)
where B(s) is the mean lifetime of the B
(s) and (B
(s)(t)  
+) is the untagged
decay rate, defined as
(B0(s)(t)  
+) = (B0(s)(t)  
+) + (B0(s)(t)  
+). (2.5)
The untagged decay rate makes no distinction between the particle and anti-particle
decays, and is accessible by experiments provided B0(s) and B
(s) are produced in equal
2.2 B0(s)  
+ Branching Fraction 11
numbers. The branching fractions are calculated this way to enable easy comparison
of different B meson branching fractions including B0, B0s and B+ [57].
The prompt decay rate is evaluated from Fermis golden rule, relating the transi-
tion amplitude,
M(B0(s)  +), and the kinematics of the decay to the decay
rate as [58]
(B0(s)(t)  
MB0(s)
1  4
MB0(s)
2 M(B0(s)  +)2 , (2.6)
where m and MB0(s) are the masses of the muon and the B
(s), respectively.
Weak decays like B0(s)  
+ include interactions that occur at different energy
scales, from the weak propagators at MW  80 GeV/c2 to the strong coupling in
the B0(s) meson at QCD  0.2 GeV [5]. The Operator Product Expansion [59, 60] is
used to create the Effective Hamiltonian, Heff , which splits the interaction into two
very different energy levels. The transition amplitude then becomes
|M(B0(s)  
+)|  |Heff |B0(s) =
V iCKM|C()iO()i|B
(s) (2.7)
where GF is the Fermi coupling constant, V iCKM are CKM matrix elements, Ci are
Wilson coefficients, Oi are local operators and i is the sum over all possible Wilson
coefficient and operator pairs. The energy scale  separates the two energy levels in
the interaction. The Wilson coefficients describe short scale processes with energies
above . This incorporates the internal structure and loops of Feynman diagrams
leading to the dependence of Wilson coefficients on the W, Z0, H0 and t quark
masses. The long distance processes are described by the local operators Oi for
energies less than . The local operators link the initial and final states of the decay.
Wilson coefficients can be calculated using perturbation theory. However, this cannot
be used for the local operators which can lead to large theoretical uncertainties on
their values. The choice of  is arbitrary; however the final transition amplitude
must be independent of . Often the mass of the decaying particle is used.
In the Effective Hamiltonian in Equation 2.7 the CKM matrix elements are
factored out of the Wilson coefficients and operators, so the same coefficients and
operators can be used to describe both the B0 and B0s decays. The Effective
Hamiltonian for B0(s)  
+ decays is [61]
Heff = 
V tqVtb
10,S,P
(CiOi + C
i), (2.8)
where  is the fine structure constant and q corresponds to the d quark in the B0 or
the s quark in the B0s . The terms proportional to V cqVcb and V cqVub are negligible
12 Theory of B  +decays; the Standard Model and beyond
and can be neglected in Equation 2.8. The operators that can contribute to the
B0(s)  
+ Effective Hamiltonian due to the initial and final decay states are
O10 = (qPLb)(l5l), O
10 = (qPRb)(l5l), (2.9)
OS = mb(qPRb)(ll), O
S = mb(qPLb)(ll), (2.10)
OP = mb(qPRb)(l5l), O
P = mb(qPLb)(l5l). (2.11)
The operator O10 encompasses the only significant contributions in the SM that come
from W -box and Z0 penguin diagrams. The operator O10 describes the equivalent
interactions as O10 but for right handed currents that are forbidden in the SM. Finally,
the operators O(
S and O
P correspond to the exchange of scalar and pseudo-scalar
particles which are negligible in the SM.
The purely leptonic final state of B0(s)  
+ decays means that the computation
of the transition amplitude can be spilt in two so that all uncertainties arising from
the bound B0(s) states are encompassed into one parameter, FB(s) , the hadronic decay
factor. This leads to a theoretically clean prediction for the branching fraction.
The branching fractions for B0(s)  
+ decays can therefore be written as [62]
B(B0(s)  
+) =
B(s)G
W sin4 W
CSM10 V tqVtb2FB(s)MB0(s)m2
1  4m2
M2B(s)
(|P |2 + |S|2), (2.12)
where W is the weak mixing angle and MW the mass of the W boson. The branching
fraction has been parametrised in terms of CSM10 , P and S, where CSM10 is the SM value
of the operator C10 and
P  |P |eiP 
C10  C
CSM10
B0(s)
mb +mq
CP  C
CSM10
, (2.13)
S  |S|eiS 
1  4m2
B0(s)
B0(s)
mb +mq
CS  C
CSM10
. (2.14)
In the SM P and S are real, with the magnitudes P = 1 and S = 0, although the
branching fractions are parametrised in terms of P and S because BSM theories
can significantly alter their values. The presence of scalar particles could increase
the branching fractions above the SM expectation through C(
S leading to S > 0.
Furthermore, the contributions from scalar particles are not subject to helicity
constraints. Additionally, pseudoscalar particles can either enhance or suppress the
2.3 Quark mixing 13
branching fractions compared to the SM prediction depending on how the values of
P interfere with C
10 in NP models.
As well as the individual branching fractions of B0  + and B0s  +
decays, the ratio of the two branching fractions is also an interesting observable to
test the flavour structure of the SM. In the ratio the dependence of the branching
fractions on Wilson coefficients cancels, leaving it dependant on the elements |Vtd|
and |Vts| of the CKM matrix. The ratio of branching fractions is given by
B(B0  +)
B(B0s  +)
VtdVts

 1 
1  4m
. (2.15)
Therefore the ratio provides a test of the coupling strengths of different quark types
as described by the CKM matrix in the SM and could reveal whether or not BSM
theories follow this structure as well. An additional advantage of using the ratio of
branching fractions is that the theoretical uncertainty on the ratio is less than the
individual branching fractions because sources of uncertainties including those from
Wilson coefficients and |Vtb| cancel.
2.3 Quark mixing
The theoretical prediction for the B0(s)  
+ branching fractions described in
Section 2.2 does not take into account the evolution of the B0(s) and B
(s) mesons with
time. Once a B0(s) is created it will oscillate between the particle and anti-particle
states as it propagates through time, the same is true for the B0(s). Therefore the
states that travel through time are a superposition of the B0(s) and B
(s). Oscillations
occur as the constituent quarks transition between different flavours through the
exchange of W bosons as illustrated in Figure 2.2. The branching fractions are
measured from data where B0(s) and B
(s) decays are not separated, which is called
an untagged sample of B0(s)  
+ decays. Since a B0(s) or B
(s) lives for  1012 s
before decaying, the state that decays will not necessarily be the same as the
one that was produced. The measured branching fraction is not the same as the
prompt branching fraction used for the theoretical prediction. The measured value
corresponds to the time integrated branching fraction given by [57]
B(B0(s)  
+)exp 
(B0(s)(t)  
+)dt. (2.16)
Therefore for a meaningful comparison between the measured and predicted branching
fraction values, the difference in the two definitions must be evaluated [57, 61, 62].
14 Theory of B  +decays; the Standard Model and beyond
u, c, t
u, c, t
B0s B0s
s u, c, t
u, c, t
_ _ _ _
W WB0s B
_    
Fig. 2.2 Oscillation of B0s and B
s quarks through the exchange of W bosons. The same
diagrams apply to B0 and B0 oscillations but with the s quark exchanged for a d quark.
2.3 Quark mixing 15
2.3.1 Time evolution of the B0(s)
In pp collisions, initially each b and b quark hadronises to form a B0(s) or B
(s) described
at t = 0 by the states |B0(s) and |B
(s). The time evolution of these states must
be evaluated in order to determine the time integrated branching fractions. The
Time-Dependent Schrdinger Equation (TDSE) describes the time evolution of the
particle and anti-particle states as
|B0(s)(t)
|B0(s)(t)
M  i
|B0(s)(t)
|B0(s)(t)
 , (2.17)
where M and  are 2  2 Hermitian matrices describing mass and decay time with
the properties M12 = M21 and 12 = 21. Invariance under charge, parity and time
inversion introduces additional constraints of M11 = M22 and 11 = 22.
The B0(s)-B
(s) oscillations ensure that for any t > 0 the particles are a superposition
of |B0(s) and |B
(s) states. The off-diagonal elements in the mass and decay time
matrices mean that the eigenstates of the TDSE have different masses and lifetime
to the B0(s) and B
(s). The eigenstates can be defined at t = 0 as
|BH = p|B0(s)  q|B
(s), |BL = p|B
(s) + q|B
(s) (2.18)
with eigenvalues of (mH,L  iH,L/2) and the coefficients p and q are constrained
by |p|2 + |q|2 = 1. The eigenstates are known as heavy, |BH, and light, |BL, mass
eigenstates. The eigenvalues are different for the B0 and B0s systems, however the
treatment of the two systems is identical. To simplify the notation only the B0s
system will be described in the following discussion. The time evolution of the heavy
and light mass eigenstates is given by
|BH(t) = |BHei(mHi
2 )t, |BL(t) = |BLei(mLi
2 )t (2.19)
from the TDSE. Therefore, the time evolution of the flavour states can now be
determined from Equations 2.18 and 2.19 as
|B0s (t) =
(|BL(t) + |BH(t)) = f+(t)|B0s  +
f(t)|B
s (2.20)
|B0s(t) =
(|BL(t)  |BH(t)) =
f(t)|B0s  + f+(t)|B
s (2.21)
where
ei(msis)t
ei(ms+is)t/2  ei(ms+is)t/2
. (2.22)
16 Theory of B  +decays; the Standard Model and beyond
The relationships
mH +mL
, ms  mH mL, (2.23)
(H + L)
, s  L  H , (2.24)
have been used in the expressions of |B0s (t) and |B
s(t). The difference ms is
defined so that it is always positive whereas s can take either sign. The time
evolution is written in terms of these variables because ms and s are measurable
quantities.
Theoretical predictions can be calculated for M12 and 12 and it is therefore
useful to express the measurable quantities in terms of these parameters. This is
done by solving the characteristic equation of the TDSE, |M  i/2 I| = 0, which
has the solutions
m2s 
= 4(|M12|2 
|12|2) (2.25)
mss = 4|12||M12| cos (2.26)
where   arg(M12/12).
The observed relationships s  ms and 12  M12 [52] are used to separate
the expressions for ms and s to give
ms = 2|M12|
1 + O
 12M12

 (2.27)
s = 2|12| cos
1 + O
 12M12

 . (2.28)
The values of p and q can also be related to the measurable quantities and 12 and
M12 by diagonalising (M  i2) to produce
m2s + is/2
2M12  i12
 eiM
 12M12

 (2.29)
where M  arg(M12/|M12|) and a  |12/M12| sin and the relationships   m
and 12  M12 have been used. The value of M is related to the elements of the
CKM matrix and M = arg(V tbVtd) for the B0 and M = arg(V tbVts) for the B0s .
The ratio of p and q is given in terms of the small parameter a which is needed to
evaluate some SM processes but can be neglected in this process.
The necessary parameters used to describe the time evolution of B0(s) and B
states have now been expressed in terms of measurable or predictable quantities, and
therefore the time-dependant decay rates can now be evaluated. The decay rates
2.3 Quark mixing 17
can be expressed as
(B0(s)(t)  
+) = N
M(B0(s)  +)2 (2.30)
(B0(s)(t)  
+) = N
M(B0(s)  +)2 , (2.31)
where N equals the additional terms in Equation 2.6 from kinematic parameters
M(B0(s)  +) and M(B0(s)  +) are the transition amplitudes for
the particle and anti-particle decays as used in Equation 2.6. For the evaluation of
the time-dependant decay rates, the exact form of the transition amplitudes are not
needed. A new parameter is defined
 =
AA
 , (2.32)
where A = M(B0(s)  
+) and A = M(B
(s)  +), to simplify the decay
rate expression. Combining the information in Equations 2.20, 2.21 and 2.31, ignoring
terms of O(a) and using , the time-dependant decay rates are
(B0s (t)  
+) =
N |A|2est
(1 + ||2) cosh
+ (1  ||2) cos(mst)  2() sinh
 2() sin(mst)
(2.33)
(B0s(t)  
+) =
N |A|2est
(1 + ||2) cosh
 (1  ||2) cos(mst)  2() sinh
+ 2() sin(mst)
. (2.34)
The time integrated branching fraction depends on the sum of the B0(s) and B
time-dependant decay rates. Using Equation 2.34, the total decay rate is
(B0s (t)  
+) = N |A|2(1+||2)est
+ A sinh
(2.35)
18 Theory of B  +decays; the Standard Model and beyond
The parameter, A, has been introduced into the total decay rate and it is defined
A =
2()
1 + ||2
. (2.36)
The meaning of A can be seen when the total decay rate is written in terms of
the heavy and light B0(s) mass eigenstates as
(B0s (t)  
+) = N |A|2(1 + ||2)
(1  A)eLt + (1 + A)eH t
= RHeH t +RLeLt. (2.37)
This final expression for the decay rates shows how B0(s)  
+ decays can be
described in terms of the sum of the decays of the heavy and light mass eigenstates.
The parameter A is therefore related to the number of heavy and light mass
eigenstates that decay as
A =
RH RL
RH +RL
. (2.38)
The values A can take range from +1 when only heavy mass eigenstates decay as
B0s  + and 1 when only light mass eigenstates decay as B0s  +. The
same is true for the B0  + decay.
2.3.2 Impact on the Branching Fraction
The time-dependent decay rates are used to understand the difference between the
two branching fraction definitions. The final form of the decay rates in Equation 2.37
is used in the evaluation of the branching fractions. The prompt branching fraction
used in the theoretical predictions is
B(B0(s)  
+)th =
B(s)
(B0(s)(t)  
+)
(2.39)
B(s)
(RH +RL). (2.40)
The time integrated branching fraction that is measured is
B(B0(s)  
+)exp =
(B0(s)  
+)dt
B(s)
(RH +RL)
1 + Ay(s)
1  y2(s)
 , (2.41)
2.4 A and the B0s  + effective lifetime 19
where y(s) relates the heavy and light mass eigenstate decay times as y(s) = (s)/2(s).
Therefore the measured and prompt branching fraction values are related as
B(B0(s)  
+)exp =
1 + Ay(s)
1  y2(s)
B(B0(s)  +)th. (2.42)
For B0-B0 oscillations the difference in the lifetimes of the heavy and light mass
eigenstates is extremely small. Therefore y is negligible and the prompt branching
fraction is equivalent to the experimental branching fraction. However, for B0s -B
oscillations there is a large difference in the lifetimes of the mass eigenstates and
ys = 0.065  0.005 [5]. The prompt branching fraction must therefore be corrected
to account for the oscillations before it is compared to the experimental value.
2.4 A and the B0s  
+ effective lifetime
The definition of A in Equation 2.36 shows that it depends upon the transition
amplitude of B0s  + decays. In Section 2.2 the Effective Hamiltonian for
this decay was discussed and the branching fraction given in terms of the complex
variables P and S. Therefore A can also be expressed in terms of these parameters
as [61]
A =
|P | cosP + |S| cosS
|P |2 + |S|2
, (2.43)
where P and S are defined in Equations 2.13 and 2.14, respectively. In the SM,
P = 1 and S = 0, therefore A takes the maximal value of +1 and only the heavy
mass eigenstate decays as B0s  +. This can be understood because the final
state of a B0s  + decay is a CP odd state and the heavy B0s mass eigenstate is
a CP odd state.
As discussed in Section 2.2, NP models can alter the values of P and S, moving
them away from the SM expectations. A change in these values could alter both
the measured branching fraction and A or just one of these observables. Since
the comparison of the measured branching fraction to the SM prediction relies on
A, in order to understand possible NP contributions to the branching fraction,
A must be measured as well.
The value of A can be measured directly from the time-dependant decay rate
of B0s  + decays. This method involves separating the B0s  + decays into
those with |B0s  and |B
s initial states, which requires a large number of B0s  +
decays. Since B0s  + are very rare decays this approach is currently not viable.
Alternatively A can be measured through the B0s  + effective lifetime [57].
The effective lifetime is the mean decay time of an untagged sample of B0s  +
20 Theory of B  +decays; the Standard Model and beyond
Decay Predicted A Predicted  /ps Measured  /ps
B0s  J/f0(980) +1 1.609  0.010 1.700  0.040  0.026
B0s  J/K0S 0.94  0.07 1.605  0.011 1.75  0.12  0.07
B0s  K+ 0 1.518  0.005 1.60  0.06  0.01
B0s  K+K 0.972
+0.014
0.009 1.416  0.008 1.407  0.016  0.007
B0s  Ds D+s 1 1.413  0.008 1.379  0.026  0.017
Table 2.1 SM predictions for A and the predicted and measured values of the effective
lifetimes for B0s decays measured by the LHCb experiment. The effective lifetimes have
been measured for B0s  J/f0(980) [64], B0s  J/K0S [65], B
s  K+ [66], B0s 
K+K [66] and B0s  Ds D+s [67] decays. The quoted A values are taken from the
listed references and the predictions for effective lifetimes are computed using Equation 2.45
with Bs = 1.505  0.005 ps [36] and ys = 0.065  0.005 [5]. The deviation from 1 and +1
for the A values of B0s  K+K and B0s  J/K0S decays comes from CP violation in
these processes.
decays, defined as [63]
 
0 t(B0s  +)dt
0 (B0s  +)dt
. (2.44)
It can be expressed in terms of A using the decay rates in Equation 2.37 as
 =
1  y2s
1 + 2Ays + y2s
1 + Ays
. (2.45)
In the SM only the heavy B0s mass eigenstate decays as B0s  + and the effective
lifetime equals the lifetime of the heavy mass eigenstate,  = H = 1H . The
effective lifetime offers a measurement complementary to the branching fractions to
study the SM and NP models in B0s  + decays due to the dependence of the
effective lifetime on A.
The B0s  + effective lifetime can be measured by fitting a single exponential
to the same set of decays used to measure the branching fraction [57]. The LHCb
experiment has measured the effective lifetimes of several B0s decays in this way. The
measurements are summarised in Table 2.1 where the measured values are given
alongside the SM predictions for A and for the effective lifetimes.
2.5 The Standard Model predictions 21
2.5 The Standard Model predictions
The SM provides precise predictions of the time-integrated B0(s)  
+ branching
fractions [68]
B(B0s  
+) = (3.65  0.23)  109 (2.46)
B(B0  +) = (1.06  0.09)  1010 (2.47)
where the latest progress in lattice QCD calculations have been taken into account [69
71]. The largest contributions to the theoretical uncertainties come from the CKM
matrix elements and the decay constants of the B0s and the B0. The ratio of the
branching fraction values, defined in Equation 2.15 is [47]
B(B0  +)
B(B0s  +)
= 0.0295+0.00280.0025. (2.48)
The B0s  + effective lifetime is determined from Equation 2.45. Using the
SM value of A = +1, the B0s mean lifetime of Bs = 1.505  0.005 ps [36] and
ys = 0.065  0.005 [5] the SM effective lifetime is
 = 1.609  0.010ps, (2.49)
which is equal to the lifetime of the heavy B0s mass eigenstate as, in the SM, only
the heavy mass eigenstate of the B0s decays into two muons. The same calculation
can be performed for A = 1, giving the lifetime of the light mass B0s eigenstate
as L = 1.413  0.006 ps. The difference in these lifetimes is 0.195 ps and therefore a
precision of 0.38 ps would be needed to distinguish between A = +1 and A = 1
at 5 with the effective lifetime.
2.6 New Physics models and B0(s)  
+ decays
There exist a large number of BSM theories that can influence B0(s)  
+ decays
in different ways. Measurements of the B0(s)  
+ branching fractions and the
B0s  + effective lifetime can constrain the parameter space available for NP
and in doing so could reveal which theories are viable extensions of the SM. This
section will briefly introduce some NP models that could influence B0(s)  
decays given the current precision of the branching fraction measurements. For more
detailed discussions of NP models relevant to B0(s)  
+ decays and constraints
on these models from measurements see references [62, 72, 73].
As discussed in Section 2.2, the ratio of the B0  + and B0s  +
branching fractions provides an excellent test of the flavour structure of the SM and
22 Theory of B  +decays; the Standard Model and beyond
MSSM-AC
0 10 20 30 40 50
MSSM-LL
MSSM-RVV2
Fig. 2.3 Correlations between the B0  + and B0s  + branching fractions
including the SM prediction, the Minimal Flavour Violation hypothesis (MFV), four
Minimal Supersymmetric Standard Models (MSSM) [75] and the SM extended to contain
four generations of fermions (SM4) [76]. Figure is taken from reference [77].
BSM theories. Figure 2.3 shows possible values accessible by BSM theories alongside
the SM prediction. The prediction of the Minimal Flavour Violation (MFV) [74]
hypothesis is included. The MFV hypothesis predicts that the coupling of quark
flavour and CP violation follow the same Yukawa structure as the SM in NP models.
It is a popular theory to describe the flavour structure in NP models due to the
current agreement of measurements with the SM predictions. A significant deviation
of the branching fraction ratio from the SM or MFV hypothesis predictions would
indicate the need for a new flavour structure in theoretical models.
Additionally, NP models could move the branching fractions and A away from
the SM predictions by providing new particles that could contribute to the decays
either through loop diagrams, similar to those in Figure 2.1, or allowing the decays
to occur at the tree level. These new particles would change the Wilson coefficients
included in the parameters P and S. The dependence of the branching fractions and
A on P and S are different, as shown in Equations 2.12 and 2.43, and therefore NP
models can influence the observables independently. The allowed values of A and
the ratio of the measured branching fraction to prompt SM prediction for B0s  +
decays are shown in Figure 2.4 for possible situations where S = 0, P = 1, P S = 1
and P , S  {0, }. These figures illustrate that if NP effects are not revealed in
the branching fraction measurements, they could still appear in A.
Amongst the BSM theories that can influence the values of P and S are the
Two Higgs Doublet Model (2HDM) [79], supersymmetric models [80] and models
including leptoquarks.
2.6 New Physics models and B0(s)  
+ decays 23
(a) (b)
(c) (d)
Fig. 2.4 Allowed values for B(B0s  +) and A for situations where a) S = 0, b)
P = 1, c) P  S = 1 and d) P , S  {0, } (d) [62, 72]. The ratio R plotted is from an
average of the individual results from the CMS and LHCb collaborations from [78], and the
results from the combined analysis of the CMS and LHCb data gives R = 0.76+0.200.18 [47].
24 Theory of B  +decays; the Standard Model and beyond
The 2HDM extends the Higgs sector of the SM by introducing two complex
scalar field doublets both with non-zero vacuum expectation values. Spontaneous
symmetry breaking then produces two charged, one neutral pseudoscalar and two
neutral scalar Higgs bosons. The new particles can enter the loops of B0(s)  
decays and allow FCNCs to occur at the tree level. Different scenarios of this model
depend on the Higgs-quark interactions and can incorporate the MFV hypothesis.
This model can produce scenarios where S = 0, P = 1 or P  S = 1 [62, 72] and the
corresponding branching fraction and A values for B0s  + decays as shown
in Figures 2.4a, 2.4b and 2.4c.
Supersymmetric (SUSY) models extend the SM by giving each SM particle
a supersymmetric partner. The resulting theory is symmetric in terms of the
transformation of fermions to bosons and bosons to fermions. So far no evidence
for SUSY particles has been found, and therefore the symmetry must be broken
and the mass of SUSY particles are greater than their SM partners. The Minimal
Supersymmetric Standard Model (MSSM) includes a Higgs sector similar to the
2HDM and there are scenarios where it obeys the MFV hypothesis. B0(s)  
decays are sensitive to this model provided the ratio of the vacuum expectation
values of the Higgs doublet is large [8183]. The MSSM can produce values for A
and the B0s  + branching fraction shown in Figure 2.4c and 2.4d for situations
where P  S = 1 and P , S  {0, } [62, 72].
Models including leptoquarks are currently popular to explain the anomalies
observed in heavy flavour measurements [8488]. A leptoquark is a boson that carries
both lepton and baryons numbers, therefore leptoquarks can allow FCNCs to occur
at the tree level. The exact quantum numbers of these particles depend on their
interactions with SM fermions. Therefore leptoquarks could enhance B0(s)  
decays but information from A is necessary for the study of leptoquarks with
B0(s)  
+ decays because it resolves degeneracies that are present when only the
branching fraction measurements are considered [89].
Although B0(s)  
+ decays are yet to reveal NP, the current experimental
precision still leaves plenty of room for NP to be revealed. The observation of
B0s  + decays makes it possible to start investigating A through the B0s 
+ effective lifetime. A measurement of A will provide important information,
complementary to the B0(s)  
+ branching fraction measurements in the search
for NP in B0s  + decays.
Chapter 3
The LHC and the LHCb
experiment
The European Organisation for Nuclear Research (CERN) was founded in 1954 and
began with 12 member states as an organisation to encourage European collaboration
and to study nuclear physics. The collaborative nature of CERN has enabled large-
scale expensive experiments to be built that individual member states would not
have been able to afford. In 1959 the Proton Synchrotron (PS) was CERNs flagship
synchrotron accelerator. It had a circumference of 628 m and accelerated protons up
to a centre-of-mass energy of
s = 25 GeV, making the PS the highest energy particle
accelerator at that time. The PS was succeeded by the Super Proton Synchrotron
(SPS) in 1976. The SPS was 7 km in circumference and designed to accelerate protons
up to a centre-of-mass energy of
s = 400 GeV. The most notable achievements of
the SPS were the discoveries of the W and Z0 bosons in 1983 after the accelerator
had been converted into a proton - anti-proton collider. After the SPS, precise
measurements of the W and Z0 bosons were performed using the Large Electron
Positron collider (LEP) from 1989. The largest e+e collider built to date, LEP was
27 km in circumference and designed to operate around a centre-of-mass energy of
s = MZ and 2MW .
Now 63 years since its foundation, CERN has grown to include 22 member states1
and is still at the forefront of high energy physics research. CERNs latest accelerator,
the Large Hadron Collider (LHC), is the most energetic particle accelerator yet to be
built. It was built in the tunnel that housed LEP and is designed to collide protons
at a centre-of-mass energy of
s = 14 TeV.
This chapter introduces the LHC and the LHCb experiment, one of the experi-
ments that studies the products of particle collisions produced at the LHC. The LHC
is described in Section 3.1 along with the experimental runs that have occurred so
1Countries and organisations that are unable to become member states can still participate in
scientific research as observer states [90].
26 The LHC and the LHCb experiment
far. The LHCb experiment and the sub-detectors it is composed of are described in
Section 3.2. The study of particles produced in proton-proton (pp) collisions requires
information about the passage of charged particles and identity of particles travelling
through the detector. The sub-detectors in LHCb experiment that are designed to
track particles and identify the particle types are described in Sections 3.2.1 and
3.2.2, respectively. Not all events that occur when protons collide contain particles
that are interesting for the study of the SM and the search for NP effects, therefore
the LHCb experiment uses a trigger system, presented in Section 3.2.3, to identify
interesting events that are saved to be later analysed. The analysis of data recorded
by the experiment requires the use of custom software packages which are described
in Section 3.2.4. Finally, the data recorded by the LHCb experiment and used for
the analyses described in this dissertation are given in Section 3.3.
3.1 The Large Hadron Collider
The LHC is a proton synchrotron designed to accelerate and collide two beams of
protons with a centre-of-mass energy of 14 TeV. Although operation of the LHC
began in 2010 it is yet to reach the design energy. The purpose of the LHC is to
provide high energy pp collisions, the products of which are used for precision tests
of the SM and to search for NP effects that cannot be explained within the context
of the SM. There are four interaction points on the LHC ring where the beams
are collided, at these points various experiments detect and study the products of
particle collisions. In addition to protons, the LHC can also accelerate lead-nuclei up
to 2.76 TeV per nucleon. It is only the products from pp collisions that are studied
in this dissertation.
The protons accelerated by the LHC originate from hydrogen gas and the hydrogen
atoms are ionised to strip away the electrons. The protons are then accelerated
through a chain of particle accelerators of increasing energy before being injected
into the LHC. The chain of accelerators, shown in Figure 3.1, consists of machines
that were used in experiments throughout the second half of the last century and
have been modified to meet the requirements needed to provide protons to the LHC.
The protons leave the chain of accelerators with an energy of 450 GeV per proton
and in bunches of  1011 protons. As the bunches are injected into the LHC they
are split into two oppositely circulating beams. The LHC accelerates the protons to
the desired centre-of-mass energy using sixteen radio frequency cavities and guides
them around the ring with 1232 superconducting dipole magnets. Once the required
energy has been reached, the bunches are focused using 392 quadrupole magnets
before being collided at 4 interaction points around the LHC ring.
3.1 The Large Hadron Collider 27
Fig. 3.1 The accelerator complex at CERN. The chain of accelerators used to provide
protons to the LHC begins with the Linac 2 which accelerates protons to 50 MeV, the
protons are passed to the Proton Synchrotron Booster that accelerates them to 1.4 GeV.
The Proton Synchrotron is next in the chain, accelerating protons to 25 GeV and creating
the desired spacing between proton bunches. Then finally the Super Proton Synchrotron
accelerates protons to 450 GeV ready for injection into the LHC. Source: CERN.
28 The LHC and the LHCb experiment
The centre-of-mass energy of a collider is an important measure of its performance
as it describes the energy available to create particles during pp collisions. Another
important measure of collider performance is the instantaneous luminosity a collider
can provide. The instantaneous luminosity, L, is a measure of how many collisions
occur per second, and is given by
N2fnb
, (3.1)
where N is the number of protons per bunch, nb the number of bunches per beam,
f the bunch revolution frequency and F contains information about the beam
geometry. The LHC is designed to operate at a maximum instantaneous luminosity
of 1034 cm2s1. To reach this luminosity the LHC can have up to 2808 proton
bunches per beam with a revolution frequency of 11.245 kHz and a separation of 25
ns between each proton bunch. The higher the luminosity, the more collisions happen
in a second and the more particles can be produced; this is either advantageous
or disadvantageous depending on the particle interactions that are being studied.
Therefore the luminosity delivered at each interaction point can be tuned using the
quadrupole magnets by altering the shape and the orbit of each bunch to suit the
experiments at each interaction point.
There are seven experiments around the LHC that study particles produced in
proton and heavy ion collisions at the interaction points. These detectors are:
 ATLAS [91] and CMS [92], are general purpose detectors designed to search
for the Higgs boson and NP effects that are beyond the scope of the SM. These
experiments operate at the full instantaneous luminosity of the LHC;
 ALICE [93] studies quark-gluon plasma produced in heavy ion collisions to
understand conditions similar to those present in the early universe, products
from pp and lead-proton collisions are used to understand collisions of lead
ions;
 TOTEM [94] studies properties of protons as they collide head-on at the
LHC, to measure the pp interaction cross section and understand the internal
structure of protons;
 MOEDAL [95] is designed to detect magnetic monopoles and massive stable
charged particles predicted by theories that go beyond the scope of the SM;
 the LHCf experiment [96] studies particles that are created at very small angles
to the incident proton beams to understand similar processes that occur in
cosmic rays; and
3.2 The LHCb experiment 29
Run Year
s / TeV
Integrated luminosity / fb1
ATLAS CMS LHCb
Run 1
2010 7 0.04 0.04 0.04
2011 7 5.08 5.55 1.11
2012 8 21.3 21.79 2.08
Run 2
2015 13 3.9 3.81 0.32
2016 13 35.6 37.76 1.67
Table 3.1 Centre-of-mass energy for each year of data taking and the integrated luminosity
recorded by ATLAS, CMS and LHCb during pp collisions [98100].
 the final experiment is the LHCb experiment [97] designed to study rare b-
hadron decays and CP violating processes. It operates at a lower luminosity
and has a smaller angular acceptance than the general purpose detectors.
Proton beams first circulated in the LHC in 2008 and since then the experiments
have recorded data during two experiment runs separated by a long shutdown
period. The amount of data recorded by an experiment is given in terms of the time
integrated luminosity. Run 1 began in 2010 and continued until 2013, during this
time protons were collided with centre-of-mass energies of
s = 7 and
s =8 TeV.
After Run 1 there was a period of long shut down during which work was done to
prepare the LHC to operate at higher energies, renovation work was performed on the
accelerators that provide the LHC with protons and the experiments were prepared
for the second experiment run. Run 2 began in 2015 with proton collisions at a
centre-of-mass energy of
s = 13 TeV, and will continue until 2018 when a second
period of upgrades and maintenance will begin. The centre-of-mass energies for pp
collisions for each year of operation so far are summarised in Table 3.1, alongside
the integrated luminosity recorded by the ATLAS, CMS and LHCb experiments.
3.2 The LHCb experiment
The LHCb experiment was built to study the SM and search for NP phenomena
through the study of CP-violating decays and rare b-hadron decays. At the LHC the
dominant production mechanisms of bb pairs are gluon-gluon fusion, quark anti-quark
annihilation and gluon-gluon splitting, as shown in Figure 3.2. The bb pairs produced
travel at small angles relative to the beam pipe and the angular distribution is shown
in Figure 3.3. The bb pair is created at the primary vertex of an event, where the
protons collide. The quarks then hadronise to form a range of b-hadrons, including
B+, B0s and 0b . A typical b hadron will exist for approximately 1.5 ps [5] before
30 The LHC and the LHCb experiment
Fig. 3.2 Dominant production mechanisms for bb pairs created in pp collisions are: gluon-
gluon fusion (a); quark anti-quark annihilation (b); and gluon-gluon splitting (c).
decaying into leptons, light hadrons or a mixture of both. The vertex where the b-
hadron decays is known as the secondary vertex and is displaced by a few centimetres
from the primary vertex. The LHCb experiment was designed considering both the
cost of the detector and the physics processes that could be studied with it.
The LHCb experiment is a single arm forward spectrometer, with an angular
coverage of 10 to 300 mrad in the vertical direction and 10 to 250 mrad in the
horizontal direction relative to the beam pipe. A cross-section of the LHCb detector
is shown in Figure 3.4, where a right-handed coordinate system is used. The z and y
directions are shown in the figure and the x-axis points into the page. Protons collide
at the interaction point on the left-hand side of the diagram, a subset of particles
produced during the collisions travel through the detector leaving information in
the sub-detectors. The coordinate system is chosen so that the interaction point is
approximately at x = y = z = 0. The information deposited in the sub-detectors
is reconstructed to determine what happened during the pp collisions. Although
the angular coverage of the LHCb experiment is only 4% of the total solid angle, it
covers the smaller angles relative to the beam pipe at which bb pairs are produced,
as illustrated by the red shaded area in Figure 3.3.
The different sub-detectors have been chosen to exploit the characteristics of
b-hadron decays and fall into two distinct categories; tracking detectors and particle
3.2 The LHCb experiment 31
  [rad]1
 [rad]2
LHCb MC
 = 7 TeVs
Fig. 3.3 Simulated angular distribution for bb production at the LHC at center-of-mass
energies of 7 TeV, angles are relative to the beam pipe with  = 0 in the forward direction
and  =  in the backward direction. The red area shows bb pairs that are produced within
the angular coverage of the LHCb detector and the purple shaded area shows bb pairs
outside the detector coverage. Source: LHCb.
Fig. 3.4 Schematic of the LHCb detector [97]. A right-handed coordinate system is chosen
where the y and z directions are shown and the x direction points into the page.
32 The LHC and the LHCb experiment
identification detectors. The sub-detectors and their performances are described
briefly in the following sections along with the trigger system and software needed to
analyse the data collected by the experiment. For a more detailed description of the
detector and its performance during Run 1, see references [101, 97, 102, 103] and
those given in the text.
3.2.1 Tracking
The tracking system within the LHCb experiment consists of the vertex locator, a
dipole magnet and three tracking stations after the magnet. The vertex locator and
tracking stations are described in Sections 3.2.1.1 and 3.2.1.2 and the magnet is
described in Section 3.2.1.3. Together, the sub-detectors provide precise information
on the passage of charged particles through the detector, a measurement of the
particle momentum and electric charge. The tracking detectors work on the principle
that the passage of high energy charged particles through silicon or ionised gas causes
the excitation or ionisation of atoms in the material. The release of this energy is
recorded and translated into an electrical signal that reveals the path of a particle.
Hits left in the different detectors are combined to form tracks that are used to
identify particle decays as described in Section 3.2.1.4.
3.2.1.1 The vertex locator
The VErtex LOcator (VELO) [104, 105] is a silicon detector surrounding the interac-
tion point. Its main purpose is to provide precise information about the pp interaction
vertices and secondary decay vertices of the particles produced. Information from the
VELO enables precise measurements of particle lifetimes and the impact parameters
of particle tracks necessary for the study of particle decays.
The VELO is made of two identical halves, each half consists of 21 stations
containing two silicon sensors arranged along the beam pipe. The two halves of
the VELO slot together and there is a small gap in the centre for the beams to
pass through. The arrangement of sensors along the z-axis, shown in Figure 3.5, is
designed so that the sensors cover the full LHCb acceptance and a charged particle
within the detector acceptance will pass through at least three stations.
Each station is composed of two sensors: the R-sensor that measures the radial
distance of charged particles from the beam axis; and the -sensor that measures the
azimuthal angle of the particle with respect to the z-axis of the detector as shown in
Figure 3.6. The information from the sensors, combined with the distance of sensors
along the z-axis, is used to reconstruct charged particle trajectories. The cylindrical
geometry used for the VELO sensors, shown in Figure 3.6, is chosen to allow fast
reconstruction of particle trajectories in the VELO.
3.2 The LHCb experiment 33
Fig. 3.5 The VELO layout and position of sensors along the beam axis [97].
Fig. 3.6 Diagram of r and  sensor layouts [97].
34 The LHC and the LHCb experiment
The momentum resolution achievable for charged tracks by the LHCb experiment
is limited by the multiple scattering of particles as they travel through material the
detector is made from. Therefore, to ensure good momentum resolution throughout
the detector, the VELO is kept in a vacuum to reduce the material each particle
must travel through. Each half of the VELO is enclosed inside an aluminium box,
which keeps it in a vacuum and shields the electronic readouts from radio frequencies
generated by the beam.
Excellent resolution of the position of each vertex is required in the VELO to
identify the particle decays that occur. To achieve this the sensors need to be as
close as possible to the interaction point. This is achieved by making the VELO out
of two retractable halves and including the pp interaction point within the coverage
of the VELO. During data taking, when the VELO is recording particle tracks, the
inner most part of the sensors are 8 mm from the beam axis. However, during the
injection phase the width of the beam is much larger than 8 mm, therefore the halves
of the VELO are retracted to 3 cm from the nominal beam axis. This keeps the
VELO safe from unnecessary radiation damage. The two halves of the VELO are
displaced by 150 mm in the z-direction, as shown in Figure 3.5, so that when the
VELO is closed, the sensors in each half overlap to help with detector alignment and
reduced edge effects.
An additional purpose of the VELO is to identify high pile-up events. There are
two VELO sensors upstream of the interaction point that provide information to
the trigger about how many pp interactions there were in a bunch crossing. This
information can be used to identify events with high numbers of primary vertices.
The VELO achieves a resolution on the position of each vertex of 10 - 20 m
transverse to the z direction and 50 - 100 m along the z direction, the resolution of
each track depends on the number of tracks in each event as shown in Figure 3.7.
The VELO also gives measurements on the impact parameters of particles tracks;
the impact parameter (IP) is the distance of closest approach between a particle
track and the primary vertex. Figure 3.8 shows the IP resolution for 2012 data; a
track with transverse momentum of 1 GeV/c has an impact parameter resolution of
35 m.
3.2.1.2 Tracking stations
The LHCb experiment has 4 tracking stations in addition to the VELO. The Tracker
Turicensis (TT) is located upstream of the magnet and the T stations, T1-T3,
located downstream of the magnet [106, 107]. These tracking stations provide
complementary information to the VELO, and the presence of the magnetic field
allows the momentum and the sign of electric charge of particles to be determined.
3.2 The LHCb experiment 35
Fig. 3.7 Resolution of the position of vertices in an event achieved by the VELO in 2012
data. The resolution is shown for primary vertices perpendicular (left) and parallel (right)
to the beam axis as a function of the number of tracks in an event [105]. The resolution,
PV , as a function of the number of tracks, N , is fitted with the function PV = A/NB+C,
where A, B and C are constants that are given on the plots.
Fig. 3.8 Impact parameter resolution as a function of momentum (left) and inverse
transverse momentum (right) achieved by the VELO for 2012 data [105].
The TT is made up of 4 layers of silicon trackers that cover the full LHCb angular
acceptance. The TT is located just within the influence of the magnetic field of
the dipole magnet, which provides the detector with two main purposes. First, the
TT tracks the passage of charged particles with high momentum to enable good
momentum resolution of tracks when the information is combined with that from
other tracking stations. The TT has a resolution of 50 m for a single hit. This
resolution was chosen so that multiple scattering in the detector material rather
than detector resolution is the limiting factor for the momentum resolution. The
second purpose of the TT is to record tracks of low momentum particles that are
then swept out of the detector acceptance as they continue through the magnetic
field. These tracks will have a lower momentum resolution and help with pattern
recognition within the RICH detectors.
The T stations, T1-T3, use two different technologies. The central part of each
station is covered by the Inner Tracker (IT), made of silicon, while the external part
is covered by the Outer Tracker and composed of straw drift tubes. There is a large
36 The LHC and the LHCb experiment
Fig. 3.9 Illustration of the relative sizes of the tracking stations. The TT is in magenta
on the left-hand side of the diagram, the IT is in magenta surrounded in turquoise by the
OT on the right-hand side of the diagram and the beam pipe is shown in red [97].
increase in the size of the tracking stations between the TT and the T3 to ensure
all stations cover the full angular acceptance of the detector. The size of the TT is
150 cm  130 cm and the T3 station is 600 cm  490 cm. The relative sizes of the
tracking stations are illustrated in Figure 3.9 as well as the IT and OT sections of
the T1-T3 stations. The IT is very similar in design to the TT, each station is made
of 4 layers of silicon trackers with an overall track resolution of 50 m. The silicon
trackers are arranged in a cross shape around the beam pipe, as shown in Figure 3.9.
Although the IT covers less than 2% of the T stations, 20% of tracks pass through it.
This allows the occupancy of the OT to be less than 10% enabling a good overall
track resolution from the OT despite it not being made of silicon. The OT of each
tracking station is made of 2 staggered layers of straw tubes, covering the remaining
area required for full coverage of the LHCb angular acceptance, including tracks bent
by the magnetic field. The straw tubes have a fast drift time of 50 ns giving a better
than 200 m track resolution.
3.2.1.3 Dipole magnet
A warm dipole magnet [108] is used to measure the momentum and electric charge of
particles travelling through the LHCb detector. The magnet was designed to have an
integrated field strength of 4 Tm for a track that travels 10 m through the detector.
The magnet is located between the TT and the T stations and magnetic field
influences all charged particles in the LHCb angular coverage. The field is in the
vertical direction therefore bending tracks in the horizontal direction. The magnet
was designed so that the field strength in the RICH detectors is negligible (less than
3.2 The LHCb experiment 37
Fig. 3.10 Magnet field of the dipole magnet along the length of the LHCb detector. The
peak strength of the field occurs between the TT and T1-T3 station.
2 mT) and to have the largest strength possible between the TT and T stations.
Figure 3.10 shows a plot of the magnet strength along the length of the detector.
The polarity of the magnetic field is periodically switched so that charged tracks
are bent in the opposite direction. The polarity is switched to enable approximately
equal amounts of data to be recorded for each magnet polarity during every year of
data taking. This is done to measure detection asymmetries in each half of the detector
and to help understand systematic uncertainties of CP violation measurements.
3.2.1.4 Track reconstruction and performance
The information left by the passage of charged particles through the VELO, TT and
T stations is combined using track reconstruction algorithms to find trajectories of
charged particles through the length of the LHCb detector and infer the particle
momentum. The tracking algorithms start with either segments of tracks in the
VELO or the T stations and extrapolate from these segments into the other tracking
detectors using specific search windows. Once all the segments of a track have
been found, the trajectory is fitted with a Kalman Filter [109, 110] which takes into
account multiple scattering and energy loss within the detector. For each track the
Filter returns the 2 per degree of freedom, which is a measure of quality for the
track. This parameter is used to ensure that only good quality tracks are used in
physics analyses. The reconstructed tracks are classified into five types depending
on which detectors they travelled through, as shown in Figure 3.11.
The different track classifications are:
38 The LHC and the LHCb experiment
Fig. 3.11 Different types of tracks that are reconstructed at the LHCb experiment [111].
 VELO tracks are formed by particles produced at large angles to the beam axis
or travelling in the negative z direction from the interaction point, therefore
these particles only leave tracks in the VELO. VELO tracks are useful for
reconstructing primary vertices;
 Upstream tracks are made by low momentum particles that leave hits in the
VELO and TT stations. The absence of hits further down the detector is
because the magnetic field sweeps the particles out of the detector acceptance.
Upstream tracks have poor momentum resolution but are useful for under-
standing backgrounds and pattern recognition in the RICH-1 detector located
between the VELO and the TT;
 Downstream tracks are produced by the decays of long-lived neutral particles,
that travel out of the VELO before decaying. These particles only leave tracks
in the TT and T stations;
 T tracks are tracks that cross only the T1-T3 stations and are formed from
particles created in interactions with the detector material. Similar to upstream
tracks, T tracks can help to understand backgrounds and pattern recognition
in the RICH-2 detector located just before the T stations; and
 Long tracks are the most useful for understanding particle decays recorded
by the detector because they are formed by particles that travel through the
VELO, TT and T1-T3 stations. Information from all the tracking stations is
combined in these tracks; therefore they have the best momentum resolution.
The efficiency to correctly reconstruct tracks varies with the particle momentum
and the number of tracks present in an event, as shown in Figure 3.12 for 2011 and
2012 data. In Run 1 long tracks were correctly reconstructed an average of 96% of
the time.
3.2 The LHCb experiment 39
Fig. 3.12 Long track reconstruction efficiency as a function of momentum (left) and
number of tracks in the event (right) for 2011 and 2012 data [111].
Inevitably not all tracks that are reconstructed are correct, there are two main
types of incorrectly reconstructed tracks. The first are clone tracks that occur when
two tracks have many hits in common. When this happens the track with the highest
number of total hits is kept and the other is discarded. The second type are ghost
tracks that are formed when track segments in different detectors are incorrectly
joined together. This most often occurs with segments in the VELO and T1-T3
stations, the number of ghost tracks in an event depends on the event multiplicity.
These tracks are removed by cutting on the output of a neural network that returns
a probability of how likely a track is to be a ghost.
The combined tracking systems achieve a momentum resolution of p/p = 0.5%
for particles with p = 20 GeV/c and a resolution of p/p = 0.8% for particles with p
= 100 GeV/c. This momentum resolution, when combined with vertex information
from the VELO, gives a decay time resolution of around 50 fs [103].
3.2.2 Particle identification
The particle identification (PID) detectors consist of two Ring Imaging CHerenkov
(RICH) detectors, electromagnetic and hadronic calorimeters, and muon stations.
Together these detectors distinguish between different charged leptons and hadrons
and between neutral particles such as photons and neutral pions. Good particle
identification is necessary to determine which b-hadron decayed and to distinguish
between topologically similar decays, such as B0  K+, B0s  K+K and
B0(s)  
+ decays. The separate particle identification detectors are described in
Sections 3.2.2.1, 3.2.2.2 and 3.2.2.3 and the methods used to combine information
from each detector to identify different particle types is described in Section 3.2.2.4.
40 The LHC and the LHCb experiment
Fig. 3.13 RICH-1 detector (left) and the RICH-2 detector (right) [97]. For Run 2 the
aerogel radiator in the RICH-1 detector was removed.
3.2.2.1 Ring Imaging Cherenkov detectors
The LHCb experiment uses two RICH detectors [112, 113] that are shown in Fig-
ure 3.13. The RICH-1 detector is located between the VELO and the TT station and
RICH-2 detector is located between the last tracking station and the first muon sta-
tion. Together the detectors provide particle identification information for particles
that fall in the momentum range of 2 to 100 GeV/c. The RICH detectors are vital
to distinguish between pions, kaons and protons frequently produced in b-hadron
decays. The energy range of the RICH detectors was chosen to cover the momentum
range of decay products coming from multi-body and 2-body b-hadron decays.
These detectors are based on the following principle; when a charged particle
travels through a dielectric medium the atoms excited by its passage are polarised by
an induced electric dipole moment. If the particle is travelling faster than the speed
of light in the medium, the excitation energy is released as a coherent wavefront.
The angle the wavefront travels at relative to the particle trajectory, c, depends on
the particle velocity, v, and the refractive index of the medium, n, as cos(c) = c/nv.
The light is produced in a ring and is called Cherenkov radiation. The angle at which
Cherenkov radiation is produced gives a measurement of a particles speed, which
when combined with the particles momentum as measured by the tracking detectors,
the particle mass and consequently its identity can be determined. However, many
particles travel through the RICH detectors and create overlapping rings of light
making particle identification complex. As charged particles travel through RICH
detectors, the rings of light produced are focused by spherical and planar mirrors
3.2 The LHCb experiment 41
onto Hybrid Photon Detectors (HPDs) [114], as shown in Figure 3.13. The radii of
the detected rings provides information about how fast the particle was travelling.
Particle trajectories through the RICH detectors are inferred from information in
the tracking stations and the expected pattern of Cherenkov radiation is calculated
for each possible particle type. The expected patterns of light are compared to the
observed pattern to find the likelihood for each particle type, all possible particle
types are compared to maximise the likelihood. An in-depth description of the
reconstruction algorithm used in the RICH detectors can be found in [115].
The two RICH detectors provide identification information for different particle
momentum ranges. The RICH-1 is sensitive to particles in the momentum range of
2 to 40 GeV/c and the RICH-2 is sensitive to particles in the range 15 - 100 GeV/c,
to achieve this the detectors are made of different materials. The RICH-1 detector
is composed of an array of 16 aerogel tiles sensitive to particles with a momentum
between 2 and 10 GeV/c, behind the aerogel is a C4F10 gas radiator sensitive to
particles in the momentum range 10 to 40 GeV/c. The aerogel radiator was removed
after Run 1, therefore the RICH-1 is only sensitive to particles in the momentum
range 10 to 40 GeV/c in Run 2. Unlike the RICH-1, the RICH-2 detector is composed
of only one radiator, a CF4 gas radiator.
As well as covering different momentum ranges the RICH detectors also have
different angular acceptances. The RICH-1 covers the full LHCb angular acceptance
whereas the RICH-2 covers  120 mrad in the horizontal and  100 mrad in the
vertical direction. Although the angular acceptance for the RICH-2 detector is
smaller, the area it covers contains the higher momentum particles it is sensitive to
because the low momentum particles have been bent out of the acceptance by the
magnetic field.
The performance of HPDs used in the RICH detectors is sensitive to the magnetic
field of the dipole magnet. Therefore the HPDs are shielded from the magnetic field
using iron sheets ensuring the field is less than 2mT across them.
The expected Cherenkov angles for particle types with different momenta is shown
in Figure 3.14 for the radiator materials in the RICH detectors. The reconstructed
Cherenkov angle as a function of momentum is shown in Figure 3.15 for particles
transversing the RICH-1 detector in 2011 data; the data shows distinct bands for
each particle type as expected for the detector.
3.2.2.2 Calorimeters
The calorimeter system [116] consists of four detectors: a Scintillating Pad Detector
(SPD); a Pre-Shower (PS); an electromagnetic calorimeter (ECAL); and a hadronic
calorimeter (HCAL). Information from the calorimeters is used to identify electrons,
photons and hadrons with high transverse momentum to be used in the first level of
42 The LHC and the LHCb experiment
RICH1
RICH2
RICH1
Fig. 3.14 Expected Cherenkov angles produced by different particles travelling through
the radiators in the RICH detectors [97].
Fig. 3.15 Cherenkov angles for isolated tracks as a function of momentum in the RICH-1
detector for 2011 data [113].
3.2 The LHCb experiment 43
the trigger and to help with the reconstruction and identification of these particles.
The ECAL is particularly important in the reconstruction of photons and neutral
pions because it is the only part of the detector that measures the energy and
momentum of these particles.
The calorimeters in LHCb are sampling calorimeters consisting of layers of lead
absorbers and scintillating material. In lead, incident particles create showers of
secondary particles, the charged particles produced in the absorbers create light as
they pass through the scintillators. The light travels through wavelength shifters
where it is collected by photo-multiplier tubes and turned into an electrical signal.
Electromagnetic showers caused by photons, electrons or positrons are started by
ionisation, bremsstrahlung radiation or pair production depending on the energy and
the type of the incident particle. Hadronic showers are caused by the interaction of
hadrons with the detector via the strong force which produces showers of secondary
particles. The showers produced in the calorimeters are along the direction of flight
of the incident particle.
The SPD, PS and ECAL identify electrons, positrons and photons. The SPD is
a layer of scintillating material at the start of the calorimeter system. It separates
electron and photon showers created later in the calorimeter because only charged
particles will produce light in the SPD. Next in the calorimeter system is the PS,
and consists of a lead absorber followed by another scintillator similar to the SPD.
The length of the lead absorber is chosen so that electrons will start showers in the
absorber but charged pions will not. There is only a 1% chance of a pion creating a
shower in the PS. Information collected by the PS enables showers created by pions
in the ECAL to be separated from those created by electrons and positrons. The
ECAL is designed to contain the entire shower of high energy photons so that it
can provide a good energy resolution for photons passing through the detector. The
ECAL has an energy resolution of E/E = 9%/
E  0.8% provided information
from the PS and SPD are used.
The HCAL is predominately designed for use in the trigger and there is no
requirement that the HCAL contains the full hadronic showers, therefore it was
designed with a worse energy resolution of E/E = 69%/
E  9%.
3.2.2.3 Muon stations
Muons are produced in many b-hadron decays; good muon identification is necessary
to trigger events containing muons and to distinguish topologically similar decays
such as B0(s)  
+ and B0  K+ in the analysis of particle decays. Compared
with other particles, muons have a high penetrating power due to their relatively
large mass and because they do not interact via the strong force. These properties
44 The LHC and the LHCb experiment
Fig. 3.16 Layout of the muon stations [97].
are exploited in the muon detectors. There are five muon stations [117] located at
the far end of the detector from the interaction point.
The layout of the muon stations is shown in Figure 3.16. The first muon station,
M1, is located before the calorimeters. The inner section, where the fluence is
greatest, is made of Gas-Electron-Multiplier detectors [118] and the outer section
is made from Multi-Wire Proportional Chambers (MWPCs) [119]. The remaining
stations, M2-5, are located after the HCAL, by which point most other particles
have been absorbed by the calorimeters. These stations are made from MWPCs
interleaved with 80 cm of lead absorber to filter out any remaining hadrons.
A muon must have a momentum of at least 3 GeV/c to pass through the
calorimeters and the M2 and M3 stations. To travel through all the muon stations
a muon must have a momentum of 6 GeV/c. Momentum information collected in
the muon stations can be used in the trigger because the stations lie outside the
magnetic field, which allows for fast reconstruction of the tracks. M1 is located
before the calorimeters to improve the transverse momentum measurement of the
muons that is needed in the trigger.
After the muon stations there is an iron wall to stop any particles from travelling
downstream of the detector. The active area of the muon stations increases with
distance from the interaction point to ensure the full angular acceptance of the
detector is covered.
3.2 The LHCb experiment 45
3.2.2.4 Particle identification and performance
The information collected in the PID detectors is combined to provide several
discriminating variables that can be used to identify muons, protons, kaons, pions
and electrons. There are three types of variables: the isMuon criteria, DLL variables;
and ProbNN variables, which are described in the following. The performance of
these variables at distinguishing between different particles types is described in
detail in references [103, 120]
The muon stations are used, along with information from the tracking system,
to produce a binary selection to identify muons called the isMuon criterion. The
tracking system is used to extrapolate a field of interest within the muon stations, a
muon is identified if hits in the muon stations can be combined with those from the
tracking system within the field of interest. The number of hits required in the muon
stations depends on the momentum of the muon. Muons with momentum in the range
3<p<6 GeV/c are required to leave hits in M2-M3, those in the momentum range
6<p<10 GeV/c leave hits in M2-M3 and either M4 or M5, and finally muons with
momentum above 10 GeV/c must be observed in all the muon stations. Figure 3.17
shows the efficiency of the isMuon selection at identifying muons and probabilities of
mis-identifying different hadrons as muons. The efficiencies and mis-identification
probabilities are computed using the tag and probe technique. This technique uses
two tracks from a decay. Particle identification requirements are applied to one
track, the tag track, and the other track, the probe track, is used to evaluate the
efficiency or mis-identification probability. The computation of the efficiency of
the isMuon criteria to correctly identify muons uses J/  + decays. Proton
mis-identification probabilities are computed using 0  p decays, and pion
and kaon mis-identification probability are computed from D+  +D0( K+)
decays. The mis-identification rate is higher for lower momentum particles, which
is expected given there are less hits in the muon detectors. The main contribution
to mis-identifying hadrons as muons comes from the kaons and pions that decay as
they travel through the detector. The muons from these decays are then detected in
the muon stations.
The information from all the PID detectors is combined using two different
methods to provide global particle identification variables. One method is based
on likelihood fits, producing the DLL variables, and the other is based on Neural
Networks [121], producing ProbNN variables. In the first method, likelihood fits
are performed in each sub-detector comparing charged particle tracks to different
particle hypotheses. The resulting variable is the difference in the log-likelihoods
between the track corresponding to a pion and a kaon, proton, muon or electron. The
likelihood information from each sub detector is added linearly to form a combined
likelihood. These variables are called DLLX variables and give a measure of how
46 The LHC and the LHCb experiment
Muon momentum [GeV/c]
0 20 40 60 80 100
<1.7 [GeV/c]
0.8<p
<3.0 [GeV/c]
1.7<p
<5.0 [GeV/c]
3.0<p
>5.0 [GeV/c]
Proton momentum [GeV/c]
0 20 40 60 80 100
0.005
0.015
0.025
<0.8 [GeV/c]
<1.7 [GeV/c]
0.8<p
<3.0 [GeV/c]
1.7<p
<5.0 [GeV/c]
3.0<p
Pion momentum [GeV/c]
0 10 20 30 40 50 60 70
LHCbLHCbLHCb
 < 1.7 [GeV/c]
0.8 < p
 < 3.0 [GeV/c]
1.7 < p
 <5.0 [GeV/c]
3.0 < p
 < 10.0 [GeV/c]
5.0 < p
Kaon momentum [GeV/c]
0 10 20 30 40 50 60 70
LHCbLHCbLHCb
 < 1.7 [GeV/c]
0.8 < p
 < 3.0 [GeV/c]
1.7 < p
 <5.0 [GeV/c]
3.0 < p
 < 10.0 [GeV/c]
5.0 < p
Fig. 3.17 Muon efficiency (top left) and mis-identification probabilities for protons (top
right), pions (bottom left) and kaons (bottom right) for isMuon criteria [120].
3.2 The LHCb experiment 47
Signal efficiency
0 0.2 0.4 0.6 0.8 1
1 LHCb
) - log L(
ProbNN
DLL
Signal efficiency
0 0.2 0.4 0.6 0.8 1
1 LHCb
) log L(p -
ProbNNp
DLLp
Fig. 3.18 Muon (left) and proton (right) signal efficiency vs background rejection for DLL
and ProbNN PID variables [97].
likely a particle hypothesis of X is compared to that of a pion, where X can be a
muon, kaon, proton or electron.
The second approach uses Neural Networks to combine information from different
sub-detectors and to provide a global probability of a track having a particular particle
hypothesis. This method takes into account correlations between detector systems
and extra detector information that is not considered in the likelihood method. The
Neural Networks are trained on simulated inclusive b-hadron decays and can be tuned
to suit different situations, such as the data taking year. The variables produced
by the Neural Networks are called ProbNN variables and ProbNNX corresponds to
the probability of a track belonging to a particle hypothesis of X where X is a pion,
kaon, proton, muon or electron.
Figure 3.18 shows a comparison of the performance of the DLL and ProbNN
variables in selecting protons and muons. Although the performance of the two types
of variables are quite different, the efficiency of each variable varies with different
kinematic properties of the decay. The most appropriate PID variable type to use
depends on the physics analysis it is being used in.
3.2.3 Trigger
The LHC was designed to collide protons at a rate of 40 MHz, which is too high for
information to be read out by the original design of the LHCb detector2. However,
most pp collisions do not produce particles within the detector acceptance that are
interesting for the physics processes studied at LHCb. A trigger system [97, 122, 123]
is used to identify pp collisions that contain potentially interesting events, the
information from these events is saved and later analysed. The trigger has been
designed to select interesting physics events with a high efficiency whilst reducing the
2After the upgrade to the LHCb detector during the second long shut down after 2018, the
detector read out will be at 40 MHz
48 The LHC and the LHCb experiment
40 MHz bunch crossing rate
450 kHz
400 kHz
150 kHz
L0 Hardware Trigger : 1 MHz 
readout, high ET/PT signatures
Software High Level Trigger
29000 Logical CPU cores
Offline reconstruction tuned to trigger 
time constraints
Mixture of exclusive and inclusive 
selection algorithms
2 kHz 
Inclusive
Topological
5 kHz (0.3 GB/s) to storage
2 kHz 
Inclusive/
Exclusive 
Charm
1 kHz
Muon and 
DiMuon
LHCb 2012 Trigger Diagram
40 MHz bunch crossing rate
450 kHz
400 kHz
150 kHz
L0 Hardware Trigger : 1 MHz 
readout, high ET/PT signatures
Software High Level Trigger
12.5 kHz (0.6 GB/s) to storage
Partial event reconstruction, select 
displaced tracks/vertices and dimuons
Buffer events to disk, perform online 
detector calibration and alignment
Full offline-like event selection, mixture 
of inclusive and exclusive triggers
LHCb 2015 Trigger Diagram
Fig. 3.19 Diagrams of the trigger systems used in 2012 (left) and 2015 (right). Source:
LHCb.
event rate to one where information from the full detector can be read out. There are
two levels to the LHCb trigger; the hardware trigger and the software trigger. The
hardware trigger is known as the Level-zero (L0) trigger and reduces the 40 MHz
collision rate to 1 MHz at which the full detector can be read out. The software
trigger is known as the High-Level-Trigger (HLT) and has two stages that run on the
output of the L0 further reducing the event rate by utilising information for all the
detector sub-systems. Each level of the trigger is composed of trigger lines; these
lines are made up of reconstruction and selection algorithms and either accept or
reject each event. Only events that are accepted by a trigger line at both the L0 and
HLT are available for use in physics analyses. During the long shut down between
Run 1 and Run 2 of the LHC significant changes were made to the reconstruction
of particle decays used to make decisions within the HLT. Diagrams of the trigger
system used in 2012 and 2015 are shown in Figure 3.19 and are good illustrations of
trigger systems used throughout Run 1 and Run 2, respectively.
3.2 The LHCb experiment 49
3.2.3.1 L0 trigger
The L0 trigger runs synchronously to the LHC bunch crossing. Its purpose is to
reduce the event rate to 1 MHz, at which point information from the full detector
can be read out. The L0 is limited to use information from the detector that can be
read at the same rate as the LHC collision rate. Therefore the L0 uses information
from only the VELO, calorimeters and the muon stations to make decisions about
the relevance of each event.
The heavy masses of b-hadrons means that their decays are characterised by the
production of daughter particles with large transverse momentum (pT ) and transverse
energy (ET ). The L0 trigger is designed to identify high pT and ET hadrons, electrons,
photons and muons produced in events. Information from the PS, SPD, ECAL and
HCAL is used to identify electrons, photons and hadrons in each event. Events are
then accepted by the trigger lines if there is an electron, photon or hadron with ET
above a threshold value, where the ET thresholds are different for each particle type.
In a similar way to the calorimeters, the muon stations are used to identify muons
with high pT for trigger lines. There are two L0 trigger lines for muons that accept
events based on muon pT if either a single muon has a pT above a threshold value or
if the two muon combination
pT1  pT2 is above a threshold value.
An additional requirement is placed on events before they can be accepted by
any L0 trigger line, this requirement is based on the number of tracks present in an
event. Events containing a large number of tracks, high multiplicity events, take
a long time to reconstruct and process in the HLT, therefore it is not efficient to
save these events. The multiplicity is measured by the number of hits in the SPD
detector (nSPD) and only events with nSPD lower than a specified value can pass
an L0 trigger line. The ET and pT thresholds and the event multiplicity limit for
the L0 trigger lines vary for each year of data taking depending on the bandwidth
available for the trigger.
Finally, there is one other type of L0 trigger line that is not used to identify events
containing interesting physics processes. The pileup veto stations in the VELO are
used in L0 pileup trigger line, these lines identify the number of collisions in an event
and are predominately used for luminosity measurements [124].
3.2.3.2 HLT trigger
Events that are accepted by the L0 trigger lines are moved to a farm of multiprocessor
computing nodes, called the Event Filter Farm, where the HLT is run. The HLT is a
software trigger that is split into two levels that are run successively.
The HLT1 is the first level of the HLT. It runs on the output of the L0 checking
the decisions and reducing the event rate. The HLT1 trigger lines are composed
of generic selection criteria, making decisions that confirm those made in the L0
50 The LHC and the LHCb experiment
about particular particle types and also identify generic types of particle decays such
as inclusive b-hadron decays. The second level of the HLT, the HLT2, runs on the
output of the HLT1 trigger and consists of trigger lines designed to select decays
relevant to specific physics analyses or particle decay topologies.
During Run 1 time constraints in the HLT1 trigger to process the output of the
L0 did not allow for full event reconstruction using all LHCb sub-detectors. Instead
the HLT1 ran reconstruction and selection algorithms on information only from the
VELO and tracking stations. The reduced output of the HLT1 provided an event
rate that was low enough to allow event reconstruction that includes all detector
subsystems to be used in the HLT2. However, the reconstruction used in the HLT2
was different to the offline reconstruction that is applied to data before it is analysed.
Significant changes were made in the reconstruction used in the HLT between Run 1
and Run 2; the details of the changes made can be found in [125]. The majority of
the changes to the HLT for Run 2 are not relevant for the measurements presented
in this dissertation, but the overall change is that the same reconstruction is used in
the HLT and the offline reconstruction.
Just like the L0 trigger, trigger lines in the HLT vary for each year of data taking;
both the selection criteria used in the lines and also new trigger lines are introduced.
The number of HLT2 lines increases with each year of data taking as understanding
of the capabilities of the experiment increases; there were about 100 HLT2 lines in
2011, 200 in 2012, and 450 in 2015.
3.2.4 Software and simulation
The data that is read out of the LHCb experiment needs further processing be-
fore it can be analysed to study the SM and search for NP effects. The Gaudi
framework [126] is a C++ framework that is the basis for the software applications
needed to process data recorded by the LHCb experiment [127]. This framework
ensures the necessary software is available to all users and changes to the software
are implemented across all applications. It is suited to the distributed computing
system used in LHCb [128].
Once events have been accepted by the trigger, the first step in processing the
output of the detector is reconstructing events; this is done by the Brunel [129]
application. The reconstruction is applied to events that are accepted by the trigger
for both Run 1 and Run 2 data. However the reconstruction used for Run 2 data is
the same as that used in the trigger. The Brunel application takes the digitised
detector read out, reconstructs hits in the tracking stations to find particle trajectories
and momenta, and combines information from the RICH detectors, calorimeters and
muon stations to compute PID variables. The output of processing by the Brunel
application is stored in Data Summary Type (DST) files.
3.2 The LHCb experiment 51
Next the DaVinci application [130] is used to fit the tracks reconstructed in
Brunel with primary and secondary vertices. This application assigns particle
hypotheses to each track and reconstructs the decay trees of particles in the detector,
computing the kinematic properties of decays. The reconstructed output of the
trigger is too large to be stored in one place and to be used by all analysts, therefore
a stripping procedure is used to break up the data into a manageable size for
each of the different analyses performed on the data. Each analyst designs a set
of loose selection requirements, called stripping lines, specific to their decays of
interest. The selections are applied centrally to the reconstructed events and are
designed to keep as much of the signal relevant to the analysis as possible but reduce
the number of background events. Only events that pass the selection criteria of a
stripping line are available to be used in analyses. The output of this process are
smaller DST files. Events passing the stripping selections can either be saved with
the full event information or with just the tracks related to the signal candidate.
The choice depends on the physics process the stripping line is relevant for. The
stripping selection is run a limited number of times and is applied separately to data
collected in different years. Requirements are imposed on the amount of data each
stripping line can retain, typically the output of a line must be less than 0.05% of
the original data set size if the full event information is saved. Each analyst then
uses the DaVinci application one last time to produce Root [131] files from the
output of their stripping lines, these files display the data and properties of particle
decays in histograms and are used to analyse the data.
As well as data collected by the experiment, simulated data that mirrors what
is expected in the experiment is needed to understand the detector performance
and for the analysis of the data. There is a set of software applications that are
dedicated to the production of Monte Carlo simulated events within the Gaudi
framework. Events are generated using the Gauss application [132, 133], which uses
Pythia [134, 135] to model pp collisions and the production of particles, and then
the EvtGen application [136] is used to calculate the decay trees and kinematics of
these particles. Final state radiation is modelled using Photos [137]. Both Pythia
and EvtGen have been tuned for the production and decay of particles within the
LHCb detector. The Geant4 [138, 139] toolkit is used to model the interaction
of particles as they travel through the LHCb sub-detectors and the hits made by
particles in the detector. In the simulation the type of particles generated and how
they decay can be specified so that the simulated events of a particular decay can
be generated. The Boole application [140] then produces the digitised detector
read out based on the information from Geant4 that mimics the detector read out
when data is recorded. The output of Boole encompasses the detector response
to the different hits, the electronic read out and the L0 hardware trigger, as well as
52 The LHC and the LHCb experiment
Fig. 3.20 Integrated luminosity collected by the LHCb experiment in each year of data
taking. Source: LHCb.
including additional hits from event spillover and LHC backgrounds. The digitised
response of the detector is then processed by Brunel and DaVinci in the same
way as the real data to produce the Root files.
The LHCb software framework is set up so that it can be used on the Worldwide
LHC Computing Grid [141, 142]. The Grid is made up of computers across the
world that each store part of the LHCb data set and simulation data. Despite the
stripping process the data produced at LHCb is too large to be stored in one place.
The Dirac [143] system manages grid sites and the Ganga [144, 145] project allows
the submission of analysis code to different grid sites. The grid enables analysts to
process and study the large amounts of data produced by LHCb without having to
store the data where the analyst is.
3.3 Summary
The data collected so far by the LHCb experiment during pp collisions is summarised
in Figure 3.20. The physics analyses described in this dissertation use an integrated
luminosity of 4.4 fb1 that consists of data recorded during 2011, 2012 and 2015
and up until September of 2016. The break down of the integrated luminosities
for each year of data used in this dissertation are given in Table 3.2. The total
integrated luminosity of Run 2 is currently less that the total from Run 1. However
the production cross section for b-hadrons approximately doubled with the increase
in centre-of-mass energy between Run 1 and Run 2, therefore Run 2 data will already
contain a comparable number of b-hadron decays to Run 1 data.
3.3 Summary 53
Run Year
s / TeV Integrated luminosity / fb1
Run 1
2011 7 1.11
2012 8 2.08
Run 2
2015 13 0.32
2016 13 1.10
Table 3.2 Integrated luminosity of data collected by the LHCb experiment during pp
collisions used in the analyses documented in Chapters 5 and 6.
Chapter 4
Event selection
This chapter describes the criteria used to select and identify B-meson decays needed
for two analyses: the measurement of the B0  + and B0s  + branching
fractions; and the measurement of the B0s  + effective lifetime. In order
to measure properties of B0(s)  
+ decays from data collected by the LHCb
experiment, B0(s)  
+ decays must be separated from backgrounds in the data.
The main sources of backgrounds are described in Section 4.1. The development
of the selection criteria and analysis strategies rely on information from simulated
particle decays, these are documented in Section 4.2.
The selection criteria used to identify B0(s)  
+ decays and decays used as
normalisation channels for the branching fraction measurement are described in
Section 4.3. There are four main steps in the selection process. First, requirements
are applied to the output of the trigger and then the data is refined by cut-based
selection criteria. The last two steps in the selection process uses particle identification
variables and multivariate classifiers to separate signal and background decays.
The selection of decays for the effective lifetime measurement differs from that
used for the branching fraction measurement due to the different analysis strategies
described in Chapters 5 and 6. The criteria used to identify decays needed for the
branching fraction measurements are adapted for the effective lifetime measurement
and the changes made to each step of the branching fraction selection process are
documented in Section 4.4.
During the development of the selection criteria, B0(s)  
+ candidates in data
that have an invariant mass of the two muons within a specified window around the
B0s or B0 meson masses are not revealed. This is done to avoid introducing biases
into the selection procedure based on statistical fluctuations in the data. An analysis
performed in this way is known as a blind analysis. The mass windows are defined
as 5287 - 5447 MeV/c2 for the B0s and 5200 - 5360 MeV/c2 for the B0.
56 Event selection
4.1 Background sources
The reconstruction of the data collected by the LHCb experiment, described in
Section 3.2.4, produces numerous B0(s)  
+ candidates from pairs of muons
in the detector. Some candidates will have come from real B0(s)  
+ decays
but there are other processes that occur during pp collisions that leave a signature
in the detector which can be reconstructed incorrectly as a B0(s)  
+ decay.
The selection aims to separate real B0(s)  
+ decays from these backgrounds
to produce a set of B0(s)  
+ candidates with a high signal purity. The main
background sources are:
 Elastic collisions of protons that produce a pair of muons via the exchange
of a photon, pp  p+p. The protons travel down the beam pipe and are
undetected leaving the muons to be reconstructed as B0(s)  
+. Typically
the muons produced in this way have low transverse momentum;
 Inelastic proton collisions that create two muons at the primary vertex. The
muons form a good vertex and can be combined to form a B0(s) that appears
to decay instantaneously. This type of background is prompt combinatorial
background;
 B0s  + decays where the photon is not reconstructed. The presence of the
photon in the decay means that B0s  + decays are not helicity suppressed
and could therefore be a sizable background. However, the photon gains a large
transverse momentum resulting in the reconstructed B0(s) mass being much
lower than the expected B0s mass. The branching fraction of B0s  +
varies with the energy of the photon and is approximately an order of magnitude
higher than the B0s  + branching fraction [68, 146, 147];
 Random combinations of muons produced by separate semi-leptonic decays.
The B0(s)  
+ candidates formed in this way are called long-lived combina-
torial background because the reconstructed B0(s) will have a significantly longer
apparent lifetime than the B0(s) candidate of prompt combinatorial background;
 Semi-leptonic decays where one of the decay products is mis-identified as
a muon and/or is not detected. The resulting mass of the B0(s) candidate
is lower than expected due to the missing particle information. The semi-
leptonic decays that contribute to B0(s)  
+ backgrounds in this way are
B0  +, B0s  K+, 0b  p, B+  ++, B0  0+
and B+c  J/+ where J/  +; and
 B  h+h decays, where h() = K, , when both hadrons are mis-identified as
muons. This usually occurs when the hadrons decay whilst travelling through
4.2 Simulated particle decays 57
Decay Branching fraction
B0s  +  108
B0s  K+K (2.52  0.17)  105
B0s  K+ (5.6  0.6)  106
B0  K+ (1.96  0.05)  105
B0  + (5.12  0.19)  106
B0  + (1.45  0.05)  104
B0s  K+ (1.42  0.35)  104
0b  p (4.1  1.0)  104
B+  ++ (1.83  0.25)  108
B0  0+ (8.6  3.6)  109
B+c  J/+ (9.5  0.2)  106
Table 4.1 Branching fractions for background decays. The estimate of the B0s  +
branching fraction comes from reference [146]. The measured values of the B  h+h
B0  + 0b  p
 and B+  ++ branching fractions are taken from
references [5, 148, 149]. The theoretical prediction for B0s  K+ branching fraction
combines information from references [150, 151], the B+c  J/+ branching fraction is
estimated from references [152, 153] and the B0  0+ branching fraction is evaluated
from references [149, 154].
the detector. Similar to mis-identified semi-leptonic decays, the reconstructed
B0(s) candidate mass is lower than expected.
The branching fractions of the backgrounds from mis-identified decays are shown
in Table 4.1. The separation of B0  + and B0s  + decays from the
backgrounds is challenging because these decays are much less abundant than the
backgrounds. Therefore reconstructed candidates are predominately made from
background decays.
4.2 Simulated particle decays
Simulated particle decays, as described in Section 3.2.4, are used to develop the
selection and analysis of B0(s)  
+ decays. Large samples of simulated decays
are needed to separate signal from background decays and to evaluate the efficiency
of the selection criteria to identify different particle decays. The simulated decays
used for studies performed for this dissertation are listed in Table 4.2 alongside the
data-taking conditions and simulation versions used to generated the decays.
There exist multiple versions of the simulation because it is updated as under-
standing of the detector improves and to incorporate differences in data taking
58 Event selection
Decay Generator level cuts Data taking Simulation Events
conditions version (106)
Cut-based selection studies
B0s  + 2012 sim06b 2.0
B0  + 2012 sim06b 2.0
B0  K+ 2012 sim06b 1.0
B+  J/K+ 2012 sim06b 1.0
Multivariate classifier training
bb  +X p > 3 GeV/c 2012 sim06b 8.0
4.7 < m+ < 6.0 GeV/c2
DOCA < 0.4mm
1 < PtProd < 16 GeV2/c4
bb  +X p > 3 GeV/c 2012 sim06b 6.6
4.7 < m+ < 6.0 GeV/c2
DOCA < 0.4mm
PtProd > 16 GeV2/c4
B0s  + 2012 sim06b 2.0
Analysis method development
B0s  + 2011 sim08a 0.6
2012 sim08i 2.1
2015 sim09a 2.1
2016 sim09a 1.1
B0  K+ 2011 sim08b 0.8
2012 sim08g 8.6
2015 sim09a 4.6
2016 sim09a 8.1
B0s  K+K 2012 sim08g 7.1
2015 sim09a 4.0
Table 4.2 Simulated samples used for developing the selection and analysis of B0(s)  
decays listed according to the study the decays are used in. Cuts are applied to bb  +X
to the muon momentum magnitude (p), invariant mass of the two muons (m+), the
distance of closest approach of the tracks of the muons to each other (DOCA) and the
product of the transverse momenta of the muons (PtProd).
4.3 Event selection for the B0(s)  
+ branching fraction measurements 59
conditions, such as new trigger lines or changes in the centre-of-mass energy. Similar
versions are chosen for decay samples used within each study listed in Table 4.2,
so that differences between different decays are not masked by variations in the
simulation.
Simulated bb  +X decays are used to understand the long-lived combina-
torial background. However, producing a large enough sample of these decays to
be useful is computationally expensive and produces large output files. Therefore
cuts are applied as the decays are generated to reduce the size of the samples and
to speed up the simulation process. The cuts, listed in Table 4.2, are applied to
the magnitude of the muon momenta, the reconstructed mass of the muon pair, the
product of the transverse momenta of the muons and the distance of closest approach
of the tracks of the two muons. In addition, these samples are stripping filtered
which means that only candidates that pass the B0(s)  
+ stripping selection
criteria, discussed in Section 4.2, are saved to further reduce the size of the output
files. The cuts applied in the stripping selection are given in Table 4.4.
Overall simulated decays accurately model what occurs in data. However, the
distributions of particle identification variables and properties of the underlying
pp collision, such as the number of tracks in an event, are not well modelled in
the simulation. The mis-modelling of particle identification variables is corrected
for using the PIDCalib package [155] and simulated decays are re-weighted using
information from data to accurately model the underlying event, as described in
Section 6.3.1.
4.3 Event selection for the B0(s)  
+ branch-
ing fraction measurements
As well as identifying B0(s)  
+ decays in data, the branching fraction measure-
ments, described in Chapter 5, require B+  J/K+ and B  h+h decays as
normalisation modes to determine the branching fractions from the observed number
of B0(s)  
+ decays in data. Furthermore B0s  J/ decays are used to verify
steps of the measurement process.
This section describes the selection criteria used to identify B0(s)  
+, B 
, B+  J/K+ and B0s  J/ decays in data. The trigger requirements
used to identify these decays are given in Section 4.3.1. Section 4.3.2 describes a cut
based selection, tailored for each decay mode, that is used to refine the candidates
that pass the trigger requirements. Included in this section is an investigation
into the selection efficiency of cuts used in this step of the selection process. Up
until the cut-based selection the process for selection of B0(s)  
+, B  h+h,
B+  J/K+ and B0s  J/ decays is similar but the selection of B0(s)  
60 Event selection
decays diverges from the other decays with the requirements placed on particle
identification variables described in Section 4.3.3. The last step in the selection
process uses two multivariate classifiers that are described in Section 4.3.4 to separate
signal and background decays. One classifier is applied to all decays needed for
the branching fraction analysis whereas the other classifier is used only to separate
B0(s)  
+ decays from backgrounds. Finally, the selection criteria used for the
branching fraction measurements are summarised in Section 4.3.5.
4.3.1 Trigger requirements
The trigger, described in Section 3.2.3, selects events that could contain interesting
particle decays. Candidates consistent with different particle decay hypotheses are
reconstructed from events that were accepted by the trigger. For each candidate it is
useful to know whether it was a component in that candidate that caused the event
to be selected by a trigger line or if it was another particle in the event. Each trigger
line produces different decisions that identify this. The possible trigger decisions are:
 TOS, triggered on signal - a candidate is identified as TOS if only information
from the candidate was enough to cause a trigger line to save the event;
 TIS, triggered independent of signal - a candidate is identified as TIS if part of
the event independent of the candidate was sufficient to cause a trigger line to
save the event; and
 DEC - a candidate is identified as DEC if anything in the event caused a trigger
line to save the event. This includes TIS and TOS decisions and also when a
combination of information from the candidate and something else in the event
caused a trigger line to save the event.
Since B0(s)  
+ decays are very rare decays, the trigger requirements are chosen
to keep a high efficiency for selecting B0(s)  
+ decays at this step of the selection.
Individual trigger lines are not used for the selection; instead global trigger lines that
combine the information from many separate lines are used. Furthermore candidates
are required to be identified as DEC for each level of the trigger to ensure a high
efficiency is achieved. The combined trigger lines used at each level of the trigger are
the L0Global, Hlt1Phys and Hlt2Phys lines. The L0Global combines all trigger lines
present in the L0 trigger. It selects an event provided at least one L0 trigger line
selects it and rejects an event if no L0 trigger selects it. The Hlt1Phys and Hlt2Phys
triggers are very similar to the L0Global trigger except that decisions are based only
on trigger lines related to physics processes and HLT trigger lines used for calibration
are excluded.
4.3 Event selection for the B0(s)  
+ branching fraction measurements 61
Trigger Line Trigger decision
B0(s)  
+, B+  J/K+, B0s  J/
L0Global DEC
Hlt1Phys DEC
Hlt2Phys DEC
B  h+h
L0Global TIS
Hlt1Phys TIS
Hlt2B2HHDecision TOS
Table 4.3 Trigger decisions used to select B0s  +, B  h+h
, B+  J/K+ and
B0s  J/ decays.
The trigger requirements to identify B0(s)  
+ decays are also used to select
B+  J/K+ and B0s  J/ decays and slightly different trigger requirements
are used for B  h+h decays. B  h+h decays are required to be TIS by the
L0Global and Hlt1Phys trigger lines and TOS at the HLT2 level by specific trigger
lines designed to select B  h+h decays. The TIS decision is used for B  h+h
decays to reduce the difference in selection efficiencies between the dominant lines
that trigger B  h+h and B0(s)  
+ decays. However, the efficiency of TIS
decisions is quite low at the HLT2 level, therefore TOS decisions are used so that
there is a large enough samples of decays.
In summary, the requirements imposed on the trigger to select B0s  +,
B  h+h, B+  J/K+ and B0s  J/ decays are shown in Table 4.3.
4.3.2 Cut-based selection
The B0(s)  
+ candidates that pass the required trigger decisions are refined
by a cut-based selection. The selection criteria for B  h+h, B+  J/K+
and B0s  J/ decays are kept as similar as possible to that used to identify
B0(s)  
+ decays in order to reduce systematic uncertainties from selection
efficiencies in the normalisation procedure described in Section 5.4. The cut-based
selection is composed of two parts; the stripping selection and the offline selection.
The stripping selection described in Section 3.2.4, is applied to all events that
pass the trigger. It consists of individual stripping lines that select reconstructed
candidates for specific decays. The stripping selection used to select B0(s)  
B  h+h, B+  J/K+ and B0s  J/ decays in the branching fraction
measurements published in references [46, 47] is described in Sections 4.3.2.1. These
62 Event selection
selection requirements were designed at the start of Run 1 by studying the efficiencies
of different selection cuts from simulated events [156]. However since then improve-
ments have been made to the simulation of particle decays at LHCb, therefore it is
prudent to check the accuracy of the selection efficiencies with updated simulated
events and also to investigate where improvements can be made to the efficiency of
the B0(s)  
+ stripping selection. An investigation into the choice of cuts used in
the stripping selection is described in Section 4.3.2.2.
The offline selection cuts are applied to the output of the stripping selection.
Overall the stripping selection imposes loose selection requirements onto B0(s)  
candidates so that as much information as possible is still available to develop the
analysis and understand background events after the stripping selection. Therefore
the offline selection further refines the data, removing background candidates. The
offline selection cuts are presented in Section 4.3.2.3 and difference in selection criteria
applied to Run 1 and Run 2 data are detailed.
4.3.2.1 Development of the stripping selection
There are four separate stripping lines that are designed to select B0(s)  
B+  J/K+, B0s  J/ and B  h+h
 candidates, respectively. Although
the selection of all decays is kept as similar as possible to the signal selection, the
selection of B+  J/K+ and B0s  J/ decays diverges from the B0(s)  
selection due to the additional particles in the final state of the decay.
The stripping selection cuts applied for the Run 1 branching fraction analysis [47,
46] to select B0(s)  
+, B+  J/K+, B0s  J/ and B  h+h
 candidates
are listed in Table 4.4 and 4.5.
The variables used in the stripping selection are:
 the reconstructed mass (M) - the mass and momenta of the decay products of
the B meson (or J/) are combined to provide its reconstructed mass. Cuts
on the mass remove candidates with a reconstructed mass far from expected,
which are consistent with background. Loose mass requirements are made in
the B0(s)  
+ selection to allow for the study of semi-leptonic backgrounds
in data that have a mass lower than the B0(s) mass when mis-identified as a
B0(s)  
+ decay;
 the direction cosine (DIRA) - this is the cosine of the angle between the
momentum vector of the particle and the vector connecting the production
and decay vertices1 of the particle. For correctly reconstructed candidates the
1The production vertex of the B or the primary vertex is identified by extrapolating the B
meson momentum vector towards the beam axis. The closest vertex to the intersection of the B
momentum and the beam axis is assigned as the primary vertex.
4.3 Event selection for the B0(s)  
+ branching fraction measurements 63
Particle B0(s)  
+ B  h+h
B0(s) |MB0(s) - M
B0(s)
| < 1200 MeV/c2 |MB - MPDGB | < 500 MeV/c2
DIRA > 0 DIRA > 0
2FD >225 2FD >225
2IP < 25 2IP < 25
2VTX < 9 2VTX < 9
DOCA < 0.3 mm DOCA < 0.3 mm
 < 13.248 ps
pT > 500 MeV/c
 or h 2trk < 3 2trk < 3
isMuon = True Ghost probability < 0.3
Minimum 2IP > 25 Minimum 2IP > 25
pT > 0.25 GeV/c 0.25 GeV/c < pT < 40 GeV/c
Table 4.4 Selection requirements applied during the stripping selection for Run 1 data
used in the B0(s)  
+ branching fraction analysis [46, 47] to select B0(s)  
+ and
B  h+h
 decays. MPDG corresponds to the Particle Data Group [5] mass of each
particle.
direction cosine should be very close to one. Requiring candidates to have
positive value ensures that candidates travelling in the wrong direction are
removed;
 the flight distance 2 (2FD) - this is computed by performing the fit for the
production vertex of a particle with and without the tracks originating from
the decay vertex of the particle. For a B meson the 2FD is likely to be large
because B mesons have long lifetimes therefore the tracks from its decay vertex
will not point towards the production vertex;
 track fit 2 per degree of freedom (2trk) - provides a measure of the quality
of a fitted track, placing an upper limit on this variable removes poor quality
tracks and backgrounds composed of poorly reconstructed decays;
 vertex fit 2 per degree of freedom (2VTX)- provides a measure of how well
tracks can be combined to form a vertex, placing an upper limit on this variable
removes poorly constrained vertices and backgrounds composed of poorly
reconstructed decays;
 distance of closest approach (DOCA) - this is the distance of closest approach
of the tracks of the two daughter particles that make up a parent particle. It
64 Event selection
Particle B+  J/(+)K+ Particle B0s  J/(+)(K+K)
B+ |MB+ - MPDGB+ | < 500 MeV/c
2 B0s |MB0s - M
| < 500 MeV/c2
2V TX < 45 2V TX < 75
2IP < 25 2IP < 25
J/ |MJ/ - MPDGJ/ | < 100 MeV/c
2 J/ |MJ/ - MPDGJ/ | < 100 MeV/c
DIRA > 0 DIRA > 0
2FD > 225 2FD > 225
2VTX < 9 2VTX < 9
DOCA < 0.3 mm DOCA < 0.3 mm
 2trk < 3  2trk < 3
isMuon = True isMuon = True
Minimum 2IP > 25 Minimum 2IP > 25
pT > 0.25 GeV/c pT > 0.25 GeV/c
K+ 2trk < 3  |M - MPDG | < 20 MeV/c2
pT > 0.25 GeV/c Minimum 2IP > 4
Minimum 2IP > 25
K 2trk < 3
pT > 0.25 GeV/c
Table 4.5 Selection requirements applied during the stripping selection for Run 1 data
used in the B0(s)  
+ branching fraction analysis [46, 47] to select B+  J/K+
and B0s  J/ decays. MPDG corresponds to the Particle Data Group [5] mass of each
particle.
4.3 Event selection for the B0(s)  
+ branching fraction measurements 65
is computed from straight tracks in the VELO. For the decay products of a
particle, for example the muons from B0(s)  
+, this distance would ideally
be zero because the muons originate from the same vertex;
 decay time () - is the length of time a particle lives as it travels from its
production vertex to its decay vertex. Applying an upper decay time cut
removes unphysical background decays;
 isMuon - particle identification variable, defined in Section 3.2.2, that returns
True for muons and False for other particles;
 transverse momentum (pT ) - the component of a particles momentum perpen-
dicular to the beam axis. Decay products of B mesons are expected to have
relatively high pT due to the heavy masses of B mesons, however, an upper
limit removes unphysical backgrounds;
 momentum (p) - an upper limit placed on the momentum of a particle to
remove unphysical backgrounds;
 ghost probability - defined in Section 3.2.1.4, provides the probability of a track
being composed of random hits in the detector, tracks from the passage of real
particles will have a low ghost probability;
 impact parameter 2 (2IP) - this is the change in the fit 2 for a primary vertex
(PV) caused by removing one track in the fit. In a B0(s)  
+ decay, the
B0(s) is produced at the PV therefore it should have a small 
IP value whereas
the muons will be displaced from the PV and will have a large 2IP because of
the relatively long lifetime of the B0(s);
 minimum impact parameter (minimum 2IP) - this is the 2IP of the muons with
respect to all PVs in the event, this parameter is used to remove prompt muons
created at any PV in the event and therefore reduce the prompt combinatorial
background.
The stripping selection imposes a greater number of cuts to select B  h+h
decays compared to B0s  + because B  h+h
 decays are much more abundant.
Therefore extra cuts are needed to reduce the number of events passing the stripping
to an acceptable level. The cuts applied to only B  h+h decays in the stripping
are applied to B0(s)  
+ candidates in the offline selection.
4.3.2.2 Investigation of the stripping selection
An investigation into the efficiency of selection cuts used in the stripping lines to
select B0(s)  
+, B  h+h and B+  J/K+ decays is presented in this
66 Event selection
section. The efficiency of the B0s  J/ stripping line is not investigated because
it is not used as a normalisation channel for the branching fraction measurements.
First, the efficiencies of selection cuts used in each stripping line to select its signal
decay are evaluated using simulated decays. This is done to identify which cuts
can be changed to improve the selection efficiency of B0(s)  
+ decays. Then,
the efficiencies of cuts used in the B0(s)  
+ stripping line are compared to
the efficiencies of the B  h+h and B+  J/K+ stripping lines for different
cut values. This is done because the selection efficiencies of B0(s)  
+ and
the normalisation channels must be similar to keep systematic uncertainties of the
normalisation procedure under control and any change made to the B0(s)  
stripping line must be propagated through to the other stripping lines. These studies
show that improvements to the selection efficiency of the B0(s)  
+ stripping line
can be made by changing the cuts on the B0(s) 
FD and the muon minimum 2IP of
B0(s)  
+ candidates. Therefore the efficiencies of different cut values applied to
these variables are investigated. These variables are chosen because the selection
requirements imposed on them have the lowest efficiencies in the stripping selection,
as shown in Table 4.6. The impact of changing the requirements placed on these
variables on the measurement of the B0(s)  
+ branching fractions has not been
evaluated. One of the main purposes of the stripping selection is to reduce the size of
the data collected by LHCb to a manageable level that can be analysed. Therefore
the change in the amount of data retained by the stripping lines is evaluated and
new cut values are chosen. Finally the cuts used to select candidates in the stripping
for the branching fraction measurements described in Chapter 5 are summarised at
the end of this section.
Stripping line efficiency
The efficiencies of the selection cuts in the B0(s)  
+, B  h+h and B+ 
J/K+ stripping lines at selecting B0(s)  
+, B  h+h and B+  J/K+,
respectively, are evaluated using simulated decays. The efficiencies are evaluated as
the fraction of reconstructed decays within the detector angular acceptance that pass
a stripping selection cut. Several selection requirements are applied to the simulated
decays before the efficiencies are evaluated. These are: the pT requirement on the
daughter particles in the decays; the 2trk requirement; and all muons are required
to have isMuon = True. These cuts are applied when Root files are created, as
described in Section 3.2.4, and cannot be changed. No trigger requirements have
been applied so that only the effect of the stripping selection on the efficiencies
can be assessed. During the simulation of particle decays the trigger is run in pass
through mode so that all reconstructed decays are saved, not just those that have
passed a trigger line.
4.3 Event selection for the B0(s)  
+ branching fraction measurements 67
68 Event selection
The efficiencies have been evaluated for each cut that is used in all three stripping
lines and also for the total selection efficiency of each stripping line, the results are
shown in Table 4.6.
The efficiencies for most of the stripping cuts are  97% or higher. However, the
efficiencies of the cuts on the 2FD of the B0(s) or J/ and the daughter 
IP of the muon
or hadron pair are lower at 83% and 80%, respectively. Therefore improvements to
the stripping selection efficiencies could be achieved by altering these two selection
requirements.
Comparison of different stripping lines
The selection efficiencies are very similar for stripping cuts across the different decays,
fitting the requirement that the selection of signal and normalisation decays used in
the branching fraction measurement are as similar as possible.
The similarity of the selection efficiencies for the signal and normalisation decays is
further illustrated in Figures 4.1 and 4.2, which show the ratio of selection efficiencies
of B0s  + decays to B+  J/K+ and B0  K+ decays for a range of
selection cuts. With the exception of the B0s  + and B+  J/K+ 2IP cuts on
the daughter particles, the ratio of efficiencies is well within 3% of unity for the range
of cuts values shown. The ratio of the B0s  + and B+  J/K+ efficiencies
for the daughter particle 2IP, Figure 4.1d, markedly deviates from unity, showing
that the 2IP distribution of the muons and kaon are very different as seen previously
in reference [156]. If the 2FD, B0s or J/ 2IP and 2VTX selection cuts are applied to
the simulated events before the daughter 2IP requirement the ratio of B0s  +
and B+  J/K+ efficiencies is much closer to 1. The stability of the ratios of
selection efficiencies across a large range of cuts values shows that changing a cut
value in the B0(s)  
+ selection will have a similar impact on the efficiencies of
the normalisation decays.
Efficiencies of different cuts values
The set of events removed by each cut in the stripping selection is not independent.
Therefore the effect of changing one cut on the total efficiency of a stripping selection
must be considered. Figure 4.3 shows the total efficiency of the B0s  + stripping
line on simulated B0s  + decays for a range of 2FD and daughter 2IP cut values.
As expected the lower the cut values the more efficient the stripping line becomes. It
is important that any increase in B0s  + selection efficiency from the stripping
is not removed when the trigger requirements are applied. Figure 4.4 shows that the
trigger efficiencies are relatively flat across a large range of 2FD and daughter 2IP cut
values. Therefore the efficiency gained by a change in the stripping selection is not
lost when trigger requirements are imposed. The selection efficiency for B0  +
4.3 Event selection for the B0(s)  
+ branching fraction measurements 69
2 +, Bs
2 3 4 5 6
B / -
 0 s
0.986
0.988
0.990
0.992
0.994
2 , J/s
4 5 6 7 8
B / -
 0 s
1.004
1.005
1.006
1.007
1.008
1.009
2 , J/s
5 10 15
B / -
 0 s
0.998
1.000
1.002
1.004
1.006
1.008
1.010
1.012
2 +, K
2 3 4 5 6
B / -
 0 s
 cut only2 IP , +K
2 and vertex 2, IP 2 cut after FD 2 IP , +K
Fig. 4.1 Ratio of B0(s)  
+ to B+  J/K+ stripping efficiencies when each cut has
been applied independently of all other cuts. The ratios are shown for cuts on the B meson
2IP (a), B meson and J/ 
VTX (b) and 
FD (c) and the muon and kaon 
IP (d). The
square root of each 2 is used to condense the x-axis of the plots and follows the previous
work in reference [156].
70 Event selection
2 0, Bs
2 3 4 5 6
B / -
 0 s
0.970
0.975
0.980
0.985
0.990
0.995
2 0, Bs
4 5 6 7 8
B / -
 0 s
0.989
0.990
0.991
0.992
0.993
0.994
0.995
2 0, Bs
5 10 15
B / -
 0 s
0.998
0.999
1.000
1.001
2 +, K
2 3 4 5 6
B / -
 0 s
1.000
1.002
1.004
1.006
1.008
Fig. 4.2 Ratio of B0s  + to B0  K+ stripping efficiencies when each cut has
been applied independently of all other cuts. The ratios are shown for cuts on the B meson
2IP (a), 
VTX (b) and 
FD (c) and the muon and kaon 
IP (d). The square root of each 
is used to condense the x-axis of the plots and follows the previous work in reference [156].
4.3 Event selection for the B0(s)  
+ branching fraction measurements 71
5 10 15 20 25
2 , J/s
5 10 15
B / -
 0 s
0.998
1.000
1.002
1.004
1.006
1.008
1.010
1.012
+  K   J/  + B  / -  +   0s B 0
Fig. 4.3 Efficiency of the B0(s)  
+ stripping line to select B0s  + simulated
decays for a range of cuts on the B0s 2FD and the minimum muon 
5 10 15 20 25
0.952
0.953
0.954
0.955
0.956
0.957
0.958
0.959
2 , J/s
5 10 15
B / -
 0 s
0.998
1.000
1.002
1.004
1.006
1.008
1.010
1.012
+  K   J/  + B  / -  +   0s B 0
Fig. 4.4 Trigger efficiencies of B0s  + simulated decays across a range of B0s 2FD
and the minimum muon 2IP cut values for the trigger requirements listed in Table 4.3 for
B0(s)  
+ decays.
72 Event selection
is very similar to B0s  + as seen in Table 4.6, therefore only B0s  + have
been studied for different stripping selection cut values.
Data retention
One of the main purposes of the stripping selection is to reduce the size of the data
set, therefore the cuts cannot be set as loose as possible and the amount of data
passing the selection must be considered. Any change applied to the B0(s)  
stripping line must be propagated through into the stripping lines for B  h+h,
B+  J/K+ and B0s  J/ decays. Therefore the retention of all stripping lines
must be evaluated. The efficiencies of the B0s  J/ stripping line have not been
presented because this decay is not used as a normalisation mode for the branching
fraction measurements but only to cross check the results, therefore the efficiency of
this stripping line compared to the B0(s)  
+ stripping line is less important.
Table 4.7 shows the total selection efficiency of the B0(s)  
+ stripping line
along side the amount of data retained for the set of cuts on the 2FD and daughter
2IP for the B0(s)  
+, B  h+h, B+  J/K+ and B0s  J/ stripping
lines. The set of chosen cuts used in Table 4.7 aims to keep both cuts as tight as
possible for a certain B0s  + efficiency.
The data retention is computed by applying the stripping selection to a sub-set
of 2012 data to find the number of events that pass the stripping lines for each pair
of 2FD and daughter 2IP cuts. No trigger requirements are imposed on trigger lines
because the stripping selection is run on the full output of the trigger. The number of
events for each set of cuts is normalised to the number of events passing the original
Run 1 stripping line requirements to show the fractional increase caused by loosening
the cut values.
An increase of 15% can be gained in the stripping selection efficiencies by using
the loosest cuts in Table 4.7. However, the loosest cuts increases the amount of data
passing the B0(s)  
+ stripping selection by a factor of 7 and the B  h+h
stripping selection by a factor of 4. Table 4.8 shows the number of Run 1 candidates
passing the original stripping selection listed in Tables 4.4 and 4.5. The B  h+h
stripping line lets through the most candidates whereas the B0(s)  
+ stripping
line saves far fewer candidates, therefore a change in the retention of the B  h+h
line is more significant than the B0(s)  
+ line.
The final set of cuts used in the stripping selection must be a compromise between
the selection efficiency and the amount of data that passes the selection. The
studies detailed here show that using selection cuts of B0s 2FD > 121 (
2FD > 11)
and minimum muon 2IP > 9 (
2IP > 3) in the stripping lines would increase
the B0(s)  
+ selection efficiency from 71% to 82% and the amount of data
retained would be doubled. The increase of the data retained by the B  h+h,
4.3 Event selection for the B0(s)  
+ branching fraction measurements 73
74 Event selection
Stripping Lines Selected events Retention / %
B0(s)  
+ 898880 0.0022
B  h+h 14502295 0.0831
B+  J/K+ 3344568 0.0087
B0s  J/ 456787 0.0011
Total 18745743 -
Table 4.8 Number of events passing stripping lines used for the B0(s)  
+ branching
fraction measurement in reference [46, 47] that are listed in Tables 4.4 and 4.5 and the
percentage of the total LHCb data set that they correspond to. The total does not include
correlation between lines and the requirements of 2FD > 225 and daughter 
IP > 25 are
used.
B+  J/K+ and B0s  J/ lines for equivalent cut values is smaller and the
efficiencies are similar to the B0(s)  
+ selection efficiencies. Therefore, the cuts
of B0s 2FD > 121 and minimum muon 2IP > 9 offer a good compromise between
signal efficiency and the amount of data retained. The stripping lines have been
updated to include the new, looser cut values that will be used in future studies of
B0(s)  
+ decays.
Final stripping selection
Although the new looser cut values would improve the efficiency of identifying
B0(s)  
+ decays at this step in the selection process, the new looser cut values
are not used in the measurements presented in this dissertation. The multivariate
classifier used to separate signal and combinatorial background decays, described
in Section 4.3.4.3, is trained on simulated bb  +X decays. As discussed in
Section 4.2, cuts are applied to bb  +X decays when the decays are simulated.
Only decays that pass the original 2FD and daughter 2IP requirements are available
in the simulated sample. Therefore to ensure the best performance of the classifier
on data, the same cuts are applied to data that are applied to the simulated samples.
Therefore the original cuts on 2FD and daughter 2IP listed in Table 4.4 are used to
select B0(s)  
+ candidates.
4.3.2.3 Additional offline cuts
Additional selection requirements are applied after the stripping to remove specific
backgrounds. A lower bound is placed on the B meson transverse momentum to
remove pairs of muons originating from pp  p+p decays and a J/ veto is used
to remove backgrounds from B+c  J/+ decays. Semi-leptonic B+c  J/+
4.3 Event selection for the B0(s)  
+ branching fraction measurements 75
decays, where J/  +, are backgrounds for B0(s)  
+ decays when a muon
from the J/ forms a good vertex with the muon from the B+c decay. Due to the high
mass of the B+c this could place mis-reconstructed candidates within the B0s mass
window. A J/ veto is used to remove background events from B+c  J/+
decays. The veto removes events where one muon from the B0(s)  
+ candidate
combined with any other oppositely charged muon in the event has |mmJ/| < 30
MeV/c2.
The offline selection of B0(s)  
+ decays includes the momentum, ghost track
probability and decay time cuts made in the B  h+h stripping line, but were
absent in the B0(s)  
+ stripping line. Also a narrower mass range of 4900 - 6000
MeV/c2 is imposed to remove B0s  + backgrounds. The stripping selection
for B0(s)  
+ decays is kept loose to allow for the study of background decays in
data.
The selection applied to Run 1 and Run 2 data is the same for all variables
except the track ghost probability and 2trk. Slightly looser cuts of track ghost
probability < 0.4 and 2trk < 4, are used in Run 2 to take advantage of changes in
the reconstruction that were introduced for Run 2.
Table 4.13 summaries all selection cuts used to identify B0(s)  
+ decays at
the end of this section.
4.3.3 Particle identification
In the selection of B0(s)  
+ decays, particle identification variables are partic-
ularly useful to reduce the backgrounds coming from mis-identified semi-leptonic
decays and B  h+h decays and also help to reduce the number of combinatorial
background decays. On top of the isMuon requirement used in the stripping selection,
ProbNN variables, defined in Section 3.2.2.4, are used. A linear combination of these
variables
PID = ProbNN (1  ProbNNK)  (1  ProbNNp) (4.1)
is used to refine the selection of B0(s)  
+ candidates. The ProbNNK variable
is effective at removing mis-identified B  h+h backgrounds and the ProbNNp
variable is effective at removing 0b  p backgrounds.
Different tunings of the algorithms used in the ProbNN variables are used to
select candidates in Run 1 and 2015 data compared to 2016 data. The tunings have
different efficiencies to select particles therefore the cut values placed on PID are
different for each tuning. The cuts applied to data are PID > 0.4 for Run 1 and
2015 data and PID > 0.8 for 2016 data. The cut value on PID for the Run 1 and
2015 is optimised using pseudoexperiments to sufficiently reduce the background
decays and give the highest sensitivity to the B0  + decays. Accurate particle
76 Event selection
identification is most important for B0  + decays because the backgrounds
from B  h+h and 0b  p pollute the B0 mass window. The cut value for
2016 was chosen to have the same or better background rejection as the Run 1 and
2015 cut, however the 2016 tuning has a better performance therefore the final cut
choice has a higher efficiency for selecting B0(s)  
+ decays.
4.3.4 Multivariate Classifiers
The selection described so far removes a large number of background candidates.
However, because B0(s)  
+ decays occur very rarely, the data is still dominated
by long-lived combinatorial background. To improve the separation of signal and
background decays multivariate classifiers are used.
A multivariate classifier is an algorithm that learns differences between signal and
background decays. The classifier is given two input samples, one containing only
signal decays and the other containing only background decays and a set of input
variables. The input variables have different distributions for signal and background
decays. The classifier uses the distributions of the input variables along with its
knowledge of which decays are signal and background to learn the difference between
the two types of decays. The algorithm is then applied to a data set containing an
unknown mixture of signal and background decays to separate them. For each decay
the algorithm produces a number, typically between 1 and +1, where high numbers
indicate signal-like decays and low numbers indicate background-like decays.
Two multivariate classifiers are used to identify B0(s)  
+ decays. Both classi-
fiers are a type called a Boosted Decision Tree (BDT), described in Section 4.3.4.1.
The first classifier, described in Section 4.3.4.2, is called the BDTS. It is used to
remove candidates that are very unlikely to be signal by placing a cut on the BDTS
output. The second classifier, described in Section 4.3.4.3, it called the global BDT.
The output of the global BDT is used to classify candidates into bins containing
increasing proportions of signal candidates. The branching fractions are measured
from the invariant mass distribution of the two muons in bins of BDT output as
described in Chapter 5. The BDTS is necessary to reduce the background to a more
manageable level for the global BDT.
4.3.4.1 Boosted Decision Trees
A BDT is made up of the combined outputs of separate decision trees. A decision
tree begins with a data sample, where each decay is known to be either signal or
background and a set of variables describing them. The decision tree applies a cut
on a variable that will be the most effective at separating the signal and background
in the sample and creates two sub-samples. Another cut is then applied to each of
4.3 Event selection for the B0(s)  
+ branching fraction measurements 77
the sub-samples to further separate signal from background. This process is repeated
until either a certain number of cuts, defined as the depth of the tree, or the number
of candidates in each sub-sample has reached a minimum value. Each sub-sample
produced at the end of the tree is called a leaf. The tree uses the knowledge of
whether decays are signal or background to assign a value of +1 or 1 to every decay.
A decay is given a value +1 if it is in a leaf where the majority of decays are signal
and the value 1 if it is in a leaf that has a majority of background decays. The
final decisions made by the tree are not perfect, some signal (background) decays
will be mis-classified as background and given the value of 1 (+1).
Often a single decision tree is not particularly good at classifying decays; there is
no way to correct mis-classified decays in the leaves, and it is particularly sensitive
to statistical fluctuations in the training samples. A BDT combines the output
of numerous decision trees to improve the classification of decays and reduce the
dependence of the final decisions on statistical fluctuations. A BDT starts with a
decision tree and assigns weights to decays in the signal and background samples
depending on whether the output of the first decision tree classified them correctly.
The weighted sample is then used as the input for the training of the next decision
tree. The weights are designed so that the next tree is more likely to correctly classify
previously mis-classified decays. This process is repeated until a certain number of
trees have been trained. The re-weighting process is known as boosting and the
weights applied to the samples are taken into account when combining the output
value of each decision tree into the overall output of the BDT. The output of a BDT
will be a number between 1 and +1 where high numbers indicate signal and low
numbers indicate background.
The TMVA package [157] is used to develop and train the BDTs. The package
provides several different methods of boosting that can be used. The adaptive
boosting method was found to produce the most effective BDT at separating B0(s) 
+ from combinatorial background. This method of boosting assigns the weight,
w, to decays incorrectly classified by one tree before being used as the input to the
next decision tree. The weights assigned are given by
1  f
, where f =
misclassified events
total events
. (4.2)
Therefore, incorrectly assigned candidates are given a higher weight than correctly
classified candidates. The speed at which the boosting occurs is controlled by the
parameter  where w  w. The parameter  is specified in the training of the
decision tree and a large number of boosting steps can improve the performance of
the BDT.
78 Event selection
The ability of a BDT to correctly identify signal and background candidates
depends on three main factors:
 the size of the training samples - a large training sample is useful to prevent
the BDT from being sensitive to statistical fluctuations and contains more
information the classifier can use to learn the difference between signal and
background;
 the input variables - different distributions in the input variables for signal
and background candidates enable the classifier to easily separate the types
of candidates. The overall performance is insensitive to poorly discriminating
variables that are included; and
 parameters that dictate the BDT training - the training of a BDT is specified by
several parameters; the number of trees (NTrees), the tree depth (MaxDepth),
the minimum number of events a leaf can contain (nEventsMin or MinNode-
Size2); the speed at which the boosting occurs () and the number of cut
values that a tree tries for a variable before making a decision (nCuts).
These three factors affect the performance of the BDT. However, the importance
of each varies. Together they are used to prevent the BDT being very sensitive to
the statistical fluctuations in the training sample. This is called overtraining; an
overtrained BDT is extremely accurate at classifying the candidates in the training
sample but performs poorly at classifying candidates in a statistically independent
sample. Although this is less common in BDTs than single decision trees, it can be
avoided by having a sufficiently large training sample or by limiting the depth of
trees or the number of trees in the BDT.
4.3.4.2 The BDTS
The BDTS uses input variables similar to those in the stripping selection to classify
events:
 2IP of the B0(s);
 2VTX of the B0(s);
 direction cosine of B0(s);
 distance of closest approach of the tracks of the muons;
2nEventsMin is the minimum number of decays in a leaf and MinNodeSize is the number of
decays in a leaf given as a percentage of the training sample size. The parameter specified in the
training depends on the version of the TMVA package used.
4.3 Event selection for the B0(s)  
+ branching fraction measurements 79
Selection applied to BDTS training samples.
B0s 
2FD > 225 pT > 500 MeV/c
2IP < 25 2trk < 3
2VTX < 9 Minimum 2IP > 25
DOCA < 0.3 mm 0.25 GeV/c < pT < 40 GeV/c
 < 13.248 ps p < 500 GeV/c
pT > 500 MeV/c
DIRA > 0
Trigger line Decision
L0Global DEC
Hlt1Phys DEC
Hlt2Phys DEC
Table 4.9 Selection cuts applied to select the signal and background samples used to train
the BDTS. The isMuon requirement is not applied to the muons so that the BDTS can be
used on B  h+h
 decays.
 minimum 2IP of the muons with respect to all primary vertices in the event;
 impact parameter (IP) of the B0(s), this is the distance of closest approach of
the B to the primary vertex.
The signal and background samples used to train the BDTS are simulated B0s  +
decays and background candidates in a sample of Run 1 data from the mass ranges
4800 - 5000 MeV/c2 and 5500 - 6000 MeV/c2. The selection cuts listed in Table 4.9
are applied to the training samples and the training parameters used are listed in
Table 4.10. The output of the BDTS is flattened to give a response between 0 and 1
so that signal is uniformly distributed across the range and background is peaked
at zero as illustrated in Figure 4.5. The BDTS is applied to all candidates passing
the B0(s)  
+, B  h+h and B+  J/K+ stripping lines, and candidates
are required to have a BDTS value above 0.05. When the BDTS is applied to
B+  J/K+ decays the distance of closest approach of the muons refers to the
muons in the J/ and the 2VTX is of the J/. The performance of the BDTS at
removing backgrounds is illustrated in Figure 4.6.
80 Event selection
Parameter Value
nTrees 250
nEventsMin 400
MaxDepth 3
 1.0
nCuts 20
Table 4.10 Training parameters used to specify the training of the BDTS.
0 0.2 0.4 0.6 0.8 1
2011 simulation
2012 simulation
2015 simulation
2016 simulation
0 0.2 0.4 0.6 0.8 1
1 2011 data
2012 data
2015 data
2016 data
Fig. 4.5 Normalised BDTS response for a) simulated B0s  + decays and b) B0(s) 
+ candidates in data with a mass above 5447 MeV/c2 consisting of background decays.
-+m
5000 5200 5400 5600 5800
Before BDTS cut
After BDTS cut
-+m
5000 5200 5400 5600 5800
Before BDTS cut
After BDTS cut
Fig. 4.6 Invariant mass spectrum for B  h+h
 decays in a) 2012 and b) 2016 data
passing the selection requirements in Table 4.9 before and after the BDTS cut is applied.
4.3 Event selection for the B0(s)  
+ branching fraction measurements 81
4.3.4.3 Global BDT
The global BDT is the final step in identifying B0(s)  
+ decays and it is very
effective at separating them from long-lived combinatorial background decays. The
discriminating power achieved by the global BDT is mostly dependent on isolation
criteria. Isolation criteria provide a measure of how far away each muon from a
B0(s)  
+ candidate is from other tracks in the event. The tracks of the muons
from a real B0(s)  
+ decay will be, in general, far from other tracks in the event
because the B0(s)  
+ decay tree contains no other tracks apart from the muons.
However, long-lived combinatorial background arises from semi-leptonic decays where
the muon tracks are likely to be close to other tracks that originate from the same
decay tree. Isolation criteria are very useful in the selection of very rare decays like
B0s  + because they enable background to be removed whilst keeping a high
efficiency for signal decays.
Two isolation criteria are used in the global BDT, one compares long tracks in
the event to the muons in B0(s)  
+ candidates and the other compares VELO
tracks in the event to the muons. The definition of the track types are given in
Section 3.2.1.4. The isolation variables are built from the output of BDTs. For each
type of track a BDT is trained on simulated B0s  + and bb  +X decays
using a set of input variables that describe track and vertex properties and the
separation between muons in a B0s  + candidate and other tracks in the event.
The BDT for the long track isolation criteria compares the + from a B0s  +
candidate with all other long tracks in the event, excluding the track of the , and
gives an output for each possible + and track pairing. The process is repeated
for the . The BDT is designed to produce high output values for muons from
bb  +X decays and a low value for muons from B0s  + decays. The long
track isolation criteria of a B0s  + candidate is then composed of the sum of the
highest BDT output values produced for the + and the . The same setup is used
for the VELO track isolation criteria except muons are compared to VELO tracks
rather than long tracks. The separation power of these isolation criteria are shown
in Figure 4.7. Full details of the isolation variables can be found in reference [158].
The isolation criteria are used along with five other variables in the global BDT.
The full list of input variables used are:
 long track isolation criteria;
 VELO track isolation criteria;
2 + 2, where  is the difference in azimuthal angles of the muons and
 the difference in the pseudo-rapidity of the muons;
82 Event selection
Parameter Value
nTrees 1000
MinNodeSize 1%
MaxDepth 3
 0.75
nCuts 30
Table 4.11 Training parameters used to specify the training of the global BDT.
 the smallest 2IP with respect to the primary vertex of the B0(s)  
+ of the
muons;
 2VTX of the B0(s);
 2IP of the B0(s) with respect to the primary vertex; and
 the angle, , between the momentum vector of theB0(s) and the vector connecting
the production and decay vertices of the B0(s).
A comparison of the signal and background distributions of the input variables
in the training samples are shown in Figure 4.7. These variables were chosen by
training a BDT beginning with the most discriminating variable, the long track
isolation criteria, and adding variables to determine which improved the performance
to the classifier. Only variables that significantly improved the performance were
included in the global BDT. The training parameters used in the BDT are listed in
Table 4.11. These parameters were chosen by scanning across a range of variables
and choosing those that gave the best performance. The performance of each BDT
with different input variables and training parameters was evaluated by comparing
the number of background decays from B0(s)  
+ candidates in data with masses
above 5447 MeV/c2 remaining after different cuts on the BDT output values. The
cut values compared have the same efficiency for each BDT to select simulated
B0s  + decays and the best performing BDT removed the lowest number of
background decays for the highest signal efficiency.
Simulated B0s  + and bb  +X decays are used to provide large signal
and background training samples for the global BDT. The complete list of selection
requirements applied to the training samples used to develop global BDT are listed
in Table 4.12, the same selection is applied to B0s  + and bb  +X decays.
The global BDT is applied to data taken in all years and in the same way as
the BDTS. The final output of the global BDT is flattened to have a response
between 0 and 1 that is uniform for signal and the background peaks at zero. The
global BDT output for signal and background is shown in Figure 4.8 for each year
4.3 Event selection for the B0(s)  
+ branching fraction measurements 83
VELO track isolation
0.5 0.0 0.5
Long track isolation
1.0 0.5 0.0 0.5 1.0
- +  s
 X- +  bb 
0.00 0.01 0.02 0.03
0 1 2 3 4 5
0.08 d)
0 2 4 6
0.30 e)
2  + 2 
0 1 2 3 4
2 Minumum 
20 40 60 80 100
- +  s
 X- +  bb 
Signal
Background
Long track isolation
1.0 0.5 0.0 0.5 1.0
- +  s
 X- +  bb 
Fig. 4.7 Distributions of input variables of the global BDT from simulated B0s  +
and bb  +X decays used to train the global BDT passing cuts in Table 4.12. Input
variables are VELO track isolation criteria (a), long track isolation criteria (b)  (c), B0s
2IP (d), B
VTX (e),
2 + 2 (f) and minimum muon 2IP (g).
84 Event selection
Selection applied to global BDT training samples.
B0s 
2FD > 225 pT > 500 MeV/c
2IP < 25 2trk < 3
2VTX < 9 Minimum 2IP > 25
DOCA < 0.3 mm 0.25 GeV/c < pT < 40 GeV/c
 < 13.248 ps p < 500 GeV/c
pT > 500 MeV/c isMuon = True
DIRA > 0 BDTS > 0.05
4900 < m < 6000 MeV/c2
Trigger line Decision
L0Global DEC
Hlt1Phys DEC
Hlt2Phys DEC
Table 4.12 Selection cuts applied to select candidates for signal and background samples
used to train the global BDT. m is the invariant mass to the two muons in the B0(s) 
+ candidate.
Global BDT
0 0.2 0.4 0.6 0.8 1
0.062
0.064
0.066
0.068
0.070
0.072
0.074 2011 simulation
2012 simulation
2015 simulation
2016 simulation
Global BDT
0 0.2 0.4 0.6 0.8 1
1 2011 data
2012 data
2015 data
2016 data
Fig. 4.8 Normalised output distributions for the global BDT for a) B0s  + simulated
decays and b) bb  +X decays in simulation and data.
4.3 Event selection for the B0(s)  
+ branching fraction measurements 85
Signal efficiency
0.7 0.8 0.9
Fig. 4.9 Global BDT performance for 2011, 2012, 2015 and 2016 data taking conditions.
Signal efficiency is calculated from B0s  + simulated decays and background rejection
from data passing the B0s  + selection with m+ > 5447 MeV/c2. The performance
is very similar for the different data taking years therefore only the most sensitive region is
shown. The full range of BDT output values is from 0 to 1.
of data taking. The flattening is useful for the branching fraction measurements
because a simultaneous fit is applied to the invariant mass of the two muons in the
B0(s)  
+ candidate in bins of BDT. Flattening the BDT output enables bins
containing equal proportions of signal decays to be created. The signal efficiency
versus the background rejection of the global BDT is shown in Figure 4.9 for all
years of data taking, the performance is similar across all the years but Run 2 data
has a slightly better background rejection for a given signal efficiency than Run 1.
A comparison of the input variables used in the global BDT for each year of data
taking is given in Appendix A.
4.3.5 Summary
The complete set of selection criteria used to identify B0(s)  
+ decays in Run 1
and Run 2 data for the branching fraction measurements is listed in Table 4.13. The
selection requirements do not remove all backgrounds decays from the data set but
reduce them to a level at which the branching fractions can be measured. Figure 4.10
shows a scatter plot of the mass and global BDT values for all candidates that pass
the selection criteria in Run 1 and Run 2 data. The criteria to select B  h+h,
B+  J/K+ and B0s  J/ decays are composed of the trigger requirements
listed in Table 4.3, the stripping selection in Tables 4.4 and 4.5, and the cut on the
BDTS output.
86 Event selection
Particle B0(s)  
B0(s) 4900 MeV/c
2 < m < 6000 MeV/c2
DIRA > 0
2FD > 225
2IP < 25
2VTX < 9
DOCA < 0.3 mm
 < 13.248 ps
pT > 500 MeV/c
BDTS > 0.05
|m mJ/| < 30 MeV/c2
 2trk < 3 (4)
Minimum 2IP > 25
0.25 GeV/c < pT < 40 GeV/c
p < 500 GeV/c
ghost probability < 0.3 (0.4)
isMuon = True
PIDRun1+2015 > 0.4 or PID2016 > 0.8
Trigger requirements L0Global = DEC
Hlt1Phys = DEC
Hlt2Phys = DEC
Table 4.13 Selection requirements applied to select B0(s)  
+ for the branching
fraction measurements, where selection is different between Run 1 and Run 2, the Run 2
values are shown in parenthesis.
4.3 Event selection for the B0(s)  
+ branching fraction measurements 87
Fig. 4.10 Mass and global BDT values for candidates in Run 1 and Run 2 data that pass
the B0(s)  
+ selection criteria. The green dashed lines show the combined B0s and B0
mass window as described at the start of this chapter.
88 Event selection
4.4 Selection for theB0s  
+ effective lifetime
measurement
The selection criteria used to identify particle decays for the B0s  + effective
lifetime measurement is based on the selection used to identify candidates for the
branching fraction measurements.
As well as B0s  + decays, B0  K+, B0s  K+K and B0s  J/
decays are used to develop and validate the effective lifetime analysis strategy. There
are some differences in the selection of B0s  + and B  h+h
 decays for the
effective lifetime measurement compared to the branching fraction measurement to
account for the different measurement strategies and because only the B0s decay
mode is required for the effective lifetime mesaurement. The selection of B0s  J/
decays is kept the same as that used for the branching fraction measurement.
The selection criteria used for B0s  + and B  h+h
 decays uses the cut
based selection in Section 4.3.2 and the BDTS requirement in Section 4.3.4.2. Changes
are made to the trigger requirements, the mass range of candidates and the particle
identification requirements. The differences in these selection requirements compared
to the selection for the branching fraction measurements and the motivation for these
changes are described in Section 4.4.1, 4.4.2 and 4.4.3, respectively. Similar to the
branching fraction measurement, the selection for the effective lifetime measurement
uses a multivariate classifier as the final step in the selection process to separate
signal from combinatorial background. A study into the best classifier for the
effective lifetime measurement is described in Section 4.4.4. The selection criteria
used to identify decays in data for the B0s  + effective lifetime measurement
are summarised in Section 4.4.5.
One important consideration for the selection of candidates for the B0s  +
effective lifetime measurement is the efficiency of the selection as a function of the B0s
decay time. This efficiency is not uniform across different decay times because the
selection relies on parameters such as the 2IP and 2FD that are correlated with the
decay time of B0s  + candidates. Since the effective lifetime is measured from
the decay time distribution of the candidates, the selection efficiency as a function
of decay time must be accurately evaluated in order to perform the measurement.
The efficiency is evaluated using simulated B0s  + decays in Chapter 6 and
the procedure to evaluate the efficiency and the analysis strategy is validated using
B0  K+ and B0s  K+K decays. The impact of selection requirements on
the decay time efficiency of B0s  + and B  h+h
 decays is important in the
choice of the trigger requirements and the multivariate classifier as described in the
following sections.
4.4 Selection for the B0s  + effective lifetime measurement 89
4.4.1 Trigger requirements
The same global triggers used to select decays for the branching fraction measurements
are used to select B0s  + and B  h+h
 candidates for the effective lifetime
measurement but different trigger decisions are used.
Candidates from B0s  + decays are required to be identified as TOS or
TIS at each level of the trigger. The change in trigger decisions is motivated by
the use of simulated decays in evaluating the selection efficiency as a function of
decay time. The trigger efficiencies for candidates that are triggered as DEC, but
not as TIS or TOS, are not well modelled in simulated decays because they depend
on the underlying pp event. Therefore only candidates triggered by TOS or TIS
decisions are used so that the selection as a function of decay time can be accurately
modelled. Candidates triggered by DEC decisions, but not TIS or TOS do not
pose the same problem for the branching fraction analysis because the selection and
trigger efficiencies are evaluated using different methods as discussed in Section 5.4.
Candidates from B  h+h decays are required to be identified as TIS at
each level of the trigger. In general trigger lines designed to select particle decays
containing muons have a uniform efficiency for candidates with different decay times.
However this is not the case for trigger lines designed to select B  h+h decays.
These lines rely on information about candidate IP and 2IP to make decisions at the
HLT level. For B  h+h decays to be useful as a validation channel the efficiency
of the trigger requirements as a function of the decay time should be similar to the
B0s  + triggers. This is achieved by requiring decays to be TIS at each level of
the trigger.
In summary, the requirements imposed on the trigger to select B0s  + and
B  h+h decays are shown in Table 4.14.
4.4.2 Mass range
The mass of B0s  + candidates is restricted to the range 5320 - 6000 MeV/c2, the
motivation for the narrower mass window compared to the selection of candidates for
the branching fraction measurements comes from the optimisation of the measurement
strategy detailed in Section 6.4. The lower mass bound now lies on the low edge
of the B0s mass window, therefore B0  + candidates and backgrounds from
mis-identified decays are almost completely removed. The dominant background left
in the data set is from combinatorial background.
Similarly, B0  K+ and B0s  K+K decays have a reduced mass range
compared to the selection of B  h+h decays for the branching fraction measure-
ments; B  h+h decays must be in the mass range 5100 - 5500 MeV/c2 in order
to remove contributions from exclusive backgrounds.
90 Event selection
Trigger Line Trigger decision
B0s  +
L0Global TIS or TOS
Hlt1Phys TIS or TOS
Hlt2Phys TIS or TOS
B  h+h
L0Global TIS
Hlt1Phys TIS
Hlt2Phys TIS
Table 4.14 Trigger lines used to select B0s  + and B  h+h
 decays for the
effective lifetime measurement.
4.4.3 Particle identification
The particle identification requirements used for selecting candidates for the branching
fraction measurements were optimised to give the greatest sensitivity to B0  +
decays. Backgrounds from B  h+h and 0b  p decays pollute the B0
mass window and must be reduced as much as possible to enable good sensitivity of
B0  + decays. The requirement placed on the linear combination of ProbNN
variables in Section 4.3.3 is a compromise between background rejection and signal
efficiency. However, for the effective lifetime measurement, theB0 mode is not relevant
and the mass region of selected candidates removes the majority of B0  +
decays as well as backgrounds from B  h+h and 0b  p decays. Therefore,
looser particle identification requirements can be used leading to a higher signal
efficiency.
The same linear combination of ProbNN variables, PID, is used because there is
still a small contribution from mis-identified B  h+h and 0b  p decays
within the mass range. Also the particle identification requirements help to reduce
the number of combinatorial background decays. Different ProbNN tunes, and
consequently cut values, are used for Run 1 and 2015 data compared to 2016 data.
The cuts are chosen to give similar efficiencies for each data set at selecting signal
and removing background and are listed in Table 4.15. The cut values have not
been optimised because there are too few candidates in data after the selection and
simulated decays are not used because particle identification variables are not well
modelled in simulation. However, the chosen particle identification requirements are
tight enough to make the expected number of mis-identified decays in the data set
after the full selection negligible, as shown in Section 7.2.
4.4 Selection for the B0s  + effective lifetime measurement 91
Decay Year Particle PID requirements
B0s  + 2011, 2012, 2015  PID > 0.2
B0s  + 2016  PID > 0.4
B0  K+ 2011, 2012, 2015, 2016 K+ DLLK > 10
 DLLK < 10
B0s  K+K 2011, 2012, 2015, 2016 K DLLK > 10
Table 4.15 Particle identification requirements to select B0s  +, B0s  K+ and
B0s  K+K decays for the B0s  + effective lifetime measurement.
The separation of B  h+h decays into B0s  K+K and B0s  K+ decays
is done using the DLLK variable, defined in Section 3.2.2.4. The DLL variables
are useful to separate B  h+h decays where h is either a pion or kaon because
the variables compare different particle hypotheses with the pion hypotheses. The
selection requirements used are given in Table 4.15 and are the same for each year of
data taking.
4.4.4 Multivariate classifier
Two multivariate classifiers are used in the selection for the branching fraction
measurements to separate signal and combinatorial background decays. The BDTS
is used first to remove candidates that are very unlikely to be signal and to reduce
the size of the data set. The global BDT is then used to classify candidates into
separate bins and a simultaneous fit is then applied across the BDT bins to measure
the branching fractions.
A different, simpler strategy is used to identify candidates for the B0s  +
effective lifetime measurement. Combinatorial background is reduced by placing a
cut on the output of a multivariate classifier. Only candidates passing the selection
cut are used to measure the effective lifetime. The measurement strategy is given in
more detail in Chapter 6.
As a consequence of the different selection methods, two classifiers may not be
necessary for the measurement of the effective lifetime. Alternative classifiers were
developed for the effective lifetime measurement in parallel to the development of
the global BDT, with a particular focus on how the cuts placed on the output of the
classifiers effect the selection efficiency as a function of decay time.
The development of classifiers for the effective lifetime measurement is described
in Section 4.4.4.1 and a study into whether using data or simulated decays as
92 Event selection
the background training sample produces a more effective classifier is presented in
Section 4.4.4.2. The impact of cuts placed on the output of the classifiers on the
selection efficiency as a function of decay time is investigated in Section 4.4.4.3. A
comparison between the performances of the classifiers developed for the effective
lifetime measurement and the global BDT developed for the branching fraction
measurement is made in Section 4.4.4.4 and the classifier with the best performance
at separating signal and combinatorial background decays is chosen. Finally, the
optimal cut value placed on the chosen classifier is determined in Section 4.4.4.5.
4.4.4.1 Development of effective lifetime multivariate classifiers
Several types of multivariate classifiers were investigated for the effective lifetime
selection and BDTs gave the best performance at separating signal from background.
A range of boosting methods for the decision trees were studied and the adaptive
boosting method once again yielded the best results. However, a boosting method
of particular interest for the effective lifetime measurement was the uBoost tech-
nique [159]. The uBoost method produces a classifier output that has a uniform
efficiency for a specified variable. The most effective input variables for achieving
good signal and background separation with a BDT are also correlated with the
decay time. These include the B0s IP, 2IP, 2FD and isolation criteria. If the output
of a BDT is correlated with the B0s decay time, the efficiency as a function of decay
time may not have a smooth or easily understandable distribution. The uBoost
method could provide a way to make modelling the efficiency as a function of decay
time easier by requiring the algorithm output to have a uniform efficiency across the
decay time distribution.
The input variables used in the adaptive boosting and uBoost BDTs were chosen
separately, starting from a large set of variables including kinematic and geometric
variables and isolation criteria. Initially the BDTs were trained using all input
variables within the set and variables that had no impact on the BDT performance
were removed until removing any of the remaining variables had a negative impact
on the BDT performance. The performance of each BDT was evaluated from the
integrated Receiver Operating Characteristic curve, which is the signal efficiency
versus background rejection. The final variable sets were different for the two boosting
methods; the adaptive boosting BDT uses 11 input variables and the uBoost BDT
uses 21 input variables. The full list of input variables used and the definition of
those variables are given in Appendix B.
Simulated B0s  + decays were used as the signal training sample and simu-
lated bb  +X decays were used as the background training sample to determine
the input variables used in the two types of BDTs. The selection requirements listed
in Table 4.12, except the BDTS requirement, were applied to training samples of
4.4 Selection for the B0s  + effective lifetime measurement 93
Sample Number of decays
Simulated B0s  + 668292
Simulated bb  +X 586586
Data 189077
Table 4.16 Number of candidates present in each training sample after the selection cuts
have been applied. Simulated decays and decays in data were identified as candidates that
pass the selection requirements listed in Table 4.12, expect the BDTS cut was not applied
and the decays in data must be in the mass range 5447 - 6000 MeV/c2.
simulated decays. The simulated decays were split into two samples for both signal
and background, so that the BDTs could be trained on one sample and tested on
the other.
The training parameters of the adaptive BDT have been optimised by iterating
over a large range of different values, whereas the training parameters of the uBoost
were not optimised because changing the parameters has a small impact on the
overall BDT performance [159]. The values used are given in Appendix B.
4.4.4.2 Investigation of background training samples
The performance of the BDTs with different boosting methods trained on two
different background training samples is compared. One sample consists of simulated
bb  +X decays and the other combinatorial background decays in Run 1 data.
At the time of the BDT development, only Run 1 data was available. The selection
requirements listed in Table 4.12, except the BDTS requirement, are applied to
training samples of simulated decays. Combinatorial background decays in data are
identified as B0s  + candidates that pass the selection requirements listed in
Table 4.12, except the BDTS requirement, and have an invariant mass of the two
muons in the range 5447 - 6500 MeV/c2, outside the B0s mass window. The number
of events in each training sample is given in Table 4.16.
The different background samples are investigated to determine which would
produce the BDT with the best performance. The final BDT is used to separate
signal from combinatorial background in data; therefore using data as the background
training sample could lead to better performance of the BDT. However there are
fewer events in the data background sample than the sample from simulation which
could limit the performance. Also, a BDT trained on a combination of data and
simulated decays could be sensitive to differences between data and simulation which
could lead to a worse performance of the BDT.
The performance of the BDTs using either simulated decays or data as the
background sample was evaluated using B  h+h decays in Run 1 data. No
94 Event selection
particle identification variables are used as input variables of the BDTs due to
the mis-modelling of particle identification variables in simulated decays, therefore
the performance on the BDTs on B  h+h decays should be very similar to
B0s  + decays. B  h+h
 decays in data were identified by the same selection
requirements used applied to the BDT training samples of simulated decays except
the isMuon requirement was not applied. Also, no particle identification requirements
were used to separate different B  h+h decays.
The performance of the BDTs is evaluated by determining the signal significance
for a range of cuts place on the output of each BDT. The signal significance is given
(4.3)
where S (B) are the number of signal (background) decays. An unbinned maximum
likelihood fit is performed on the B  h+h mass distribution, where all B  h+h
decays are reconstructed as B0s  +, to find the signal and background yields for
each cut value. In the mass fit, the B  h+h mass distribution is modelled with a
Gaussian function and the combinatorial background decays with an exponential
function. An example of the mass fit is given in Figure 4.11. The number of signal
and background decays used to calculated the signal significance are found as the
signal and background yields within 3 of the centre of the B  h+h mass peak,
where  is the width of the Gaussian function. It is assumed that the larger number of
B  h+h decays present in data compared to B0(s)  
+ decays has a negligible
impact on which BDT is the most effective at separating signal from background.
Therefore the optimal BDT for separating B  h+h decays from combinatorial
background is the same as the optimal BDT to separate B0(s)  
+ decays from
combinatorial background.
The signal significances as a function of the cut value placed on the BDT output
for the BDTs trained on the different background samples are shown in Figure 4.12.
The outputs of the BDTs are not flattened; adaptive boosting BDT gives output
values between 1 and +1 and uBoost BDT gives output values between 0 and
+1. The signal significance of BDTs trained on simulated decays is higher than that
of the BDTs trained on data. Therefore, from now on only BDTs trained using
simulated decays as the background training sample will be considered.
Both the adaptive and uBoost BDTs shown in Figure 4.12 were trained without
applying the BDTS cut to the training samples. However, the signal significance on
B  h+h decays has also been evaluated with the BDTS cut applied both after
the BDT training and before the BDT training. The improvement in the overall
performances of the BDTs is small but applying the BDTS cut to B  h+h after
the BDT training produces the highest signal significances.
4.4 Selection for the B0s  + effective lifetime measurement 95
]2c [MeV/hhm
5100 5200 5300 5400 5500
Total
 h+ hB 
Combinatorial background
Fig. 4.11 Example of the mass fit to B  h+h
 Run 1 data to find the signal significance
for the adaptive boosting BDT with a cut value at 0.0 on the BDT output. The BDT
produces a response between 1 and +1.
Cut value
0.5 0 0.5
Data background sample
Simulation background sample
Cut value
0 0.5 1
Data background sample
Simulation background sample
Fig. 4.12 Signal significance from B  h+h
 decays in Run 1 data of the a) adaptive
boosting and b) uBoost BDTs trained using simulated decays and data as the background
training samples.
96 Event selection
Decay time [ps]
0.000 0.005 0.010
0.6 100% 75%
50% 25%
Decay time [ps]
0 0.005 0.01
0.6 75%
Fig. 4.13 Selection efficiency as a function of decay time of simulated 2012 B0s  +
decays for the a) adaptive and b) uBoost BDTs. The selection requirements applied to
the training sample are applied to the simulated decays and cuts are places on the BDT
output so that the efficiency of the cut on decays passing the other selection requirements
is 100, 75, 50 and 25%.
4.4.4.3 Selection efficiency with decay time
The selection efficiency as a function of decay time has been evaluated in simulated
B0s  + decays after all selection requirements and a range of different cut
values on the outputs of the adaptive and uBoost BDTs trained on simulated decays.
The cut values are chosen to have the same selection efficiencies for each algorithm.
The efficiencies are shown in Figure 4.13. The shape of the selection efficiency as
a function of decay time for the uBoost BDT is the same for each cut placed on
the BDT response whereas the shape of the decay time efficiency of the adaptive
boosting BDT changes as cut placed on the BDT output changes. For the adaptive
boosting BDT, tighter cuts on the output remove a greater proportion of decays
with shorter decay times than those with longer decay times. Both algorithms have
a smooth efficiency as a function of decay time; therefore, with either algorithm the
efficiency as function of decay time can be well modelled.
Ideally, to reduce systematic uncertainties on the measurement of the effective
lifetime described in Chapter 7, the selection would not bias the decay time dis-
tribution. However, the most effective variables at separating B0s  + decays
from backgrounds, such as the isolation criteria, the B0s 2IP and B0s 2FD, are highly
correlated with the B0s decay time. Removing these variables from the selection
procedure would make it less effective at removing background decays and sensitivity
of the analysis to B0s  + decays would be reduced. Since B0s  + decays
occur very rarely and very few are expected in the current dataset, an unbiased
selection would not be appropriate at this time because it would make identifying
any B0s  + decays in the dataset much more challenging.
4.4 Selection for the B0s  + effective lifetime measurement 97
4.4.4.4 Classifier performance comparison
The final classifier used to select B0s  + candidates is the BDT that has the
greatest separation power between signal and combinatorial background decays
and consequently removing the most combinatorial background decays for a given
signal efficiency, provided the selection efficiency as a function of decay time can
be accurately modelled. The performances of the BDTs developed for the effective
lifetime measurement are compared to that of the global BDT used to classify
candidates for the branching fraction measurements. Two different approaches are
used to evaluate the performances: the signal significance of B  h+h decays as a
function of BDT cut values; and the rejection of B0s  + backgrounds in data.
In order to enable easy comparison of the different BDTs, the outputs of the BDTs
developed for the effective lifetime measurement have been flattened in the same way
as the global BDT, described in Section 4.3.4.
The signal significance for each BDT is evaluated on B  h+h decays in Run 1
data and the maximum signal significance is found in the same way as described
earlier for comparing BDTs trained with data or simulated decays as the background
sample. The BDTS cut is applied in the selection process because the global BDT
was designed to be used with the BDTS and the performance of the BDTs developed
for the effective lifetime is best when the BDTS requirement is used. The results are
shown in Figure 4.14; the global BDT produces the highest signal significance, but is
closely followed by the adaptive boosting BDT developed for the effective lifetime
measurement.
The purpose of the BDT is to remove combinatorial background decays passing the
B0s  + selection, therefore an additional comparison of the different algorithms
is made. The number of combinatorial background decays present in Run 1 data
passing the effective lifetime selection criteria but in the mass range 5447 - 6550
MeV/c2 are found for a range of cuts on the output of the BDTs. The same cut values
are applied to each BDT and, since all the BDTs are flattened to have a uniform
distribution of signal decays between 0 and 1, the cut values will have very similar
signal efficiencies for each BDT. The results are given in Table 4.17. The global BDT
is most effective at removing background decays for a given signal efficiency. The
same comparisons were made with the BDT used in the previous analysis [46, 47]
and all BDTs described in this dissertation have a better performance at removing
background decays.
Although the global BDT, combined with the BDTS, performs best at separating
signal from background decays, the efficiency as a function of decay time must also
be evaluated for this algorithm to ensure it does not exhibit any strange behaviour
98 Event selection
Cut value
0.1 0.2 0.3 0.4 0.5
 0.2)global BDT (max = 479.0 
 0.2)uBoost BDT (max = 465.8 
 0.2)adaptive BDT (max = 476.4 
Fig. 4.14 Signal significance from B  h+h
 decays in Run 1 data of the adaptive and
uBoost BDTs trained using simulated decays as the background sample and the signal
significance of the global BDT developed for the branching fraction measurement. The
selection requirements listed in Table 4.12 are used, apart from the isMuon requirement.
4.4 Selection for the B0s  + effective lifetime measurement 99
BDT Number events above BDT output value
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Global BDT 2261 597 229 89 34 13 4 1 0
Adaptive BDT 4623 1395 513 215 77 32 15 4 2
uBoost BDT 7904 3344 1535 630 268 92 27 7 0
Table 4.17 Number of candidates in Run 1 data passing the effective lifetime selection
and the BDTS cut in the mass range 5447 - 6000 MeV/c2. The output of each BDT is
flattened to have a uniform response between 0 and 1, therefore the cuts applied to each
BDT will have approximately the same efficiency.
Decay time [ps]
0 0.005 0.01
0.6 100 %
Fig. 4.15 Selection efficiency as a function of decay time of simulated 2012 B0s  +
decays for the global BDT. The selection requirements applied to the training sample
are applied to the simulated decays and cuts are places on the BDT output so that the
efficiency of the cut on already selected event is 100, 75, 50 and 25%.
which would make modelling the decay time efficiency challenging. The decay time
efficiency is shown in Figure 4.15 for several cut values on t he BDT output and gives
a smooth distribution as a function of decay time. For the data set used to measure
the B0s  + effective lifetime, the expected number of B0s  + decays is
very low. Therefore the benefits of using the uBoost method are outweighed by
its poor performance. Since the global BDT developed for the branching fraction
measurements has the best performance in both tests and a smooth decay time
efficiency it is the best BDT to use for the selection of events for effective lifetime
measurement.
100 Event selection
4.4.4.5 Optimisation of BDT cut choice
A cut is placed on the output of the global BDT to select B0s  + decays. The cut
value is optimised to give the smallest expected uncertainty on the measurement of the
B0s  + effective lifetime, . The optimisation is done using pseudoexperiments
generating the expected number of B0s  + and combinatorial background decays
in Run 1 and Run 2 data for different cuts on the global BDT output.
The fit procedure to extract  from the data is described in Chapter 6. The
pseudoexperiments used to optimise the global BDT cut value are performed following
the steps:
 the mass and decay time distributions for number of expected B0s  + and
combinatorial background events are generated using the expected mass and
decay time probability density functions (PDFs);
 an unbinned maximum likelihood fit is performed to the invariant mass distri-
bution of the two muons, where the B0s  + and combinatorial background
yields are free to float in the fit along with the slope, , of the combinatorial
background PDF; and
 the mass fit is used to compute sWeights using the sPlot method [160] and a
maximum likelihood fit is performed to the sWeighted decay time distribution
to extract .
The number of expected B0s  + and combinatorial background decays for
different BDT cut values is derived from the expected number of candidates that
pass the effective lifetime selection cuts and a cut on the global BDT of BDT > 0.553.
These predictions are given in Table 4.18 and assume the SM branching fraction for
B0s  + decays. The methods used to evaluate the expected number of each
decay are detailed in Chapter 5.
The expected number of B0s  + decays after different BDT cut values is
straightforward to compute from the information in Table 4.18. This is because
the flattening procedure applied to the global BDT output means that the number
of B0s  + decays is evenly distributed across the BDT range. The number of
combinatorial background decays expected after each BDT cut is determined from the
number of decays in Table 4.18 and using information from simulated bb  +X
decays that have had all effective lifetime selection requirements applied up until the
3Initially the observed yields from published the Run 1 branching fraction measurements were
used to determine the expected number of decays present in 4.4 fb1 of Run 1 and Run 2 data and
a global BDT cut of 0.55 was found to be optimal. However, the expected number of decays was
then re-evaluated using the more sophisticated techniques described in Chapter 5 and using global
BDT cut of 0.55 and the pseudoexperiments were repeated to check the optimal BDT cut was the
same.
4.4 Selection for the B0s  + effective lifetime measurement 101
Decay Expected number of candidates
B0s  + 30.5
Combinatorial background 40.6
Total 71.1
Table 4.18 Expected number of B0s  + and combinatorial background candidates
after the B0s  + selection requirement and with a global BDT value greater than 0.55
in the mass range 5320 < m+  < 6000 MeV/c2.
cut on the global BDT. A ratio is evaluated from bb  +X decays, given by
R(Y ) =
(BDT > Y )
(BDT > 0.55)
, (4.4)
where (BDT > Y ) is the fraction of simulated bb  +X decays that have a
global BDT value greater than Y and (BDT > 0.55) is the fraction of simulated
bb  +X decays that have a global BDT value greater than 0.55. The expected
number of combinatorial background decays after a BDT cut of Y is then evaluated
from multiplying R(Y ) by the number of decays in Table 4.18. The ratios for the
different cuts values are shown in Table 4.19 along with the expected number of
B0s  + and combinatorial background decays for each BDT cut. Simulated
decays had to be used to compute the efficiencies rather than data because there are
too few candidates left after tight BDT cuts in data to enable meaningful studies.
The mass distribution of the combinatorial background is described by an ex-
ponential function. It was observed from the simulated bb  +X decays that
the slope of the mass distribution changed with the BDT cut value as illustrated in
Figure 4.16. The change in the slope value is accounted for in the mass distribution
used in the pseudoexperiments by changing the slope parameter () for each BDT
cut. Table 4.19 shows the slope of the mass distribution for different BDT cuts values
evaluated from bb  +X simulated decays.
The results from 10,000 pseudoexperiments for BDT cut values every 0.05 in the
range 0.40 - 0.65 are shown in Table 4.20 with the median uncertainty of the fits for
 and the signal significance for each BDT cut. The median uncertainties are used
rather than the mean because the distribution of uncertainties is asymmetric. The
highest signal significance and lowest expected uncertainties occur for a BDT cut of
0.55. Therefore this cut value is used to select B0s  + decays and the same cut
is applied to the global BDT to select B  h+h decays.
102 Event selection
]2[MeV/c -+m
5000 5500 6000
18 a)
]2[MeV/c -+m
5000 5500 6000
Fig. 4.16 Mass distribution of simulated decays that have passes the B0s  + effective
lifetime selection requirements and after global BDT cuts of a) 0.40 and b) 0.55.
BDT cut N (B0s  +) R(Y ) N (Comb.)  /c2MeV1
0.40 40.5 8.69 269.1 0.00114  0.00028
0.45 37.2 3.91 116.2 0.00129  0.00041
0.50 33.8 1.91 56.3 0.00132  0.00060
0.55 30.5 1.00 40.6 0.00004  0.00089
0.60 27.1 0.55 22.5 0.00000  0.00114
0.65 23.8 0.32 12.4 0.00024  0.00122
Table 4.19 Inputs to the pseudoexperiments used to determine the optimum global
BDT cut value for the effective lifetime analysis. For each BDT cut value the number of
expected B0s  + decays (N (B0s  +)), the ratio (R(Y )) used to find the number
of combinatorial background decays, the expected number of combinatorial background
decays (N (Combinatorial)) and the slope of the combinatorial background mass distribution
() are given.
Global BDT cut S
S+B  () / ps
0.40 3.87 0.345
0.45 4.51 0.309
0.50 4.85 0.291
0.55 4.94 0.285
0.60 4.86 0.297
0.65 4.65 0.309
Table 4.20 The signal significance for each cut value in the global BDT and median of the
expected uncertainties for  and 1 from 10,000 pseudoexperiments for the expected
number of events.
4.4 Selection for the B0s  + effective lifetime measurement 103
4.4.5 Summary
The complete set of selection criteria used to identify B0s  + decays in Run 1
and Run 2 data for the effective lifetime measurement are listed in Table 4.21. The
selection requirements do not remove all background decays from the data set but
reduce them to a level at which the effective lifetime can be measured. The selection
criteria for B  h+h decays used to verify the measurement strategy are very
similar to the selection used to identify B0(s)  
+ decays. The differences are
in the mass range used and the trigger and particle identification requirements as
discussed in Sections 4.4.2, 4.4.1 and 4.4.3. The mass and decay time distributions
for B0s  + candidates passing the selection criteria in 4.4 fb1 of Run 1 and
Run 2 data are shown in Figure 4.17.
]2c [MeV/+m
5400 5600 5800 6000
Decay time [ps]
0 5 10
Fig. 4.17 Dimuon invariant mass (a) and decay time (b) distributions for B0s  +
candidates in 4.4 fb1 of Run 1 and Run 2 data passing the selection requirements in
Table 4.21.
104 Event selection
Particle B0s  +
B0s 5320 MeV/c2 < m < 6000 MeV/c2
DIRA > 0
2FD > 225
2IP < 25
2VTX < 9
DOCA < 0.3 mm
 < 13.248 ps
pT > 500 MeV/c
BDTS > 0.05
|m mJ/| < 30 MeV/c2
Global BDT > 0.55
 2trk < 3 (4)
Minimum 2IP > 25
0.25 GeV/c < pT < 40 GeV/c
p < 500 GeV/c
ghost probability < 0.3 (0.4)
isMuon = True
PIDRun1+2015 > 0.2 or PID2016 > 0.4
Trigger requirements L0Global = TIS or TOS
Hlt1Phys = TIS or TOS
Hlt2Phys = TIS or TOS
Table 4.21 Selection cuts applied to select B0s  + for the effective lifetime measure-
ment, where selection is different between Run 1 and Run 2 the Run 2 values are shown in
parenthesis.
Chapter 5
Measurement of B0(s)  
branching fractions
This chapter presents the measurements of the B0  + and B0s  +
branching fractions, focusing in more detail on the parts of the analysis that are
also used for the measurement of the B0s  + effective lifetime in Chapter 6.
Section 5.1 gives an overview of the analysis strategy and a description of how
the B0(s)  
+ yield is extracted from the data is given in Section 5.2. The
estimation of the background decays that must be understood for the branching
fraction measurements is detailed in Section 5.3 and the normalisation procedure to
convert the number of observed B0(s)  
+ decays into the branching fractions
is explained in Section 5.4. Finally, the results are presented in Section 5.5. The
B0s  + effective lifetime measurement uses the mass distributions of signal and
background decays and the expected yields described in Sections 5.2 and 5.3.
5.1 Analysis strategy
The B0(s)  
+ branching fractions, B(B0(s)  
+), are defined as the fraction
of B0(s) mesons which decay into two muons. In reality, not every B
(s)  
decay produced in pp collisions will be within the LHCb detector acceptance or be
reconstructed and pass the selection criteria of Chapter 4. Therefore, the number of
observed B0(s)  
+ decays at LHCb is reduced by the efficiency, , of the detector,
trigger, reconstruction and selection criteria. The B0(s)  
+ branching fractions
are measured as
B(B0(s)  
+) =
NB0(s)
NB0(s)
N obs
B0(s)
NB0(s)
(5.1)
106 Measurement of B0(s)  
+ branching fractions
where NB0(s) is the total number of B
(s)  
+ decays that occur, NB0(s) is the
total number of B0(s) mesons and N
B0(s)
is the number of observed B0(s)  
decays.
The number of B0(s) mesons produced can be calculated from the integrated
luminosity, Lint, and the bb production cross-section, bb, via
NB0(s) = 2  Lint  bb  fd(s), (5.2)
where fd(s) is the hadronisation factor, giving the probability for a b or b quark to
form a B0 (B0s ) or a B
0 (B0s) meson. The factor of 2 arises because no distinction is
made between the B0(s) and the B
(s). Although the number of B0(s) mesons can be
computed in this way the measured cross-section is not precisely known and neither
are the hadronisation factors. Therefore, in order to achieve more precise branching
fraction measurements, an alternative approach is used. Another decay with a well
known branching fraction is used to normalise the observed number of B0(s)  
decays and obtain the branching fractions. The normalisation channel can be chosen
in such a way to allow several uncertainties associated with the measurement to
cancel in the normalisation process. The extraction of B(B0(s)  
+) from the
number of observed decays is therefore
B(B0(s)  
+) = Bnorm 
fnorm
fd(s)
norm
B0(s)
N obs
B0(s)
N obsnorm
= d(s)  NobsB0(s),
(5.3)
where norm indicates the normalisation channel. The normalisation factors can be
combined into one normalisation parameter d(s) for each of the B0s and B0 decays.
The normalisation procedure removes the uncertainty from bb, the systematic
uncertainties in the efficiencies cancel out in the ratio, as well as uncertainties on
fd(s) depending on the choice of the normalisation channel. Therefore, to measure
the branching fractions in this way the number of B0(s)  
+ decays in data and
the normalisation parameters d(s) must be measured.
The number of B0(s)  
+ decays in data is found by performing a simultaneous
unbinned extended maximum likelihood fit [131, 161] to the dimuon invariant mass
distribution of B0(s)  
+ candidates in data in four global BDT bins. For this
measurement data from Run 1 and Run 2 are kept separate in the fit, therefore the
simultaneous fit is performed over 8 categories; four BDT bins for each run. The
BDT bin boundaries used in the fit are
[0.25, 0.4, 0.5, 0.6, 1.0]. (5.4)
5.1 Analysis strategy 107
Pseudoexperiments based on the expected number of signal and background decays
in different BDT bin configurations were performed to determine the binning choice
that gave the best fit stability and sensitivity to the B0(s)  
+ branching fractions.
The bins were optimised for the B0  + sensitivity because this decay is yet to
be observed. Candidates with BDT values between 0 and 0.25 are not included in
the fit because this bin is dominated by backgrounds from random combinations
of muons in the event. The inclusion of this bin does not improve the branching
fraction sensitivity and reduces the stability of the fit.
The candidates in data that pass the selection criteria described in Chapter 4
consist of background as well as signal decays. Therefore in order to find the number
of B0(s)  
+ decays from the simultaneous fit information is needed about both
the signal and background. For the fit, the mass PDFs of B0(s)  
+ decays must
be known as well as the BDT PDF, which describes the fraction of B0(s)  
decays expected in each BDT bin. The evaluation of the B0(s)  
+ mass and
BDT PDFs in Run 1 and Run 2 data are described in Section 5.2. The backgrounds
present in the data must be modelled in the mass fit, therefore the mass PDFs and
expected yields of the backgrounds in each BDT bin must be evaluated for Run 1
and Run 2 data. The backgrounds included in the fit are described in Section 5.3
along with the mass PDFs and expected yields for each background.
The normalisation parameters are evaluated for two different normalisation
decays and are then combined to measure the B0(s)  
+ branching fractions. A
normalisation decay is chosen to be as similar as possible to B0(s)  
+ decays,
in order to reduce systematic uncertainties introduced by different detection and
selection efficiencies between the signal and normalisation channels. Furthermore, the
chosen decay needs to be abundant and have a precisely measured branching fraction
so that the precision of the B0(s)  
+ branching fraction measurements are not
limited by the uncertainties of the normalisation channel. Two decays are chosen
as normalisation channels: B+  J/K+, where J/  +; and B0  K+.
Both decays have large, precisely measured branching fractions and are similar to
B0(s)  
+ decays in complementary ways. The B+  J/K+ decay has a very
similar trigger efficiency due to the two muons from the J/, although the extra
particle in the final state leads to different selection and reconstruction efficiencies.
The B0  K+ decay has a very similar topology to B0(s)  
+, therefore the
selection and reconstruction efficiencies will be similar, but the trigger efficiency
for hadrons is quite different to muons. A B0s decay is not used as a normalisation
channel because using a B0s decay would not lead to a reduction in the uncertainty of
the measured branching fractions from the normalisation procedure. The B0s  J/
decay could make a good choice for a normalisation channel instead of B+  J/K+
decays, however, the uncertainty on the measured branching fraction for this decay [5]
108 Measurement of B0(s)  
+ branching fractions
is too large to make using this decay useful. Another possibility could be to use
B0s  K+K decays but B0s  K+K decays, just like B0  K+ decays, have
quite different trigger efficiencies compared to B0(s)  
+ decays. Therefore
B0s  K+K decays would not be a substitute for B+  J/K+ decays in the
normalisation which have very similar trigger efficiencies to B0(s)  
+ decays and
using B0s  K+K decays instead of B0  K+ would not reduce the uncertainty
on the measurements.
The normalisation factors d(s) for B0  + and B0s  + decays are
evaluated independently for each normalisation channel and year of data taking, the
factors are combined to produce an overall normalisation factor for Run 1 and Run 2.
The evaluation of the normalisation factors is described in Section 5.4. As mentioned
in Chapter 4, the mass region 5200 - 5447 MeV/c2 is not revealed until each step in
the analysis procedure has been finalised.
5.2 B0(s)  
+ mass and BDT PDFs
5.2.1 Mass PDFs
The mass PDFs for B0  + and B0s  + decays are modelled by a Crystal
Ball function [162]. A Crystal Ball function is a Gaussian function that has a
power-law tail on the low mass side to model radiative energy loss in the final state.
The parameters defining the function are: the mean, ; and resolution, , of the
Gaussian; the slope of the exponential, n; and a parameter , defined in terms of
, that determines the transition point between the Gaussian and the exponential
function.
The signal shape parameters are evaluated in the following ways:
  - the means of B0 and B0s decays are evaluated separately from fits to
B0  K+ and B0s  K+K decays;
  - the resolution is interpolated from the resolutions of quarkonia resonances.
The resolutions for the J/, (2S) and (1, 2, 3S) decaying into two muons
are measured from fits to data. The B0 and B0s resolutions are interpolated
from the power-law relationship between quarkonia mass and resolution and
using the mean B0 and B0s values from B0  K+ and B0s  K+K decays,
respectively; and
 n and  - these parameters are evaluated from the mass spectrum of B0  +
and B0s  + simulated decays where the mass distributions are smeared to
have the same resolution as that measured from the quarkonia decays in data.
5.2 B0(s)  
+ mass and BDT PDFs 109
Parameter B0  + B0s  +
 (MeV/c2) 5284.73  0.15stat 0.27syst 5372.05  0.16stat 0.36syst
 (MeV/c2) 22.68  0.05stat 0.39syst 23.07  0.05stat 0.39syst
n 1.141  0.026 1.156  0.013
 2.054  0.013 2.053  0.007
Table 5.1 Parameter values for Crystal Ball functions used to describe the B0(s)  
mass PDFs in Run 1 data.
Parameter B0  + B0s  +
 (MeV/c2) 5279.95  0.13stat 0.08syst 5367.34  0.14stat 0.35syst
 (MeV/c2) 22.46  0.08stat 0.41syst 22.85  0.08stat 0.42syst
n 1.118  0.014 1.110  0.017
 2.063  0.007 2.062  0.008
Table 5.2 Parameter values for Crystal Ball functions used to describe the B0(s)  
mass PDFs in Run 2 data.
Fig. 5.1 Maximum likelihood fits to B0  K+ (top) and B0s  K+K (bottom) for
Run 1 and Run 2 data to measure B0 and B0s masses.
110 Measurement of B0(s)  
+ branching fractions
Fig. 5.2 Maximum likelihood fit to the mass spectrum of J/ (top), (2S) (centre) and
(1, 2, 3S) (bottom) decaying into two muons in Run 1 and Run 2 data.
5.2 B0(s)  
+ mass and BDT PDFs 111
]2c [GeV/m
5000 10000
LHCb Run 1
Interpolation fit
Resolution from mass fits
]2c [GeV/m
5000 10000
LHCb Run 2
Interpolation fit
Resolution from mass fits
Fig. 5.3 Power law fit to the resolution of quarkonia resonances to determine mass
resolution for B0  + and B0s  + decays on Run 1 and Run 2 data.
All parameters are evaluated separately for the B0 and B0s for the Run 1 and
Run 2 data sets. The resulting parameter values are given in Tables 5.1 and 5.2 and
the mass fits are shown in Figures 5.1, 5.2 and 5.3. The systematic uncertainties
on the means come from varying the particle identification cuts used to separate
the different B  h+h decays and the systematic uncertainties on the resolutions
come from the mass windows chosen for the quarkonia mass fits and the chosen mass
fit model.
The same mass PDFs are used for all BDT bins because the invariant mass of
B0(s)  
+ candidates is not correlated with the global BDT. The correlation was
evaluated for each year of data-taking and found to be less than 4% and plots of
dimuon mass versus global BDT showed no visible correlation. The plots can be
found in [163].
5.2.2 BDT PDFs
The global BDT distribution for B0(s)  
+ decays is expected to be uniform
between 0 and 1 as designed by the flattening procedure described in Section 4.3.4.2.
The fraction of B0(s)  
+ decays in a BDT bin should be proportional to the
bin width. However, the global BDT was trained and flattened using simulated
decays, therefore to avoid differences between simulated decays and data affecting
the expected fraction of B0(s)  
+ decays in each BDT bin, the BDT PDF is
evaluated from B0  K+ decays in data. This process is known as the BDT
calibration. The global BDT is designed to use only kinematic and geometric
information to classify candidates and includes no PID information. Therefore the
BDT distributions of B0  K+ decays will be the same to a good approximation
as B0(s)  
+ decays since they are kinematically very similar.
The number of B0  K+ decays is extracted from data by fitting the mass
distribution of B0  K+ candidates in each BDT bin for Run 1 and Run 2 data.
112 Measurement of B0(s)  
+ branching fractions
0 0.2 0.4 0.6 0.8 1
LHCb Run I
Signal
Background
0 0.2 0.4 0.6 0.8 1
LHCb Run II
Signal
Background
Fig. 5.4 B0(s)  
+ BDT PDFs (black squares) for Run 1 and Run 2 data calibrated
using B0  K+ decays and the combinatorial background decays (blue circles) for
B0(s)  
+ candidates in data with a dimuon mass above 5477 MeV/c2. The uncertainties
on the signal fractions are included on the plots but are too small to be visible.
The B0  K+ candidates must pass the standard B  h+h selection outlined
in Section 4.3 are separated from other B  h+h modes using the DLLK variable.
The particle identification and trigger efficiencies are different for B0  K+
and B0(s)  
+ decays. Therefore, the B0  K+ yields in each BDT bin are
corrected for the different efficiencies. The same calibration is used for B0  +
and B0s  + decays. The calibration is performed for each year separately then
combined to give the Run 1 and Run 2 fractions per BDT bin. Figure 5.4 shows
the BDT distribution for B0(s)  
+ decays calibrated with B0  K+ data for
Run 1 and Run 2. The systematic uncertainties on the BDT calibration arise from
the mass range used in the fit, the choice of the fit model and particle identification
requirements and the trigger and particle identification efficiency corrections.
Although the BDT is calibrated, the dependence of the BDT response on the
B0(s) candidate decay time must also be considered. The response of the global BDT
for B0(s)  
+ decays is correlated with their decay time due to the use of the
B0s IP and 2IP and isolation criteria as inputs to the BDT. This correlation will
lead to slightly incorrect estimations of the B0s  + BDT PDF. In the SM the
B0s  + effective lifetime, , is equal to the lifetime of the heavy B0s mass
eigenstate, H . However in reality  could be somewhere in between the lifetimes
of the heavy and light mass eigenstates. As described in Chapter 2 the B0s  +
effective lifetime is related to the parameter A, where A = +1 for  = H
and A = 1 for  = L, where L is the lifetime of the light B0s  + mass
eigenstate.
The simulated decays used to train and flatten the global BDT use as the
B0s  + lifetime the mean of the measured H and L values at the time of
the simulation production [5]. Therefore, the lifetime used is different between
simulation versions. Since the BDT output is correlated with the lifetime, the
5.3 Background mass PDFs and expected yields 113
fraction of B0s  + decays in each BDT bin will depend on the lifetime used in
the simulation. Numerical correction factors are computed for each year to scale the
fraction of B0s  + decays in each BDT bin for the situations where A = 1,
0 or +1, so that the dependence on A of the measured branching fractions can be
evaluated.
No corrections are needed for B0  + because the difference in lifetime of
the heavy and light B0 mass eigenstates is negligible and the need for correction
cancels out with the BDT calibration that uses the B0 decay B0  K+.
5.3 Background mass PDFs and expected yields
The selection described in Chapter 4 is effective at reducing the backgrounds in
the data set to a suitable level so that the number of B0(s)  
+ decays can
be measured. However, some background decays remain in the final data set that
cannot be completely removed without drastically reducing the signal efficiency. The
backgrounds present in the final data set originate from:
 B  h+h decays when both hadrons are mis-identified as muons, commonly
caused by hadrons decaying semi-leptonically during their flight through the
detector after leaving the VELO. This background peaks within the B0 mass
window and has a small contribution in the B0s mass window due to the missing
energy from the undetected neutrino;
 semi-leptonic decays where one hadron is mis-identified as a muon that include
 B0  + and B0s  K+ decays where the final state hadrons
are mis-identified as muons. The majority of these backgrounds fall below
the B0 mass window in the left mass sideband; and
 0b  p decays when the proton is mis-identified as a muon. This
background produces a small number of decays with masses within the
B0s and B0 mass windows and in the left mass sideband;
 decays which contain two muons that form a good vertex that include
 B0(+)  0(+)+ decays where the pion is not detected. The missing
hadron means that these backgrounds fall well below the B0 mass window;
 B+c  J/+ decays where J/  +. The large mass of the B+c
causes this background to cover the full mass range 4900 - 6000 MeV/c2;
114 Measurement of B0(s)  
+ branching fractions
]2c [MeV/+m
5000 5200 5400 5600 5800 6000
Combinatorial
h'+ hB 
+)(K  (s)
+0(+)  0(+)B
 p b
+ J/ +cB
BDT > 0.5
Fig. 5.5 Mass distributions for B0(s)  
+ backgrounds with global BDT values of
BDT > 0.5. The backgrounds shown are from B  h+h
, B0  +, B0s  K+,
0b  p
, B0(+)  0(+)+, B+c  J/+ and combinatorial background. The
green dashed lines show the B0(s)  
+ mass window defined in Section 5.1.
 combinatorial background formed by the random combination of any two muons
in the event, this background is distributed across the full mass range.
The backgrounds present in the data set must be included in the fit to the dimuon
invariant mass in order to accurately measure the B0(s)  
+ branching fractions.
Therefore, the mass PDFs and expected yields of each background must be evaluated.
The following sections summarise the information used for each background source
in the branching fraction fit and Figure 5.5 shows the mass distributions of the
background sources for the expected number of candidates with BDT values of
BDT > 0.5.
5.3.1 Mis-identified B  h+h decays
The mass PDF describing mis-identified B  h+h decays is formed of two Crystal
Ball functions. The two functions have the same mean but all other parameters can
be different and the power-law tails for each function are on opposite sides of the
mean value. This combination of functions is called a double Crystal Ball function.
The parameter values are evaluated from simulated B0  K+, B0s  K+K,
B0  + and B0s  K+ decays in which the momenta of tracks are smeared
to model the hadrons decaying in flight. The parameters are evaluated separately for
each B  h+h decay and combined using the branching fractions and the particle
5.3 Background mass PDFs and expected yields 115
identification efficiencies for each decay. The mass PDFs are evaluated separately for
Run 1 and Run 2 data and the same PDF is used for all BDT bins.
The total number of mis-identified B  h+h decays expected in Run 1 and
Run 2 data, NBhh, is found using the relationship
NBhh = TRIGB0(s) 
NBhh
TRIGBhh
 Bhh (5.5)
where NBhh is the number of TIS B  h+h
 decays in data, TRIG
B0(s),Bhh
are the
B0(s)  
+ and B  h+h trigger efficiencies and Bhh is the probability that
a B  h+h decay is mis-identified as B0(s)  
+. The number of B  h+h
decays is calculated from a fit to the mass distribution of B0  K+ candidates
identified in data, the number of B0  K+ candidates is translated into the total
number of B  h+h by scaling the B0  K+ yields by the relative production
rates of B0  K+ decays compared to the other B  h+h decays. Different
trigger requirements are used to identify B0  K+ and B0(s)  
+ decays in
data and the trigger efficiencies for both selections are calculated from simulated
decays. The probability that a B  h+h decay is mis-identified as a B0(s)  
decay is evaluated in each BDT bin for each year of data-taking using the PIDCalib
package [155]. The number of mis-identified B  h+h decays expected in each
BDT bin after the B0(s)  
+ selection is calculated by multiplying the total
number of B  h+h decays by the mis-identification probability for each BDT
bin and correcting for the different trigger efficiencies used to select B0  K+
and B0(s)  
+ decays. The output of this procedure gives the expected number
of mis-identified B  h+h decays in each BDT bin for Run 1 and Run 2 data
separately.
5.3.2 Exclusive backgrounds
The mass PDFs and expected yields for exclusive backgrounds from B0  +,
B0s  K+, 0b  p, B+  ++, B0  0+ and B+c  J/+
decays are all evaluated using the same techniques.
The mass PDFs of exclusive backgrounds vary across the BDT range. Therefore
these PDFs are evaluated using simulated decays for each BDT bin separately. An
Argus function [164] convoluted with a Gaussian function is used to describe the
mass distributions. The Gaussian function accounts for the mass resolution of the
detector. The shapes of B0  + and B0s  K+ are extremely similar
and therefore these backgrounds are modelled with one common PDF. Similarly one
mass PDF is used to model B+  ++ and B0  0+ decays. The mass
PDFs are shown in Figure 5.5 for high BDT output values.
116 Measurement of B0(s)  
+ branching fractions
The expected yields of the exclusive backgrounds in each BDT bin are estimated
by using to the number of B+  J/K+ decays observed in data via
N expx = NB+J/K+ 
BB+J/K+
+J/K+ (5.6)
where x represents each background decay. The background estimation can be
factorised as
N expx =   fx  x  Bx (5.7)
where  combines the yield, selection efficiency and hadronisation factor of B+ 
J/K+ decays and is the same for all backgrounds. The  term is evaluated using
the same method as the normalisation of the B0(s)  
+ branching fractions
described in Section 5.4. The B+  J/K+ efficiencies and yields are evaluated
across the full BDT range whereas the detection and selection efficiency of each
background, x, are evaluated separately for each BDT bin using information from
both data and simulated decays. The hadronisation factors and branching fractions
are specific to each background and where possible measured, rather than predicted,
branching fractions are used. The branching fraction values used for each background
are given in Table 4.1. The output of the procedure gives the expected yields of each
background in each BDT bin for both Run 1 and Run 2 data.
5.3.3 Combinatorial background
The combinatorial background is the most straightforward background to model and
it is described by an exponential function. The slope of the function is required to
have the same value for all BDT bins but the slope can be different for Run 1 and
Run 2 data. These slopes are determined from a simultaneous fit to candidates in
data across the BDT bins in the mass ranges [4900, (mB0(s)  80)] MeV/c
2 and [(mB0(s)
+ 80), 6000] MeV/c2, where the mass shapes and yields of the remaining backgrounds
are constrained to their expected values. The expected number of combinatorial
background decays does not need to be evaluated because the yield is not constrained
in the fit to measure the branching fractions.
5.4 Normalisation
The B0(s)  
+ branching fractions are measured by normalising the number
of observed B0(s)  
+ decays to the number of observed B+  J/K+ and
B0  K+ decays. The normalisation parameters d(s), in Equation 5.3 for
B0(s)  
+ decays depend on the yields of the normalisation decays, the ratio of
the detection and selection efficiencies and the hadronisation factors. The yields of
5.4 Normalisation 117
]2c [MeV/+KJ/m
5200 5250 5300 5350
510 LHCb Run 1
Total
+K J/ +B
+ J/ +B
Comb. bkg.
]2c [MeV/+KJ/m
5200 5250 5300 5350
510 LHCb Run 2
Total
+K J/ +B
+ J/ +B
Comb. bkg.
Fig. 5.6 Mass fit to measure the B+  J/K+ yield for the normalisation for Run 1
(left) and Run 2 (right) data. The total PDF is made up of components of B+  J/K+
and B+  J/+ decays and combinatorial background.
B+  J/K+ and B0  K+ decays are evaluated separately for Run 1 and Run 2
data and this process is described in Section 5.4.1. The evaluation of the selection
efficiencies is described in Section 5.4.2 and this is done separately for each year of
data taking. The hadronisation factors used for the normalisation are discussed in
Section 5.4.3 and depend on the centre-of-mass energy of collisions. The different
inputs are combined to obtain the final normalisation parameters for Run 1 and Run 2
data that are presented in Section 5.4.4. In addition to the normalisation channels,
B0s  J/ decays are used to check the normalisation parameters. Consequently
the yields of decays and the detection and selection efficiencies must also be evaluated.
This is done in the same way as the normalisation channels.
5.4.1 B0  K+ and B+  J/K+ yields
The yields of B+  J/K+ and B0  K+ decays are measured from data
by fitting the mass distributions of these decays in Run 1 and Run 2 data. The
B+  J/K+ mass PDF is modelled by an Ipathia function [165] and the fit includes
components for combinatorial background and B+  J/+ decays that are mis-
identified as B+  J/K+ decays. The mass PDF parameters are determined from
a mixture of information from data and simulated decays. The B0  K+ mass fit
includes components for B0s  K+ decays and combinatorial background as well
as B0  K+ decays. Both B0  K+ and B0s  K+ decays are modelled
by double Crystal Ball functions and the parameters are determined from a mixture
of information from data and simulated decays. Figure 5.6 and 5.7 show the mass
fits used to calculate the Run 1 and Run 2 B+  J/K+ and B0  K+ yields.
118 Measurement of B0(s)  
+ branching fractions
]2c [MeV/+Km
5200 5400 5600 5800
LHCb Run 1
Total
+ K0B
+ Ks
Comb. bkg
]2c [MeV/+Km
5200 5400 5600 5800
LHCb Run 2
Total
+ K0B
+ Ks
Comb. bkg
Fig. 5.7 Mass fit to measure the B0  K+ yield for the normalisation for Run 1 (left)
and Run 2 (right) data. The total PDF is made up of component ts for B0  K+ and
B0s  K+ decays and combinatorial background.
5.4.2 Efficiency ratio
The efficiency ratio in Equation 5.3 is divided into several separate efficiency terms
norm
B0(s)
Accnorm
B0(s)
RecSel|Accnorm
RecSel|Acc
B0(s)
Trig|RecSelnorm
Trig|RecSel
B0(s)
, (5.8)
where Acc is the detector acceptance efficiency, RecSel|Acc the reconstruction and
selection efficiency given the detector efficiency, and Trig|RecSel the trigger efficiency
given the reconstruction and selection efficiency.
The detector acceptance efficiency gives the efficiency for the decay products
to be within the LHCb detector angular acceptance. This efficiency is evaluated
on simulated decays for decay products that fall within the range [10,400] mrad in
both x and y directions. The range is chosen to be slightly larger than the detector
acceptance so that particles recovered by the magnetic field are included. To keep
this efficiency similar for B0(s)  
+ and B0  K+ decays, the hadrons from
B0  K+ decays are required to be within the muon detector acceptance.
The reconstruction and selection efficiency of decays within the detector accep-
tance is evaluated from a combination of information from data and simulated decays.
Similar to the fraction of B0s  + in each BDT bin, a correction is applied for
the lifetime used in simulated B0s  + decays assuming A = +1.
The trigger efficiencies for decays passing the reconstruction and selection are
evaluated for each decay by data driven methods as described in [58, 166].
The efficiencies are calculated for B0s  +, B0  +, B0  K+ and
B+  J/K+ separately to account for differences between the decay kinematics.
The ratio of efficiencies between signal and normalisation channels used in the
normalisation parameters ensures that systematic uncertainties arising from the
5.4 Normalisation 119
use of simulated decays cancel out and will not affect the measurements of the
B0(s)  
+ branching fractions.
5.4.3 Hadronisation factors
The normalisation factors depend on the hadronisation factors, fu, fs, fd, that give
the fraction of bb pairs that produce B, B0 or B0 and B0s or B
s mesons. The factors
fd and fu are equal to good approximation, therefore the B0  + branching
fraction does not depend on any hadronisation factors. For the B0s  + decay
the ratio fs/fd is used in the normalisation, since fd = fu. This ratio has been
measured at LHCb for pp collisions at
s = 7 TeV [167]. The stability of this ratio
at different centre-of-mass energies was tested using the ratio of B0s  J/ and
B+  J/K+ decays at 8 and 13 TeV relative to their ratio at 7 TeV. The ratios are
stable across the different collision energies and fs/fd is assumed to be identical for
s = 8 TeV. For Run 2, the fs/fd ratio is modified due to a small relative production
difference in B0s  J/ and B+  J/K+ decays observed for Run 2 compared
to Run 1. The uncertainty on the hadronisation factor ratio contributes the largest
systematic uncertainty to the B0s  + branching fraction.
Alternatively, the B0s  + branching fraction could be normalised using a
different B0s decay, such as B0s  J/. However the precision of the measured
branching fractions and abundance of such decays is not high enough at present to
provide a lower overall uncertainty on the measured branching fraction.
5.4.4 Normalisation parameters
The yields, efficiencies and hadronisation factors are combined to produce separate
normalisation factors for each year of data taking and each normalisation channel.
The consistency of the efficiencies and yields for each normalisation channel are
checked for each year by comparing the ratios B(B0  K+)/B(B+  J/K+)
and B(B+  J/K+)/B(B0s  J/) with the average of previously measured
values of these quantities in reference [5]. The efficiencies and yields are consistent
with the measured values for these decays.
The yearly normalisation factors are combined for each channel to produce the
overall normalisation factors for Run 1 and Run 2, taking into account correlations
between the parameters. A weighted average of the normalisation factors for B0 
K+ and B+  J/K+ decays are used to produce the overall normalisation
factors for Run 1 and Run 2 as shown in Table 5.3.
120 Measurement of B0(s)  
+ branching fractions
Normalisation Parameters Run 1 Run 2
d  1011 2.88  0.10 3.52  0.16
s  1010 1.07  0.07 1.31 0.10
Table 5.3 Normalisation parameters for B0s  + and B0  + for Run 1 and
Run 2.
5.5 Results
The B0  + and B0s  + branching fractions are measured by a simultaneous
fit to the dimuon invariant mass distribution across eight categories: Run 1, Run 2 and
four BDT bins, as described in Section 5.1. The fit results are shown in Figure 5.8.
In the fit all PDF shapes, except the combinatorial background, are constrained
within Gaussian limits around their expected values using the uncertainties on the
PDF shape parameters. The fraction of B0(s)  
+ decays in each BDT bin is
constrained using the BDT PDF and the yields of the mis-identified background are
constrained around their expected values. The combinatorial background yields are
left free in the fit and the slope of the mass distribution is required to have the same
value across all bins for each data set.
Pseudoexperiments are performed to test the reliability of the branching fraction
fit. These studies use the SM predictions for the B0s and the B0 branching fractions
and the background yields and slope of the combinatorial background are taken
from a fit to the dataset but including only B0(s)  
+ candidates with masses
outside the B0s and B0 mass windows. For each pseudoexperiment the significance of
the measured branching fractions is evaluated using Wilks theorem [168] by taking
the difference in the likelihood in fits when the signal component is included and
excluded from the fit. The pseudoexperiments show that the branching fraction fit
returns unbiased results for the B0s and the B0 branching fractions and the expected
mean significance of the measured B0s and B0 branching fractions, assuming the SM
values, is 9.6 and 1.6, respectively. Details and results from the pseudoexperiments
can be found in reference [163].
The measured branching fractions are
B(B0s  
+) = (3.0  0.6+0.30.2)  10
B(B0  +) = (1.5+1.2+0.21.00.1)  10
(5.9)
where the first quoted uncertainty is the statistical uncertainty and the second is the
systematic uncertainty. The dominant contributions to the systematic uncertainties
are from the ratio fs/fd and the uncertainty on the background yields. Most
5.5 Results 121
]2c [MeV/+m
5000 5500 6000
LHCbBDT > 0.5
LHCb Run 1
 [0.25,0.40]BDT 
]2c [MeV/+m
5000 5500 6000
LHCbBDT > 0.5
LHCb Run 2
 [0.25,0.40]BDT 
]2c [MeV/+m
5000 5500 6000
LHCbBDT > 0.5
LHCb Run 1
 [0.40,0.50]BDT 
]2c [MeV/+m
5000 5500 6000
LHCbBDT > 0.5
LHCb Run 2
 [0.40,0.50]BDT 
]2c [MeV/+m
5000 5500 6000
LHCbBDT > 0.5
LHCb Run 1
 [0.50,0.60]BDT 
]2c [MeV/+m
5000 5500 6000
LHCbBDT > 0.5
LHCb Run 2
 [0.50,0.60]BDT 
]2c [MeV/+m
5000 5500 6000
LHCbBDT > 0.5
LHCb Run 1
 [0.60,1.00]BDT 
]2c [MeV/+m
5000 5500 6000
LHCbBDT > 0.5
LHCb Run 2
 [0.60,1.00]BDT 
Fig. 5.8 Mass distribution in BDT bins for selected B0s  + and B0  +
candidates with the fit overlaid for Run 1 and Run 2 data. The fit includes components for
B0  +, B0s  +, combinatorial backgrounds and backgrounds from mis-identified
decays.
122 Measurement of B0(s)  
+ branching fractions
contributions to the systematic uncertainties of the branching fractions do not
depend on the size of the dataset used to make the measurement. However with more
data, the systematic uncertainty from the expected yields of background decays will
decrease as more precise measurements of the branching fractions of the backgrounds
are made. Furthermore, measurements of the ratio fs/fd at 8 and 13 TeV will reduce
the overall systematic uncertainty on the measured branching fractions as well.
The significance of the B0s  + signal is 7.8 making this measurement the
first single experiment observation of the B0s  + decay. The significance of the
B0  + signal is 1.6, therefore the CLs method [48] is used to place an upper
limit on the branching fraction of B(B0  +)< 3.41010 at the 95% confidence
level. The significances are determined using Wilks theorem [168] evaluating the
difference in the likelihood of the fit when the signal component is included and
excluded.
Additional tests were performed to check the fit produces accurate values for
the branching fractions. The branching fraction fit was applied to Run 1 and Run
2 data separately and the measured values of the B0s  + branching fractions
for the two datasets were within 1.7 of each other. Furthermore, the B0s  +
and B0  + branching fractions were estimated separately for Run 1 and Run 2
data from the number of candidates in the B0s and B0 mass windows with global
BDT > 0.6. The estimated branching fractions for each dataset were consistent with
the measured branching fractions from the fits. Full details of the checks performed
can be found in reference [163].
The B0s  + branching fraction in Equation 5.9 assumes the Standard Model
value for A of A = +1, applying the corrections detailed in Section 5.2.2;
A values of 0 and 1 shift the central value of B(B0s  +) by 4.6% and
10.9%, respectively. All results are consistent with the predictions of the SM as
illustrated in Figure 5.9. A comparison between Figure 5.9 and the previous branching
fraction results displayed in Figure 1.2 shows the results presented here have a better
agreement with the SM predictions. This is due to the lower measured value of
the B0  + branching fraction whereas the B0s  + branching fraction
measurement is very similar to that from the combined analysis of the CMS and
LHCb Run 1 datasets.
5.5 Results 123
)+  0sBF(B
0 2 4 6 8
910
910
68.27%
95.45%
99.73%
99.99%
Fig. 5.9 B0  + and B0s  + 2-dimensional likelihood plot for the simultaneous
branching fraction fit to Run 1 and Run 2 data.
Chapter 6
Measurement of the
B0s  
+effective lifetime
This chapter describes the measurement of the B0s  + effective lifetime. Sec-
tion 6.1 presents an overview of the analysis strategy. The PDFs of the mass and
decay time distributions for signal and background candidates are described in
Sections 6.2 and 6.3. Due to the very rare nature of B0s  + decays, the fit
configuration used to measured the effective lifetime is optimised to produce the
smallest expected statistical uncertainty on the measured value; the optimisation
studies are detailed in Section 6.4. Finally, the measurement of the B0s  +
effective lifetime is presented in Section 6.5.
6.1 Analysis strategy
The B0s  + effective lifetime is measured from the decay time distribution of
B0s  + candidates passing the selection criteria described in Section 4.4. Since
the selection requirements do not completely separate real B0s  + decays from
the backgrounds, in order to measure the B0s  + effective lifetime, either the
PDFs describing the decay time distributions of the signal and all backgrounds must
be known, or the background candidates must be removed from the data leaving only
the signal distribution. Several approaches were investigated to determine which
would produce stable results for the measured B0s  + effective lifetime for the
data set and yield the smallest expected statistical uncertainty on the result. The
most successful approach was found to be the sPlot statistical weighting method,
described in reference [160], which allows the signal and background components of
a dataset to be disentangled in a statistically rigorous way.
The sPlot method produces a two step strategy to measure the effective lifetime.
The first step is an unbinned extended maximum likelihood fit to the dimuon invariant
mass spectrum, where components are included in the PDF for B0s  + decays
126 Measurement of the B0
 +effective lifetime
Year B0s  + correlation bb  +X correlation
2011 0.008 0.003
2012 0.006 0.008
2015 0.006 0.010
2016 0.008 0.002
Table 6.1 Correlation between mass and decay time for candidates from B0s  +
simulated decays and combinatorial background decays from data for 2011, 2012, 2015
and 2016 data-taking conditions. The selection given in Table 4.21 is applied to simulated
B0s  + decays and the same selection is applied to decays in data apart from the
global BDT cut and have a dimuon invariant mass of > 5447 MeV/c2. Furthermore plots
of mass versus decay time showed no visible correlation for each year.
and each background decay in the data. The mass fit determines the yields of the
signal and background decays and from the fit each event is assigned a weight, called
an sWeight, depending on how likely the event is to be signal or background. In the
second step the sWeights are applied to the data, effectively removing all background
decays. An unbinned maximum likelihood fit to the decay time distribution of the
sWeighted data is performed to measure the B0s  + effective lifetime. In the
final fit only the B0s  + decay time PDF is needed to measure the effective
lifetime as any background will have been removed by the sPlot technique. The PDF
describing the decay time will need to take into account the selection efficiency as
a function of decay time. Due to the low statistics expected for the data set, Run
1 and Run 2 data are combined and the fits to the mass and weighted decay time
distributions are performed to the combined data.
The approach outlined here is suited to the measurement of the B0s  +
effective lifetime because the mass PDFs are accurately known for the signal and
background decays from the branching fraction analysis. Furthermore, no knowledge
is required for the decay time PDFs of the backgrounds in the final fit. This is
advantageous because decay time distributions of combinatorial background decays
are challenging to model accurately.
A requirement of the sPlot procedure is that the variable used to calculate
the sWeights and the variable from which the observable is measured must be
independent. The correlation of the mass and decay time for B0s  + decays
and combinatorial background decays has been evaluated using simulated decays
and data. The correlation is negligible as shown in Table 6.1 and the distribution of
events for plots of mass versus decay time showed no visible correlation. Therefore
the invariant mass of the B0s  + candidate can be used to accurately determine
sWeights applied to measure the B0s  + effective lifetime.
6.2 Mass PDFs 127
The sWeights used in the fit are calculated using the RooFit package [169].
However, the raw sWeights from the mass fit cannot be used directly in the maximum
likelihood fit to measure the effective lifetime. The normalisation of the sWeights will
not produce the correct statistical uncertainty on the effective lifetime measurement.
The uncertainty will be related to the sum of the weights rather that the number of
candidates in the data set [170, 171]. Therefore, the fit uses re-normalised sWeights
given by
i = i 
, (6.1)
where i are the sWeight values for each decay and j are sWeights summed over all
decays. The re-normalised sWeights will produce the correct statistical uncertainty
in a maximum likelihood fit to measure the B0s  + effective lifetime.
The measurement strategy of the B0s  + effective lifetime requires the mass
and decay time PDFs of B0s  + decays and the mass PDFs of background that
pass the selection criteria in Chapter 4. However, the overall performance of this
strategy depends on the fit to the invariant mass distribution and how accurately
the sWeights are calculated. Pseudoexperiments are performed to determine the
best mass fit configuration to measure the effective lifetime and the fit is studied
for different B0s  + mass ranges, the largest of which is 4900 - 6000 MeV/c2.
Therefore the pseudoexperiments require the decay time PDFs of the backgrounds
as well as the signal and the signal and background mass PDFs in the range 4900
- 6000 MeV/c2. The mass PDFs used for the effective lifetime measurement are
described in Section 6.2 and the decay time PDFs are described in Section 6.3. The
pseudoexperiments used to determine the fit configuration are described in Section 6.4
along with the final fit configuration and the expected sensitivity of the measurement.
Finally, the results are presented in Section 6.5.
6.2 Mass PDFs
The selection criteria used to identify B0s  + candidates for the B0(s)  
branching fraction and B0s  + effective lifetime measurements are very similar.
Therefore, the background decays passing the selection for the effective lifetime
measurement are the same as those passing the selection for the branching fraction
measurements, although the yields are different. Consequently the mass fit used
to extract the sWeights is very similar to the fit used for the branching fraction
measurements in Sections 5.2 and 5.3. The PDF used in the mass fit has the form
Ptot(m) = NsigPsig(m) +
N ibkgP
bkg(m), (6.2)
128 Measurement of the B0
 +effective lifetime
where i represents a particular background, Nsig(bkg) are the signal (background)
yields and Psig(bkg) are the signal (background) PDFs. The background decays
include; B0  +, B  h+h, 0b  p, B0  +, B0s  K+,
B+  ++, B0  0+, B+c  J/+ and combinatorial background
decays. For the effective lifetime measurement the B0  + decay is included as
a background.
The B0s  + and B0  + mass PDFs are described by the same
Crystal Ball functions used in the branching fraction measurements, with the Run 1
parameters given in Table 5.1. The choice of Run 1 or Run 2 parameters in the PDF
has a negligible effect on the measurement of the B0s  + effective lifetime as
shown in Section 7.3.
Mis-identified semi-leptonic decays, 0b  p, B0  +, B0s  K+,
B+  ++, B0  0+ and B+c  J/+ are each described by an Argus
function [164] convoluted with a Gaussian function evaluated from simulated decays
using the same method as described in Section 5.3. The particle identification
requirements and the cut on the global BDT used in the selection of candidates for
the effective lifetime measurement are taken into account in the evaluation of the
PDF shapes.
Backgrounds from mis-identified B  h+h decays are described by a double
Crystal Ball function evaluated using the method described in Section 5.3 with the
effective lifetime particle identification requirements applied. Finally, the combina-
torial background is modelled with a decaying exponential where the slope is not
constrained in the final fit.
6.3 Decay time distributions
The efficiency of the selection criteria for both signal and background decays varies
as a function of decay time which biases the decay time distribution, as described in
Chapter 4. Therefore, the PDF describing the decay time is not just an exponential
but is described by
P(t) = (t)  et/ , (6.3)
where (t) is the selection efficiency as a function of decay time. The decay time
distribution and selection efficiency as a function of decay time are shown in Figure 6.1
for simulated B0s  + decays at different stages through the selection. The cut
on the global BDT causes the biggest decay time bias which is as expected since it is
the hardest selection cut applied.
To measure the B0s  + effective lifetime, the efficiency of the selection of
B0s  + decays as a function of decay time must be accurately modelled. The
determination of (t) for B0s  + decays is described in Section 6.3.1. Although
6.3 Decay time distributions 129
Decay time [ps]
0 5 10
610 a)
Decay time [ps]
0 5 10
0.45 b)
Fig. 6.1 Decay time distribution (a) and selection efficiency as a function of decay time
(b) for 2012 B0s  + simulated decays at different stages of the selection process. The
decay time distributions and efficiencies are shown for reconstructed decays that pass
the trigger, stripping and pre-selection cuts (magenta squares), the decays that go on to
pass PID requirements (green triangles) and decays that pass all selection requirement
including the global BDT cut (blue circles). Also the decay time distribution is shown for
all generated simulated decays (red stars).
the sPlot method used to measure the B0s  + effective lifetime means that the
decay time PDFs of the backgrounds present in the data set are not needed, realistic
descriptions of the background decay time PDFs are necessary for optimising the
mass fit configuration. The background PDFs, both the efficiency as a function of
decay time and the lifetime used for each background, are described in Section 6.3.2.
6.3.1 B0s  
+ decay time PDF
The selection efficiency of B0s  + decays as a function of decay time is modelled
by an acceptance function and a range of different models were investigated. The
model that described the B0s  + decay time efficiency best was the parametrised
acceptance used in reference [172]
(t) =
[a(t t0)]n
1 + [a(t t0)]n
, (6.4)
where t is the decay time, a and n describe the curvature of the efficiency at low
decay times and t0 is the decay time below which the efficiency is zero.
The acceptance function parameters are determined by fitting the reconstructed
decay time distribution of simulated decays using the PDF in Equation 6.3 with the
lifetime fixed to the value used to generate the simulated decays. The normalisation
of the PDF in the fit means that the limit of (t)  1 as t   is not relevant in
this situation. In the fit to data to measure the effective lifetime the acceptance
function parameters are fixed and a systematic uncertainty describing how well the
acceptance function is understood is detailed in Section 7.4.
130 Measurement of the B0
 +effective lifetime
There are several steps performed in the evaluation of the acceptance function
parameters to ensure the final function describes the selection efficiency ofB0s  +
decays accurately. First, simulatedB0s  + decays are weighted using information
from B0  K+ decays in data and simulation to correct for mis-modelling of the
underlying event in simulation. Second, simulated B0s  + decays from each
year of data-taking are combined into one sample to account for different selection
efficiencies for each year. Third, a unbinned maximum likelihood fit is performed to
the reconstructed decay time distribution of the weighted simulated decays to find
the acceptance function parameters. Each of the steps is described in the following.
 + simulated decays weighted using B0  K+ decays
In general simulated decays model distributions in data reasonably well. However the
number of tracks present in an event is not well modelled in the simulation. Although
the B0s  + decay time distribution does not depend on the number of tracks
present in the event, the isolation criteria used in the global BDT do. Therefore,
the selection efficiency as a function of decay time depends on the number of tracks
in the event and cannot be accurately described by simulated decays alone. To
overcome this the number of tracks for simulated B0s  + decays are weighted
using information from the number of tracks per event for B0  K+ decays
in both data and simulation. The number of tracks for B0  K+ decays is
found for decays in data and simulated decays for each year of data-taking where
no requirement is made on the output of the BDT. The difference between the
distributions from simulation and data are used to evaluated weights which are
applied to the simulated decays so that the distribution of number of tracks in an
event matches the distribution in data. These weights are then applied to simulated
B0s  + decays before the BDT cut is applied. The effect of the weights can
be seen in the different reconstructed decay time distributions of weighted and
unweighted decays that have a BDT value of BDT > 0.55.
The selection requirements described in Chapter 4 are used to identify B0 
K+ decays in data and simulation but, importantly the global BDT cut is not
applied. The distribution of the number of tracks B0  K+ decays in data is
obtained by performing a fit to the K mass distribution and extracting sWeights.
The sWeights are applied to data to find the distribution of the number of tracks
in an event for B0  K+ decays. The distribution of the weighted number of
tracks per event in data is compared with the distribution in simulated B0  K+
decays. The mass fits to B0  K+ decays in data are shown in Figure 6.2 and
the normalised distributions of the number of tracks per event in weighted data
and simulated decays are shown in Figure 6.3. Each year of data-taking is kept
6.3 Decay time distributions 131
]2 [MeV/c-+Km
5200 5300 5400 5500
]2 [MeV/c-+Km
5200 5300 5400 5500
10000
]2 [MeV/c-+Km
5200 5300 5400 5500
]2 [MeV/c-+Km
5200 5300 5400 5500
10000
12000 Total
- + K s
- + K 0B
Combinatorial background
Fig. 6.2 Maximum likelihood fits to the mass distribution of B0  K+ candidates
in a) 2011, b) 2012, c) 2015 and d) 2016 data. The mass PDF includes components for
B0  K+, B0s  K+ and combinatorial background.
132 Measurement of the B0
 +effective lifetime
nTracks
0 200 400 600
0.10 a)
nTracks
0 200 400 600
nTracks
0 200 400 600
nTracks
0 200 400 600
Simulation
Fig. 6.3 Normalised histograms of the number of tracks per event (nTracks) in simulated
B0  K+ decays and sWeighted B0  K+ decays in data for a) 2011, b) 2012, c)
2015 and d) 2016 data-taking conditions.
6.3 Decay time distributions 133
Decay time [ns]
0 0.005 0.01
Decay time [ns]
0.000 0.005 0.010
Decay time [ns]
0.000 0.005 0.010
Decay time [ns]
0.000 0.005 0.010
Unweighted
Weighted
Fig. 6.4 Decay time distributions for weighted and unweighted B0  K+ simulated
decays for a) 2011, b) 2012, c) 2015 and d) 2016 data-taking conditions.
separate and the same simulation version is used for B0  K+ simulated decays
as available for B0s  + decays.
The distributions of the number of tracks per event for B0  K+ decays
in data and simulated decays are used to weight B0  K+ decays so that the
distribution in simulation matches that in data. The weights are evaluated by taking
the ratio of the normalised histograms in Figure 6.3 for each year. The affect on the
decay time distribution of using these weights and then applying the global BDT cut
is shown in Figure 6.4 for the simulated B0  K+ decays. The difference between
the decay time distributions with and without the weights is not large but clearly
noticeable at low decay times where the change in selection efficiency is greatest.
The same weights are applied to simulated B0s  + decays by binning the
number of tracks per event for B0s  + decays in the same way as used for
B0  K+ decays. The weights are applied to decays that pass the selection but
before the global BDT cut is applied. The reconstructed decay time distributions
for weighted and unweighted B0s  + simulated decays after the global BDT
cut has been applied are shown in Figure 6.5. Similar to B0  K+ decays, the
largest effect is at low decay times where the change in selection efficiency, caused
by the BDT cut, is greatest as seen in Figure 6.1. The re-weighting relies on the
134 Measurement of the B0
 +effective lifetime
Decay time [ns]
0.000 0.005 0.010
Decay time [ns]
0.000 0.005 0.010
Decay time [ns]
0.000 0.005 0.010
Decay time [ns]
0.000 0.005 0.010
Unweighted
Weighted
Fig. 6.5 Decay time distributions for weighted and unweighted B0s  + simulated
decays for a) 2011, b) 2012, c) 2015 and d) 2016 data-taking conditions. Distributions
have been normalised to have unit area.
6.3 Decay time distributions 135
nTracks
0 200 400 600
nTracks
0 200 400 600
nTracks
0 200 400 600
nTracks
0 200 400 600
- + K 0B
- +  s
Fig. 6.6 Normalised histograms of the number of tracks per event in simulated B0  K+
and simulated B0s  + decays for a) 2011, b) 2012, c) 2015 and d) 2016 data.
number of tracks per event being similar for B0  K+ and B0s  + decays.
This cannot be evaluated in data due to the small number of B0s  + decays in
data. However, Figure 6.6 shows a comparison of the number of tracks per event
for simulated B0s  + and B0  K+ decays in each year and resulting
distributions are similar.
Combining B0
 + simulated decays from each year of data-taking
So far, each year of data-taking is treated separately. This is due to the different
B0s lifetimes used in the generation of simulated decays as well as different selection
and trigger efficiencies. The different selection efficiencies for each data-taking year
are shown in Figure 6.7. Therefore to accurately model the B0s  + acceptance
function, simulated decays from each year of data-taking must be used. The number
of simulated decays available for each year does not correspond to the proportions
of decays present in each year of the data. Therefore, additional weights are used
to combine the simulated decays so that the combined set of decays has the same
proportions of decays for each year as the complete data set.
The proportion of events expected in each year of data is taken from the number
of B0s  J/ decays in data for each year corrected for the selection differences for
136 Measurement of the B0
 +effective lifetime
Decay time [ps]
0 5 10
Fig. 6.7 Selection efficiency histograms for each year of data-taking for weighted simulated
B0s  + decays.
B0s  + and B0s  J/ decays. The B0s  J/ yields are extracted from fits
to the mass spectrum of candidates in each year of data-taking. The selection applied
to identify B0s  J/ candidates is very similar to that applied to B0s  +
decays apart from the particle identification and global BDT requirements. This
decay is chosen because the ratio of the efficiencies for the stripping, trigger and
pre-selection requirements of B0s  + and B0s  J/ decays is uniform across
the different years making B0s  J/ decays a good proxy for B0s  +. The
weights applied to simulated B0s  + decays are
i i
, (6.5)
where i represents the year, Y J/ the B0s  J/ yields, N
i the number
of simulated B0s  + decays available for the year passing the full B0s 
+ selection and i the efficiency of the particle identification and global BDT
requirements for B0s  + decays that have passed all other selection requirement
evaluated from simulated decays. The sums, over k and j, are performed over all
years of data-taking. The weights applied to simulated B0s  + decays and
values of the different components of the weights are given in Table 6.2.
6.3 Decay time distributions 137
Year (i) Yi i Ni i Ni  Nii
2011 19190 0.412 70448 1.72 131364
2012 42103 0.406 254822 1.03 262461
2015 8571 0.410 222820 0.24 53917
2016 37765 0.406 124870 1.88 235218
Table 6.2 Weights used to combine simulated B0s  + decays for each year to
determine the acceptance function. Weights ensure the proportion of simulated events for
each year matches what is expected in data.
Parameter Value
a /ps 1 0.574  0.011
n 1.49  0.03
t0 /ps 0.313  0.007
Table 6.3 Parameters for the B0s  + acceptance function determined from weighted
simulated B0s  + decays.
Acceptance parameter fit
The weights applied to B0s  + simulated decays from B0  K+ decays
ensure that the decay time efficiency is described accurately and the simulated decays
have been combined to represent the proportion of decays present from each year of
data. Therefore the acceptance parameters can now be determined. An unbinned
maximum likelihood fit is performed to the reconstructed decay time distribution of
the weighted simulated B0s  + decays to determine the acceptance parameters
in Equation 6.4. In the fit the acceptance parameters are free and the B0s  +
lifetime is constrained to the weighted average of lifetimes used to generate each
year of simulated decays. The fit result is shown in Figure 6.8 and the acceptance
parameters are given in Table 6.3. Figure 6.9 shows the shape of the fitted acceptance
function.
6.3.2 Background decay time PDFs
The selection biases the decay time distributions of the backgrounds in a similar
way as the B0s  + decay time. Therefore, they are described by the same PDF
as in Equation 6.3 and the acceptance function in Equation 6.4 is used to model
the selection efficiency as a function of decay time. However, different acceptance
function parameters are needed to describe the different backgrounds.
138 Measurement of the B0
 +effective lifetime
Decay time [ps]
Fig. 6.8 Maximum likelihood fit to the combined reconstructed decay time distribution of
weighted 2011, 2012, 2015 and 2016 simulated B0s  + decays.
Decay time [ps]
Fig. 6.9 Acceptance function determined from the fit to the combined reconstructed decay
time distribution of weighted 2011, 2012, 2015 and 2016 simulated B0s  + decays.
6.3 Decay time distributions 139
The backgrounds from mis-identified and B0  + decays are assigned the
same acceptance parameters as B0s  + decays because the decay time efficiency
of these backgrounds is approximately the same as the signal. The acceptance
functions of these backgrounds do not need to be as accurately known as the
acceptance function of the signal because very few background decays from these
sources will be present in the dataset after the selection and the final result does
not depend on the acceptance function of the backgrounds. The lifetimes of these
background decays are taken from a fit to simulated decays. For B  h+h the fit
is performed to a combined set of B  h+h decays representing what is expected
in data.
The decay time PDF of the combinatorial background is more challenging to
determine. This background arises from random combinations of muons in the event
and not from one source, therefore there is no single lifetime that describes the
background. Furthermore, the global BDT which is designed to separate B0s  +
decays from combinatorial background decays will have a different efficiency as a
function of decay time for the combinatorial background compared to the B0s  +
decays. The decay time PDF of the combinatorial background cannot be evaluated
from simulated decays or decays in data that pass the B0s  + selection because
there are too few candidates left after the selection has been applied. Therefore, it is
evaluated from the combinatorial background of B  h+h decays using candidates
in data that pass the B  h+h selection and have a dimuon invariant mass greater
than 5447 MeV/c2.
The decay time PDF for combinatorial background decays is modelled by
Pcbg(t) = (t) 
f  et/1 + (1  f)  et/2
(6.6)
where 1 and 2 are two independent lifetimes used to describe the background,
f describes the fraction of candidates with lifetime 1 and the same acceptance
parametrisation as in Equation 6.4 is used for describe the decay time efficiency (t).
The lifetimes in the PDF are different, one describes a long-lived component and the
other a short-lived component that can be seen in the data. The decay time PDF
for the combinatorial background is not used in the fit to measure the B0s  +
effective lifetime but only during studies to determine the best fit strategy. Therefore
the exact parametrisation of this background is not critical to the measurement of
the B0s  + effective lifetime.
Two fits are applied to B  h+h combinatorial background to find the decay
time PDF parameters. The first fit determines f , 1 and 2 and the second is used
to find a and n. The value of t0 is fixed in the fit to improve fit stability. The biases
to the decay time distribution from the selection criteria have the greatest effect at
low decay times, therefore the decay time acceptance is flat at large decay times.
140 Measurement of the B0
 +effective lifetime
Parameter Value
a /ps 1 1.45  0.12
n 1.92  0.17
t0 /ps 0.290
1 /ps 17  16
2 /ps 1.3  0.3
f 0.032  0.027
Table 6.4 Parameters used to describe the background decay time distribution from
combinatorial background decays in data passing the B  h+h
 selection.
Decay time [ps]
Decay time [ps]
0 5 10
Fig. 6.10 Maximum likelihood fit to determine the lifetimes to describe the combinatorial
background (a), with the long live component (green) and the short-lived component (red),
and the fit to determine the acceptance function parameters (b) from the decay time
distribution of combinatorial background decays in data passing the B  h+h
 selection
requirements.
The lifetimes of the combinatorial background decays and the fraction of decays
with each lifetime are determined from a fit using Equation 6.6, setting (t) = 1, to
candidates with a decay time above 2.5 ps. The acceptance function parameters are
then determined from a fit to the full decay time range using Equation 6.6, where
the lifetimes and the fraction of candidates with each lifetime are fixed. The results
are shown in Figure 6.10 and the PDF parameters in Table 6.4.
This model for the background assumes that the decay time distribution of
B  h+h candidates formed by random combinations of kaons and pions is the
same as that of B0s  + candidates formed by randomly combining muons. There
are too few candidates passing the B0s  + selection to verify this assumption,
although the validity of this model and the impact on the measured B0s  +
effective lifetime is investigated in Section 7.6.
6.4 Measurement strategy 141
6.4 Measurement strategy
The strategy to measure the B0s  + effective lifetime is described in Section 6.1.
The extremely rare nature of B0s  + decays means that the stability and
performance of the final fit will be highly dependent on the fit to the invariant
mass distribution used to find the sWeights. Pseudoexperiments are performed to
determine which mass range would produce an accurate fit with the smallest expected
uncertainty on the measured effective lifetime for the dataset. The choice of the
mass range determines which background sources need to be included into the fit.
The expected number of signal and background decays in data passing the
B0s  + selection in the mass range 4900 - 6000 MeV/c2 are used as the basis
for the pseudoexperiments. The expected background yields are calculated using the
same methods described in Section 5.3 but taking into account the looser particle
identification requirement and the cut placed on the global BDT. The number of
B0s  + and B0  + decays are calculated using the normalisation factors
in Section 5.4 and assuming the branching fraction values predicted by the SM. The
expected yields are shown in Table 6.5.
The pseudoexperiments are performed by generating the mass and decay time
distributions for the expected number of signal and background decays in the data for
a particular mass range. The number of decays generated in the pseudoexperiments
are fluctuated using Poisson distributions for each decay type where the mean values
are taken from the expected yields in Table 6.5. The PDFs described in Section 6.2
Decay Expected yields in mass ranges
4900 - 6000 MeV/c2 5320 - 6000 MeV/c2
B0s  + 30.94 30.47
B0  + 3.27 0.20
B  h+h 9.68 0.92
0b  p 13.34 0.64
B0  + 40.50 0.06
B0s  K+ 9.13 0.03
B+  ++ 6.01 0.00
B0  0+ 4.86 0.60
B+c  J/+ 9.79 0.00
Combinatorial background 66.2 40.6
Table 6.5 Number of expected signal and background decays in data passing the B0s 
+ effective lifetime selection in the mass ranges 4900 - 6000 MeV/c2 and 5320 -
6000 MeV/c2.
142 Measurement of the B0
 +effective lifetime
and 6.3 are used and the slope of the combinatorial background mass PDF is taken
from simulated bb  +X decays. The SM prediction for  is used to describe
the lifetime of B0s  + decays. The effective lifetime is then measured using
the strategy described in Section 6.1, where the sWeights are computed from a
fit to the invariant mass distribution and the lifetime is measured by a fit to the
sWeighted decay time distribution. A series of different mass ranges and background
components are tested. For each possible configuration a study containing 10,000
pseudoexperiments are performed and the performance of each configuration is
evaluated using two different metrics. The first is the median expected uncertainty of
the B0s  + lifetime. The median rather than the mean uncertainty is used due
to the asymmetric spread of uncertainties observed for the expected statistics. The
second measure is the pull distributions of any free parameters in the fit, where the
pull is defined as (x )/ with x the measured parameter value,  the value used
in the generation and  the uncertainty on the measured parameter value. Ideally
the pull distributions will be Gaussian in shape with a mean at 0 and a width of 1.
The details of the pseudoexperiments and mass fits tested are given in Section 6.4.2.
However, first is a discussion of whether the lifetime or inverse lifetime should be
measured given the expected number of decays present in the data set.
6.4.1 To fit for  or 1?
During the development of the fit strategy, the pseudoexperiments produced biased
pull distributions for the measured B0s  + effective lifetime no matter what
mass fit configuration or acceptance function was used. The pull distribution for the
effective lifetime, , is shown in Figure 6.11 for a simplified configuration where no
acceptance function is used and only signal and combinatorial background decays are
generated in the mass range 4900 - 6000 MeV/c2. The distribution is not Gaussian in
shape, and the bias was more pronounced in early stages of the analysis development
which was performed assuming the expected signal and background yields of only
the Run 1 data set.
The log-likelihood profile of the fit as a function of  reveals the cause of the
biased pull distribution. For the simplified studies illustrated in Figure 6.11, the
decay time is modelled by
N(t, ) = N0et/ . (6.7)
The likelihood profile as a function of decay time for this model is shown in Figure 6.11
and there is a clear discontinuity at the zero. The discontinuity arises because the
value of N(t, ) approaches zero as  reduces in value until at the origin where  = 0
and N(t, ) is undefined.
6.4 Measurement strategy 143
)Pull(
10 5 0 5 10
800  = -0.223 +/- 0.010
 =  1.100 +/- 0.008
 [ps]
0 2 4
Fig. 6.11 Pull distribution (a) for  using a simplified configuration where no acceptance
function is used and only signal and combinatorial background decays are generated in the
mass range 4900 - 6000 MeV/c2 with the expected statistics for 4.4 fb1 of data used to
measured the effective lifetime and the likelihood profile for  (b). A fit is performed to
the pull distribution using a Gaussian function, the results are shown by the blue curve
and the mean () and width () of the Gaussian function are shown.
)Pull(
10 5 0 5 10
800  = -0.057 +/- 0.010
 =  1.023 +/- 0.007
)Pull(
10 5 0 5 10
800  = -0.012 +/- 0.010
 =  0.996 +/- 0.007
Fig. 6.12 Pull distribution for  using simplified mass and decay time model for 50 fb1
(a) and 300 fb1 (b) where no acceptance function is used and only signal and combinatorial
background decays are generated in the mass range 4900 - 6000 MeV/c2. A fit is performed
to each pull distribution using a Gaussian function, the results are shown by the blue
curves and the means () and widths () of the Gaussian functions are shown.
144 Measurement of the B0
 +effective lifetime
   1 Gaussian
1 68.50  0.08% 67.92  0.08% 68.27%
2 93.44  0.10% 95.91  0.10% 95.45%
3 98.06  0.10% 99.55  0.10% 99.73%
Table 6.6 Coverage of the statistical uncertainties evaluated as the number of pseudoex-
periments for the expected number of decays with measured  () values that are with
1, 2 and 3 times  () of the generated lifetime value.
For the low number of B0s  + decays expected in data the fitted value for
 is only a few standard deviations away from this discontinuity, thereby biasing the
estimation of the statistical uncertainty and changing the pull distribution from the
expected Gaussian shape. However, as the number of expected signal and background
decays increases, the  pull distributions become Gaussian in shape as shown in
Figure 6.12. This is as expected because when the statistical uncertainty decreases,
the discontinuity of Figure 6.11 is no longer within a few standard deviations of the
measured .
The bias in the  pull distribution shows that the distribution cannot be
interpreted in the usual way and also that the statistical uncertainties from the
maximum likelihood to the weighted decay time distribution may not be correct.
Another way to assess the accuracy of the statistical uncertainties returned
by the fit is the coverage of the uncertainties; the percentage of fitted  values
from the pseudoexperiments that fall within 1, 2 and 3 standard deviations of the
lifetime used to generate the pseudoexperiments. Table 6.6 shows the coverage
of the statistical uncertainties for  from a set of 10,000 pseudoexperiments for
the expected B0s  + and combinatorial background yields with the data
set alongside the intervals expected for a Gaussian distribution. The simple toy
configuration used to produce the log-likelihood function is used. A comparison
between the coverage of  and the Gaussian intervals shows that the coverage
of the statistical uncertainties is very close to the expected values. Therefore the
uncertainty on  is still reasonably estimated from the fit despite the poor pull
distribution.
Alternatively, a biased pull distribution can be avoided by fitting for the inverse
of the effective lifetime, 1  . The pull distributions for  are shown in
Figure 6.13 and produce unbiased pull values regardless of the amount of data. This
is unsurprising given the smooth log-likelihood profile as a function of  also shown
in Figure 6.13. Furthermore, the statistical coverage of  is closer to the expected
Gaussian coverage than the coverage of .
6.4 Measurement strategy 145
)Pull(
10 5 0 5 10
800  =  0.006 +/- 0.010
 =  0.993 +/- 0.007
)Pull(
10 5 0 5 10
800  = 0.004 +/- 0.010
 =  1.017 +/- 0.007
)Pull(
10 5 0 5 10
800  = -0.009 +/- 0.010
 =  0.996 +/- 0.007
]-1 [ps
5 0 5
410 d)
Fig. 6.13 Pull distribution for  using simplified pseudoexperiments for the Run 1 and
Run 2 data set of 4.4 fb1 (a) as well as 50 (b) and 300 (c) fb1 and the likelihood profile
as a function of  (d). The pull distributions are fitted with a Gaussian function in blue.
Ideally, the fit strategy would be performed to extract the lifetime not the inverse
lifetime. However, for the moment the fit for both  and  is used in the
pseudoexperiments. The statistical coverage for both parameters is good and using
either will give a reasonable estimate of the statistical uncertainty on the measured
value. The final decision is made based on the statistical coverage for the observed
number of decays in the data set.
6.4.2 Optimisation of fit configuration
The mass distribution of the expected number of B0s  + candidates passing the
effective lifetime selection is shown in Figure 6.14 alongside the corresponding decay
time distribution for one pseudoexperiment for the combined Run 1 and Run 2 data
set. The contributions from the different signal and background sources are shown
and the backgrounds beneath the B0s mass peak are the combinatorial background
and the tails of the B  h+h, B0  + and 0b  p backgrounds. The
expected mass distribution is used to determine a range of mass fit configurations to be
tested using toy studies to find the configuration that produces the smallest expected
uncertainty on the measurement of  and  provided the pull distributions of
free parameters in the fit are accurate.
146 Measurement of the B0
 +effective lifetime
]2 [ MeV/cm
5000 5500 6000
30 a)
Decay time [ps]
0 5 10 15
Total
 +  s
 +  0B
 h+ hB 
+  0B
 K s
 ++  +B
 +0  0B
 p b
+  J/ c
Combinatorial background
Fig. 6.14 Distributions of a) mass and b) decay time for the generated decays in the mass
range 4900 - 6000 for one pseudoexperiment based on the expected number of signal and
background decays in the data set.
6.4 Measurement strategy 147
Thirteen mass configurations are studied. In each mass fit configuration the mass
PDF in Equation 6.2 is used and the mass ranges and backgrounds included in the
PDF for the different configurations are given in Table 6.7.
For each possible mass fit configuration the B0s  +, B0  + and
combinatorial background yields are left free in the fit whereas the yields of any
other backgrounds are constrained to their expected values. The mass shapes of
all components are fixed in the maximum likelihood fit except the slope of the
combinatorial background because this is not accurately known in data. The SM
predicts that  is equal to the lifetime of the heavy B0s mass eigenstate, H . The
average value calculated by the Particle Data Group of  = 1.661 ps, is used to
generated events for the pseudoexperiments [5]. Also, regardless of which background
components are included in the mass fit all backgrounds are generated for each mass
range.
A total of 10,000 pseudoexperiments are performed for each mass configuration
and the results are given in Table 6.8; the events are generated in the same mass
range which is used in the fits. The mean and widths of the pull distributions of
, the B0s  + yield, the combinatorial background yield and the slope of
the background mass PDF as well as the median expected uncertainties on  and
 are used to measure the performance of each mass fit configuration. The pull
distribution of the fit for  is not used to assess the performance of each mass fit
configuration given the discussion in Section 6.4.1.
The expected statistical uncertainties for  and  are smallest for fit configu-
ration 11, where the mass range is restricted to 5320 - 6000 MeV/c2 and only the
B0s  + and combinatorial background components are included in the mass fit
PDF. The mean and widths for the different pull distributions are consistent with
the expected mean of 0 and width of 1 for this fit configuration. The larger mass
ranges with more background components included in the mass PDF have larger
uncertainties for  and  as well as biased pull distributions.
Therefore, the fit configuration 11 is chosen to measure the B0s  + effective
lifetime. Figure 6.15 gives an example of the mass and decay time fits for the chosen
configuration. Figure 6.14 and Table 6.5 show that the number of background decays
from B0  +, B  h+h and 0b  p is extremely low above 5320 MeV/c2,
therefore these backgrounds do not need to be modelled in the mass PDF. The effect
on the final result of not modelling these backgrounds is estimated in Section 7.2.
The expected uncertainties for the chosen fit configuration for  and  are
 () = 0.28 ps and  () = 0.11 ps 1, respectively. However, due to the low
expected number of decays there is a large spread in the expected uncertainties as
shown in Figure 6.16. Therefore, the uncertainties on the measurements would range
between 0.1 - 0.8 ps for  and 0.07 - 0.2 ps 1 for .
148 Measurement of the B0
 +effective lifetime
Fit no. Mass Range Components included in the mass PDF Yields Yields
/MeV/c2 free fixed
1. 4900 - 6000
B0s  +, B0  +, comb. bkg. 
B  h+h, 0b  p, B+c  J/+,
B0  +, B0s  K+,
B+  ++, B0  0+
2. 4900 - 6000
B0s  +, B0  +, comb. bkg. 
B  h+h, 0b  p, B+c  J/+, 
B0(s)  
(K)+, B0(+)  0(+)+
3. 5150 - 6000
B0s  +, B0  +, comb. bkg. 
B  h+h, 0b  p, B+c  J/+,
B0  +, B0s  K+,
B+  ++, B0  0+,
4. 5150 - 6000
B0s  +, B0  +, comb. bkg. 
B  h+h, 0b  p, B+c  J/+ 
B0(s)  
(K)+, B0(+)  0(+)+
5. 5200 - 6000
B0s  +, B0  +, comb. bkg. 
B  h+h, 0b  p, B+c  J/+ 
6. 5200 - 6000
B0s  +, B0  +, comb. bkg. 
B  h+h, 0b  p 
7. 5200 - 6000 B0s  +, B0  +, comb. bkg. 
8. 5200 - 6000 B0s  +, comb. bkg. 
9. 5250 - 6000 B0s  +, comb. bkg. 
10. 5300 - 6000 B0s  +, comb. bkg. 
11. 5320 - 6000 B0s  +, comb. bkg. 
12. 5340 - 6000 B0s  +, comb. bkg. 
13. 5350 - 6000 B0s  +, comb. bkg. 
Table 6.7 Mass ranges and components included in the different mass fit configurations
tested using pseudoexperiments. The final two columns indicate which components in the
mass fits have fixed yields at the expected value and which are left free in the fit. In fit
configurations 2 and 4 a single mass PDF is used to describe both B0  + and
B0s  K+ and a single PDF is used to describe B+  ++ and B0  0+
decays, all other configurations have one mass PDF per component. The shapes for all
mass PDFs are fixed in the mass fit except the slope of the combinatorial background mass
6.4 Measurement strategy 149
150 Measurement of the B0
 +effective lifetime
]2c [MeV/-+m
5400 5600 5800 6000
Total
- +  s
Combinatorial background
Decay time [ps]
0 5 10 15
12 b)
Fig. 6.15 Example of a) the mass and b) the decay time maximum likelihood fits for one
pseudoexperiment using the chosen fit configuration where only components for B0s  +
and combinatorial background are modelled in the mass PDF.
) (ps)
0 0.5 1 1.5
800 mean = 0.31 ps
median = 0.29 ps
standard deviation = 0.11 ps
)-1) (ps
0 0.1 0.2 0.3 0.4 0.5
-1mean = 0.11 ps
-1median = 0.11 ps
-1standard deviation = 0.04 ps
Fig. 6.16 Expected statistical uncertainties for a)  and b)  using fit configuration 11
in Table 6.7.
6.5 Results 151
6.5 Results
The results of the unbinned maximum likelihood fit to the dimuon mass distribution
and the sWeighted decay time of B0s  + candidates for Run 1 and Run 2 data
are shown in Figure 6.17. The number of observed decays is 22  6 B0s  +
decays and 20  6 combinatorial background decays. The measured values of 
and  are
 = 2.04  0.44 ps (6.8)
 = 0.49  0.12 ps1 (6.9)
where the uncertainties are statistical only. The results are consistent with the SM
prediction given in Chapter 2 and the measured value is 1 from A = +1 and
1.4 from A = 1.
The observed number of signal and background decays are lower than the expected
yields given in Table 6.5 for the data. Therefore, it is important to check whether
the statistical coverage for  uncertainties is still good. The pseudoexperiments
in Section 6.4.1 are repeated, this time using the observed number of B0s  +
and combinatorial background decays and the results are shown in Table 6.9. The
statistical coverage of the  uncertainty is good and therefore  and its statistical
uncertainty can be trusted as accurate and the measurement can be quoted in terms
of .
  Gaussian
1 68.83  0.08% 67.76  0.08% 68.27%
2 93.11  0.10% 95.55  0.10% 95.45%
3 97.92  0.10% 99.67  0.10% 99.73 %
Table 6.9 Coverage of the statistical uncertainties evaluated as the number of pseudoex-
periments using the observed number of decays with measured  () values that are
with 1, 2 and 3 times  () of the generated lifetime value.
152 Measurement of the B0
 +effective lifetime
]2c [MeV/+m
5400 5600 5800 6000
18 Total
 +  s
Combinatorial background
Decay time [ps]
0 5 10
Fig. 6.17 Maximum likelihood fit to a) the invariant mass distribution and b) sWeighted
decay time distribution of B0s  + candidates using an integrated luminosity of 4.4 fb1
of data collected by the LHCb experiment.
Chapter 7
Systematic uncertainties and cross
checks on the effective lifetime
The measured B0s  + effective lifetime presented in Chapter 6 is influenced by
various systematic biases arising from different areas of the analysis procedure. In this
chapter the sizes of the different systematic uncertainties are estimated and several
cross checks are made on the measurement strategy to ensure the uncertainty quoted
on the final result is correct. The total systematic uncertainty on the measurement
of  is given at the end of the chapter.
As discussed in Section 6.4.1, pseudoexperiments showed that the pull distribu-
tions used for fitting for  are biased. Therefore the pull distributions of  are
used, when needed, as a measure of the fit performance instead.
7.1 Accuracy of the fit
The final configuration used to measure the effective lifetime was chosen using
pseudoexperiments for the expected number of decays and by optimising two different
figures of merit: the mean and width of the pull distributions of free parameters in the
fit; and the expected uncertainties on . To test the fit accuracy, the values for the
figures of merit for a set of 10,000 pseudoexperiments using the final fit configuration
and assuming the SM B0(s)  
+ branching fractions are given in Table 7.1. The
same set up as described in Section 6.4 is used but in these pseudoexperiments
only B0s  + and combinatorial background decays are generated, all other
backgrounds are ignored. Based on these results several aspects of the fit deserve
further investigation. This includes the stability of the fit with different  values,
the slightly biased pull distribution for B0s  + yields and the overall bias in the
measured value of .
154 Systematic uncertainties and cross checks on the effective lifetime
 N (B0s  +) N (Comb.) Comb. slope 
Mean Width Mean Width Mean Width Mean Width
H -0.097 1.020 -0.062 1.030 -0.013 0.992 -0.000 0.993
L -0.098 1.019 -0.062 1.018 -0.003 0.987 -0.010 1.018
B0s -0.102 1.017 -0.059 1.032 -0.027 0.996 0.001 0.989
Table 7.1 Results from 10,000 pseudoexperiments using the final fit configuration for
the expected number of decays and using as the B0s  + effective lifetime; the SM
prediction (H); the lifetime of the light B0s mass eigenstate (L); and the mean lifetime
of the B0s (B0s ). The mean and width of the pull distributions for the B
s  + and
combinatorial background yields, the slope of the combinatorial background mass PDF
and the measured values of  are shown. The uncertainties on the means are 0.010 and
widths are 0.007 for all configurations.
7.1.1 Fit stability with  values
The pull distribution for  and the coverage of the statistical uncertainties given in
Section 6.4 show that the fit gives a good estimation of  for the expected number of
decays. However, it is necessary to understand if this is due to accurate background
subtraction by the sPlot method or if it could be resulting from similarities between
the decay time distributions of B0s  + and combinatorial background decays.
As a test, pseudoexperiments are performed for a range of generated B0s  +
lifetimes different from the SM prediction. Only B0s  + and combinatorial
background decays are generated so that the small contamination from mis-identified
backgrounds does not mask the effects of using different lifetimes. The bias arising
from the small contribution of mis-identified backgrounds in the mass range of the
fit is evaluated in Section 7.2.
The results of 10,000 pseudoexperiments are shown in Table 7.1 and the different
lifetimes return accurate pull distributions for the fitted  values with means and
widths consistent with 0 and 1, respectively. Therefore, the fit returns an accurate
measured value for the B0s  + lifetime independent of the lifetime chosen for
the B0s .
7.1.2 B0s  
+ yield estimation
The pull distributions for B0s  + yields in Table 7.1 have slightly biased mean
values of  0.010. implying that the mass fit does not accurately estimate the
B0s  + yield. However, the pull distribution for  is accurate therefore this
bias in the B0s  + yield could originate from a different source.
7.1 Accuracy of the fit 155
 ) / Ngen - Nmeas(N
0.5 0 0.5
mean =
-0.0089 +/- 0.0012
Fig. 7.1 Fractional bias of the measured B0s  + yield from pseudoexperiments for the
expected number of decays with 4.4 fb1. Only B0s  + and combinatorial background
decays are included in the pseudoexperiments.
In the pseudoexperiments the number of expected decays in the mass range 4900
- 6000 MeV/c2 are given in Table 6.5. These numbers are used as the basis for the
pseudoexperiments. However, the number of decays generated is fluctuated for each
study about the expected value using a Poisson distribution. Therefore the number
of decays generated, Ngen, is different from the expected number. This enables
an extended maximum likelihood fit to be used to fit the mass distribution where
the total number of events is a free parameter. To achieve a Gaussian shaped pull
distribution for the measured B0s  + yields, the uncertainties on the measured
yields must be distributed according to a Gaussian function. This will be true
when there are a large number of B0s  + decays, in the high statistics limit,
where a Poisson distribution is a good approximation of a Gaussian distribution.
However, this is not the case for the current dataset where there are a small number
of B0s  + decays. Therefore, the uncertainties on the B0s  + yields will
not distributed according to a Gaussian function which leads the observed shift in
the pull distribution.
To test that the shift in the pull distribution arises from the distribution of
uncertainties on the yields rather the estimation of the yields themselves the fractional
bias of the yields is evaluated. The fractional bias is defined as (Nmeas Ngen)/Ngen,
where Nmeas is the measured yield and Ngen the number of generated decays, and the
results are shown in Figure 7.1. The mean of this distribution has a negligible bias of
0.8%, therefore showing that the fit returns accurate estimates for the B0s  +
yield.
Furthermore, the pull distributions for B0s  + yields for pseudoexperiments
with higher statistics produce means that tend towards zero as the number of decays
increases as shown in Figure 7.2. Therefore the mass fit returns accurate yields for
156 Systematic uncertainties and cross checks on the effective lifetime
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
])-+0
Pull(N[B
10 5 0 5 10
700  =  0.001 +/- 0.010
 =  0.998 +/- 0.007
Fig. 7.2 Pull distribution for B0s  + measured yields from 10,000 pseudoexperiments
for the expected number of decays in a) 50 fb1 and b) 300 fb1. Only B0s  + and
combinatorial background decays are included in the pseudoexperiments. A fit is performed
to each pull distribution using a Gaussian function, the results are shown by the blue
curves and the mean () and width () of the Gaussian functions are shown.
B0s  + and the biased pull distribution arises from the low statistics of the
data set. The same reasoning can be applied to the pull distribution of the yields
of combinatorial background decays that have a slightly less biased mean value of
 0.06 compared with the B0s  + yields.
7.1.3 Overall bias on 
The remaining area of the fit to investigate is any underlying bias from the fit on the
measured value of .
The overall bias in the fit for measuring  is evaluated from the difference
between the measured and generated values of  from pseudoexperiments. A
total of 10,000 pseudoexperiments are performed generating only B0s  + and
combinatorial background decays. Only the combinatorial background is included in
these pseudoexperiments so that the bias from the fit is not masked by the presence
of the other backgrounds that are not modelled in the fit. The difference between
the measured and generated  values is evaluated for pseudoexperiments generated
with the expected and also the observed number of B0s  + and combinatorial
background decays. The fit bias is evaluated for the observed number of decays
as well as the expected number of decays; because there are fewer than expected,
therefore the bias may be larger. The resulting distributions are shown in Figure 7.3.
The mean of the difference in  values is 0.02 ps for the expected number of decays
and 0.03 ps for the observed number of decays. Therefore the larger uncertainty of
0.03 ps is used as the measure of the systematic uncertainty caused by the fit on the
final result for .
7.2 Background contamination 157
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
generated - measured
1 0 1 2 3
mean = 0.021 +/- 0.003
generated - measured
0 2 4
mean = 0.033 +/- 0.004
generated - measured
0 2 4
mean = 0.033 +/- 0.004
[ps]( )generated - measured
1 0 1 2 3
mean = 0.021 +/- 0.003 ps
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
generated - measured
0 2 4
mean = 0.033 +/- 0.004
generated - measured
0 2 4
mean = 0.033 +/- 0.004
generated - measured
0 2 4
mean = 0.033 +/- 0.004
[ps]( )
Fig. 7.3 Overall bias in , evaluated as the difference between the measured, measured,
and the generated, generated, lifetimes for pseudoexperiments using a) the expected and b)
the observed B0s  + and combinatorial background decays.
7.2 Background contamination
The mass fit configuration used to measure the B0s  + effective lifetime
includes components for B0s  + and combinatorial background decays to fit
candidates with a B0s mass between 5320 - 6000 MeV/c2. Although the majority
of background decays from mis-identified and B0  + decays fall outside this
mass window, as shown in Figure 6.14, the tails of some backgrounds are still within
this region. The backgrounds of particular importance for the chosen mass range
include B0  +, B  h+h, 0b  p, B0  +, B0s  K+,
B+  ++, B0  0+ and B+c  J/+.
The number of expected background decays and their mass PDFs in the range
4900 - 6000 MeV/c2 are computed using the methods described in Chapter 5 and
the number of decays expected in the smaller mass range 5320 - 6000 MeV/c2 are
determined by integrating the mass PDFs over this mass range. The expected yields
for each background are given in Table 6.5 and are less than 1 candidate, except the
combinatorial background, in the range 5320 - 6000 MeV/c2.
The impact of backgrounds not modelled in the mass fit on the measured 
value is evaluated using two sets of pseudoexperiments. The pseudoexperiments have
the same general set up as described in Section 6.4. One set of pseudoexperiments
assumes there are no backgrounds other than the combinatorial background and
therefore only B0s  + and combinatorial background candidates are generated.
The second set of pseudoexperiments uses a more realistic model and generates all
possible background decays. The same fit is used in both sets of pseudoexperiments to
measure the B0s  + effective lifetime; in the fit only components for B0s  +
decays and combinatorial background are included. The expected yields are fluctuated
using a Poisson distribution around their expected values to two decimal places. For
158 Systematic uncertainties and cross checks on the effective lifetime
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
)Pull(
10 5 0 5 10
800  =  0.000 +/- 0.010
 =  0.993 +/- 0.007
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
)Pull(
10 5 0 5 10
 =  0.024 +/- 0.010
 =  0.982 +/- 0.007
Fig. 7.4 Pull distribution for  from 10,000 pseudoexperiments, using background sources
of a) combinatorial background only and b) combinatorial background, mis-identified decays
and B0  + decays. A fit is performed to each pull distribution using a Gaussian
function, the results are shown by the blue curves and the mean () and width () of the
Gaussian functions are shown.
each configuration 10,000 pseudoexperiments are performed and the pull distributions
for  of each set up are compared.
The inclusion of all the background decays causes a shift in the mean of the
 pull distribution of 0.024 ps1 as shown in Figure 7.4. Therefore, assuming the
expected uncertainty in Section 6.4.2 for , the systematic shift from not including
all backgrounds in the fit configuration is 0.007 ps.
The expected number of B0s  + and B0  + decays assumes the SM
branching fractions. However, the measured values for the branching fractions are
slightly different from the SM predictions. Using the measured values from the
combined analysis of the Run 1 CMS and LHCb data [47], the expected number of
B0s  + and B0  + decays decreases and increases, respectively, compared
to the SM expectations. The changes in the yields are given in Table 7.2. The
pseudoexperiments were repeated with the measured branching fractions but the
shift in the mean of the pull distribution was smaller. Therefore the larger value
from the SM predictions is used as the systematic uncertainty for the background
contamination.
7.3 Mass PDF parameters
The data collected in Run 1 and Run 2 are combined for the measurement of the
B0s  + effective lifetime and the mass and decay time fits are applied to the
combined data. However, the parameters used in the mass PDF in Table 5.1 were
evaluated specifically for Run 1 data and different parameters are available for Run 2
data. Therefore, the influence of the choice of mass PDF parameters on the measured
 value must be evaluated.
7.3 Mass PDF parameters 159
Decay Expected yield in 5320 - 6000 MeV/c2
SM World average
B0s  + 30.47 22.50
B0  + 0.20 0.73
Table 7.2 Number of expected decays in data passing the B0s  + effective lifetime
selection in the mass range 5320 - 6000 MeV/c2 using the SM predictions and branching
fraction measurements from the combined analysis of the Run 1 CMS and LHCb data [47].
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
)Pull(
10 5 0 5 10
800  =  0.000 +/- 0.010
 =  0.993 +/- 0.007
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
)Pull(
10 5 0 5 10
 = -0.004 +/- 0.010
 =  0.992 +/- 0.007
Fig. 7.5 Pull distribution for  from 10,000 pseudoexperiments where the B0s  +
mass distribution is generated using the Run 1 parameters and the mass fit is performed
using a) Run 1 parameters and b) Run 2 parameters. A fit is performed to each pull
distribution using a Gaussian function, the results are shown by the blue curves and the
mean () and width () of the Gaussian functions are shown.
Once again pseudoexperiments are performed to understand the size of the impact
of the mass model choice on the effective lifetime measurement. Only B0s  +
and combinatorial background decays are generated to separate mass PDF effects
from the contamination of mis-identified backgrounds and B0  + decays.
B0s  + candidates are generated using the Run 1 parameters in Table 5.1
but the mass fit is performed using the Run 2 parameters in Table 5.2. The pull
distribution for 10,000 pseudoexperiments for  from this configuration is compared
with those from pseudoexperiments where Run 1 parameters are used to generate and
fit the mass distribution. The change in the measured lifetime with the mass PDF
parameters is negligible as shown in Figure 7.5. Therefore, no systematic uncertainty
is assigned.
160 Systematic uncertainties and cross checks on the effective lifetime
7.4 Acceptance function accuracy
The B0s  + decay time acceptance function is determined from weighted
simulated decays, as described in Section 6.3.1. It relies on the assumption that
weighted simulated decays model the data reasonably well and weights taken from
the number of tracks in B0  K+ decays can be used for B0s  + decays.
To test this assumption, as well as the strategy used to measure the B0s  +
effective lifetime, the lifetimes of the more abundant B0  K+ and B0s  K+K
decays are measured using the same approach as the B0s  + lifetime. The
measurement of the B0  K+ lifetime is used to define a systematic uncertainty
associated with the accuracy of the acceptance function and B0s  K+K decays
are used as a cross-check to ensure the weights computed from B0  K+ decays
can be used to measure the lifetime of other decays as well.
The selection requirements used to identify B0  K+ decays in 2011, 2012,
2015 and 2016 data are detailed in Chapter 4 and are kept very similar to the
B0s  + selection. Although considerably reducing the statistics, all candidates
are required to be triggered as TIS, in order to keep the B  h+h trigger efficiency
similar to that of B0s  + decays. The DLLK variable is used to separate
B0  K+ decays from other B  h+h decays and candidates are reconstructed
with the daughter with the highest DLLK value assigned the kaon mass hypothesis
and the daughter particle with the lowest DLLK value the pion mass hypothesis.
The measurement of the lifetime is performed in the same way as the B0s  +
effective lifetime measurement and all years of data are combined into one data set.
An extended unbinned maximum likelihood fit is performed to the B0  K+
mass distribution. Components for B0  K+, B0s  K+ and combinatorial
background decays are included in the mass fit. Both B-meson decays are modelled
by Crystal Ball functions and combinatorial background decays are modelled by an
exponential function. The mass fit, shown in Figure 7.6, is used to calculate sWeights
that are re-normalised using Equation 6.1. The lifetime, K, is measured from the
sWeighted decay time distribution.
The decay time PDF has the same form as the one used for the B0s  +
decays in Equation 6.3. The acceptance parameters are found from a fit to weighted
B0  K+ simulated decays using the same method described in Section 6.3.1 with
the number of tracks in the event weighted using the same weights as B0s  +
decays. However, the weights applied to combine simulated B0  K+ decays
from each year are not dependent on B0s  J/ decays. Since B0  K+ decays
have a high yield in data, mass fits to each year are used to find the yields and
combine the simulated decays from each year. The same mass PDF used to fit the
combined mass distribution is applied to each year. The weights used to combine
7.4 Acceptance function accuracy 161
]2 [MeV/c-+Km
5200 5300 5400 5500
Total
 + K s
 + K 0B
Combinatorial background
Fig. 7.6 Maximum likelihood fit to the mass distribution of B0  K+ decays for data
taken in 2011, 2012, 2015 and 2016.
Decay time [ns]
0.005 0.01
10000
12000
Fig. 7.7 Decay time distribution in weighted 2011, 2012, 2015 and 2016 simulated decays
and the maximum likelihood fit results to determine the acceptance function parameters.
simulated decays in different years are
Y datai
Y dataj
, (7.1)
where Y datai are the B0  K+ yields in each year of data and NKi the number of
simulated decays available for each year. The acceptance function fit is shown in
Figure 7.7 and for consistency the same simulation versions are used for B0  K+
decays as B0s  + decays.
The results from the decay time fit are shown in Figure 7.8 and the measured
B0  K+ lifetime is
K = 1.52  0.03 ps, (7.2)
162 Systematic uncertainties and cross checks on the effective lifetime
Decay time [ns]
0.005 0.010
Fig. 7.8 Maximum likelihood fit to the signal weighted decay time distribution of B0 
K+ decays for data taken in 2011, 2012, 2015 and 2016.
where only the statistical uncertainty is given. The measured results are consistent
with the expected value of 1.520  0.004 ps [5] and the measurement strategy
used to find the B0s  + effective lifetime has been shown to work. The
statistical uncertainty of the measured B0  K+ decay time is assigned as a
systematic uncertainty to provide a measure of how well the acceptance function can
be determined from weighted simulated decays for measuring .
The B0s  K+K lifetime is measured using 2012 and 2015 data with B0s 
K+K candidates identified using the selection requirements in Chapter 4. The
same measurement strategy is used to measure the B0s  K+K lifetime as used
for the B0s  + effective lifetime. Only 2012 and 2015 data are used due to the
available simulation versions of simulated B0s  K+K decays. Once again TIS
triggers are used to minimise the bias on the decay time distribution from the trigger
efficiency and candidates are reconstructed assuming both daughters are kaons. The
mass PDF includes B0s  K+K and combinatorial background decays and the
same PDF is used for B0s  K+K as for B0s  K+. The unbinned extended
maximum likelihood fit used to extract the sWeights is shown in Figure 7.9.
The B0s  K+K acceptance is found using the same method as B0s  +
with B0s  J/ decays used to determine the relative proportions of decays in each
year of data. Figure 7.10 shows the acceptance fit and the results of the decay time
fit is shown in Figure 7.11. The measured values for the lifetime, KK , is
KK = 1.39  0.06 ps, (7.3)
where only the statistical uncertainty is given. The measured value is consistent with
the predicted value of 1.416  0.008 given in Table 2.1 and shows that B0  K+
weights can be used for other decays as well as B0  K+.
7.4 Acceptance function accuracy 163
)2 (MeV/c-+Km
5200 5300 5400 5500
Total
 K+ K s
Combinatorial background
Fig. 7.9 Maximum likelihood fit to the mass distribution of B0s  K+K decays for data
taken in 2012 and 2015.
Decay time [ns]
0.005 0.01
Fig. 7.10 Decay time distribution in weighted 2012 and 2015 simulated decays and the fit
results to determine the acceptance function parameters.
Decay time [ns]
0.005 0.010
Fig. 7.11 Maximum likelihood fit to the signal weighted decay time distribution of
B0s  K+K decays for 2012 and 2015 data.
164 Systematic uncertainties and cross checks on the effective lifetime
7.5 Incorrectly assigned primary vertices and the
detector resolution
Measuring the B0s  + effective lifetime accurately relies on the B0s candidate
being assigned to the correct primary vertex in the event; an incorrect assignment
would lead to the wrong value for the B0s decay time. In references [173, 174] that
study the lifetimes of B  J/X decays at LHCb, a component is included into the
decay time PDF to model the number of incorrectly assigned primary vertices (PVs)
as well as the resolution of the detector. The decay time PDF is convoluted by the
sum of three Gaussian functions; two narrow Gaussian functions model the detector
resolution and a third wider Gaussian function corresponds to < 1% of decays
assigned incorrect PVs. The decay time fit to measure the B0s  + effective
lifetime does not explicitly model incorrectly assigned PVs or the detector resolution,
although these effects will, to some degree, be included into the acceptance function.
A similar model to references [173, 174] is used to check the effect on the measured
lifetime of decays with incorrectly assigned PVs and detector resolution effects that
are not included in the acceptance function. A set of 1 million decays are generated
using the decay time model
(t)[R(t)  et/ ], (7.4)
where (t) is the acceptance function with parameters given in Table 6.3 and R(t)
is the resolution function composed of 3 Gaussian functions. Decays are generated
assuming the SM prediction of the B0s  + effective lifetime of  = 1.610 ps.
A fit is then performed to the generated decay time distribution but the resolution
term is no longer included in the PDF. The measured  value is compared to the
value used to generate the decays.
The resolution function is determined from weighted simulated B0s  +
decays that were used to compute the acceptance function in Section 6.3.1. The
difference between the reconstructed decay time and the true decay time that each
decay is generated with is evaluated for decays that passes the full selection. The
resulting distribution is fitted with the resolution function. Each Gaussian function
has the same mean value, which is left free in the fit. The widths of the Gaussian
functions are different and these are also free in the fit. The fit parameters are shown
in Table 7.3 and the results in Figure 7.12. The resulting distribution has a similar
form to those used in references [173, 174].
The result from the fit to the generated decays without the resolution function
included is  = 1.6098 0.0014 ps, which is consistent with the lifetime of generated
events. The difference between the lifetime used to generate events and the fitted
value is 0.0002 ps, a factor of 10 smaller than the smallest systematic uncertainty.
This cross check shows that the presence of incorrectly assigned PVs or detector
7.5 Incorrectly assigned primary vertices and the detector resolution 165
Parameter Fit value
 (ps) 0.00063  0.00005
1(ps) 5.620.07
f1 0.006
2(ps) 0.0573 0.0003
f2 0.313
3(ps) 0.0294  0.0001
f3 0.681
Table 7.3 Parameters from the fit to the difference between the reconstructed decay time
and the true decay time for simulated decays that pass the B0s  + effective lifetime
selection. The mean used for all Gaussian is  and i are the widths of each Gaussian that
make up a fraction fi of the total sum.
 [ps]true - reconstructed
0.2 0.1 0 0.1 0.2
10000
20000
30000
40000
50000
60000
70000
Fig. 7.12 Fit result to the difference between the reconstructed decay time and the true
decay time for simulated decays that pass the B0s  + effective lifetime selection.
resolution effects that are not included in the acceptance function have a negligible
effect on the B0s  + effective lifetime.
However, this check assumes that simulated decays provide a good estimate of the
number of incorrectly assigned PVs. Figure 7.13 shows the number of B0  K+
decays passing the selection for simulated B0  K+ decays and sWeighted decays
data for each year. On average there are more PVs per event in simulated decays
compared to data, therefore using simulation would give an overestimation of the
number of incorrectly assigned PVs expected in data supporting the conclusion that
incorrectly assigned PVs has a negligible effect on the measured B0s  + effective
lifetime.
166 Systematic uncertainties and cross checks on the effective lifetime
Primary vertices
0 2 4 6 8 10
Primary vertices
0 2 4 6 8 10
Primary vertices
0 2 4 6 8 10
0.5 c)
Primary vertices
0 2 4 6 8 10
Simulation
Fig. 7.13 Distributions for the number of primary vertices in an event B0  K+ data
and simulated decays for a) 2011, b) 2012, c) 2015 and d) 2016.
7.6 Combinatorial background decay time model 167
7.6 Combinatorial background decay time model
The decay time distribution of combinatorial background decays is largely unknown
due to the nature of the background. The model used for this distribution in the
pseudoexperiments is described in Section 6.3.2. The decay time distribution of
combinatorial background decays consists of mostly a short-lived component with a
lifetime of 1.3 ps and a long-lived component with a lifetime of 17 ps.
The sWeighting method is sensitive to backgrounds that are significantly longer
lived than the signal and this can lead to a biased estimate of . During the
selection an upper decay time cut is applied to remove long-lived backgrounds. This
cut is very effective at removing the bias entering the final results, although the
remaining effect must be evaluated.
As discussed in Section 6.3.2 determining the decay time distribution of com-
binatorial background decays is challenging because there are too few decays left
in either data or bb  +X simulated decays after the selection requirements
to determine the decay time PDF. Therefore, the combinatorial background of
B  h+h decays in the mass range 5600 - 6000 MeV/c2 is used. The validity of
using B  h+h combinatorial background to model B0s  + combinatorial
background is studied by comparing the average lifetime of decays in bins of global
BDT. The average lifetimes are shown in Table 7.4 for decays in data passing the
selection requirements for B0s  + and B  h+h
 decays and in the mass
ranges 5447 - 6000 MeV/c2 and 5600 - 6000 MeV/c2, respectively. At low values of
the global BDT the average lifetimes are similar and the lifetime of backgrounds
of both decays increases with the output of the global BDT. Overall B  h+h
combinatorial background decays are longer lived than B0s  + combinatorial
background decays therefore the B  h+h decay time model is a conservative
estimate for B0s  + combinatorial background as far as the effect of long-lived
components in concerned.
The model used for the combinatorial background decay time currently introduces
no significant bias into the pull distribution of  for pseudoexperiments as shown
in Table 6.8. However, the size of a systematic bias from the choice of the lifetimes
used in the combinatorial background decay time distribution is estimated by two
sets of pseudoexperiments. The first uses the background decay time distribution in
Table 6.4 and the second set uses a modified version this distribution: 1 and 2 are
both increased by 1; and the fraction of decays with lifetime 1 is increased by 1.
For both sets of pseudoexperiments only combinatorial background and B0s  +
decays are generated and 10,000 studies are performed for each configuration.
The resulting pull distributions for  are shown in Figure 7.14, the difference
in the mean value of the distributions for the two studies is negligible and the width
changes by 0.008 ps1 between the two studies. The change in the width is the
168 Systematic uncertainties and cross checks on the effective lifetime
B0s  + B  h+h
BDT mean decay Number of mean decay Number of
bin time / ps candidates time / ps candidates
1 1.178  0.005 50,695 1.124  0.001 964,502
2 1.94  0.10 244 2.394  0.022 8,838
3 2.6  0.3 46 2.78  0.05 2,373
4 2.2  0.4 17 3.02  0.08 1,125
5 2.6  1.1 4 3.42  0.11 655
6 2.5  0.4 3 3.98  0.19 313
7 2.9  1.1 2 4.6  0.4 109
8 - 0 5.7  0.7 35
Table 7.4 The mean decay time of B0s  + and B  h+h
 candidates in 2011, 2012,
2015 and 2016 data in bins of the global BDT output. The mass ranges 5447 - 6000 MeV/c2
and 5600 - 6000 MeV/c2 are used for B0s  + and B  h+h
 decays, respectively.
larger and therefore the systematic uncertainty is estimated from this. Assuming the
expected uncertainty for , a systematic uncertainty of 0.002 ps is assigned due to
the combinatorial background decay time model.
7.7 Mix of B0s mass eigenstates
In the SM the B0s  + effective lifetime is equal to the lifetime of the heavy B0s
mass eigenstate. However, the real B0s  + effective lifetime could be different
due to the mixture of the light and heavy mass eigenstates.
As shown in Section 6.3 the selection efficiency used to identify B0s  +
candidates is not uniform across the decay time range. The selection rejects a
greater proportion of candidates with short lifetimes compared to candidates with
longer lifetimes. Therefore, the presence of the light B0s mass eigenstate decaying as
B0s  + could be masked by the bias in the decay time distribution, since the
efficiency to select the light B0s mass eigenstate is lower than the efficiency to select
the heavy B0s mass eigenstate.
The size of this effect has been estimated using two simple pseudoexperiments.
The first assumes that the selection has no bias on the decay time distribution and
1 million candidates are generated with equal contributions from the heavy and light
B0s mass eigenstates. A second set of 1 million candidates are generated with the
same mix of eigenstates but with a more realistic decay time model including the
B0s  + acceptance function. A fit is performed to the first set of candidates
7.7 Mix of B0s mass eigenstates 169
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
)Pull(
10 5 0 5 10
800  =  0.000 +/- 0.010
 =  0.993 +/- 0.007
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
)Pull(
10 5 0 5 10
 =  0.002 +/- 0.010
 =  1.001 +/- 0.007
Fig. 7.14 Pull distributions for  from 10,000 pseudoexperiments using a) the nominal
combinatorial background decay time model and b) the nominal model with the lifetimes
and fraction of longer lived decays increased by one standard deviation. A fit is performed
to each pull distribution using a Gaussian function, the results are shown by the blue
curves and the mean () and width () of the Gaussian functions are shown.
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
Decay time [ps]
0 5 10 15 20
510  = 1.5342 +/- 0.0016
Decay time [ps]
0 5 10 15 20
510  = 1.5342 +/- 0.0016
Decay time [ps]
0 5 10 15 20
510  = 1.5342 +/- 0.0016 ps
])-+0
Pull(N[B
10 5 0 5 10
800  = -0.025 +/- 0.010
 =  0.996 +/- 0.007
Decay time [ps]
0 5 10 15 20
510  = 1.5518 +/- 0.0014
Decay time [ps]
0 5 10 15 20
510  = 1.5342 +/- 0.0016
Decay time [ps]
0 5 10 15 20
510  = 1.5518 +/- 0.0014 ps
Fig. 7.15 Maximum likelihood fits to the decay time distribution to measure  for
B0s  + decays that are composed of an equal mix from the heavy and light mass
eigenstates. Decay time distributions are generated assuming a) a flat acceptance function
and b) the acceptance function used to describe B0s  + decays in data.
with a single exponential function and the second set with the acceptance function
and exponential function in order to find  for each distribution. The acceptance
parameters are fixed in the second fit.
The values of  are compared for the two studies and a systematic uncertainty
is assigned for the change in  caused by the inclusion of the acceptance function.
The fit results are shown in Figure 7.15 and the difference between the measured
lifetimes for the two studies is 0.018 ps and is assigned as a systematic uncertainty.
170 Systematic uncertainties and cross checks on the effective lifetime
7.8 Production asymmetry of B0s and B
s mesons
The B0s  + effective lifetime is the mean lifetime of an unbiased sample of
B0s  + decays, as discussed in Chapter 2, and is given by
 
0 t  (B0s (t)  +) dt
0  (B0s (t)  +) dt
, (7.5)
where the untagged decay rate is
B0s (t)  
B0s (t)  
B0s (t)  
, (7.6)
and assumes that B0s and B
s mesons are produced at equal rates. This assumption
is made for the measured value of . However, since the LHC is a pp collider, B0s
and B0s mesons are not produced at equal rates. The effect of such a production
asymmetry of B0s and B
s mesons on the measured results must therefore be evaluated.
The production asymmetry is given by
 (B0s )  
 (B0s ) + 
) , (7.7)
where  (B0s ) and 
are the production cross-sections for B0s and B
s mesons,
respectively. The production asymmetry was measured by LHCb in 2011 at a centre-
of-mass energy of 7 TeV as Ap = (1.09  2.61  0.66)% [175]. The presence of the
production asymmetry modifies the untagged B0s  + decay rate to
B0s (t)  
 = (1 + Ap)(B0s (t)  
+ (1  Ap)(B
s(t)  
+). (7.8)
The effect of the production asymmetry on the measured lifetime is determined
from Equations 7.5 and 7.8 using the decay rates of B0s  + and B
s  +
given in Equations 2.33 and 2.34.
The total decay rate with the production asymmetry is
B0s (t)  
 = N |A|2(1 + ||2)est
+ A sinh
+ Ap[C cos(mst) + S sin(mst)]
+ O(a),
where C = (1  ||2)/(1 + ||2) and S = 2/(1 + ||2) are CP asymmetries
and are related to A by |A|2 + |C|2 + |S|2 = 1 [50].
7.9 Summary 171
The production asymmetry introduces an oscillatory term into the decay rate
which disappears when Ap = 0. Using the relationships s = L  H and
s = (L + H)/2 and ignoring terms O(a), the decay rate becomes
B0s (t)  
 N 
(1  A)eLt + (1 + A)eH t
+ 2Apest [C cos(mst) + S sin(mst)]
, (7.10)
where N   12N |A|
2(1+||2). This decay rate is used to calculate the B0s  +
effective lifetime in the presence of a production asymmetry. Using integration by
parts the contributing terms to the effective lifetime become
B0s (t)  
dt =N 
1  A
1 + A
(7.11)
(m2s + 2s)2
C(2S  m
s) + 2SSms
Bs(t)  +
dt =N 
1  A
1 + A
+ 2Ap
m2s + 2s
m2s + 2s
. (7.12)
The effect of the production asymmetry on the effective lifetime can now be
calculated using the values of ms = 17.717 ps1, s = 0.662 ps1, L = 0.703
ps1 and H = 0.621 ps1 [5]. A value of Ap = 0.040 is used, which is 1 standard
deviation greater than the value measured by LHCb, and A = 0.0 is chosen. Since
(A)2 + (C)2 + (S)2 = 1, it is assumed that C = S =
In the presence of the production asymmetry, the B0s  + effective lifetime
is found to be 1.520 ps, whereas when there is no production asymmetry and Ap = 0,
the effective lifetime is 1.522 ps. Therefore the production asymmetry introduces a
bias on 0.002 ps into the measurement of  and this value is assigned as a systematic
uncertainty.
7.9 Summary
The complete list of systematic uncertainties for  are summarised in Table 7.5.
Adding the uncertainties in quadrature gives a total uncertainty of 0.05 ps for ,
which corresponds to 11% of the observed statistical uncertainty. The small size of
172 Systematic uncertainties and cross checks on the effective lifetime
Uncertainty source Uncertainty/ps
Fit accuracy 0.033
Background contamination 0.007
Acceptance function 0.028
Combinatorial background decay time model 0.008
Mix of B0s eigenstates 0.018
Production asymmetry 0.002
Total 0.048
Table 7.5 Summary of the systematic uncertainties on , the total uncertainty is achieved
by adding the separate uncertainties in quadrature.
the total of the systematic uncertainties compared to the statistical uncertainty is
expected given the small number of observed number of decays.
The two largest systematic uncertainties, related to the fit accuracy and the
acceptance function parametrisation, are dependant on the size of the dataset and
will therefore decrease as LHCb records more data. However, the other sources of
systematic uncertainties will not change as the size of the dataset increases unless
the analysis strategy used to measure the B0s  + effective lifetime changes.
Chapter 8
Summary and Outlook
8.1 Summary
The LHCb experiment was built to test the predictions of the SM and search for
NP effects through the study of CP violating and rare decays of b-hadrons. So far
measurements performed using the LHCb experiment, and other LHC experiments,
have not revealed conclusive evidence for NP effects, although some interesting
anomalies have been seen in measured results in heavy flavour physics [2136]. The
search for B0(s)  
+ decays was identified as one of the key measurements to
be made with the LHCb experiment [176] as an indirect search for NP. In 2011
LHCb joined the search for these decays, that began over 30 years ago, using the
unprecedented energies available at the LHC. The first evidence for B0s  +
decays was found by the LHCb experiment with 2.1 fb1 of Run 1 data from pp
collisions [45]. A combined analysis of the Run 1 data from the CMS and LHCb
experiments produced the first observation of B0s  + decays and the first
evidence for B0  + decays [47]. The measured branching fractions of these
decays are consistent with the SM predictions and place constraints on BSM theories.
However, the precision of the measurements still leaves room for NP effects to be
revealed, therefore it is important to improve the precision of the branching fraction
measurements. With the observation of the B0s mode the search for B0s  +
decays is complete and properties of this decay, including the effective lifetime, can
now be studied. The effective lifetime offers a new observable to test the SM in
B0s  + decays that is complementary to the branching fraction.
The measurements of the B0(s)  
+ branching fractions and the B0s  +
effective lifetime with 4.4 fb1 of Run 1 and Run 2 data collected by the LHCb
experiment are presented in this dissertation. Figure 8.1 shows a summary of the
fit used to measure the B0(s)  
+ branching fractions for candidates in Run 1
and Run 2 data with a global BDT value of BDT > 0.5. The measured branching
174 Summary and Outlook
]2c [MeV/+m
5000 5200 5400 5600 5800 6000
35 Total
+  s
+  0B
Combinatorial
h'+ hB 
+)(K  (s)
+0(+)  0(+)B
 p b
+ J/ +cB
BDT > 0.5
Fig. 8.1 B0(s)  
+ candidates with a global BDT value of BDT > 0.5 in 4.4 fb1 of
Run 1 and Run 2 data collected by the LHCb experiment and the mass fit used to measure
the B0(s)  
+ branching fractions overlaid.
fractions are
B(B0s  
+) = (3.0  0.6+0.30.2)  10
B(B0  +) = (1.5+1.2+0.21.00.1)  10
 10.
(8.1)
The B0s mode is observed with a statistical significance of 7.8, making this result the
first single experiment observation of this decay and the most precise measurement
to date. The B0 mode has a significance of 1.6, therefore a limit is placed on the
branching fraction of B(B0  +)< 3.4  1010 at the 95% confidence level. The
measured values are consistent with the SM predictions.
The effective lifetime of B0s  + decays is measured for the first time to be
 = 2.04  0.44  0.05 ps, (8.2)
which is within 1.0 of the SM prediction. The result is consistent with A = +1
hypothesis at 1.0 and with A = 1 hypothesis at 1.4. Although the current
precision of the measurement does not enable constraints to be placed on BSM
theories it is important to illustrate the ability of the LHCb experiment to make this
measurement.
The measured values of the branching fraction presented in this dissertation have
already been used to help constrain parameters in BSM theories [89, 177179]. The
possible values available for the parameters P and S, defined in Section 2.2, are
shown in Figure 8.2, where the values are constrained from the branching fraction
results in Equation 8.1 and the results from the CMS collaboration in reference [41].
8.2 Outlook 175
-1.0 -0.5 0.0 0.5 1.0
Fig. 8.2 Constraints in the P - S plane where P and S are defined in Section 2.2. The blue
band corresponds to constraints from the B0(s)  
+ branching fraction measurements
presented in this dissertation and the CMS experiment Run 1 results in reference [41]. The
dashed lines show different values for A and the constraints assume P , S  0, . The
figure is taken from [177].
The current measurements produce a circular band of possible P and S values, and
a precise measurement of A through the B0s  + effective lifetime will help
resolve the ambiguities.
8.2 Outlook
The measured values of the branching fractions and the effective lifetime still leave
plenty of room for NP effects to be observed with these decays. At the end of Run 2
of the LHC, the LHCb dataset will have almost doubled to 8 fb1, enabling the
precision of these measurements to be improved. Looking further ahead, LHCb is
expected to collect 50 fb1 of data by the end of Run 4 and with the high luminosity
LHC up to 300 fb1 could be recorded.
With more data, the expected precision of the branching fraction measurements
is expected to be reduced to  0.19  109 with 50 fb1 [180]. Not only are the
branching fraction measurements in themselves interesting to test the SM but the
ratio of the branching fractions of the two modes is also useful to test the SM, in
particular the MFV hypothesis. The current precision of the ratio of branching
fractions is  60% [47], and future runs of the LHC will enable the precision of the
ratio of branching fractions to be reduced to 40% with 50 fb1 of pp data and 20%
with 300 fb1 of data [181].
176 Summary and Outlook
The expected uncertainty achievable by the LHCb experiment for the effective
lifetime at the end of Run 2 and after future runs of the LHC is estimated using
pseudoexperiments based on the observed numbers of decays with 4.4 fb1 and
the current measurement strategy. At the end of Run 2, with 8 fb1, the median
uncertainty of the effective lifetime will be 0.2 ps which is reduced to 0.08 ps
with 50 fb1 and 0.03 ps with 300 fb1. Therefore, with 300 fb1 the precision
on the effective lifetime will enable A = +1 to be distinguished from A = 1
with a statistical significance of 5. The expected mass and decay time distributions
for 8, 50 and 300 fb1 are shown in Figure 8.3. The expected uncertainties for the
effective lifetime measurement are conservative estimates because they are based on
the current measurement strategy which was designed for low expected statistics.
Therefore the precision of the measurement could be much better as different analysis
methods can be taken advantage of with more statistics.
The current systematic uncertainty on the effective lifetime is 0.05 ps which is
too large to allow possible NP effects to be observed. However, several components
contributing to the total, such as the fit accuracy and the acceptance function
systematic, will be reduced with the availability of more data enabling greater
precision on the measurement. With more data, an alternative analysis approach
could be used which would reduce the systematic uncertainties on the effective
lifetime; the selection criteria can be designed so that it does not bias B0s  +
decay time distribution, therefore removing the need for an acceptance function and
the associated systematic.
The study of B0(s)  
+ decays has been in progress for over 30 years and with
the energy and luminosity available at the LHC, the study of these decays is just as
interesting as it ever was. As more data is collected by the LHCb experiment NP
effects will have less and less space to hide. It will either be seen in B0(s)  
decays or these decays will place ever tighter constraints on BSM theories.
8.2 Outlook 177
]2c [MeV/-+m
5400 5600 5800 6000
Total
- +  s
Combinatorial background
Decay time [ps]
0 5 10
12 1
]2c [MeV/-+m
5400 5600 5800 6000
200 1
50 fb
Decay time [ps]
0 5 10
80 1
50 fb
]2c [MeV/-+m
5400 5600 5800 6000
1200 1300 fb
Decay time [ps]
0 5 10
300 fb
Fig. 8.3 The expected mass and decay time distributions for B0s  + candidates to
measure the effective lifetime with 8, 50 and 300 fb1. The signal and background yields
are determined from the observed number of B0s  + and combinatorial background
decays and the expected number of mis-identified backgrounds and B0  + decays in
4.4 fb1 of Run 1 and Run 2 data.
Bibliography
[1] LHCb collaboration, R. Aaij et al., Measurement of the B0s  + branching
fraction and effective lifetime and search for B0  + decays, Phys. Rev.
Lett. 118 (2017) 191801.
[2] S. L. Glashow, Partial-symmetries of weak interactions, Nuclear Physics 22
(1961), no. 4 579.
[3] S. Weinberg, A model of leptons, Phys. Rev. Lett. 19 (1967) 1264.
[4] S. L. Glashow, J. Iliopoulos, and L. Maiani, Weak interactions with lepton-
hadron symmetry, Phys. Rev. D 2 (1970) 1285.
[5] Particle Data Group, C. Patrignani et al., Review of Particle Physics, Chin.
Phys. C40 (2016), no. 10 100001.
[6] R. Davis, D. S. Harmer, and K. C. Hoffman, Search for neutrinos from the
sun, Phys. Rev. Lett. 20 (1968) 1205.
[7] Super-Kamiokande collaboration, Y. Fukuda et al., Measurements of the
solar neutrino flux from Super-Kamiokandes first 300 days, Phys. Rev.
Lett. 81 (1998) 1158, arXiv:hep-ex/9805021, [Erratum: Phys. Rev.
Lett.81,4279(1998)].
[8] Super-Kamiokande Collaboration, S. Fukuda et al., Constraints on Neutrino
Oscillations Using 1258 Days of Super-Kamiokande Solar Neutrino Data, Phys.
Rev. Lett. 86 (2001) 5656.
[9] SNO Collaboration, Q. R. Ahmad et al., Measurement of the Rate of e + d 
p+p+e Interactions Produced by 8B Solar Neutrinos at the Sudbury Neutrino
Observatory, Phys. Rev. Lett. 87 (2001) 071301.
[10] F. Zwicky, Spectral displacement of extra galactic nebulae, Helv. Phys. Acta 86
(1933).
[11] M. S. Roberts and A. H. Rots, Comparison of rotation curves of different
galaxy types, Astronomy and Astrophysics 26 (1973) 483.
[12] J. Dunkley et al., Five-Year Wilkinson Microwave Anisotropy Probe (WMAP)
Observations: Likelihoods and Parameters from the WMAP data, Astrophys. J.
Suppl. 180 (2009) 306, arXiv:0803.0586.
[13] P. A. R. Ade et al., Planck 2015 results. XIII. Cosmological parameters, Astron.
Astrophys. 594 (2016) A13, arXiv:1502.01589.
http://dx.doi.org/10.1103/PhysRevLett.118.191801
http://dx.doi.org/10.1103/PhysRevLett.118.191801
http://dx.doi.org/http://dx.doi.org/10.1016/0029-5582(61)90469-2
http://dx.doi.org/http://dx.doi.org/10.1016/0029-5582(61)90469-2
http://dx.doi.org/10.1103/PhysRevLett.19.1264
http://dx.doi.org/10.1103/PhysRevD.2.1285
http://dx.doi.org/10.1088/1674-1137/40/10/100001
http://dx.doi.org/10.1088/1674-1137/40/10/100001
http://dx.doi.org/10.1103/PhysRevLett.20.1205
http://dx.doi.org/10.1103/PhysRevLett.81.1158
http://dx.doi.org/10.1103/PhysRevLett.81.1158
http://arxiv.org/abs/hep-ex/9805021
http://dx.doi.org/10.1103/PhysRevLett.86.5656
http://dx.doi.org/10.1103/PhysRevLett.86.5656
http://dx.doi.org/10.1103/PhysRevLett.87.071301
http://dx.doi.org/10.1088/0067-0049/180/2/306
http://dx.doi.org/10.1088/0067-0049/180/2/306
http://arxiv.org/abs/0803.0586
http://dx.doi.org/10.1051/0004-6361/201525830
http://dx.doi.org/10.1051/0004-6361/201525830
http://arxiv.org/abs/1502.01589
180 Bibliography
[14] A. D. Sakharov, Violation of CP Invariance, C Asymmetry, and Baryon
Asymmetry of the Universe, Pisma Zh. Eksp. Teor. Fiz. 5 (1967) 32, [Usp. Fiz.
Nauk161,61(1991)].
[15] M. B. Gavela, P. Hernandez, J. Orloff, and O. Pene, Standard model
CP violation and baryon asymmetry, Mod. Phys. Lett. A9 (1994) 795,
arXiv:hep-ph/9312215.
[16] M. Dine, Supersymmetry and String Theory: Beyond the Standard Model,
Cambridge University Press, 2007.
[17] J. R. Ellis, Limits of the standard model, in PSI Zuoz Summer School on
Exploring the Limits of the Standard Model Zuoz, Engadin, Switzerland, August
18-24, 2002, 2002. arXiv:hep-ph/0211168.
[18] A. Pomarol, Beyond the Standard Model, in Proceedings, High-energy Physics.
Proceedings, 18th European School (ESHEP 2010): Raseborg, Finland, June
20 - July 3, 2010, pp. 115151, 2012. arXiv:1202.1391.
[19] CMS collaboration, S. Chatrchyan et al., Observation of a new boson at a mass
of 125 GeV with the CMS experiment at the LHC, Phys. Lett. B716 (2012)
30, arXiv:1207.7235.
[20] ATLAS collaboration, G. Aad et al., Observation of a new particle in the search
for the Standard Model Higgs boson with the ATLAS detector at the LHC, Phys.
Lett. B716 (2012) 1, arXiv:1207.7214.
[21] Belle Collaboration, S. Wehle et al., Lepton-flavor-dependent angular analysis
of b  K+, Phys. Rev. Lett. 118 (2017) 111801.
[22] LHCb collaboration, R. Aaij et al., Differential branching fractions and
isospin asymmetries of B  K()+ decays, JHEP 06 (2014) 133,
arXiv:1403.8044.
[23] LHCb collaboration, R. Aaij et al., Angular analysis of the B0 
K0+ decay using 3 fb1 of integrated luminosity, JHEP 02 (2016) 104,
arXiv:1512.04442.
[24] ATLAS Collaboration, Angular analysis of B0d  K+ decays in pp colli-
sions at
s = 8 TeV with the ATLAS detector, Tech. Rep. ATLAS-CONF-
2017-023, CERN, Geneva, Apr, 2017.
[25] CMS Collaboration, Measurement of the P1 and P 5 angular parameters of the
decay B0  K0+ in proton-proton collisions at
s = 8 TeV, Tech. Rep.
CMS-PAS-BPH-15-008, CERN, Geneva, 2017.
[26] LHCb collaboration, R. Aaij et al., Angular analysis and differential branching
fraction of the decay B0s  +, JHEP 09 (2015) 179, arXiv:1506.08777.
[27] LHCb collaboration, R. Aaij et al., Test of lepton universality using B+ 
K++ decays, Phys. Rev. Lett. 113 (2014) 151601.
[28] LHCb, R. Aaij et al., Test of lepton universality with B0  K0+ decays,
arXiv:1705.05802.
http://dx.doi.org/10.1070/PU1991v034n05ABEH002497
http://dx.doi.org/10.1142/S0217732394000629
http://arxiv.org/abs/hep-ph/9312215
http://arxiv.org/abs/hep-ph/0211168
http://arxiv.org/abs/1202.1391
http://dx.doi.org/10.1016/j.physletb.2012.08.021
http://dx.doi.org/10.1016/j.physletb.2012.08.021
http://arxiv.org/abs/1207.7235
http://dx.doi.org/10.1016/j.physletb.2012.08.020
http://dx.doi.org/10.1016/j.physletb.2012.08.020
http://arxiv.org/abs/1207.7214
http://dx.doi.org/10.1103/PhysRevLett.118.111801
http://dx.doi.org/10.1007/JHEP06(2014)133
http://arxiv.org/abs/1403.8044
http://dx.doi.org/10.1007/JHEP02(2016)104
http://arxiv.org/abs/1512.04442
http://dx.doi.org/10.1007/JHEP09(2015)179
http://arxiv.org/abs/1506.08777
http://dx.doi.org/10.1103/PhysRevLett.113.151601
http://arxiv.org/abs/1705.05802
Bibliography 181
[29] LHCb collaboration, R. Aaij et al., Measurement of the ratio of branch-
ing fractions B(B0  D+ )/B(B0  D+), Phys. Rev. Lett.
115 (2015), no. 11 111803, arXiv:1506.08614, [Erratum: Phys. Rev.
Lett.115,no.15,159901(2015)].
[30] Belle Collaboration, M. Huschle et al., Measurement of the branching ratio of
B  D() relative to B  D() decays with hadronic tagging at Belle,
Phys. Rev. D92 (2015), no. 7 072014, arXiv:1507.03233.
[31] BaBar Collaboration, J. P. Lees et al., Evidence for an excess of B  D()
decays, Phys. Rev. Lett. 109 (2012) 101802, arXiv:1205.5442.
[32] BaBar Collaboration, J. P. Lees et al., Measurement of an Excess of B 
D() Decays and Implications for Charged Higgs Bosons, Phys. Rev. D88
(2013), no. 7 072012, arXiv:1303.0571.
[33] Belle Collaboration, Y. Sato et al., Measurement of the branching ratio of
B0  D+ relative to B0  D+ decays with a semileptonic tagging
method, Phys. Rev. D94 (2016), no. 7 072007, arXiv:1607.07923.
[34] W. Altmannshofer, P. Stangl, and D. M. Straub, Interpreting Hints for Lepton
Flavor Universality Violation, arXiv:1704.05435.
[35] B. Capdevila et al., Patterns of New Physics in b  s+ transitions in the
light of recent data, arXiv:1704.05340.
[36] Heavy Flavor Averaging Group, Y. Amhis et al., Averages of b-hadron, c-hadron,
and  -lepton properties as of summer 2016, arXiv:1612.07233.
[37] ATLAS collaboration, G. Aad et al., Search for the decay B0s   with the
ATLAS detector, Phys. Lett. B713 (2012) 387, arXiv:1204.0735.
[38] ATLAS collaboration, M. Aaboud et al., Study of the rare decays of B0s and B0
into muon pairs from data collected during the LHC Run 1 with the ATLAS
detector, Eur. Phys. J. C76 (2016), no. 9 513, arXiv:1604.04263.
[39] CMS collaboration, S. Chatrchyan et al., Search for B0s  + and B0 
+ decays in pp collisions at
s = 7 TeV, Phys. Rev. Lett. 107 (2011)
191802, arXiv:1107.5834.
[40] CMS collaboration, S. Chatrchyan et al., Search for B0s  + and B0 
+ decays, JHEP 04 (2012) 033, arXiv:1203.3976.
[41] CMS collaboration, S. Chatrchyan et al., Measurement of the B0s  +
branching fraction and search for B0  + with the CMS Experiment, Phys.
Rev. Lett. 111 (2013) 101804, arXiv:1307.5025.
[42] LHCb collaboration, R. Aaij et al., Search for the rare decays B0s  + and
B0  +, Phys. Lett. B699 (2011) 330, arXiv:1103.2465.
[43] LHCb collaboration, R. Aaij et al., Search for the rare decays B0s  + and
B0  +, Phys. Lett. B708 (2012) 55, arXiv:1112.1600.
[44] LHCb collaboration, R. Aaij et al., Strong constraints on the rare decays Bs 
+ and B0  +, Phys. Rev. Lett. 108 (2012) 231801, arXiv:1203.4493.
http://dx.doi.org/10.1103/PhysRevLett.115.159901, 10.1103/PhysRevLett.115.111803
http://dx.doi.org/10.1103/PhysRevLett.115.159901, 10.1103/PhysRevLett.115.111803
http://arxiv.org/abs/1506.08614
http://dx.doi.org/10.1103/PhysRevD.92.072014
http://arxiv.org/abs/1507.03233
http://dx.doi.org/10.1103/PhysRevLett.109.101802
http://arxiv.org/abs/1205.5442
http://dx.doi.org/10.1103/PhysRevD.88.072012
http://dx.doi.org/10.1103/PhysRevD.88.072012
http://arxiv.org/abs/1303.0571
http://dx.doi.org/10.1103/PhysRevD.94.072007
http://arxiv.org/abs/1607.07923
http://arxiv.org/abs/1704.05435
http://arxiv.org/abs/1704.05340
http://arxiv.org/abs/1612.07233
http://dx.doi.org/10.1016/j.physletb.2012.06.013
http://arxiv.org/abs/1204.0735
http://dx.doi.org/10.1140/epjc/s10052-016-4338-8
http://arxiv.org/abs/1604.04263
http://dx.doi.org/10.1103/PhysRevLett.107.191802
http://dx.doi.org/10.1103/PhysRevLett.107.191802
http://arxiv.org/abs/1107.5834
http://dx.doi.org/10.1007/JHEP04(2012)033
http://arxiv.org/abs/1203.3976
http://dx.doi.org/10.1103/PhysRevLett.111.101804
http://dx.doi.org/10.1103/PhysRevLett.111.101804
http://arxiv.org/abs/1307.5025
http://dx.doi.org/10.1016/j.physletb.2011.04.031
http://arxiv.org/abs/1103.2465
http://dx.doi.org/10.1016/j.physletb.2012.01.038
http://arxiv.org/abs/1112.1600
http://dx.doi.org/10.1103/PhysRevLett.108.231801
http://arxiv.org/abs/1203.4493
182 Bibliography
[45] LHCb collaboration, R. Aaij et al., First Evidence for the Decay B0s  +,
Phys. Rev. Lett. 110 (2013), no. 2 021801, arXiv:1211.2674.
[46] LHCb collaboration, R. Aaij et al., Measurement of the B0s  + branching
fraction and search for B0  + decays at the LHCb experiment, Phys. Rev.
Lett. 111 (2013) 101805, arXiv:1307.5024.
[47] LHCb collaboration, CMS collaboration, V. Khachatryan et al., Observation
of the rare B0s  + decay from the combined analysis of CMS and LHCb
data, Nature 522 (2015) 68, arXiv:1411.4413.
[48] A. L. Read, Presentation of search results: the CLs technique, Journal of
Physics G: Nuclear and Particle Physics 28 (2002), no. 10 2693.
[49] T. Blake, G. Lanfranchi, and D. M. Straub, Rare B Decays as Tests of the
Standard Model, Prog. Part. Nucl. Phys. 92 (2017) 50, arXiv:1606.00916.
[50] K. Anikeev et al., B physics at the Tevatron: Run II and beyond, in Workshop
on B Physics at the Tevatron: Run II and Beyond Batavia, Illinois, September
23-25, 1999, 2001. arXiv:hep-ph/0201071.
[51] I. Dunietz, R. Fleischer, and U. Nierste, In pursuit of new physics with Bs
decays, Phys. Rev. D63 (2001) 114015, arXiv:hep-ph/0012219.
[52] U. Nierste, Three Lectures on Meson Mixing and CKM phenomenology, in
Heavy quark physics. Proceedings, Helmholtz International School, HQP08,
Dubna, Russia, August 11-21, 2008, pp. 138, 2009. arXiv:0904.1869.
[53] A. Arbey, M. Battaglia, F. Mahmoudi, and D. Martnez Santos, Supersymmetry
confronts Bs  + : Present and future status, Phys. Rev. D87 (2013),
no. 3 035026, arXiv:1212.4887.
[54] N. Cabibbo, Unitary symmetry and leptonic decays, Phys. Rev. Lett. 10 (1963)
[55] M. Kobayashi and T. Maskawa, CP-violation in the renormalizable theory of
weak interaction, Progress of Theoretical Physics 49 (1973), no. 2 652.
[56] L. Wolfenstein, Parametrization of the Kobayashi-Maskawa matrix, Phys. Rev.
Lett. 51 (1983) 1945.
[57] K. De Bruyn et al., Branching Ratio Measurements of Bs Decays, Phys. Rev.
D86 (2012) 014027, arXiv:1204.1735.
[58] S. Tolk, Discovery Of Rare B decays. First observation of the Bs  +
decays, first evidence of the B0  + decays., PhD thesis, Groningen U.,
Dec, 2015, Presented 08 Apr 2016.
[59] K. G. Wilson, Non-Lagrangian Models of Current Algebra, Phys. Rev. 179
(1969) 1499.
[60] K. G. Wilson, Operator product expansions and composite field operators in the
general framework of quantum field theory, Communications in Mathematical
Physics 24 (1972), no. 2 87.
[61] K. De Bruyn et al., Probing New Physics via the B0s  + Effective Lifetime,
Phys. Rev. Lett. 109 (2012) 041801, arXiv:1204.1737.
http://dx.doi.org/10.1103/PhysRevLett.110.021801
http://arxiv.org/abs/1211.2674
http://dx.doi.org/10.1103/PhysRevLett.111.101805
http://dx.doi.org/10.1103/PhysRevLett.111.101805
http://arxiv.org/abs/1307.5024
http://dx.doi.org/10.1038/nature14474
http://arxiv.org/abs/1411.4413
http://dx.doi.org/10.1016/j.ppnp.2016.10.001
http://arxiv.org/abs/1606.00916
http://arxiv.org/abs/hep-ph/0201071
http://dx.doi.org/10.1103/PhysRevD.63.114015
http://arxiv.org/abs/hep-ph/0012219
http://arxiv.org/abs/0904.1869
http://dx.doi.org/10.1103/PhysRevD.87.035026
http://dx.doi.org/10.1103/PhysRevD.87.035026
http://arxiv.org/abs/1212.4887
http://dx.doi.org/10.1103/PhysRevLett.10.531
http://dx.doi.org/10.1103/PhysRevLett.10.531
http://dx.doi.org/10.1143/PTP.49.652
http://dx.doi.org/10.1103/PhysRevLett.51.1945
http://dx.doi.org/10.1103/PhysRevLett.51.1945
http://dx.doi.org/10.1103/PhysRevD.86.014027
http://dx.doi.org/10.1103/PhysRevD.86.014027
http://arxiv.org/abs/1204.1735
http://dx.doi.org/10.1103/PhysRev.179.1499
http://dx.doi.org/10.1103/PhysRev.179.1499
http://dx.doi.org/10.1007/BF01878448
http://dx.doi.org/10.1007/BF01878448
http://dx.doi.org/10.1103/PhysRevLett.109.041801
http://arxiv.org/abs/1204.1737
Bibliography 183
[62] A. J. Buras, R. Fleischer, J. Girrbach, and R. Knegjens, Probing New
Physics with the B0s  + Time-Dependent Rate, JHEP 07 (2013) 77,
arXiv:1303.3820.
[63] R. Fleischer and R. Knegjens, Effective Lifetimes of Bs Decays and their
Constraints on the B0s -B0s Mixing Parameters, Eur. Phys. J. C71 (2011) 1789,
arXiv:1109.5115.
[64] LHCb collaboration, R. Aaij et al., Measurement of the Bs effective life-
time in the J/f0(980) final state, Phys. Rev. Lett. 109 (2012) 152002,
arXiv:1207.0878.
[65] LHCb collaboration, R. Aaij et al., Measurement of the effective B0s  J/K0S
lifetime, Nucl. Phys. B873 (2013) 275, arXiv:1304.4500.
[66] LHCb collaboration, R. Aaij et al., Effective lifetime measurements in the
B0s  K+K , B0  K+ and B0s  +K decays, Phys. Lett. B736 (2014)
446, arXiv:1406.7204.
[67] LHCb collaboration, R. Aaij et al., Measurement of the B0s  Ds D+s and
B0s  DD+s effective lifetimes, Phys. Rev. Lett. 112 (2014), no. 11 111802,
arXiv:1312.1217.
[68] C. Bobeth et al., Bs,d  l+l in the Standard Model with Reduced Theoretical
Uncertainty, Phys. Rev. Lett. 112 (2014) 101801, arXiv:1311.0903.
[69] Fermilab Lattice, MILC, A. Bazavov et al., B- and D-meson decay con-
stants from three-flavor lattice QCD, Phys. Rev. D85 (2012) 114506,
arXiv:1112.3051.
[70] H. Na et al., The B and Bs Meson Decay Constants from Lattice QCD, Phys.
Rev. D86 (2012) 034506, arXiv:1202.4914.
[71] O. Witzel, B-meson decay constants with domain-wall light quarks and non-
perturbatively tuned relativistic b-quarks, PoS LATTICE2013 (2014) 377,
arXiv:1311.0276.
[72] R. J. Knegjens, Strategies to Hunt for New Physics with Strange Beauty Mesons,
PhD thesis, Vrije U., Amsterdam, 2014.
[73] W. Altmannshofer and D. M. Straub, New physics in b  s transitions after
LHC run 1, Eur. Phys. J. C75 (2015), no. 8 382, arXiv:1411.3161.
[74] G. DAmbrosio, G. F. Giudice, G. Isidori, and A. Strumia, Minimal flavor
violation: An Effective field theory approach, Nucl. Phys. B645 (2002) 155,
arXiv:hep-ph/0207036.
[75] S. P. Martin, A Supersymmetry primer, arXiv:hep-ph/9709356, [Adv. Ser.
Direct. High Energy Phys.18,1(1998)].
[76] W.-S. Hou, Source of CP Violation for the Baryon Asymmetry of the Universe,
Chin. J. Phys. 47 (2009) 134, arXiv:0803.1234.
[77] D. M. Straub, New physics correlations in rare decays, in CKM unitarity
triangle. Proceedings, 6th International Workshop, CKM 2010, Warwick, UK,
September 6-10, 2010. arXiv:1012.3893.
http://dx.doi.org/10.1007/JHEP07(2013)077
http://arxiv.org/abs/1303.3820
http://dx.doi.org/10.1140/epjc/s10052-011-1789-9
http://arxiv.org/abs/1109.5115
http://dx.doi.org/10.1103/PhysRevLett.109.152002
http://arxiv.org/abs/1207.0878
http://dx.doi.org/10.1016/j.nuclphysb.2013.04.021
http://arxiv.org/abs/1304.4500
http://dx.doi.org/10.1016/j.physletb.2014.07.051
http://dx.doi.org/10.1016/j.physletb.2014.07.051
http://arxiv.org/abs/1406.7204
http://dx.doi.org/10.1103/PhysRevLett.112.111802
http://arxiv.org/abs/1312.1217
http://dx.doi.org/10.1103/PhysRevLett.112.101801
http://arxiv.org/abs/1311.0903
http://dx.doi.org/10.1103/PhysRevD.85.114506
http://arxiv.org/abs/1112.3051
http://dx.doi.org/10.1103/PhysRevD.86.034506
http://dx.doi.org/10.1103/PhysRevD.86.034506
http://arxiv.org/abs/1202.4914
http://arxiv.org/abs/1311.0276
http://dx.doi.org/10.1140/epjc/s10052-015-3602-7
http://arxiv.org/abs/1411.3161
http://dx.doi.org/10.1016/S0550-3213(02)00836-2
http://arxiv.org/abs/hep-ph/0207036
http://arxiv.org/abs/hep-ph/9709356
http://arxiv.org/abs/0803.1234
http://arxiv.org/abs/1012.3893
184 Bibliography
[78] LHCb collaboration, CMS collaboration, Combination of results on the rare
decays B0(s)  
+ from the CMS and LHCb experiments, .
[79] L. J. and M. B. Wise, Flavor changing higgs boson couplings, Nuclear Physics
B 187 (1981), no. 3 397 .
[80] E. Witten, Dynamical Breaking of Supersymmetry, Nucl. Phys. B188 (1981)
[81] A. J. Buras, P. H. Chankowski, J. Rosiek, and L. Slawianowska, Correlation
between Ms and B0s,d  + in supersymmetry at large tan , Phys. Lett.
B546 (2002) 96, arXiv:hep-ph/0207241.
[82] K. S. Babu and C. F. Kolda, Higgs mediated B0  + in minimal super-
symmetry, Phys. Rev. Lett. 84 (2000) 228, arXiv:hep-ph/9909476.
[83] G. Isidori and A. Retico, Scalar flavor changing neutral currents in the large
tan beta limit, JHEP 11 (2001) 001, arXiv:hep-ph/0110121.
[84] R. Barbieri, C. W. Murphy, and F. Senia, B-decay Anomalies in a Composite
Leptoquark Model, Eur. Phys. J. C77 (2017), no. 1 8, arXiv:1611.04930.
[85] D. Beirevi, S. Fajfer, N. Konik, and O. Sumensari, Leptoquark model to
explain the B-physics anomalies, RK and RD, Phys. Rev. D94 (2016), no. 11
115021, arXiv:1608.08501.
[86] G. Hiller and M. Schmaltz, RK and future b  s physics beyond the Standard
Model opportunities, Phys. Rev. D90 (2014) 054014, arXiv:1408.1627.
[87] M. Bauer and M. Neubert, Minimal Leptoquark Explanation for the RD() ,
RK , and (g  2)g Anomalies, Phys. Rev. Lett. 116 (2016), no. 14 141802,
arXiv:1511.01900.
[88] S. Fajfer and N. Konik, Vector leptoquark resolution of RK and RD() puzzles,
Phys. Lett. B755 (2016) 270, arXiv:1511.06024.
[89] W. Altmannshofer, C. Niehoff, and D. M. Straub, Bs  + as current and
future probe of new physics, arXiv:1702.05498.
[90] CERN. http://home.cern/about/member-states.
[91] ATLAS, G. Aad et al., The ATLAS Experiment at the CERN Large Hadron
Collider, JINST 3 (2008) S08003.
[92] CMS, S. Chatrchyan et al., The CMS Experiment at the CERN LHC, JINST
3 (2008) S08004.
[93] ALICE, K. Aamodt et al., The ALICE experiment at the CERN LHC, JINST
3 (2008) S08002.
[94] TOTEM, G. Anelli et al., The TOTEM experiment at the CERN Large Hadron
Collider, JINST 3 (2008) S08007.
[95] MoEDAL, J. Pinfold et al., Technical Design Report of the MoEDAL Experi-
ment, , CERN-LHCC-2009-006, MoEDAL-TDR-001.
http://dx.doi.org/http://dx.doi.org/10.1016/0550-3213(81)90469-7
http://dx.doi.org/http://dx.doi.org/10.1016/0550-3213(81)90469-7
http://dx.doi.org/10.1016/0550-3213(81)90006-7
http://dx.doi.org/10.1016/0550-3213(81)90006-7
http://dx.doi.org/10.1016/S0370-2693(02)02639-4
http://dx.doi.org/10.1016/S0370-2693(02)02639-4
http://arxiv.org/abs/hep-ph/0207241
http://dx.doi.org/10.1103/PhysRevLett.84.228
http://arxiv.org/abs/hep-ph/9909476
http://dx.doi.org/10.1088/1126-6708/2001/11/001
http://arxiv.org/abs/hep-ph/0110121
http://dx.doi.org/10.1140/epjc/s10052-016-4578-7
http://arxiv.org/abs/1611.04930
http://dx.doi.org/10.1103/PhysRevD.94.115021
http://dx.doi.org/10.1103/PhysRevD.94.115021
http://arxiv.org/abs/1608.08501
http://dx.doi.org/10.1103/PhysRevD.90.054014
http://arxiv.org/abs/1408.1627
http://dx.doi.org/10.1103/PhysRevLett.116.141802
http://arxiv.org/abs/1511.01900
http://dx.doi.org/10.1016/j.physletb.2016.02.018
http://arxiv.org/abs/1511.06024
http://arxiv.org/abs/1702.05498
http://dx.doi.org/10.1088/1748-0221/3/08/S08003
http://dx.doi.org/10.1088/1748-0221/3/08/S08004
http://dx.doi.org/10.1088/1748-0221/3/08/S08004
http://dx.doi.org/10.1088/1748-0221/3/08/S08002
http://dx.doi.org/10.1088/1748-0221/3/08/S08002
http://dx.doi.org/10.1088/1748-0221/3/08/S08007
Bibliography 185
[96] LHCf, O. Adriani et al., The LHCf detector at the CERN Large Hadron Collider,
JINST 3 (2008) S08006.
[97] LHCb collaboration, A. A. Alves, Jr. et al., The LHCb Detector at the LHC,
JINST 3 (2008) S08005.
[98] LHCb collaboration, http://lhcb-public.web.cern.ch/lhcb-public/.
[99] CMS collaboration, https://twiki.cern.ch/twiki/bin/view/CMSPublic/LumiPu
blicResultsOverview.
[100] ATLAS collaboration, https://twiki.cern.ch/twiki/bin/view/AtlasPublic/Lumin
osityPublicResults and https://twiki.cern.ch/twiki/bin/view/AtlasPublic/Lumi
nosityPublicResultsRun2.
[101] LHCb Collaboration, LHCb : Technical Proposal, Tech. Proposal, CERN,
Geneva, 1998. CERN-LHCC-98-04, CERN-LHCC-P-4.
[102] LHCb Collaboration, LHCb technical design report: Reoptimized detector design
and performance, , CERN-LHCC-2003-030.
[103] LHCb collaboration, R. Aaij et al., LHCb Detector Performance, Int. J. Mod.
Phys. A30 (2015), no. 07 1530022, arXiv:1412.6352.
[104] LHCb Collaboration, LHCb VELO (VErtex LOcator): Technical Design Report,
Technical Design Report LHCb, CERN, Geneva, 2001.
[105] LHCb collaboration, R. Aaij et al., Performance of the LHCb Vertex Locator,
JINST 9 (2014) 09007, arXiv:1405.7808.
[106] LHCb Collaboration, LHCb inner tracker: Technical Design Report, Technical
Design Report LHCb, CERN, Geneva, 2002. CERN-LHCC-2002-029.
[107] LHCb Collaboration, LHCb outer tracker: Technical Design Report, Technical
Design Report LHCb, CERN, Geneva, 2001. CERN-LHCC-2001-024.
[108] LHCb Collaboration, LHCb magnet: Technical Design Report, Technical Design
Report LHCb, CERN, Geneva, 2000. CERN-LHCC-2000-007.
[109] R. E. Kalman, A New Approach to Linear Filetering and Prediction Problems,
Journal of Basic Engineering 82 (1960) 35.
[110] R. Fruhwirth, Application of Kalman filtering to track and vertex fitting, Nucl.
Instrum. Meth. A262 (1987) 444.
[111] LHCb collaboration, R. Aaij et al., Measurement of the track reconstruction
efficiency at LHCb, JINST 10 (2015), no. 02 P02007, arXiv:1408.1251.
[112] LHCb Collaboration, LHCb RICH: Technical Design Report, Technical Design
Report LHCb, CERN, Geneva, 2000. CERN-LHCC-2000-037.
[113] LHCb RICH Group, M. Adinolfi et al., Performance of the LHCb RICH
detector at the LHC, Eur. Phys. J. C73 (2013) 2431, arXiv:1211.6759.
[114] TA2, M. Alemi et al., First operation of a hybrid photon detector prototype with
electrostatic cross-focussing and integrated silicon pixel readout, Nucl. Instrum.
Meth. A449 (2000) 48.
http://dx.doi.org/10.1088/1748-0221/3/08/S08006
http://dx.doi.org/10.1088/1748-0221/3/08/S08005
http://dx.doi.org/10.1142/S0217751X15300227
http://dx.doi.org/10.1142/S0217751X15300227
http://arxiv.org/abs/1412.6352
http://dx.doi.org/10.1088/1748-0221/9/09/P09007
http://arxiv.org/abs/1405.7808
http://dx.doi.org/10.1115/1.3662552
http://dx.doi.org/10.1016/0168-9002(87)90887-4
http://dx.doi.org/10.1016/0168-9002(87)90887-4
http://dx.doi.org/10.1088/1748-0221/10/02/P02007
http://arxiv.org/abs/1408.1251
http://dx.doi.org/10.1140/epjc/s10052-013-2431-9
http://arxiv.org/abs/1211.6759
http://dx.doi.org/10.1016/S0168-9002(99)01448-5
http://dx.doi.org/10.1016/S0168-9002(99)01448-5
186 Bibliography
[115] R. W. Forty and O. Schneider, RICH pattern recognition, Tech. Rep. LHCb-
98-040, CERN, Geneva, Apr, 1998.
[116] LHCb Collaboration, LHCb calorimeters: Technical design report, , CERN-
LHCC-2000-036.
[117] LHCb Collaboration, LHCb muon system: Technical Design Report, Technical
Design Report LHCb, CERN, Geneva, 2001. CERN-LHCC-2001-010.
[118] G. Bencivenni et al., A triple-GEM detector with pad readout for the inner
region of the first LHCb muon station, Tech. Rep. LHCb-2001-051, CERN,
Geneva, Jul, 2001.
[119] B. Botchine et al., Wire pad chambers and cathode pad chambers for the LHCb
muon system, Tech. Rep. LHCb-2000-114, CERN, Geneva, Jan, 2002.
[120] F. Archilli et al., Performance of the Muon Identification at LHCb, JINST 8
(2013) P10020, arXiv:1306.0249.
[121] M. Feindt and U. Kerzel, The NeuroBayes neural network package, Nucl.
Instrum. Meth. A559 (2006) 190.
[122] R. Aaij et al., The LHCb Trigger and its Performance in 2011, JINST 8 (2013)
P04022, arXiv:1211.3055.
[123] LHCb HLT project, J. Albrecht, V. V. Gligorov, G. Raven, and S. Tolk,
Performance of the LHCb High Level Trigger in 2012, J. Phys. Conf. Ser. 513
(2014) 012001, arXiv:1310.8544.
[124] LHCb collaboration, R. Aaij et al., Absolute luminosity measurements with the
LHCb detector at the LHC, JINST 7 (2012) P01010, arXiv:1110.2866.
[125] O. Lupton and G. Wilkinson, Studies of D0  K0Sh+h
 decays at the LHCb
experiment, PhD thesis, Oxford U., Jul, 2016, Presented 14 Sep 2016.
[126] P. Mato, GAUDI-Architecture design document, Tech. Rep. LHCb-98-064,
CERN, Geneva, Nov, 1998.
[127] LHCb collaboration, R. Antunes-Nobrega et al., LHCb computing: Technical
Design Report, Technical Design Report LHCb, CERN, Geneva, 2005. CERN-
LHCC-2005-019.
[128] F. Stagni et al., LHCbDirac: Distributed computing in LHCb, J. Phys. Conf.
Ser. 396 (2012) 032104.
[129] http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/brunel/.
[130] http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/davinci/.
[131] R. Brun and F. Rademakers, ROOT: An object oriented data analysis frame-
work, Nucl. Instrum. Meth. A389 (1997) 81.
[132] LHCb collaboration, I. Belyaev et al., Handling of the generation of primary
events in Gauss, the LHCb simulation framework, Journal of Physics: Confer-
ence Series 331 (2011) 032047.
http://dx.doi.org/10.1088/1748-0221/8/10/P10020
http://dx.doi.org/10.1088/1748-0221/8/10/P10020
http://arxiv.org/abs/1306.0249
http://dx.doi.org/10.1016/j.nima.2005.11.166
http://dx.doi.org/10.1016/j.nima.2005.11.166
http://dx.doi.org/10.1088/1748-0221/8/04/P04022
http://dx.doi.org/10.1088/1748-0221/8/04/P04022
http://arxiv.org/abs/1211.3055
http://dx.doi.org/10.1088/1742-6596/513/1/012001
http://dx.doi.org/10.1088/1742-6596/513/1/012001
http://arxiv.org/abs/1310.8544
http://dx.doi.org/10.1088/1748-0221/7/01/P01010
http://arxiv.org/abs/1110.2866
http://dx.doi.org/10.1088/1742-6596/396/3/032104
http://dx.doi.org/10.1088/1742-6596/396/3/032104
http://dx.doi.org/10.1016/S0168-9002(97)00048-X
Bibliography 187
[133] LHCb collaboration, M. Clemencic et al., The LHCb simulation application,
Gauss: Design, evolution and experience, J. Phys. Conf. Ser. 331 (2011) 032023.
[134] T. Sjostrand, S. Mrenna, and P. Z. Skands, PYTHIA 6.4 Physics and Manual,
JHEP 05 (2006) 026, arXiv:hep-ph/0603175.
[135] T. Sjostrand, S. Mrenna, and P. Z. Skands, A Brief Introduction to PYTHIA
8.1, Comput. Phys. Commun. 178 (2008) 852, arXiv:0710.3820.
[136] D. J. Lange, The EvtGen particle decay simulation package, Nucl. Instrum.
Meth. A462 (2001) 152.
[137] P. Golonka and Z. Was, PHOTOS Monte Carlo: A Precision tool for
QED corrections in Z and W decays, Eur. Phys. J. C45 (2006) 97,
arXiv:hep-ph/0506026.
[138] GEANT4, S. Agostinelli et al., GEANT4: A Simulation toolkit, Nucl. Instrum.
Meth. A506 (2003) 250.
[139] J. Allison et al., Geant4 developments and applications, IEEE Trans. Nucl. Sci.
53 (2006) 270.
[140] http://lhcb-release-area.web.cern.ch/LHCb-release-area/DOC/boole/.
[141] I. Bird, Computing for the Large Hadron Collider, Ann. Rev. Nucl. Part. Sci.
61 (2011) 99.
[142] Worldwide LHC Computing Grid, http://www.cern.ch/LHCgrid.
[143] S. Paterson and A. Tsaregorodtsev, DIRAC Infrastructure for Distributed Anal-
ysis, , https://cds.cern.ch/record/1397926/files/LHCb-TALK-2006-013.pdf.
[144] http://ganga.web.cern.ch/ganga/.
[145] K. Harrison et al., GANGA: a user-grid interface for ALTAS and LHCb,
CoRR cs.SE/0306085 (2003).
[146] D. Melikhov and N. Nikitin, Rare radiative leptonic decays B(d,s) > l+l-
gamma, Phys. Rev. D70 (2004) 114028, arXiv:hep-ph/0410146.
[147] Y. G. Aditya, K. J. Healey, and A. A. Petrov, Faking Bs  +, Phys. Rev.
D87 (2013) 074028, arXiv:1212.4166.
[148] LHCb, R. Aaij et al., Determination of the quark coupling strength |Vub| using
baryonic decays, Nature Phys. 11 (2015) 743, arXiv:1504.01568.
[149] LHCb, R. Aaij et al., First measurement of the differential branching frac-
tion and CP asymmetry of the B  + decay, JHEP 10 (2015) 034,
arXiv:1509.00414.
[150] C. M. Bouchard et al., Bs  K form factors from lattice QCD, Phys. Rev.
D90 (2014) 054506, arXiv:1406.2279.
[151] RBC and UKQCD Collaborations, J. M. Flynn et al., b   and bs  k
form factors and |vub| from 2 + 1-flavour lattice qcd with domainwall light
quarks and relativistic heavy quarks, Phys. Rev. D 91 (2015) 074510.
http://dx.doi.org/10.1088/1742-6596/331/3/032023
http://dx.doi.org/10.1088/1126-6708/2006/05/026
http://arxiv.org/abs/hep-ph/0603175
http://dx.doi.org/10.1016/j.cpc.2008.01.036
http://arxiv.org/abs/0710.3820
http://dx.doi.org/10.1016/S0168-9002(01)00089-4
http://dx.doi.org/10.1016/S0168-9002(01)00089-4
http://dx.doi.org/10.1140/epjc/s2005-02396-4
http://arxiv.org/abs/hep-ph/0506026
http://dx.doi.org/10.1016/S0168-9002(03)01368-8
http://dx.doi.org/10.1016/S0168-9002(03)01368-8
http://dx.doi.org/10.1109/TNS.2006.869826
http://dx.doi.org/10.1109/TNS.2006.869826
http://dx.doi.org/10.1146/annurev-nucl-102010-130059
http://dx.doi.org/10.1146/annurev-nucl-102010-130059
http://dx.doi.org/10.1103/PhysRevD.70.114028
http://arxiv.org/abs/hep-ph/0410146
http://dx.doi.org/10.1103/PhysRevD.87.074028
http://dx.doi.org/10.1103/PhysRevD.87.074028
http://arxiv.org/abs/1212.4166
http://dx.doi.org/10.1038/nphys3415
http://arxiv.org/abs/1504.01568
http://dx.doi.org/10.1007/JHEP10(2015)034
http://arxiv.org/abs/1509.00414
http://dx.doi.org/10.1103/PhysRevD.90.054506
http://dx.doi.org/10.1103/PhysRevD.90.054506
http://arxiv.org/abs/1406.2279
http://dx.doi.org/10.1103/PhysRevD.91.074510
188 Bibliography
[152] LHCb, R. Aaij et al., Measurements of B+c production and mass with the
B+c  J/+ decay, Phys. Rev. Lett. 109 (2012) 232001, arXiv:1209.5634.
[153] LHCb, R. Aaij et al., Measurement of the ratio of B+c branching fractions to
J/+ and J/+, Phys. Rev. D90 (2014), no. 3 032009, arXiv:1407.2126.
[154] W.-F. Wang and Z.-J. Xiao, The semileptonic decays B/Bs 
(,K)(+, , ) in the perturbative QCD approach beyond the leading-order,
Phys. Rev. D86 (2012) 114025, arXiv:1207.0265.
[155] L. Anderlini et al., The PIDCalib package, Tech. Rep. LHCb-PUB-2016-021.
CERN-LHCb-PUB-2016-021, CERN, Geneva, Jul, 2016.
[156] D. Martinez Santos, Study of the very rare decay Bs  + in LHCb, PhD
thesis, Santiago de Compostela, Universidade de Santiago de Compostela,
Santiago de Compostela, 2010, Presented on 05 May 2010.
[157] A. Hoecker et al., TMVA: Toolkit for Multivariate Data Analysis, PoS ACAT
(2007) 040, arXiv:physics/0703039.
[158] F. Archilli et al., Background studies for B0  + analysis optimization,
Tech. Rep. LHCb-INT-2014-047. CERN-LHCb-INT-2014-047, CERN, Geneva,
Nov, 2014.
[159] J. Stevens and M. Williams, uBoost: A boosting method for producing uniform
selection efficiencies from multivariate classifiers, JINST 8 (2013) P12013,
arXiv:1305.7248.
[160] M. Pivk and F. R. Le Diberder, SPlot: A Statistical tool to unfold data distri-
butions, Nucl. Instrum. Meth. A555 (2005) 356, arXiv:physics/0402083.
[161] F. James and M. Roos, Minuit: A System for Function Minimization and
Analysis of the Parameter Errors and Correlations, Comput. Phys. Commun.
10 (1975) 343.
[162] T. Skwarnicki, A study of the radiative cascade transitions between the Upsilon-
prime and Upsilon resonances, PhD thesis, Institute of Nuclear Physics, Krakow,
1986, DESY-F31-86-02.
[163] F. Archilli et al., Search for the B0  + decay and measurement of the
B0s  + branching fraction and effective lifetime, Tech. Rep. LHCb-ANA-
2016-038, May, 2016.
[164] ARGUS, H. Albrecht et al., Search for hadronic bu decays, Phys. Lett. B241
(1990) 278.
[165] D. Martnez Santos and F. Dupertuis, Mass distributions marginalized over
per-event errors, Nucl. Instrum. Meth. A764 (2014) 150, arXiv:1312.5000.
[166] S. Tolk, J. Albrecht, F. Dettori, and A. Pellegrino, Data-driven measurement
of trigger efficiencies with the TisTos method, Tech. Rep. LHCb-INT-2013-038.
CERN-LHCb-INT-2013-038, CERN, Geneva, Jun, 2013.
[167] LHCb collaboration, R. Aaij et al., Updated average fs/fd bhadron production
fraction ratio for 7 TeV pp collisions, Tech. Rep. LHCb-CONF-2013-011.
http://dx.doi.org/10.1103/PhysRevLett.109.232001
http://arxiv.org/abs/1209.5634
http://dx.doi.org/10.1103/PhysRevD.90.032009
http://arxiv.org/abs/1407.2126
http://dx.doi.org/10.1103/PhysRevD.86.114025
http://arxiv.org/abs/1207.0265
http://arxiv.org/abs/physics/0703039
http://dx.doi.org/10.1088/1748-0221/8/12/P12013
http://arxiv.org/abs/1305.7248
http://dx.doi.org/10.1016/j.nima.2005.08.106
http://arxiv.org/abs/physics/0402083
http://dx.doi.org/10.1016/0010-4655(75)90039-9
http://dx.doi.org/10.1016/0010-4655(75)90039-9
http://inspirehep.net/record/230779/
http://dx.doi.org/10.1016/0370-2693990091293-K
http://dx.doi.org/10.1016/0370-2693990091293-K
http://dx.doi.org/10.1016/j.nima.2014.06.081
http://arxiv.org/abs/1312.5000
Bibliography 189
[168] S. S. Wilks, The large-sample distribution of the likelihood ratio for testing
composite hypotheses, Ann. Math. Statist. 9 (1938) 60.
[169] W. Verkerke and D. P. Kirkby, The RooFit toolkit for data modeling, eConf
C0303241 (2003) MOLT007, arXiv:physics/0306116.
[170] M. Baak and W. Verkerke. https://twiki.cern.ch/twiki/pub/Main/RooFit/baak
_eventweights.pdf.
[171] Y. Xie. https://indico.cern.ch/event/201535/contributions/384769/attachment
s/301972/421937/sFit_analsyis_week_feb_2013_MAC_version.pdf.
[172] LHCb collaboration, R. Aaij et al., Measurement of the CP violating phase s
in B0s  J/f0(980), Phys. Lett. B707 (2012) 497, arXiv:1112.3056.
[173] LHCb collaboration, R. Aaij et al., First study of the CP-violating phase and
decay-width difference in B0s  (2S) decays, Phys. Lett. B762 (2016) 253,
arXiv:1608.04855.
[174] LHCb collaboration, R. Aaij et al., Measurement of CP violation in B0 
J/K0S decays, Phys. Rev. Lett. 115 (2015), no. 3 031601, arXiv:1503.07089.
[175] LHCb collaboration, R. Aaij et al., Measurement of the B0 B0 and B0s B0s
production asymmetries in pp collisions at
s = 7 TeV, Phys. Lett. B739
(2014) 218, arXiv:1408.0275.
[176] LHCb collaboration, B. Adeva et al., Roadmap for selected key measurements
of LHCb, arXiv:0912.4179.
[177] R. Fleischer, R. Jaarsma, and G. Tetlalmatzi-Xolocotzi, In Pursuit of New
Physics with B0s,d  +, arXiv:1703.10160.
[178] C. Bobeth, A. J. Buras, A. Celis, and M. Jung, Yukawa enhancement of Z-
mediated New Physics in S = 2 and B = 2 Processes, arXiv:1703.04753.
[179] C.-W. Chiang, X.-G. He, F. Ye, and X.-B. Yuan, Constraints and Implications
on Higgs FCNC Couplings from Precision Measurement of Bs  + Decay,
arXiv:1703.06289.
[180] LHCb Collaboration, R. Aaij et al., Impact of the LHCb upgrade detector design
choices on physics and trigger performance, Tech. Rep. LHCb-PUB-2014-040.
CERN-LHCb-PUB-2014-040. LHCb-INT-2013-024, CERN, Geneva, Aug, 2014.
[181] LHCb Collaboration, R. Aaij et al., Expression of Interest for a Phase-II LHCb
Upgrade: Opportunities in flavour physics, and beyond, in the HL-LHC era,
Tech. Rep. CERN-LHCC-2017-003, CERN, Geneva, Feb, 2017.
[182] O. Augusto, LHCb; LHCb Jet Reconstruction, Dec, 2012.
[183] W. Barter and D. Ward, Z boson and associated jet production at the LHCb
experiment, PhD thesis, Cambridge University, Mar, 2014, Presented 27 May
2014.
[184] X. Cid Vidal, Using jets to identify semi-leptonic B decays, Tech. Rep. LHCb-
INT-2015-022. CERN-LHCb-INT-2015-022, CERN, Geneva, Jun, 2015.
http://dx.doi.org/10.1214/aoms/1177732360
http://arxiv.org/abs/physics/0306116
http://dx.doi.org/10.1016/j.physletb.2012.01.017
http://arxiv.org/abs/1112.3056
http://dx.doi.org/10.1016/j.physletb.2016.09.028
http://arxiv.org/abs/1608.04855
http://dx.doi.org/10.1103/PhysRevLett.115.031601
http://arxiv.org/abs/1503.07089
http://dx.doi.org/10.1016/j.physletb.2014.10.005
http://dx.doi.org/10.1016/j.physletb.2014.10.005
http://arxiv.org/abs/1408.0275
http://arxiv.org/abs/0912.4179
http://arxiv.org/abs/1703.10160
http://arxiv.org/abs/1703.04753
http://arxiv.org/abs/1703.06289
190 Bibliography
[185] D. J. Jackson, A Topological vertex reconstruction algorithm for hadronic jets,
Nucl. Instrum. Meth. A388 (1997) 247.
[186] A. Mord and G. Mancinelli, Rare dileptonic B0(s) meson decays at LHCb,
PhD thesis, Aix-Marseille U., 2015, presented 28 Sep 2015.
[187] CDF, A. Abulencia et al., Search for Bs  + and Bd  + de-
cays in pp collisions with CDF II, Phys. Rev. Lett. 95 (2005) 221805,
arXiv:hep-ex/0508036, [Erratum: Phys. Rev. Lett.95,249905(2005)].
http://dx.doi.org/10.1016/S0168-9002(97)00341-0
http://dx.doi.org/10.1103/PhysRevLett.95.221805
http://arxiv.org/abs/hep-ex/0508036
Appendix A
Distributions of input variables for
the global BDT
Comparison of the signal and background distributions of input variables used in the
global BDT for 2011, 2012, 2015 and 2016 data taking conditions. Signal distributions
are from simulated B0s  + decays for each year that have passed the selection
cuts in Table 4.12. The background distributions are from bb  +X decays in
2011, 2012, 2015 and 2016 data with m > 5447 MeV/c2 and passing the selection
cuts in Table 4.12. The input variables used for the global BDT are:
 long track isolation criteria;
 VELO track isolation criteria;
2 + 2, where  is the difference in azimuthal angles of the muons and
 the difference in the pseudo-rapidity of the muons;
 the smallest 2IP with respect to the primary vertex of the B0s  + of the
muons;
 2VTX of the B0s ;
 2IP of the B0s with respect to the primary vertex; and
 the angle, , between the momentum vector of the B0s and the vector connecting
the production and decay vertices of the B0s .
192 Distributions of input variables for the global BDT
2  + 2 
1 2 3 4
0.00 0.01 0.02 0.03
2 Minumum 
20 40 60 80 100
0 1 2 3 4 5
VELO track isolation
0.5 0.0 0.5
Long track isolation
1 0.5 0 0.5 1
0 2 4 6
2011 simulation
2012 simulation
2015 simulation
2016 simulation
Fig. A.1 Signal distributions for input variables for the global BDT for B0s  +
simulated decays in 2011, 2012, 2015 and 2016.
2  + 2 
0 1 2 3 4
2011 data
2012 data
2015 data
2016 data
0 0.01 0.02 0.03
2011 data
2012 data
2015 data
2016 data
2 Minumum 
20 40 60 80 100
0 1 2 3 4 5
2011 data
2012 data
2015 data
2016 data
VELO track isolation
0.5 0.0 0.5
2011 data
2012 data
2015 data
2016 data
Long track isolation
1.0 0.5 0.0 0.5 1.0
2011 data
2012 data
2015 data
2016 data
0 2 4 6
2011 data
2012 data
2015 data
2016 data
Fig. A.2 Background distributions for input variables from bb  +X decays in 2011,
2012, 2015 and 2016 data with m > 5447 MeV/c2.
Appendix B
Multivariate classifier development
for the B0s  
+ effective
lifetime measurement
B.1 Input variables
The input variables used in the adaptive boosting and uBoost BDTs were chosen
separately, starting from a large set of variables. Initially the BDTs were trained
using all input variables within the set and variables that had no impact on the
BDT performance were removed until removing any of the remaining variables had
a negative impact on the BDT performance. The performance of each BDT was
evaluated from the integrated Receiver Operating Characteristic curve, which is the
signal efficiency versus (1 - background rejection).
The adaptive boosting BDT uses 11 input variables and the uBoost BDT uses
21 variables which includes all variables used by adaptive boosting BDT. The input
variables used in both algorithms are related to the B0s , the muons, isolation variables
and properties of jets reconstructed in the event. Isolation variables, discussed in
Section 4.3.4.3, give a measure of how busy an event is and the separation of the
tracks in a B0s  + candidate from other tracks in the event.
The reconstruction of jets in an event provides the most inclusive way to recon-
struct semi-leptonic decays, where both the neutral particles and hadrons produced
in the decays can be included into one jet. The BDTs are designed to remove
combinatorial background decays formed from combining muons produced by semi-
leptonic bb  +X1X2 processes, therefore information about semi-leptonic decays
from reconstructed jets can help to separate signal and background decays. The
reconstruction of jets at LHCb is detailed in reference [182, 183] and, during the
reconstruction, constraints can be placed on the jets as to whether one or both muons
in the B0s  + candidate or the B0s is within a jet. Once the jets in an event
196 Multivariate classifier development
have been created variables can be constructed based on the properties of the jets
and the comparisons between the jets and muons in the event [184]. These variables
can be used to exploit differences in the jets created for semi-leptonic decays and
B0s  + decays. For example a jet containing the B0s of a B0s  + candidate
created from two semi-leptonic decays by bb  +X will include both the b and b
created in the pp interaction, whereas a jet containing a real B0s  + decay is
less likely to include both the original b and b quarks. The information included in
jet variables is complementary to that contained in the isolation variables.
The adaptive boosting and uBoost BDTs use input variables that are also used
in the cut based selection. These variables are:
 IP and 2IP of the B0s ;
 2VTX of the B0s ;
 the flight distance of the B0s ;
 the pT of the B0s and the minimum pT of the two muons; and
 the minimum 2IP of the two muons.
The definitions of these variables are given in Section 4.3.2.1. The additional input
variables used in both BDTs are:
 the polarisation angle which is the cosine of the angle between a vector
perpendicular to a plane containing the B0s momentum and the beam axis and
the muon momentum in the B0s rest frame;
 ()2, where  is the difference in azimuthal angles of the muons;
 a BDT isolation variable designed in the same way to those described in
Section 4.3.4.3, using information from long tracks. This isolation version was
produced during the development of the final isolations used in the global BDT,
the details of this variable can be found in reference [158]1; and
 ZVtop isolation variable which uses a topological vertex algorithm [185] and is
defined in reference [186].
The remaining input variables used in the uBoost BDT are:
 the direction cosine, DIRA, as defined in Section 4.3.2.1;
 ()2, where  is the difference in the pseudorapidity of the muons;
1Replacing this isolation variable with the Long track and VELO track isolations does not
significantly improve the overall performance of either BDT.
B.1 Input variables 197
 an isolation variable of the B0s candidate based on the definition used by the
CDF collaboration in the search for B0(s)  
+ decays [187]. The isolation
is computed from the transverse momentum of the B0s , pT (B), and transverse
momenta of tracks, pT (tracks), in an event that fall within a cone around
the B0s . The cone is defined as
2 + 2 > 1.0 where  and  are the
differences in pseudorapidity and azimuthal angle of a track in the event and
the B0s candidate. The isolation variable is defined as
ICDF =
pT (Bs0)
pT (Bs0) +
trackcone
pT (track)
; (B.1)
 a cut based muon isolation, I, this isolation variable was the precursor of
the BDT based isolation variables and is based on placing cuts on variables
relating long tracks in the event to the muons in B0s  + candidates. The
definition of this variable can be found in reference [186];
 the angle between the B0s momentum and the sum of the momenta of all tracks
in the event, excluding tracks from long lived particles and tracks associated
with a different primary vertex than the primary vertex of the B0s . Since b and
b quarks are produced in pairs in pp collisions, the angle is effectively the angle
between the B0s and the other b quark from the pair produced. Therefore this
variable is called the other B angle, if there are too few candidates in the
event to compute this variable the value is set to 1;
 the angle between the + candidate in the B0s rest frame and the sum of the
momenta in the B0s rest frame of all tracks in the event, excluding tracks
from long lived particles and tracks associated with a different primary vertex
than the primary vertex of the B0s . If there are too few tracks in the event to
compute this variable the angle is set to /2;
 the jet width of jets that are forced to contain both muons in the B0s  +
candidate and are constructed around the B0s . The width is defined as the
average value of
2 + 2 where the difference is computed between each
component in the jet and the jet total, in the total width each component in
the jet is a weighted by its pT ;
 the difference,
2 + 2, between a jet forced to contain one lepton from
the B0s  + candidate and the other lepton in the B0s  + candidate
not contained in the jet
 the transverse momentum of jets that are forced to contain both muons in the
B0s  + candidate and are constructed around the B0s ; and
198 Multivariate classifier development
 the ratio of the transverse momenta of the muons and the jet that contains the
muons and is constructed around the B0s .
The distributions of the input variables for B0s  + and bb  +X 2012
simulated decays are shown in Figure B.3.
B.2 Training parameters
The training parameters discussed in Section 4.3.4.1 put constraints on how a BDT
separates signal and background decays. The training parameters used in the adaptive
boost BDT were optimised by iterating over different training parameter values and
choosing the BDT that gave the best signal significance for identifying B  h+h
decays in Run 1 data. The computation of the signal significance is described in
Section 4.4.4.1. The final set of training parameters are given in Table B.1. The
training parameters used in the uBoost BDT have not been optimised and are given
in Table B.1. The parameter values suggested in reference [159] have been used
where it was shown that different training parameters had a small impact of the
overall BDT performance.
Adaptive Boost BDT uBoost BDT
Parameter Value Parameter Value
nTrees 1000 nTrees 100
MinNodeSize 5% nEventsMin 100
MaxDepth 3 MaxDepth 4
 0.1  1.0
nCuts 30 nCuts 200
Table B.1 Training parameters used to specify the training of the adaptive boost and
uBoost BDT.
B.3 Overtraining test
As discussed in Section 4.3.4.1, it is important that BDTs are not overtrained. To
test this assumption the signal and background samples are both split in two, to
create a training set and a testing set. A BDT is trained using the training set, and
the BDT is then applied to both the training and testing sets. The distribution of
BDT output values for signal and background decays in the training and testing
sets are compared. If the BDT is overtrained the response of the BDT will be quite
B.3 Overtraining test 199
 IP [mm]s
0.1 0.2 0.3
0 5 10 15 20 25
0 2 4 6 8
 flight distance [mm]s
20 40 60 80
 [MeV/c]
10000 20000 30000
]2MeV/c [
p Minimum 
5000 10000
2 Minumum 
50 100
Polerization angle
-1.0 -0.5 0.0 0.5 1.0
0.015
0.020
0.025
0.030
0.035
0.040
Signal
Background
Fig. B.1 The distributions of the input variables used in the adaptive boost and uBoost
BDTs for B0s  + and bb  +X 2012 simulated decays.
200 Multivariate classifier development
| [rad] |
2 4 6
Isolation BDT
-1.0 -0.5 0.0 0.5 1.0
ZVtop isolation
-1.0 -0.5 0.0 0.5 1.0
-0.4 -0.2 0.0 0.2 0.4
| |
0 1 2 3
CDF isolation
0.5 1.0
Muon isolation
0 5 10
Other B angle
-1.0 -0.5 0.0 0.5
Signal
Background
Fig. B.2 The distributions of the input variables used in the adaptive boost and uBoost
BDTs for B0s  + and bb  +X 2012 simulated decays.
B.3 Overtraining test 201
 angle+
1 0 1 2 3
Jet width
0.0 0.5 1.0 1.5 2.0 2.5
Jet and muon distance
2 4 6
 [MeV/c]
0 20000 40000 60000
 ratio
0.0 0.2 0.4 0.6 0.8 1.0
0.05 BackgroundSignal
Fig. B.3 The distributions of the input variables used in only the uBoost BDT for
B0s  + and bb  +X 2012 simulated decays.
202 Multivariate classifier development
different for the training and testing sets for signal and background decays. However,
if the BDT is not overtrained the distributions will be similar for the training and
testing sets.
Figure B.4 shows the results of this test where the responses for the training
and testing samples lie on top of each other. Therefore, neither the uBoost BDT
or the adaptive boosting BDT developed for the effective lifetime measurement are
overtrained. The same test was performed for the global BDT developed of the
branching fraction measurements and the global BDT is not overtrained.
Adaptive boosting BDT
1 0.5 0 0.5 1
0.18 signal training
background training
signal testing
background testing
Uboost BDT
0 0.2 0.4 0.6 0.8 1
signal training
background training
signal testing
background testing
Fig. B.4 BDT response for training and testing samples of signal and background decays
for a) the adaptive boost BDT and b) the uBoost BDT.
	Abstract
	Declaration
	Acknowledgements
	Preface
	Table of contents
	1 Introduction
	2 Theory of B+ -decays; the Standard Model and beyond
	2.1 B0(s)+ - decays in the Standard Model
	2.2 B0(s) + - Branching Fraction
	2.3 Quark mixing
	2.3.1 Time evolution of the B(s)0
	2.3.2 Impact on the Branching Fraction
	2.4 A and the Bs0 + - effective lifetime
	2.5 The Standard Model predictions
	2.6 New Physics models and B0(s) + - decays
	3 The LHC and the LHCb experiment
	3.1 The Large Hadron Collider
	3.2 The LHCb experiment
	3.2.1 Tracking
	3.2.2 Particle identification
	3.2.3 Trigger
	3.2.4 Software and simulation
	3.3 Summary
	4 Event selection
	4.1 Background sources
	4.2 Simulated particle decays
	4.3 Event selection for the B0(s) + - branching fraction measurements
	4.3.1 Trigger requirements
	4.3.2 Cut-based selection
	4.3.3 Particle identification
	4.3.4 Multivariate Classifiers
	4.3.5 Summary
	4.4 Selection for the Bs0 + - effective lifetime measurement
	4.4.1 Trigger requirements
	4.4.2 Mass range
	4.4.3 Particle identification
	4.4.4 Multivariate classifier
	4.4.5 Summary
	5 Measurement of B0(s) + - branching fractions
	5.1 Analysis strategy
	5.2 B0(s) + - mass and BDT PDFs
	5.2.1 Mass PDFs
	5.2.2 BDT PDFs
	5.3 Background mass PDFs and expected yields
	5.3.1 Mis-identified B h+ h'- decays
	5.3.2 Exclusive backgrounds
	5.3.3 Combinatorial background
	5.4 Normalisation
	5.4.1 B0 K+ - and B+ J/K+ yields
	5.4.2 Efficiency ratio
	5.4.3 Hadronisation factors
	5.4.4 Normalisation parameters
	5.5 Results
	6 Measurement of the Bs0 + -effective lifetime
	6.1 Analysis strategy
	6.2 Mass PDFs
	6.3 Decay time distributions
	6.3.1 Bs0 + - decay time PDF
	6.3.2 Background decay time PDFs
	6.4 Measurement strategy
	6.4.1 To fit for  or -1?
	6.4.2 Optimisation of fit configuration
	6.5 Results
	7 Systematic uncertainties and cross checks on the effective lifetime
	7.1 Accuracy of the fit
	7.1.1 Fit stability with  values
	7.1.2 Bs0 + - yield estimation
	7.1.3 Overall bias on 
	7.2 Background contamination
	7.3 Mass PDF parameters
	7.4 Acceptance function accuracy
	7.5 Incorrectly assigned primary vertices and the detector resolution
	7.6 Combinatorial background decay time model
	7.7 Mix of Bs0 mass eigenstates
	7.8 Production asymmetry of Bs0 and Bs0 mesons
	7.9 Summary
	8 Summary and Outlook
	8.1 Summary
	8.2 Outlook
	Bibliography
	Appendix A Distributions of input variables for the global BDT
	Appendix B Multivariate classifier development
	B.1 Input variables
	B.2 Training parameters
	B.3 Overtraining test
