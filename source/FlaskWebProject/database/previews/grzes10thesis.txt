Improving Exploration in Reinforcement Learning through Domain Knowledge and Parameter Analysis
This thesis presents novel work on how to improve exploration in reinforcement learning using
domain knowledge and knowledge-based approaches to reinforcement learning. It also identi-
fies novel relationships between the algorithms and domains parameters and the exploration
efficiency.
The goal of solving reinforcement learning problems is to learn how to execute actions in
order to maximise the long term reward. Solving this type of problems is a hard task when real
domains of realistic size are considered because the state space grows exponentially with each
state feature added to the representation of the problem.
In its basic form, reinforcement learning is tabula rasa, i.e. it starts learning with very lim-
ited knowledge about the domain. One of the ways of improving the performance of reinforce-
ment learning is the principled use of domain knowledge. Knowledge is successful in related
branches of artificial intelligence, and it is becoming increasingly important in the area of re-
inforcement learning as well. Reinforcement learning algorithms normally face the problem of
deciding whether to execute explorative of exploitative actions, and the paramount goal is to limit
the number of executions of suboptimal explorative actions. In this thesis, it is shown how do-
main knowledge and understanding of algorithms and domains properties can help to achieve
this.
Exploration is an immensely complicated process in reinforcement learning and is influenced
by numerous factors. This thesis presents a new range of methods for dealing more efficiently
with the exploration-exploitation dilemma which is a crucial issue of applying reinforcement
learning in practice. Reward shaping was used in this research as a well established framework
for incorporating procedural knowledge into model-free reinforcement learning. Two new ways
of obtaining heuristics for potential-based shaping were introduced and evaluated: high level
symbolic knowledge and the application of different hypothesis spaces to learn the heuristic.
